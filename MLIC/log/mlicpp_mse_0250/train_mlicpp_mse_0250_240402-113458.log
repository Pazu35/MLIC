24-04-02 11:36:17.861 - INFO: Namespace(experiment='mlicpp_mse_0250', dataset='/mnt/bn/jiangwei-lvc3/dataset/image', epochs=500, learning_rate=0.0001, num_workers=8, lmbda=0.025, metrics='mse', batch_size=4, test_batch_size=1, aux_learning_rate=0.001, patch_size=[384, 384], gpu_id=0, cuda=True, save=True, seed=1984.0, clip_max_norm=1.0, checkpoint='/mnt/bn/jiangwei-lvc3/work_space/MLICPlusPlus/playground/experiments/mlicpp_mse_0250/checkpoints', world_size=4, dist_url='env://', rank=1, gpu=1, distributed=True, dist_backend='nccl')
24-04-02 11:36:17.862 - INFO: {'N': 192, 'M': 320, 'enc_dims': [3, 192, 192, 192, 320], 'dec_dims': [320, 192, 192, 192, 16, 3], 'slice_num': 10, 'context_window': 5, 'slice_ch': [8, 8, 8, 8, 16, 16, 32, 32, 96, 96], 'max_support_slices': 5, 'quant': 'ste', 'lambda_list': [0.07, 0.08, 0.09], 'use_hyper_gain': False, 'interpolated_type': 'exponential', 'act': <class 'torch.nn.modules.activation.GELU'>, 'L': 10, 'target_bpp': [0.0761, 0.1854, 0.2752, 0.3652, 0.4282, 0.5238, 0.5653, 0.6334, 0.745], 'bpp_threshold': [0.02, 0.02, 0.02, 0.02, 0.03, 0.02, 0.02, 0.02, 0.02], 'min_lmbda': 0.001, 'init_lmbda': [0.001, 0.0018, 0.0035, 0.0035, 0.0067, 0.0067, 0.013, 0.013, 0.025, 0.0483], 'lower_bound': 1e-09, 'ki': 0.1, 'kp': 0.1}
24-04-02 11:36:17.863 - INFO: DistributedDataParallel(
  (module): MLICPlusPlus(
    (entropy_bottleneck): EntropyBottleneck(
      (likelihood_lower_bound): LowerBound()
    )
    (g_a): AnalysisTransform(
      (analysis_transform): Sequential(
        (0): ResidualBlockWithStride(
          (conv1): Conv2d(3, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (gdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (skip): Conv2d(3, 192, kernel_size=(1, 1), stride=(2, 2))
        )
        (1): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (2): ResidualBlockWithStride(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (gdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (skip): Conv2d(192, 192, kernel_size=(1, 1), stride=(2, 2))
        )
        (3): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (4): ResidualBlockWithStride(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (gdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (skip): Conv2d(192, 192, kernel_size=(1, 1), stride=(2, 2))
        )
        (5): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (6): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      )
    )
    (g_s): SynthesisTransform(
      (synthesis_transform): Sequential(
        (0): ResidualBlock(
          (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (1): ResidualBlockUpsample(
          (subpel_conv): Sequential(
            (0): Conv2d(320, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
          (act): GELU(approximate='none')
          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (igdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (upsample): Sequential(
            (0): Conv2d(320, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
        )
        (2): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (3): ResidualBlockUpsample(
          (subpel_conv): Sequential(
            (0): Conv2d(192, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
          (act): GELU(approximate='none')
          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (igdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (upsample): Sequential(
            (0): Conv2d(192, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
        )
        (4): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (5): ResidualBlockUpsample(
          (subpel_conv): Sequential(
            (0): Conv2d(192, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
          (act): GELU(approximate='none')
          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (igdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (upsample): Sequential(
            (0): Conv2d(192, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
        )
        (6): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (7): Sequential(
          (0): Conv2d(192, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): PixelShuffle(upscale_factor=2)
        )
      )
    )
    (h_a): HyperAnalysis(
      (reduction): Sequential(
        (0): Conv2d(320, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): GELU(approximate='none')
        (2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): GELU(approximate='none')
        (4): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (5): GELU(approximate='none')
        (6): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): GELU(approximate='none')
        (8): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      )
    )
    (h_s): HyperSynthesis(
      (increase): Sequential(
        (0): Conv2d(192, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): GELU(approximate='none')
        (2): Sequential(
          (0): Conv2d(320, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): PixelShuffle(upscale_factor=2)
        )
        (3): GELU(approximate='none')
        (4): Conv2d(320, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): GELU(approximate='none')
        (6): Sequential(
          (0): Conv2d(480, 1920, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): PixelShuffle(upscale_factor=2)
        )
        (7): GELU(approximate='none')
        (8): Conv2d(480, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (gaussian_conditional): GaussianConditional(
      (likelihood_lower_bound): LowerBound()
      (lower_bound_scale): LowerBound()
    )
    (local_context): ModuleList(
      (0-9): 10 x LocalContext(
        (qkv_proj): Linear(in_features=32, out_features=96, bias=True)
        (unfold): Unfold(kernel_size=5, dilation=1, padding=2, stride=1)
        (softmax): Softmax(dim=-1)
        (proj): Linear(in_features=64, out_features=64, bias=True)
        (mlp): MLP(
          (fc1): Linear(in_features=64, out_features=128, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=128, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (fusion): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
      )
    )
    (channel_context): ModuleList(
      (0): None
      (1): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(32, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (2): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (3): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (4): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (5): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(160, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (6): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (7): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(224, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (8): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (9): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(288, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (global_inter_context): ModuleList(
      (0): None
      (1): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (queries): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (values): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (reprojection): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
        )
        (queries): Sequential(
          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
        )
        (values): Sequential(
          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
        )
        (reprojection): Conv2d(64, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (3): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
        )
        (queries): Sequential(
          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
        )
        (values): Sequential(
          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
        )
        (reprojection): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (4): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
        )
        (queries): Sequential(
          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
        )
        (values): Sequential(
          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
        )
        (reprojection): Conv2d(128, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (5): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)
        )
        (queries): Sequential(
          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)
        )
        (values): Sequential(
          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)
        )
        (reprojection): Conv2d(160, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (6): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
        )
        (queries): Sequential(
          (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
        )
        (values): Sequential(
          (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
        )
        (reprojection): Conv2d(192, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (7): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(224, 224, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=224)
        )
        (queries): Sequential(
          (0): Conv2d(224, 224, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=224)
        )
        (values): Sequential(
          (0): Conv2d(224, 224, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=224)
        )
        (reprojection): Conv2d(224, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (8): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
        )
        (queries): Sequential(
          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
        )
        (values): Sequential(
          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
        )
        (reprojection): Conv2d(256, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (9): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)
        )
        (queries): Sequential(
          (0): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)
        )
        (values): Sequential(
          (0): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)
        )
        (reprojection): Conv2d(288, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (global_intra_context): ModuleList(
      (0): None
      (1-9): 9 x LinearGlobalIntraContext(
        (keys): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (queries): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (values): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (reprojection): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
    (entropy_parameters_anchor): ModuleList(
      (0): EntropyParameters(
        (fusion): Sequential(
          (0): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
          (5): GELU(approximate='none')
          (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (1-9): 9 x EntropyParameters(
        (fusion): Sequential(
          (0): Conv2d(832, 320, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
          (5): GELU(approximate='none')
          (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
    (entropy_parameters_nonanchor): ModuleList(
      (0): EntropyParameters(
        (fusion): Sequential(
          (0): Conv2d(704, 320, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
          (5): GELU(approximate='none')
          (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (1-9): 9 x EntropyParameters(
        (fusion): Sequential(
          (0): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
          (5): GELU(approximate='none')
          (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
    (lrp_anchor): ModuleList(
      (0): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(352, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (1): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(384, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (2): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(416, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (3): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(448, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (4): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(480, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (5): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(512, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (6): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(544, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (7): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(576, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (8): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(608, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (9): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(640, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (lrp_nonanchor): ModuleList(
      (0): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(352, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (1): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(384, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (2): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(416, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (3): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(448, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (4): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(480, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (5): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(512, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (6): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(544, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (7): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(576, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (8): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(608, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (9): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(640, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
  )
)
24-04-02 11:36:17.897 - INFO: Learning rate: 0.0001
24-04-02 12:10:55.428 - INFO: Learning rate: 0.0001
24-04-02 12:45:24.374 - INFO: Learning rate: 0.0001
24-04-02 13:20:04.578 - INFO: Learning rate: 0.0001
24-04-02 13:55:16.174 - INFO: Learning rate: 0.0001
24-04-02 14:29:41.653 - INFO: Learning rate: 0.0001
24-04-02 15:04:11.952 - INFO: Learning rate: 0.0001
24-04-02 15:38:34.156 - INFO: Learning rate: 0.0001
24-04-02 16:13:07.086 - INFO: Learning rate: 0.0001
24-04-02 16:47:36.192 - INFO: Learning rate: 0.0001
24-04-02 17:22:07.693 - INFO: Learning rate: 0.0001
24-04-02 17:56:31.705 - INFO: Learning rate: 0.0001
24-04-02 18:30:53.963 - INFO: Learning rate: 0.0001
24-04-02 19:05:12.752 - INFO: Learning rate: 0.0001
24-04-02 19:39:36.379 - INFO: Learning rate: 0.0001
24-04-02 20:14:00.653 - INFO: Learning rate: 0.0001
24-04-02 20:48:25.466 - INFO: Learning rate: 0.0001
24-04-02 21:22:57.321 - INFO: Learning rate: 0.0001
24-04-02 21:57:06.361 - INFO: Learning rate: 0.0001
24-04-02 22:31:25.562 - INFO: Learning rate: 0.0001
24-04-02 23:06:16.220 - INFO: Learning rate: 0.0001
24-04-02 23:40:29.466 - INFO: Learning rate: 0.0001
24-04-03 00:14:45.812 - INFO: Learning rate: 0.0001
 | Aux loss: 85.55
24-04-02 11:40:40.790 - INFO: Train epoch 365: [11200/94637 (12%)] Step: [2159676] | Lr: 0.000100 | Loss: 0.9260 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 77.22
24-04-02 11:41:16.322 - INFO: Train epoch 365: [12800/94637 (14%)] Step: [2159776] | Lr: 0.000100 | Loss: 0.7061 | MSE loss: 0.0001 | Bpp loss: 0.48 | Aux loss: 93.28
24-04-02 11:41:51.987 - INFO: Train epoch 365: [14400/94637 (15%)] Step: [2159876] | Lr: 0.000100 | Loss: 1.3741 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 79.33
24-04-02 11:42:28.228 - INFO: Train epoch 365: [16000/94637 (17%)] Step: [2159976] | Lr: 0.000100 | Loss: 2.1332 | MSE loss: 0.0006 | Bpp loss: 1.22 | Aux loss: 80.03
24-04-02 11:43:05.494 - INFO: Train epoch 365: [17600/94637 (19%)] Step: [2160076] | Lr: 0.000100 | Loss: 1.4888 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 83.20
24-04-02 11:43:40.811 - INFO: Train epoch 365: [19200/94637 (20%)] Step: [2160176] | Lr: 0.000100 | Loss: 1.3799 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 90.10
24-04-02 11:44:15.378 - INFO: Train epoch 365: [20800/94637 (22%)] Step: [2160276] | Lr: 0.000100 | Loss: 1.0854 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 80.32
24-04-02 11:44:49.872 - INFO: Train epoch 365: [22400/94637 (24%)] Step: [2160376] | Lr: 0.000100 | Loss: 1.4081 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 85.47
24-04-02 11:45:24.070 - INFO: Train epoch 365: [24000/94637 (25%)] Step: [2160476] | Lr: 0.000100 | Loss: 1.6634 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 78.01
24-04-02 11:45:59.359 - INFO: Train epoch 365: [25600/94637 (27%)] Step: [2160576] | Lr: 0.000100 | Loss: 1.2921 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 78.73
24-04-02 11:46:34.535 - INFO: Train epoch 365: [27200/94637 (29%)] Step: [2160676] | Lr: 0.000100 | Loss: 1.0597 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 72.69
24-04-02 11:47:09.750 - INFO: Train epoch 365: [28800/94637 (30%)] Step: [2160776] | Lr: 0.000100 | Loss: 1.7581 | MSE loss: 0.0004 | Bpp loss: 1.14 | Aux loss: 77.31
24-04-02 11:47:45.718 - INFO: Train epoch 365: [30400/94637 (32%)] Step: [2160876] | Lr: 0.000100 | Loss: 0.7529 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 75.87
24-04-02 11:48:20.928 - INFO: Train epoch 365: [32000/94637 (34%)] Step: [2160976] | Lr: 0.000100 | Loss: 0.5240 | MSE loss: 0.0001 | Bpp loss: 0.34 | Aux loss: 75.63
24-04-02 11:48:55.756 - INFO: Train epoch 365: [33600/94637 (36%)] Step: [2161076] | Lr: 0.000100 | Loss: 1.1855 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 68.05
24-04-02 11:49:30.571 - INFO: Train epoch 365: [35200/94637 (37%)] Step: [2161176] | Lr: 0.000100 | Loss: 1.2676 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 75.15
24-04-02 11:50:05.524 - INFO: Train epoch 365: [36800/94637 (39%)] Step: [2161276] | Lr: 0.000100 | Loss: 1.1517 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 72.14
24-04-02 11:50:40.062 - INFO: Train epoch 365: [38400/94637 (41%)] Step: [2161376] | Lr: 0.000100 | Loss: 1.1054 | MSE loss: 0.0003 | Bpp loss: 0.60 | Aux loss: 71.99
24-04-02 11:51:14.278 - INFO: Train epoch 365: [40000/94637 (42%)] Step: [2161476] | Lr: 0.000100 | Loss: 1.2721 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 73.91
24-04-02 11:51:48.004 - INFO: Train epoch 365: [41600/94637 (44%)] Step: [2161576] | Lr: 0.000100 | Loss: 0.9912 | MSE loss: 0.0003 | Bpp loss: 0.58 | Aux loss: 71.30
24-04-02 11:52:21.478 - INFO: Train epoch 365: [43200/94637 (46%)] Step: [2161676] | Lr: 0.000100 | Loss: 1.1676 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 67.95
24-04-02 11:52:54.435 - INFO: Train epoch 365: [44800/94637 (47%)] Step: [2161776] | Lr: 0.000100 | Loss: 1.5510 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 77.95
24-04-02 11:53:27.007 - INFO: Train epoch 365: [46400/94637 (49%)] Step: [2161876] | Lr: 0.000100 | Loss: 1.3881 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 76.16
24-04-02 11:54:01.720 - INFO: Train epoch 365: [48000/94637 (51%)] Step: [2161976] | Lr: 0.000100 | Loss: 1.8349 | MSE loss: 0.0004 | Bpp loss: 1.12 | Aux loss: 72.20
24-04-02 11:54:35.040 - INFO: Train epoch 365: [49600/94637 (52%)] Step: [2162076] | Lr: 0.000100 | Loss: 1.3737 | MSE loss: 0.0004 | Bpp loss: 0.77 | Aux loss: 78.90
24-04-02 11:55:09.084 - INFO: Train epoch 365: [51200/94637 (54%)] Step: [2162176] | Lr: 0.000100 | Loss: 1.5502 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 72.13
24-04-02 11:55:44.044 - INFO: Train epoch 365: [52800/94637 (56%)] Step: [2162276] | Lr: 0.000100 | Loss: 1.6388 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 82.24
24-04-02 11:56:19.311 - INFO: Train epoch 365: [54400/94637 (57%)] Step: [2162376] | Lr: 0.000100 | Loss: 0.8222 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 70.63
24-04-02 11:56:54.479 - INFO: Train epoch 365: [56000/94637 (59%)] Step: [2162476] | Lr: 0.000100 | Loss: 0.9135 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 71.37
24-04-02 11:57:31.366 - INFO: Train epoch 365: [57600/94637 (61%)] Step: [2162576] | Lr: 0.000100 | Loss: 1.6409 | MSE loss: 0.0004 | Bpp loss: 1.05 | Aux loss: 68.68
24-04-02 11:58:06.089 - INFO: Train epoch 365: [59200/94637 (63%)] Step: [2162676] | Lr: 0.000100 | Loss: 1.1610 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 73.60
24-04-02 11:58:40.172 - INFO: Train epoch 365: [60800/94637 (64%)] Step: [2162776] | Lr: 0.000100 | Loss: 1.0110 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 70.29
24-04-02 11:59:15.188 - INFO: Train epoch 365: [62400/94637 (66%)] Step: [2162876] | Lr: 0.000100 | Loss: 1.5188 | MSE loss: 0.0004 | Bpp loss: 0.93 | Aux loss: 70.89
24-04-02 11:59:50.013 - INFO: Train epoch 365: [64000/94637 (68%)] Step: [2162976] | Lr: 0.000100 | Loss: 1.8122 | MSE loss: 0.0005 | Bpp loss: 1.02 | Aux loss: 70.34
24-04-02 12:00:24.039 - INFO: Train epoch 365: [65600/94637 (69%)] Step: [2163076] | Lr: 0.000100 | Loss: 0.9811 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 72.45
24-04-02 12:00:58.388 - INFO: Train epoch 365: [67200/94637 (71%)] Step: [2163176] | Lr: 0.000100 | Loss: 1.2196 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 72.61
24-04-02 12:01:32.213 - INFO: Train epoch 365: [68800/94637 (73%)] Step: [2163276] | Lr: 0.000100 | Loss: 1.1155 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 68.40
24-04-02 12:02:06.545 - INFO: Train epoch 365: [70400/94637 (74%)] Step: [2163376] | Lr: 0.000100 | Loss: 1.8068 | MSE loss: 0.0004 | Bpp loss: 1.09 | Aux loss: 71.22
24-04-02 12:02:41.812 - INFO: Train epoch 365: [72000/94637 (76%)] Step: [2163476] | Lr: 0.000100 | Loss: 0.7868 | MSE loss: 0.0002 | Bpp loss: 0.48 | Aux loss: 69.84
24-04-02 12:03:16.600 - INFO: Train epoch 365: [73600/94637 (78%)] Step: [2163576] | Lr: 0.000100 | Loss: 1.6192 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 70.00
24-04-02 12:03:52.321 - INFO: Train epoch 365: [75200/94637 (79%)] Step: [2163676] | Lr: 0.000100 | Loss: 1.2987 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 67.21
24-04-02 12:04:27.106 - INFO: Train epoch 365: [76800/94637 (81%)] Step: [2163776] | Lr: 0.000100 | Loss: 1.9276 | MSE loss: 0.0008 | Bpp loss: 0.68 | Aux loss: 74.23
24-04-02 12:05:02.372 - INFO: Train epoch 365: [78400/94637 (83%)] Step: [2163876] | Lr: 0.000100 | Loss: 1.2574 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 76.28
24-04-02 12:05:37.945 - INFO: Train epoch 365: [80000/94637 (85%)] Step: [2163976] | Lr: 0.000100 | Loss: 1.2541 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 73.85
24-04-02 12:06:13.537 - INFO: Train epoch 365: [81600/94637 (86%)] Step: [2164076] | Lr: 0.000100 | Loss: 1.0875 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 78.98
24-04-02 12:06:48.699 - INFO: Train epoch 365: [83200/94637 (88%)] Step: [2164176] | Lr: 0.000100 | Loss: 1.1438 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 76.31
24-04-02 12:07:23.712 - INFO: Train epoch 365: [84800/94637 (90%)] Step: [2164276] | Lr: 0.000100 | Loss: 1.2686 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 78.03
24-04-02 12:07:58.501 - INFO: Train epoch 365: [86400/94637 (91%)] Step: [2164376] | Lr: 0.000100 | Loss: 1.1816 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 71.29
24-04-02 12:08:33.587 - INFO: Train epoch 365: [88000/94637 (93%)] Step: [2164476] | Lr: 0.000100 | Loss: 1.5858 | MSE loss: 0.0005 | Bpp loss: 0.85 | Aux loss: 76.82
24-04-02 12:09:08.806 - INFO: Train epoch 365: [89600/94637 (95%)] Step: [2164576] | Lr: 0.000100 | Loss: 1.0834 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 79.01
24-04-02 12:09:42.463 - INFO: Train epoch 365: [91200/94637 (96%)] Step: [2164676] | Lr: 0.000100 | Loss: 1.4161 | MSE loss: 0.0004 | Bpp loss: 0.81 | Aux loss: 73.61
24-04-02 12:10:17.228 - INFO: Train epoch 365: [92800/94637 (98%)] Step: [2164776] | Lr: 0.000100 | Loss: 0.9479 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 81.83
24-04-02 12:10:50.349 - INFO: Train epoch 365: [94400/94637 (100%)] Step: [2164876] | Lr: 0.000100 | Loss: 1.9684 | MSE loss: 0.0005 | Bpp loss: 1.18 | Aux loss: 74.06
24-04-02 12:11:14.406 - INFO: Learning rate: 0.0001
24-04-02 12:11:15.303 - INFO: Train epoch 366: [    0/94637 (0%)] Step: [2164891] | Lr: 0.000100 | Loss: 1.3142 | MSE loss: 0.0004 | Bpp loss: 0.70 | Aux loss: 77.24
24-04-02 12:11:48.919 - INFO: Train epoch 366: [ 1600/94637 (2%)] Step: [2164991] | Lr: 0.000100 | Loss: 1.2389 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 75.64
24-04-02 12:12:26.105 - INFO: Train epoch 366: [ 3200/94637 (3%)] Step: [2165091] | Lr: 0.000100 | Loss: 1.0165 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 79.94
24-04-02 12:13:00.652 - INFO: Train epoch 366: [ 4800/94637 (5%)] Step: [2165191] | Lr: 0.000100 | Loss: 0.8974 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 73.12
24-04-02 12:13:34.232 - INFO: Train epoch 366: [ 6400/94637 (7%)] Step: [2165291] | Lr: 0.000100 | Loss: 1.4294 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 76.64
24-04-02 12:14:07.485 - INFO: Train epoch 366: [ 8000/94637 (8%)] Step: [2165391] | Lr: 0.000100 | Loss: 0.8702 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 83.05
24-04-02 12:14:41.396 - INFO: Train epoch 366: [ 9600/94637 (10%)] Step: [2165491] | Lr: 0.000100 | Loss: 1.4040 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 79.70
24-04-02 12:15:15.291 - INFO: Train epoch 366: [11200/94637 (12%)] Step: [2165591] | Lr: 0.000100 | Loss: 1.2218 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 73.52
24-04-02 12:15:48.687 - INFO: Train epoch 366: [12800/94637 (14%)] Step: [2165691] | Lr: 0.000100 | Loss: 1.2180 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 79.16
24-04-02 12:16:22.298 - INFO: Train epoch 366: [14400/94637 (15%)] Step: [2165791] | Lr: 0.000100 | Loss: 1.2531 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 76.21
24-04-02 12:16:56.896 - INFO: Train epoch 366: [16000/94637 (17%)] Step: [2165891] | Lr: 0.000100 | Loss: 1.4755 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 79.80
24-04-02 12:17:31.251 - INFO: Train epoch 366: [17600/94637 (19%)] Step: [2165991] | Lr: 0.000100 | Loss: 2.4552 | MSE loss: 0.0007 | Bpp loss: 1.39 | Aux loss: 71.97
24-04-02 12:18:04.244 - INFO: Train epoch 366: [19200/94637 (20%)] Step: [2166091] | Lr: 0.000100 | Loss: 1.1389 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 78.10
24-04-02 12:18:38.185 - INFO: Train epoch 366: [20800/94637 (22%)] Step: [2166191] | Lr: 0.000100 | Loss: 1.3418 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 74.49
24-04-02 12:19:11.976 - INFO: Train epoch 366: [22400/94637 (24%)] Step: [2166291] | Lr: 0.000100 | Loss: 0.9138 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 75.84
24-04-02 12:19:46.761 - INFO: Train epoch 366: [24000/94637 (25%)] Step: [2166391] | Lr: 0.000100 | Loss: 1.4388 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 79.13
24-04-02 12:20:21.937 - INFO: Train epoch 366: [25600/94637 (27%)] Step: [2166491] | Lr: 0.000100 | Loss: 1.0476 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 76.47
24-04-02 12:20:56.878 - INFO: Train epoch 366: [27200/94637 (29%)] Step: [2166591] | Lr: 0.000100 | Loss: 0.8958 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 79.45
24-04-02 12:21:31.399 - INFO: Train epoch 366: [28800/94637 (30%)] Step: [2166691] | Lr: 0.000100 | Loss: 0.9440 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 76.65
24-04-02 12:22:05.576 - INFO: Train epoch 366: [30400/94637 (32%)] Step: [2166791] | Lr: 0.000100 | Loss: 1.2622 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 81.68
24-04-02 12:22:40.249 - INFO: Train epoch 366: [32000/94637 (34%)] Step: [2166891] | Lr: 0.000100 | Loss: 1.0792 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 82.25
24-04-02 12:23:14.182 - INFO: Train epoch 366: [33600/94637 (36%)] Step: [2166991] | Lr: 0.000100 | Loss: 1.5223 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 76.32
24-04-02 12:23:47.753 - INFO: Train epoch 366: [35200/94637 (37%)] Step: [2167091] | Lr: 0.000100 | Loss: 1.0949 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 81.01
24-04-02 12:24:22.800 - INFO: Train epoch 366: [36800/94637 (39%)] Step: [2167191] | Lr: 0.000100 | Loss: 1.1735 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 75.63
24-04-02 12:24:57.286 - INFO: Train epoch 366: [38400/94637 (41%)] Step: [2167291] | Lr: 0.000100 | Loss: 1.0726 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 77.16
24-04-02 12:25:31.809 - INFO: Train epoch 366: [40000/94637 (42%)] Step: [2167391] | Lr: 0.000100 | Loss: 1.6502 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 76.36
24-04-02 12:26:06.047 - INFO: Train epoch 366: [41600/94637 (44%)] Step: [2167491] | Lr: 0.000100 | Loss: 0.9203 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 74.58
24-04-02 12:26:43.261 - INFO: Train epoch 366: [43200/94637 (46%)] Step: [2167591] | Lr: 0.000100 | Loss: 1.5904 | MSE loss: 0.0004 | Bpp loss: 0.99 | Aux loss: 76.43
24-04-02 12:27:17.865 - INFO: Train epoch 366: [44800/94637 (47%)] Step: [2167691] | Lr: 0.000100 | Loss: 0.9521 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 81.06
24-04-02 12:27:52.156 - INFO: Train epoch 366: [46400/94637 (49%)] Step: [2167791] | Lr: 0.000100 | Loss: 1.1920 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 75.58
24-04-02 12:28:25.539 - INFO: Train epoch 366: [48000/94637 (51%)] Step: [2167891] | Lr: 0.000100 | Loss: 1.1005 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 80.07
24-04-02 12:29:00.634 - INFO: Train epoch 366: [49600/94637 (52%)] Step: [2167991] | Lr: 0.000100 | Loss: 1.0694 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 73.22
24-04-02 12:29:35.830 - INFO: Train epoch 366: [51200/94637 (54%)] Step: [2168091] | Lr: 0.000100 | Loss: 1.8032 | MSE loss: 0.0004 | Bpp loss: 1.11 | Aux loss: 76.35
24-04-02 12:30:10.886 - INFO: Train epoch 366: [52800/94637 (56%)] Step: [2168191] | Lr: 0.000100 | Loss: 1.4921 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 73.37
24-04-02 12:30:45.786 - INFO: Train epoch 366: [54400/94637 (57%)] Step: [2168291] | Lr: 0.000100 | Loss: 1.0252 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 79.42
24-04-02 12:31:21.062 - INFO: Train epoch 366: [56000/94637 (59%)] Step: [2168391] | Lr: 0.000100 | Loss: 0.9558 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 77.52
24-04-02 12:31:55.778 - INFO: Train epoch 366: [57600/94637 (61%)] Step: [2168491] | Lr: 0.000100 | Loss: 1.3184 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 80.74
24-04-02 12:32:29.855 - INFO: Train epoch 366: [59200/94637 (63%)] Step: [2168591] | Lr: 0.000100 | Loss: 1.7228 | MSE loss: 0.0004 | Bpp loss: 1.11 | Aux loss: 77.60
24-04-02 12:33:03.874 - INFO: Train epoch 366: [60800/94637 (64%)] Step: [2168691] | Lr: 0.000100 | Loss: 1.2202 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 83.26
24-04-02 12:33:39.009 - INFO: Train epoch 366: [62400/94637 (66%)] Step: [2168791] | Lr: 0.000100 | Loss: 0.5441 | MSE loss: 0.0001 | Bpp loss: 0.38 | Aux loss: 80.46
24-04-02 12:34:14.080 - INFO: Train epoch 366: [64000/94637 (68%)] Step: [2168891] | Lr: 0.000100 | Loss: 1.3538 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 75.88
24-04-02 12:34:48.733 - INFO: Train epoch 366: [65600/94637 (69%)] Step: [2168991] | Lr: 0.000100 | Loss: 0.9705 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 79.76
24-04-02 12:35:23.600 - INFO: Train epoch 366: [67200/94637 (71%)] Step: [2169091] | Lr: 0.000100 | Loss: 0.9486 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 81.06
24-04-02 12:35:59.342 - INFO: Train epoch 366: [68800/94637 (73%)] Step: [2169191] | Lr: 0.000100 | Loss: 1.3234 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 81.97
24-04-02 12:36:34.886 - INFO: Train epoch 366: [70400/94637 (74%)] Step: [2169291] | Lr: 0.000100 | Loss: 1.3453 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 76.66
24-04-02 12:37:09.772 - INFO: Train epoch 366: [72000/94637 (76%)] Step: [2169391] | Lr: 0.000100 | Loss: 1.4325 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 82.67
24-04-02 12:37:45.012 - INFO: Train epoch 366: [73600/94637 (78%)] Step: [2169491] | Lr: 0.000100 | Loss: 1.0872 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 83.11
24-04-02 12:38:20.574 - INFO: Train epoch 366: [75200/94637 (79%)] Step: [2169591] | Lr: 0.000100 | Loss: 1.5129 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 72.35
24-04-02 12:38:55.741 - INFO: Train epoch 366: [76800/94637 (81%)] Step: [2169691] | Lr: 0.000100 | Loss: 1.1014 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 80.82
24-04-02 12:39:30.015 - INFO: Train epoch 366: [78400/94637 (83%)] Step: [2169791] | Lr: 0.000100 | Loss: 1.6728 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 82.71
24-04-02 12:40:05.040 - INFO: Train epoch 366: [80000/94637 (85%)] Step: [2169891] | Lr: 0.000100 | Loss: 0.7605 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 75.92
24-04-02 12:40:40.491 - INFO: Train epoch 366: [81600/94637 (86%)] Step: [2169991] | Lr: 0.000100 | Loss: 1.2438 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 77.66
24-04-02 12:41:17.452 - INFO: Train epoch 366: [83200/94637 (88%)] Step: [2170091] | Lr: 0.000100 | Loss: 1.5380 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 78.29
24-04-02 12:41:53.102 - INFO: Train epoch 366: [84800/94637 (90%)] Step: [2170191] | Lr: 0.000100 | Loss: 1.2691 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 74.84
24-04-02 12:42:27.742 - INFO: Train epoch 366: [86400/94637 (91%)] Step: [2170291] | Lr: 0.000100 | Loss: 1.3940 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 83.48
24-04-02 12:43:02.755 - INFO: Train epoch 366: [88000/94637 (93%)] Step: [2170391] | Lr: 0.000100 | Loss: 1.1636 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 82.34
24-04-02 12:43:37.552 - INFO: Train epoch 366: [89600/94637 (95%)] Step: [2170491] | Lr: 0.000100 | Loss: 0.9217 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 80.59
24-04-02 12:44:12.328 - INFO: Train epoch 366: [91200/94637 (96%)] Step: [2170591] | Lr: 0.000100 | Loss: 1.5865 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 82.06
24-04-02 12:44:45.275 - INFO: Train epoch 366: [92800/94637 (98%)] Step: [2170691] | Lr: 0.000100 | Loss: 1.2807 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 79.14
24-04-02 12:45:19.343 - INFO: Train epoch 366: [94400/94637 (100%)] Step: [2170791] | Lr: 0.000100 | Loss: 1.4603 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 79.54
24-04-02 12:45:41.822 - INFO: Learning rate: 0.0001
24-04-02 12:45:42.752 - INFO: Train epoch 367: [    0/94637 (0%)] Step: [2170806] | Lr: 0.000100 | Loss: 1.4726 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 76.80
24-04-02 12:46:16.963 - INFO: Train epoch 367: [ 1600/94637 (2%)] Step: [2170906] | Lr: 0.000100 | Loss: 1.9049 | MSE loss: 0.0004 | Bpp loss: 1.21 | Aux loss: 75.93
24-04-02 12:46:51.099 - INFO: Train epoch 367: [ 3200/94637 (3%)] Step: [2171006] | Lr: 0.000100 | Loss: 1.7678 | MSE loss: 0.0004 | Bpp loss: 1.13 | Aux loss: 80.24
24-04-02 12:47:25.913 - INFO: Train epoch 367: [ 4800/94637 (5%)] Step: [2171106] | Lr: 0.000100 | Loss: 1.4975 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 82.80
24-04-02 12:48:00.225 - INFO: Train epoch 367: [ 6400/94637 (7%)] Step: [2171206] | Lr: 0.000100 | Loss: 1.3153 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 82.05
24-04-02 12:48:33.875 - INFO: Train epoch 367: [ 8000/94637 (8%)] Step: [2171306] | Lr: 0.000100 | Loss: 1.2464 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 85.63
24-04-02 12:49:07.076 - INFO: Train epoch 367: [ 9600/94637 (10%)] Step: [2171406] | Lr: 0.000100 | Loss: 1.4307 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 80.02
24-04-02 12:49:40.577 - INFO: Train epoch 367: [11200/94637 (12%)] Step: [2171506] | Lr: 0.000100 | Loss: 1.8129 | MSE loss: 0.0005 | Bpp loss: 1.01 | Aux loss: 82.71
24-04-02 12:50:14.335 - INFO: Train epoch 367: [12800/94637 (14%)] Step: [2171606] | Lr: 0.000100 | Loss: 0.7511 | MSE loss: 0.0002 | Bpp loss: 0.48 | Aux loss: 87.79
24-04-02 12:50:48.775 - INFO: Train epoch 367: [14400/94637 (15%)] Step: [2171706] | Lr: 0.000100 | Loss: 1.2027 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 84.43
24-04-02 12:51:23.421 - INFO: Train epoch 367: [16000/94637 (17%)] Step: [2171806] | Lr: 0.000100 | Loss: 1.8017 | MSE loss: 0.0004 | Bpp loss: 1.08 | Aux loss: 85.75
24-04-02 12:51:57.835 - INFO: Train epoch 367: [17600/94637 (19%)] Step: [2171906] | Lr: 0.000100 | Loss: 1.0808 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 80.74
24-04-02 12:52:32.823 - INFO: Train epoch 367: [19200/94637 (20%)] Step: [2172006] | Lr: 0.000100 | Loss: 1.4933 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 82.40
24-04-02 12:53:07.680 - INFO: Train epoch 367: [20800/94637 (22%)] Step: [2172106] | Lr: 0.000100 | Loss: 1.7046 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 81.55
24-04-02 12:53:42.457 - INFO: Train epoch 367: [22400/94637 (24%)] Step: [2172206] | Lr: 0.000100 | Loss: 1.0869 | MSE loss: 0.0003 | Bpp loss: 0.61 | Aux loss: 81.59
24-04-02 12:54:16.581 - INFO: Train epoch 367: [24000/94637 (25%)] Step: [2172306] | Lr: 0.000100 | Loss: 1.3570 | MSE loss: 0.0004 | Bpp loss: 0.77 | Aux loss: 79.49
24-04-02 12:54:51.768 - INFO: Train epoch 367: [25600/94637 (27%)] Step: [2172406] | Lr: 0.000100 | Loss: 1.5031 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 78.48
24-04-02 12:55:28.449 - INFO: Train epoch 367: [27200/94637 (29%)] Step: [2172506] | Lr: 0.000100 | Loss: 1.3980 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 77.15
24-04-02 12:56:03.140 - INFO: Train epoch 367: [28800/94637 (30%)] Step: [2172606] | Lr: 0.000100 | Loss: 0.7893 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 81.89
24-04-02 12:56:38.258 - INFO: Train epoch 367: [30400/94637 (32%)] Step: [2172706] | Lr: 0.000100 | Loss: 0.8850 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 80.17
24-04-02 12:57:12.332 - INFO: Train epoch 367: [32000/94637 (34%)] Step: [2172806] | Lr: 0.000100 | Loss: 1.3234 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 81.82
24-04-02 12:57:46.152 - INFO: Train epoch 367: [33600/94637 (36%)] Step: [2172906] | Lr: 0.000100 | Loss: 1.2771 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 78.81
24-04-02 12:58:19.539 - INFO: Train epoch 367: [35200/94637 (37%)] Step: [2173006] | Lr: 0.000100 | Loss: 1.3451 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 82.80
24-04-02 12:58:54.796 - INFO: Train epoch 367: [36800/94637 (39%)] Step: [2173106] | Lr: 0.000100 | Loss: 1.6774 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 87.41
24-04-02 12:59:29.902 - INFO: Train epoch 367: [38400/94637 (41%)] Step: [2173206] | Lr: 0.000100 | Loss: 1.3939 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 76.11
24-04-02 13:00:04.812 - INFO: Train epoch 367: [40000/94637 (42%)] Step: [2173306] | Lr: 0.000100 | Loss: 1.7692 | MSE loss: 0.0005 | Bpp loss: 0.97 | Aux loss: 85.61
24-04-02 13:00:40.015 - INFO: Train epoch 367: [41600/94637 (44%)] Step: [2173406] | Lr: 0.000100 | Loss: 1.4479 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 82.63
24-04-02 13:01:14.570 - INFO: Train epoch 367: [43200/94637 (46%)] Step: [2173506] | Lr: 0.000100 | Loss: 1.1744 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 81.24
24-04-02 13:01:49.708 - INFO: Train epoch 367: [44800/94637 (47%)] Step: [2173606] | Lr: 0.000100 | Loss: 1.1642 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 79.83
24-04-02 13:02:24.697 - INFO: Train epoch 367: [46400/94637 (49%)] Step: [2173706] | Lr: 0.000100 | Loss: 2.0587 | MSE loss: 0.0005 | Bpp loss: 1.24 | Aux loss: 83.80
24-04-02 13:02:58.552 - INFO: Train epoch 367: [48000/94637 (51%)] Step: [2173806] | Lr: 0.000100 | Loss: 1.8296 | MSE loss: 0.0005 | Bpp loss: 1.09 | Aux loss: 83.73
24-04-02 13:03:32.849 - INFO: Train epoch 367: [49600/94637 (52%)] Step: [2173906] | Lr: 0.000100 | Loss: 1.1080 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 85.77
24-04-02 13:04:08.498 - INFO: Train epoch 367: [51200/94637 (54%)] Step: [2174006] | Lr: 0.000100 | Loss: 2.2191 | MSE loss: 0.0006 | Bpp loss: 1.28 | Aux loss: 84.49
24-04-02 13:04:43.720 - INFO: Train epoch 367: [52800/94637 (56%)] Step: [2174106] | Lr: 0.000100 | Loss: 0.7449 | MSE loss: 0.0002 | Bpp loss: 0.48 | Aux loss: 81.89
24-04-02 13:05:17.306 - INFO: Train epoch 367: [54400/94637 (57%)] Step: [2174206] | Lr: 0.000100 | Loss: 1.7197 | MSE loss: 0.0005 | Bpp loss: 0.92 | Aux loss: 85.22
24-04-02 13:05:53.233 - INFO: Train epoch 367: [56000/94637 (59%)] Step: [2174306] | Lr: 0.000100 | Loss: 1.3783 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 80.53
24-04-02 13:06:28.886 - INFO: Train epoch 367: [57600/94637 (61%)] Step: [2174406] | Lr: 0.000100 | Loss: 1.0324 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 84.68
24-04-02 13:07:04.604 - INFO: Train epoch 367: [59200/94637 (63%)] Step: [2174506] | Lr: 0.000100 | Loss: 1.1400 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 84.19
24-04-02 13:07:39.732 - INFO: Train epoch 367: [60800/94637 (64%)] Step: [2174606] | Lr: 0.000100 | Loss: 0.8007 | MSE loss: 0.0002 | Bpp loss: 0.45 | Aux loss: 82.63
24-04-02 13:08:15.572 - INFO: Train epoch 367: [62400/94637 (66%)] Step: [2174706] | Lr: 0.000100 | Loss: 1.4170 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 82.78
24-04-02 13:08:50.564 - INFO: Train epoch 367: [64000/94637 (68%)] Step: [2174806] | Lr: 0.000100 | Loss: 1.1361 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 84.87
24-04-02 13:09:26.155 - INFO: Train epoch 367: [65600/94637 (69%)] Step: [2174906] | Lr: 0.000100 | Loss: 0.9102 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 78.37
24-04-02 13:10:03.853 - INFO: Train epoch 367: [67200/94637 (71%)] Step: [2175006] | Lr: 0.000100 | Loss: 1.0352 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 76.21
24-04-02 13:10:38.518 - INFO: Train epoch 367: [68800/94637 (73%)] Step: [2175106] | Lr: 0.000100 | Loss: 0.9348 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 87.38
24-04-02 13:11:13.501 - INFO: Train epoch 367: [70400/94637 (74%)] Step: [2175206] | Lr: 0.000100 | Loss: 1.1864 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 82.04
24-04-02 13:11:47.897 - INFO: Train epoch 367: [72000/94637 (76%)] Step: [2175306] | Lr: 0.000100 | Loss: 1.4256 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 84.06
24-04-02 13:12:22.918 - INFO: Train epoch 367: [73600/94637 (78%)] Step: [2175406] | Lr: 0.000100 | Loss: 1.3655 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 80.00
24-04-02 13:12:57.537 - INFO: Train epoch 367: [75200/94637 (79%)] Step: [2175506] | Lr: 0.000100 | Loss: 1.0320 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 80.55
24-04-02 13:13:31.824 - INFO: Train epoch 367: [76800/94637 (81%)] Step: [2175606] | Lr: 0.000100 | Loss: 0.8848 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 78.33
24-04-02 13:14:06.508 - INFO: Train epoch 367: [78400/94637 (83%)] Step: [2175706] | Lr: 0.000100 | Loss: 0.9236 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 89.64
24-04-02 13:14:40.810 - INFO: Train epoch 367: [80000/94637 (85%)] Step: [2175806] | Lr: 0.000100 | Loss: 1.1417 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 79.49
24-04-02 13:15:16.019 - INFO: Train epoch 367: [81600/94637 (86%)] Step: [2175906] | Lr: 0.000100 | Loss: 0.9333 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 87.55
24-04-02 13:15:51.249 - INFO: Train epoch 367: [83200/94637 (88%)] Step: [2176006] | Lr: 0.000100 | Loss: 1.4015 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 82.06
24-04-02 13:16:27.528 - INFO: Train epoch 367: [84800/94637 (90%)] Step: [2176106] | Lr: 0.000100 | Loss: 0.9154 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 76.45
24-04-02 13:17:02.513 - INFO: Train epoch 367: [86400/94637 (91%)] Step: [2176206] | Lr: 0.000100 | Loss: 1.2359 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 87.28
24-04-02 13:17:38.154 - INFO: Train epoch 367: [88000/94637 (93%)] Step: [2176306] | Lr: 0.000100 | Loss: 0.7147 | MSE loss: 0.0002 | Bpp loss: 0.45 | Aux loss: 78.14
24-04-02 13:18:13.654 - INFO: Train epoch 367: [89600/94637 (95%)] Step: [2176406] | Lr: 0.000100 | Loss: 1.4562 | MSE loss: 0.0004 | Bpp loss: 0.88 | Aux loss: 83.98
24-04-02 13:18:48.646 - INFO: Train epoch 367: [91200/94637 (96%)] Step: [2176506] | Lr: 0.000100 | Loss: 1.7097 | MSE loss: 0.0004 | Bpp loss: 1.07 | Aux loss: 81.25
24-04-02 13:19:24.283 - INFO: Train epoch 367: [92800/94637 (98%)] Step: [2176606] | Lr: 0.000100 | Loss: 1.6037 | MSE loss: 0.0004 | Bpp loss: 0.99 | Aux loss: 78.66
24-04-02 13:19:59.523 - INFO: Train epoch 367: [94400/94637 (100%)] Step: [2176706] | Lr: 0.000100 | Loss: 2.3339 | MSE loss: 0.0008 | Bpp loss: 1.03 | Aux loss: 79.43
24-04-02 13:20:21.803 - INFO: Learning rate: 0.0001
24-04-02 13:20:22.715 - INFO: Train epoch 368: [    0/94637 (0%)] Step: [2176721] | Lr: 0.000100 | Loss: 1.6191 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 85.11
24-04-02 13:20:57.292 - INFO: Train epoch 368: [ 1600/94637 (2%)] Step: [2176821] | Lr: 0.000100 | Loss: 1.3493 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 78.98
24-04-02 13:21:32.141 - INFO: Train epoch 368: [ 3200/94637 (3%)] Step: [2176921] | Lr: 0.000100 | Loss: 1.0170 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 84.54
24-04-02 13:22:07.330 - INFO: Train epoch 368: [ 4800/94637 (5%)] Step: [2177021] | Lr: 0.000100 | Loss: 0.9109 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 88.90
24-04-02 13:22:41.764 - INFO: Train epoch 368: [ 6400/94637 (7%)] Step: [2177121] | Lr: 0.000100 | Loss: 0.9420 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 81.19
24-04-02 13:23:15.784 - INFO: Train epoch 368: [ 8000/94637 (8%)] Step: [2177221] | Lr: 0.000100 | Loss: 1.4155 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 82.14
24-04-02 13:23:49.507 - INFO: Train epoch 368: [ 9600/94637 (10%)] Step: [2177321] | Lr: 0.000100 | Loss: 0.8447 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 85.31
24-04-02 13:24:23.411 - INFO: Train epoch 368: [11200/94637 (12%)] Step: [2177421] | Lr: 0.000100 | Loss: 1.2419 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 81.59
24-04-02 13:24:58.914 - INFO: Train epoch 368: [12800/94637 (14%)] Step: [2177521] | Lr: 0.000100 | Loss: 1.4195 | MSE loss: 0.0004 | Bpp loss: 0.83 | Aux loss: 80.21
24-04-02 13:25:32.888 - INFO: Train epoch 368: [14400/94637 (15%)] Step: [2177621] | Lr: 0.000100 | Loss: 0.9994 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 82.55
24-04-02 13:26:06.789 - INFO: Train epoch 368: [16000/94637 (17%)] Step: [2177721] | Lr: 0.000100 | Loss: 1.0268 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 84.18
24-04-02 13:26:40.875 - INFO: Train epoch 368: [17600/94637 (19%)] Step: [2177821] | Lr: 0.000100 | Loss: 1.0960 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 77.59
24-04-02 13:27:16.029 - INFO: Train epoch 368: [19200/94637 (20%)] Step: [2177921] | Lr: 0.000100 | Loss: 1.0168 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 83.18
24-04-02 13:27:51.088 - INFO: Train epoch 368: [20800/94637 (22%)] Step: [2178021] | Lr: 0.000100 | Loss: 2.0630 | MSE loss: 0.0005 | Bpp loss: 1.25 | Aux loss: 81.44
24-04-02 13:28:26.548 - INFO: Train epoch 368: [22400/94637 (24%)] Step: [2178121] | Lr: 0.000100 | Loss: 1.0054 | MSE loss: 0.0003 | Bpp loss: 0.56 | Aux loss: 85.86
24-04-02 13:29:01.130 - INFO: Train epoch 368: [24000/94637 (25%)] Step: [2178221] | Lr: 0.000100 | Loss: 0.9248 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 86.40
24-04-02 13:29:36.458 - INFO: Train epoch 368: [25600/94637 (27%)] Step: [2178321] | Lr: 0.000100 | Loss: 0.9806 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 82.28
24-04-02 13:30:11.752 - INFO: Train epoch 368: [27200/94637 (29%)] Step: [2178421] | Lr: 0.000100 | Loss: 1.3373 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 80.42
24-04-02 13:30:45.887 - INFO: Train epoch 368: [28800/94637 (30%)] Step: [2178521] | Lr: 0.000100 | Loss: 1.0523 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 86.71
24-04-02 13:31:49.283 - INFO: Train epoch 368: [30400/94637 (32%)] Step: [2178621] | Lr: 0.000100 | Loss: 1.2091 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 77.16
24-04-02 13:32:23.083 - INFO: Train epoch 368: [32000/94637 (34%)] Step: [2178721] | Lr: 0.000100 | Loss: 1.1747 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 81.06
24-04-02 13:32:57.927 - INFO: Train epoch 368: [33600/94637 (36%)] Step: [2178821] | Lr: 0.000100 | Loss: 1.7930 | MSE loss: 0.0005 | Bpp loss: 1.02 | Aux loss: 80.20
24-04-02 13:33:33.547 - INFO: Train epoch 368: [35200/94637 (37%)] Step: [2178921] | Lr: 0.000100 | Loss: 0.9918 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 76.79
24-04-02 13:34:07.751 - INFO: Train epoch 368: [36800/94637 (39%)] Step: [2179021] | Lr: 0.000100 | Loss: 0.8888 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 86.35
24-04-02 13:34:43.117 - INFO: Train epoch 368: [38400/94637 (41%)] Step: [2179121] | Lr: 0.000100 | Loss: 1.1069 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 75.66
24-04-02 13:35:17.792 - INFO: Train epoch 368: [40000/94637 (42%)] Step: [2179221] | Lr: 0.000100 | Loss: 1.1484 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 77.75
24-04-02 13:35:52.498 - INFO: Train epoch 368: [41600/94637 (44%)] Step: [2179321] | Lr: 0.000100 | Loss: 1.0560 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 78.42
24-04-02 13:36:26.667 - INFO: Train epoch 368: [43200/94637 (46%)] Step: [2179421] | Lr: 0.000100 | Loss: 1.7043 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 83.14
24-04-02 13:37:02.093 - INFO: Train epoch 368: [44800/94637 (47%)] Step: [2179521] | Lr: 0.000100 | Loss: 0.8883 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 81.56
24-04-02 13:37:37.314 - INFO: Train epoch 368: [46400/94637 (49%)] Step: [2179621] | Lr: 0.000100 | Loss: 1.4846 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 80.13
24-04-02 13:38:12.310 - INFO: Train epoch 368: [48000/94637 (51%)] Step: [2179721] | Lr: 0.000100 | Loss: 1.4938 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 79.53
24-04-02 13:38:45.927 - INFO: Train epoch 368: [49600/94637 (52%)] Step: [2179821] | Lr: 0.000100 | Loss: 1.5746 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 85.14
24-04-02 13:39:19.632 - INFO: Train epoch 368: [51200/94637 (54%)] Step: [2179921] | Lr: 0.000100 | Loss: 1.3675 | MSE loss: 0.0004 | Bpp loss: 0.76 | Aux loss: 81.06
24-04-02 13:39:57.079 - INFO: Train epoch 368: [52800/94637 (56%)] Step: [2180021] | Lr: 0.000100 | Loss: 1.7247 | MSE loss: 0.0005 | Bpp loss: 0.99 | Aux loss: 86.82
24-04-02 13:40:32.104 - INFO: Train epoch 368: [54400/94637 (57%)] Step: [2180121] | Lr: 0.000100 | Loss: 1.6013 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 86.53
24-04-02 13:41:07.784 - INFO: Train epoch 368: [56000/94637 (59%)] Step: [2180221] | Lr: 0.000100 | Loss: 0.8732 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 81.64
24-04-02 13:41:43.727 - INFO: Train epoch 368: [57600/94637 (61%)] Step: [2180321] | Lr: 0.000100 | Loss: 1.6645 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 81.30
24-04-02 13:42:18.417 - INFO: Train epoch 368: [59200/94637 (63%)] Step: [2180421] | Lr: 0.000100 | Loss: 1.0729 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 81.18
24-04-02 13:42:52.981 - INFO: Train epoch 368: [60800/94637 (64%)] Step: [2180521] | Lr: 0.000100 | Loss: 1.3003 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 84.76
24-04-02 13:43:27.111 - INFO: Train epoch 368: [62400/94637 (66%)] Step: [2180621] | Lr: 0.000100 | Loss: 0.9600 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 84.71
24-04-02 13:44:02.915 - INFO: Train epoch 368: [64000/94637 (68%)] Step: [2180721] | Lr: 0.000100 | Loss: 0.8626 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 86.79
24-04-02 13:44:37.422 - INFO: Train epoch 368: [65600/94637 (69%)] Step: [2180821] | Lr: 0.000100 | Loss: 2.1205 | MSE loss: 0.0006 | Bpp loss: 1.17 | Aux loss: 85.13
24-04-02 13:45:12.882 - INFO: Train epoch 368: [67200/94637 (71%)] Step: [2180921] | Lr: 0.000100 | Loss: 1.0571 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 81.23
24-04-02 13:45:47.850 - INFO: Train epoch 368: [68800/94637 (73%)] Step: [2181021] | Lr: 0.000100 | Loss: 1.8931 | MSE loss: 0.0005 | Bpp loss: 1.03 | Aux loss: 88.66
24-04-02 13:46:23.875 - INFO: Train epoch 368: [70400/94637 (74%)] Step: [2181121] | Lr: 0.000100 | Loss: 1.8960 | MSE loss: 0.0005 | Bpp loss: 1.09 | Aux loss: 87.35
24-04-02 13:47:00.033 - INFO: Train epoch 368: [72000/94637 (76%)] Step: [2181221] | Lr: 0.000100 | Loss: 1.2250 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 78.38
24-04-02 13:47:35.011 - INFO: Train epoch 368: [73600/94637 (78%)] Step: [2181321] | Lr: 0.000100 | Loss: 1.2144 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 78.13
24-04-02 13:48:09.759 - INFO: Train epoch 368: [75200/94637 (79%)] Step: [2181421] | Lr: 0.000100 | Loss: 1.0390 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 75.37
24-04-02 13:48:44.782 - INFO: Train epoch 368: [76800/94637 (81%)] Step: [2181521] | Lr: 0.000100 | Loss: 1.2880 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 75.44
24-04-02 13:49:19.779 - INFO: Train epoch 368: [78400/94637 (83%)] Step: [2181621] | Lr: 0.000100 | Loss: 1.3352 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 73.45
24-04-02 13:49:54.273 - INFO: Train epoch 368: [80000/94637 (85%)] Step: [2181721] | Lr: 0.000100 | Loss: 1.0816 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 76.98
24-04-02 13:50:29.692 - INFO: Train epoch 368: [81600/94637 (86%)] Step: [2181821] | Lr: 0.000100 | Loss: 1.5812 | MSE loss: 0.0003 | Bpp loss: 1.03 | Aux loss: 76.96
24-04-02 13:51:04.417 - INFO: Train epoch 368: [83200/94637 (88%)] Step: [2181921] | Lr: 0.000100 | Loss: 1.6654 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 72.97
24-04-02 13:51:38.907 - INFO: Train epoch 368: [84800/94637 (90%)] Step: [2182021] | Lr: 0.000100 | Loss: 1.9047 | MSE loss: 0.0004 | Bpp loss: 1.19 | Aux loss: 75.46
24-04-02 13:52:13.588 - INFO: Train epoch 368: [86400/94637 (91%)] Step: [2182121] | Lr: 0.000100 | Loss: 0.8703 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 75.93
24-04-02 13:52:48.316 - INFO: Train epoch 368: [88000/94637 (93%)] Step: [2182221] | Lr: 0.000100 | Loss: 1.0675 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 76.30
24-04-02 13:53:23.634 - INFO: Train epoch 368: [89600/94637 (95%)] Step: [2182321] | Lr: 0.000100 | Loss: 1.1451 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 77.08
24-04-02 13:53:58.132 - INFO: Train epoch 368: [91200/94637 (96%)] Step: [2182421] | Lr: 0.000100 | Loss: 1.6715 | MSE loss: 0.0004 | Bpp loss: 1.05 | Aux loss: 81.51
24-04-02 13:54:35.096 - INFO: Train epoch 368: [92800/94637 (98%)] Step: [2182521] | Lr: 0.000100 | Loss: 0.9831 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 76.89
24-04-02 13:55:11.146 - INFO: Train epoch 368: [94400/94637 (100%)] Step: [2182621] | Lr: 0.000100 | Loss: 1.1999 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 76.96
24-04-02 13:55:27.677 - INFO: Learning rate: 0.0001
24-04-02 13:55:28.505 - INFO: Train epoch 369: [    0/94637 (0%)] Step: [2182636] | Lr: 0.000100 | Loss: 1.2435 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 80.41
24-04-02 13:56:02.330 - INFO: Train epoch 369: [ 1600/94637 (2%)] Step: [2182736] | Lr: 0.000100 | Loss: 1.6050 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 80.11
24-04-02 13:56:36.678 - INFO: Train epoch 369: [ 3200/94637 (3%)] Step: [2182836] | Lr: 0.000100 | Loss: 1.0007 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 72.86
24-04-02 13:57:10.022 - INFO: Train epoch 369: [ 4800/94637 (5%)] Step: [2182936] | Lr: 0.000100 | Loss: 1.1710 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 79.40
24-04-02 13:57:43.384 - INFO: Train epoch 369: [ 6400/94637 (7%)] Step: [2183036] | Lr: 0.000100 | Loss: 1.0952 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 71.47
24-04-02 13:58:16.957 - INFO: Train epoch 369: [ 8000/94637 (8%)] Step: [2183136] | Lr: 0.000100 | Loss: 0.9817 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 80.23
24-04-02 13:58:50.494 - INFO: Train epoch 369: [ 9600/94637 (10%)] Step: [2183236] | Lr: 0.000100 | Loss: 0.8307 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 76.05
24-04-02 13:59:24.269 - INFO: Train epoch 369: [11200/94637 (12%)] Step: [2183336] | Lr: 0.000100 | Loss: 1.0220 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 78.44
24-04-02 13:59:58.532 - INFO: Train epoch 369: [12800/94637 (14%)] Step: [2183436] | Lr: 0.000100 | Loss: 0.9504 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 76.37
24-04-02 14:00:32.242 - INFO: Train epoch 369: [14400/94637 (15%)] Step: [2183536] | Lr: 0.000100 | Loss: 1.0902 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 78.22
24-04-02 14:01:06.496 - INFO: Train epoch 369: [16000/94637 (17%)] Step: [2183636] | Lr: 0.000100 | Loss: 1.7856 | MSE loss: 0.0004 | Bpp loss: 1.13 | Aux loss: 69.33
24-04-02 14:01:41.827 - INFO: Train epoch 369: [17600/94637 (19%)] Step: [2183736] | Lr: 0.000100 | Loss: 1.4390 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 80.85
24-04-02 14:02:15.102 - INFO: Train epoch 369: [19200/94637 (20%)] Step: [2183836] | Lr: 0.000100 | Loss: 0.9090 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 83.00
24-04-02 14:02:50.530 - INFO: Train epoch 369: [20800/94637 (22%)] Step: [2183936] | Lr: 0.000100 | Loss: 1.5757 | MSE loss: 0.0003 | Bpp loss: 1.02 | Aux loss: 77.11
24-04-02 14:03:25.681 - INFO: Train epoch 369: [22400/94637 (24%)] Step: [2184036] | Lr: 0.000100 | Loss: 1.6431 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 81.36
24-04-02 14:04:00.831 - INFO: Train epoch 369: [24000/94637 (25%)] Step: [2184136] | Lr: 0.000100 | Loss: 1.2301 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 76.61
24-04-02 14:04:36.119 - INFO: Train epoch 369: [25600/94637 (27%)] Step: [2184236] | Lr: 0.000100 | Loss: 1.1337 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 78.34
24-04-02 14:05:11.752 - INFO: Train epoch 369: [27200/94637 (29%)] Step: [2184336] | Lr: 0.000100 | Loss: 2.0148 | MSE loss: 0.0005 | Bpp loss: 1.20 | Aux loss: 79.75
24-04-02 14:05:46.607 - INFO: Train epoch 369: [28800/94637 (30%)] Step: [2184436] | Lr: 0.000100 | Loss: 1.4967 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 80.30
24-04-02 14:06:21.092 - INFO: Train epoch 369: [30400/94637 (32%)] Step: [2184536] | Lr: 0.000100 | Loss: 0.7973 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 76.25
24-04-02 14:06:55.372 - INFO: Train epoch 369: [32000/94637 (34%)] Step: [2184636] | Lr: 0.000100 | Loss: 1.2110 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 88.10
24-04-02 14:07:29.871 - INFO: Train epoch 369: [33600/94637 (36%)] Step: [2184736] | Lr: 0.000100 | Loss: 1.7750 | MSE loss: 0.0004 | Bpp loss: 1.16 | Aux loss: 80.62
24-04-02 14:08:04.584 - INFO: Train epoch 369: [35200/94637 (37%)] Step: [2184836] | Lr: 0.000100 | Loss: 1.7811 | MSE loss: 0.0005 | Bpp loss: 1.03 | Aux loss: 71.11
24-04-02 14:08:38.788 - INFO: Train epoch 369: [36800/94637 (39%)] Step: [2184936] | Lr: 0.000100 | Loss: 1.3760 | MSE loss: 0.0004 | Bpp loss: 0.80 | Aux loss: 80.19
24-04-02 14:09:15.809 - INFO: Train epoch 369: [38400/94637 (41%)] Step: [2185036] | Lr: 0.000100 | Loss: 1.1611 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 82.59
24-04-02 14:09:48.665 - INFO: Train epoch 369: [40000/94637 (42%)] Step: [2185136] | Lr: 0.000100 | Loss: 1.2692 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 82.23
24-04-02 14:10:23.696 - INFO: Train epoch 369: [41600/94637 (44%)] Step: [2185236] | Lr: 0.000100 | Loss: 1.3805 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 81.11
24-04-02 14:10:58.970 - INFO: Train epoch 369: [43200/94637 (46%)] Step: [2185336] | Lr: 0.000100 | Loss: 1.4367 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 74.30
24-04-02 14:11:33.796 - INFO: Train epoch 369: [44800/94637 (47%)] Step: [2185436] | Lr: 0.000100 | Loss: 1.1582 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 81.75
24-04-02 14:12:09.084 - INFO: Train epoch 369: [46400/94637 (49%)] Step: [2185536] | Lr: 0.000100 | Loss: 1.5982 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 81.12
24-04-02 14:12:44.080 - INFO: Train epoch 369: [48000/94637 (51%)] Step: [2185636] | Lr: 0.000100 | Loss: 1.2418 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 82.05
24-04-02 14:13:19.312 - INFO: Train epoch 369: [49600/94637 (52%)] Step: [2185736] | Lr: 0.000100 | Loss: 0.9868 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 78.56
24-04-02 14:13:53.926 - INFO: Train epoch 369: [51200/94637 (54%)] Step: [2185836] | Lr: 0.000100 | Loss: 0.6891 | MSE loss: 0.0002 | Bpp loss: 0.44 | Aux loss: 78.09
24-04-02 14:14:28.911 - INFO: Train epoch 369: [52800/94637 (56%)] Step: [2185936] | Lr: 0.000100 | Loss: 1.4894 | MSE loss: 0.0004 | Bpp loss: 0.84 | Aux loss: 81.02
24-04-02 14:15:04.304 - INFO: Train epoch 369: [54400/94637 (57%)] Step: [2186036] | Lr: 0.000100 | Loss: 1.8799 | MSE loss: 0.0005 | Bpp loss: 1.06 | Aux loss: 77.41
24-04-02 14:15:39.076 - INFO: Train epoch 369: [56000/94637 (59%)] Step: [2186136] | Lr: 0.000100 | Loss: 0.8225 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 76.44
24-04-02 14:16:14.289 - INFO: Train epoch 369: [57600/94637 (61%)] Step: [2186236] | Lr: 0.000100 | Loss: 0.8934 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 82.58
24-04-02 14:16:48.870 - INFO: Train epoch 369: [59200/94637 (63%)] Step: [2186336] | Lr: 0.000100 | Loss: 1.0551 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 79.66
24-04-02 14:17:22.326 - INFO: Train epoch 369: [60800/94637 (64%)] Step: [2186436] | Lr: 0.000100 | Loss: 1.2109 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 78.76
24-04-02 14:17:55.763 - INFO: Train epoch 369: [62400/94637 (66%)] Step: [2186536] | Lr: 0.000100 | Loss: 1.3832 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 77.91
24-04-02 14:18:29.652 - INFO: Train epoch 369: [64000/94637 (68%)] Step: [2186636] | Lr: 0.000100 | Loss: 1.2318 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 81.62
24-04-02 14:19:04.469 - INFO: Train epoch 369: [65600/94637 (69%)] Step: [2186736] | Lr: 0.000100 | Loss: 1.1781 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 78.07
24-04-02 14:19:39.742 - INFO: Train epoch 369: [67200/94637 (71%)] Step: [2186836] | Lr: 0.000100 | Loss: 0.8854 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 79.48
24-04-02 14:20:14.810 - INFO: Train epoch 369: [68800/94637 (73%)] Step: [2186936] | Lr: 0.000100 | Loss: 1.2366 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 71.33
24-04-02 14:20:49.461 - INFO: Train epoch 369: [70400/94637 (74%)] Step: [2187036] | Lr: 0.000100 | Loss: 1.6771 | MSE loss: 0.0004 | Bpp loss: 1.07 | Aux loss: 73.58
24-04-02 14:21:24.775 - INFO: Train epoch 369: [72000/94637 (76%)] Step: [2187136] | Lr: 0.000100 | Loss: 1.1710 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 78.40
24-04-02 14:22:00.343 - INFO: Train epoch 369: [73600/94637 (78%)] Step: [2187236] | Lr: 0.000100 | Loss: 1.3028 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 77.23
24-04-02 14:22:35.415 - INFO: Train epoch 369: [75200/94637 (79%)] Step: [2187336] | Lr: 0.000100 | Loss: 1.1159 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 76.41
24-04-02 14:23:10.420 - INFO: Train epoch 369: [76800/94637 (81%)] Step: [2187436] | Lr: 0.000100 | Loss: 0.9574 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 81.92
24-04-02 14:23:47.208 - INFO: Train epoch 369: [78400/94637 (83%)] Step: [2187536] | Lr: 0.000100 | Loss: 1.0723 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 76.24
24-04-02 14:24:21.811 - INFO: Train epoch 369: [80000/94637 (85%)] Step: [2187636] | Lr: 0.000100 | Loss: 1.1432 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 84.89
24-04-02 14:24:56.440 - INFO: Train epoch 369: [81600/94637 (86%)] Step: [2187736] | Lr: 0.000100 | Loss: 1.2537 | MSE loss: 0.0002 | Bpp loss: 0.85 | Aux loss: 79.71
24-04-02 14:25:31.857 - INFO: Train epoch 369: [83200/94637 (88%)] Step: [2187836] | Lr: 0.000100 | Loss: 1.7108 | MSE loss: 0.0004 | Bpp loss: 1.09 | Aux loss: 79.82
24-04-02 14:26:06.454 - INFO: Train epoch 369: [84800/94637 (90%)] Step: [2187936] | Lr: 0.000100 | Loss: 1.3765 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 84.22
24-04-02 14:26:42.444 - INFO: Train epoch 369: [86400/94637 (91%)] Step: [2188036] | Lr: 0.000100 | Loss: 1.1745 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 84.32
24-04-02 14:27:17.505 - INFO: Train epoch 369: [88000/94637 (93%)] Step: [2188136] | Lr: 0.000100 | Loss: 1.8118 | MSE loss: 0.0004 | Bpp loss: 1.10 | Aux loss: 78.75
24-04-02 14:27:52.003 - INFO: Train epoch 369: [89600/94637 (95%)] Step: [2188236] | Lr: 0.000100 | Loss: 1.2942 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 77.84
24-04-02 14:28:26.420 - INFO: Train epoch 369: [91200/94637 (96%)] Step: [2188336] | Lr: 0.000100 | Loss: 1.2867 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 76.85
24-04-02 14:29:01.580 - INFO: Train epoch 369: [92800/94637 (98%)] Step: [2188436] | Lr: 0.000100 | Loss: 0.9965 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 76.89
24-04-02 14:29:36.681 - INFO: Train epoch 369: [94400/94637 (100%)] Step: [2188536] | Lr: 0.000100 | Loss: 1.5108 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 77.06
24-04-02 14:29:53.422 - INFO: Learning rate: 0.0001
24-04-02 14:29:54.266 - INFO: Train epoch 370: [    0/94637 (0%)] Step: [2188551] | Lr: 0.000100 | Loss: 1.8782 | MSE loss: 0.0005 | Bpp loss: 1.12 | Aux loss: 84.81
24-04-02 14:30:28.900 - INFO: Train epoch 370: [ 1600/94637 (2%)] Step: [2188651] | Lr: 0.000100 | Loss: 0.8221 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 80.53
24-04-02 14:31:04.417 - INFO: Train epoch 370: [ 3200/94637 (3%)] Step: [2188751] | Lr: 0.000100 | Loss: 1.3481 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 78.91
24-04-02 14:31:39.326 - INFO: Train epoch 370: [ 4800/94637 (5%)] Step: [2188851] | Lr: 0.000100 | Loss: 1.0610 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 77.72
24-04-02 14:32:14.288 - INFO: Train epoch 370: [ 6400/94637 (7%)] Step: [2188951] | Lr: 0.000100 | Loss: 0.7619 | MSE loss: 0.0002 | Bpp loss: 0.48 | Aux loss: 85.65
24-04-02 14:32:47.888 - INFO: Train epoch 370: [ 8000/94637 (8%)] Step: [2189051] | Lr: 0.000100 | Loss: 1.3222 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 77.58
24-04-02 14:33:22.181 - INFO: Train epoch 370: [ 9600/94637 (10%)] Step: [2189151] | Lr: 0.000100 | Loss: 1.0519 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 82.15
24-04-02 14:33:56.479 - INFO: Train epoch 370: [11200/94637 (12%)] Step: [2189251] | Lr: 0.000100 | Loss: 1.3384 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 81.70
24-04-02 14:34:31.339 - INFO: Train epoch 370: [12800/94637 (14%)] Step: [2189351] | Lr: 0.000100 | Loss: 1.0579 | MSE loss: 0.0003 | Bpp loss: 0.61 | Aux loss: 78.37
24-04-02 14:35:06.465 - INFO: Train epoch 370: [14400/94637 (15%)] Step: [2189451] | Lr: 0.000100 | Loss: 2.0361 | MSE loss: 0.0005 | Bpp loss: 1.25 | Aux loss: 80.72
24-04-02 14:35:42.119 - INFO: Train epoch 370: [16000/94637 (17%)] Step: [2189551] | Lr: 0.000100 | Loss: 1.7581 | MSE loss: 0.0004 | Bpp loss: 1.08 | Aux loss: 81.59
24-04-02 14:36:17.426 - INFO: Train epoch 370: [17600/94637 (19%)] Step: [2189651] | Lr: 0.000100 | Loss: 0.9852 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 78.11
24-04-02 14:36:52.199 - INFO: Train epoch 370: [19200/94637 (20%)] Step: [2189751] | Lr: 0.000100 | Loss: 1.1081 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 84.02
24-04-02 14:37:28.079 - INFO: Train epoch 370: [20800/94637 (22%)] Step: [2189851] | Lr: 0.000100 | Loss: 1.5049 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 77.71
24-04-02 14:38:02.307 - INFO: Train epoch 370: [22400/94637 (24%)] Step: [2189951] | Lr: 0.000100 | Loss: 1.2285 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 80.32
24-04-02 14:38:38.905 - INFO: Train epoch 370: [24000/94637 (25%)] Step: [2190051] | Lr: 0.000100 | Loss: 0.9713 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 75.72
24-04-02 14:39:12.617 - INFO: Train epoch 370: [25600/94637 (27%)] Step: [2190151] | Lr: 0.000100 | Loss: 1.2302 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 78.61
24-04-02 14:39:47.239 - INFO: Train epoch 370: [27200/94637 (29%)] Step: [2190251] | Lr: 0.000100 | Loss: 1.1958 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 74.74
24-04-02 14:40:22.662 - INFO: Train epoch 370: [28800/94637 (30%)] Step: [2190351] | Lr: 0.000100 | Loss: 1.2829 | MSE loss: 0.0004 | Bpp loss: 0.70 | Aux loss: 79.77
24-04-02 14:40:56.427 - INFO: Train epoch 370: [30400/94637 (32%)] Step: [2190451] | Lr: 0.000100 | Loss: 1.4025 | MSE loss: 0.0004 | Bpp loss: 0.83 | Aux loss: 78.97
24-04-02 14:41:31.811 - INFO: Train epoch 370: [32000/94637 (34%)] Step: [2190551] | Lr: 0.000100 | Loss: 1.5089 | MSE loss: 0.0004 | Bpp loss: 0.93 | Aux loss: 83.29
24-04-02 14:42:06.715 - INFO: Train epoch 370: [33600/94637 (36%)] Step: [2190651] | Lr: 0.000100 | Loss: 0.7050 | MSE loss: 0.0002 | Bpp loss: 0.45 | Aux loss: 79.04
24-04-02 14:42:41.185 - INFO: Train epoch 370: [35200/94637 (37%)] Step: [2190751] | Lr: 0.000100 | Loss: 1.3892 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 80.42
24-04-02 14:43:15.955 - INFO: Train epoch 370: [36800/94637 (39%)] Step: [2190851] | Lr: 0.000100 | Loss: 1.1473 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 82.09
24-04-02 14:43:52.242 - INFO: Train epoch 370: [38400/94637 (41%)] Step: [2190951] | Lr: 0.000100 | Loss: 1.3834 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 81.12
24-04-02 14:44:27.064 - INFO: Train epoch 370: [40000/94637 (42%)] Step: [2191051] | Lr: 0.000100 | Loss: 1.0055 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 73.25
24-04-02 14:45:01.238 - INFO: Train epoch 370: [41600/94637 (44%)] Step: [2191151] | Lr: 0.000100 | Loss: 1.2111 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 79.19
24-04-02 14:45:35.983 - INFO: Train epoch 370: [43200/94637 (46%)] Step: [2191251] | Lr: 0.000100 | Loss: 1.0317 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 77.38
24-04-02 14:46:10.447 - INFO: Train epoch 370: [44800/94637 (47%)] Step: [2191351] | Lr: 0.000100 | Loss: 1.6923 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 74.79
24-04-02 14:46:45.186 - INFO: Train epoch 370: [46400/94637 (49%)] Step: [2191451] | Lr: 0.000100 | Loss: 1.8063 | MSE loss: 0.0004 | Bpp loss: 1.15 | Aux loss: 84.10
24-04-02 14:47:19.097 - INFO: Train epoch 370: [48000/94637 (51%)] Step: [2191551] | Lr: 0.000100 | Loss: 1.3842 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 84.63
24-04-02 14:47:53.422 - INFO: Train epoch 370: [49600/94637 (52%)] Step: [2191651] | Lr: 0.000100 | Loss: 1.3092 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 80.39
24-04-02 14:48:27.675 - INFO: Train epoch 370: [51200/94637 (54%)] Step: [2191751] | Lr: 0.000100 | Loss: 1.2642 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 79.68
24-04-02 14:49:02.007 - INFO: Train epoch 370: [52800/94637 (56%)] Step: [2191851] | Lr: 0.000100 | Loss: 1.0797 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 85.63
24-04-02 14:49:36.849 - INFO: Train epoch 370: [54400/94637 (57%)] Step: [2191951] | Lr: 0.000100 | Loss: 2.1400 | MSE loss: 0.0006 | Bpp loss: 1.14 | Aux loss: 78.95
24-04-02 14:50:11.210 - INFO: Train epoch 370: [56000/94637 (59%)] Step: [2192051] | Lr: 0.000100 | Loss: 1.5846 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 79.34
24-04-02 14:50:45.967 - INFO: Train epoch 370: [57600/94637 (61%)] Step: [2192151] | Lr: 0.000100 | Loss: 1.3933 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 81.83
24-04-02 14:51:20.953 - INFO: Train epoch 370: [59200/94637 (63%)] Step: [2192251] | Lr: 0.000100 | Loss: 0.8404 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 78.23
24-04-02 14:51:55.100 - INFO: Train epoch 370: [60800/94637 (64%)] Step: [2192351] | Lr: 0.000100 | Loss: 1.2421 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 78.08
24-04-02 14:52:29.486 - INFO: Train epoch 370: [62400/94637 (66%)] Step: [2192451] | Lr: 0.000100 | Loss: 0.6145 | MSE loss: 0.0001 | Bpp loss: 0.39 | Aux loss: 76.93
24-04-02 14:53:07.202 - INFO: Train epoch 370: [64000/94637 (68%)] Step: [2192551] | Lr: 0.000100 | Loss: 1.4173 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 79.22
24-04-02 14:53:41.921 - INFO: Train epoch 370: [65600/94637 (69%)] Step: [2192651] | Lr: 0.000100 | Loss: 0.7671 | MSE loss: 0.0002 | Bpp loss: 0.48 | Aux loss: 76.48
24-04-02 14:54:16.101 - INFO: Train epoch 370: [67200/94637 (71%)] Step: [2192751] | Lr: 0.000100 | Loss: 1.0238 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 81.65
24-04-02 14:54:49.816 - INFO: Train epoch 370: [68800/94637 (73%)] Step: [2192851] | Lr: 0.000100 | Loss: 1.1215 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 86.03
24-04-02 14:55:23.674 - INFO: Train epoch 370: [70400/94637 (74%)] Step: [2192951] | Lr: 0.000100 | Loss: 1.2312 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 76.73
24-04-02 14:55:58.842 - INFO: Train epoch 370: [72000/94637 (76%)] Step: [2193051] | Lr: 0.000100 | Loss: 1.8594 | MSE loss: 0.0005 | Bpp loss: 1.01 | Aux loss: 76.15
24-04-02 14:56:33.373 - INFO: Train epoch 370: [73600/94637 (78%)] Step: [2193151] | Lr: 0.000100 | Loss: 1.1652 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 81.68
24-04-02 14:57:08.537 - INFO: Train epoch 370: [75200/94637 (79%)] Step: [2193251] | Lr: 0.000100 | Loss: 1.2306 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 77.05
24-04-02 14:57:43.427 - INFO: Train epoch 370: [76800/94637 (81%)] Step: [2193351] | Lr: 0.000100 | Loss: 1.0919 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 81.14
24-04-02 14:58:18.033 - INFO: Train epoch 370: [78400/94637 (83%)] Step: [2193451] | Lr: 0.000100 | Loss: 1.3782 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 81.03
24-04-02 14:58:52.461 - INFO: Train epoch 370: [80000/94637 (85%)] Step: [2193551] | Lr: 0.000100 | Loss: 0.7559 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 81.45
24-04-02 14:59:27.061 - INFO: Train epoch 370: [81600/94637 (86%)] Step: [2193651] | Lr: 0.000100 | Loss: 1.4032 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 80.37
24-04-02 15:00:02.228 - INFO: Train epoch 370: [83200/94637 (88%)] Step: [2193751] | Lr: 0.000100 | Loss: 1.1579 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 80.06
24-04-02 15:00:36.913 - INFO: Train epoch 370: [84800/94637 (90%)] Step: [2193851] | Lr: 0.000100 | Loss: 1.2199 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 80.52
24-04-02 15:01:11.915 - INFO: Train epoch 370: [86400/94637 (91%)] Step: [2193951] | Lr: 0.000100 | Loss: 1.3783 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 78.14
24-04-02 15:01:47.045 - INFO: Train epoch 370: [88000/94637 (93%)] Step: [2194051] | Lr: 0.000100 | Loss: 1.3250 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 77.45
24-04-02 15:02:22.032 - INFO: Train epoch 370: [89600/94637 (95%)] Step: [2194151] | Lr: 0.000100 | Loss: 1.0095 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 74.59
24-04-02 15:02:57.386 - INFO: Train epoch 370: [91200/94637 (96%)] Step: [2194251] | Lr: 0.000100 | Loss: 1.2332 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 80.94
24-04-02 15:03:32.480 - INFO: Train epoch 370: [92800/94637 (98%)] Step: [2194351] | Lr: 0.000100 | Loss: 0.8450 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 81.90
24-04-02 15:04:06.916 - INFO: Train epoch 370: [94400/94637 (100%)] Step: [2194451] | Lr: 0.000100 | Loss: 1.8350 | MSE loss: 0.0004 | Bpp loss: 1.11 | Aux loss: 84.92
24-04-02 15:04:23.666 - INFO: Learning rate: 0.0001
24-04-02 15:04:24.623 - INFO: Train epoch 371: [    0/94637 (0%)] Step: [2194466] | Lr: 0.000100 | Loss: 0.9495 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 86.28
24-04-02 15:04:59.189 - INFO: Train epoch 371: [ 1600/94637 (2%)] Step: [2194566] | Lr: 0.000100 | Loss: 1.9714 | MSE loss: 0.0006 | Bpp loss: 0.99 | Aux loss: 81.87
24-04-02 15:05:33.475 - INFO: Train epoch 371: [ 3200/94637 (3%)] Step: [2194666] | Lr: 0.000100 | Loss: 1.3735 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 79.14
24-04-02 15:06:07.782 - INFO: Train epoch 371: [ 4800/94637 (5%)] Step: [2194766] | Lr: 0.000100 | Loss: 1.4783 | MSE loss: 0.0003 | Bpp loss: 0.96 | Aux loss: 77.28
24-04-02 15:06:41.691 - INFO: Train epoch 371: [ 6400/94637 (7%)] Step: [2194866] | Lr: 0.000100 | Loss: 0.8291 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 80.70
24-04-02 15:07:16.025 - INFO: Train epoch 371: [ 8000/94637 (8%)] Step: [2194966] | Lr: 0.000100 | Loss: 0.9991 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 82.92
24-04-02 15:07:52.599 - INFO: Train epoch 371: [ 9600/94637 (10%)] Step: [2195066] | Lr: 0.000100 | Loss: 1.0574 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 81.11
24-04-02 15:08:27.113 - INFO: Train epoch 371: [11200/94637 (12%)] Step: [2195166] | Lr: 0.000100 | Loss: 1.1581 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 82.55
24-04-02 15:09:01.039 - INFO: Train epoch 371: [12800/94637 (14%)] Step: [2195266] | Lr: 0.000100 | Loss: 1.5969 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 77.78
24-04-02 15:09:35.586 - INFO: Train epoch 371: [14400/94637 (15%)] Step: [2195366] | Lr: 0.000100 | Loss: 1.0808 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 84.07
24-04-02 15:10:10.698 - INFO: Train epoch 371: [16000/94637 (17%)] Step: [2195466] | Lr: 0.000100 | Loss: 1.0434 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 85.14
24-04-02 15:10:45.563 - INFO: Train epoch 371: [17600/94637 (19%)] Step: [2195566] | Lr: 0.000100 | Loss: 1.1607 | MSE loss: 0.0002 | Bpp loss: 0.78 | Aux loss: 77.57
24-04-02 15:11:20.076 - INFO: Train epoch 371: [19200/94637 (20%)] Step: [2195666] | Lr: 0.000100 | Loss: 0.5881 | MSE loss: 0.0001 | Bpp loss: 0.38 | Aux loss: 79.34
24-04-02 15:11:54.321 - INFO: Train epoch 371: [20800/94637 (22%)] Step: [2195766] | Lr: 0.000100 | Loss: 1.3417 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 85.30
24-04-02 15:12:29.678 - INFO: Train epoch 371: [22400/94637 (24%)] Step: [2195866] | Lr: 0.000100 | Loss: 0.9375 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 74.49
24-04-02 15:13:04.409 - INFO: Train epoch 371: [24000/94637 (25%)] Step: [2195966] | Lr: 0.000100 | Loss: 1.2195 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 84.79
24-04-02 15:13:38.657 - INFO: Train epoch 371: [25600/94637 (27%)] Step: [2196066] | Lr: 0.000100 | Loss: 0.9621 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 81.05
24-04-02 15:14:13.218 - INFO: Train epoch 371: [27200/94637 (29%)] Step: [2196166] | Lr: 0.000100 | Loss: 1.0855 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 80.90
24-04-02 15:14:47.817 - INFO: Train epoch 371: [28800/94637 (30%)] Step: [2196266] | Lr: 0.000100 | Loss: 1.1905 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 80.25
24-04-02 15:15:22.644 - INFO: Train epoch 371: [30400/94637 (32%)] Step: [2196366] | Lr: 0.000100 | Loss: 0.4468 | MSE loss: 0.0001 | Bpp loss: 0.33 | Aux loss: 83.24
24-04-02 15:15:57.136 - INFO: Train epoch 371: [32000/94637 (34%)] Step: [2196466] | Lr: 0.000100 | Loss: 0.9625 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 80.54
24-04-02 15:16:31.022 - INFO: Train epoch 371: [33600/94637 (36%)] Step: [2196566] | Lr: 0.000100 | Loss: 1.8337 | MSE loss: 0.0005 | Bpp loss: 1.06 | Aux loss: 82.80
24-04-02 15:17:05.183 - INFO: Train epoch 371: [35200/94637 (37%)] Step: [2196666] | Lr: 0.000100 | Loss: 1.1622 | MSE loss: 0.0004 | Bpp loss: 0.58 | Aux loss: 82.68
24-04-02 15:17:39.683 - INFO: Train epoch 371: [36800/94637 (39%)] Step: [2196766] | Lr: 0.000100 | Loss: 2.1245 | MSE loss: 0.0005 | Bpp loss: 1.25 | Aux loss: 76.84
24-04-02 15:18:14.534 - INFO: Train epoch 371: [38400/94637 (41%)] Step: [2196866] | Lr: 0.000100 | Loss: 1.2275 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 79.38
24-04-02 15:18:50.172 - INFO: Train epoch 371: [40000/94637 (42%)] Step: [2196966] | Lr: 0.000100 | Loss: 1.3599 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 78.66
24-04-02 15:19:25.573 - INFO: Train epoch 371: [41600/94637 (44%)] Step: [2197066] | Lr: 0.000100 | Loss: 1.5262 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 80.06
24-04-02 15:20:00.971 - INFO: Train epoch 371: [43200/94637 (46%)] Step: [2197166] | Lr: 0.000100 | Loss: 1.3176 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 77.77
24-04-02 15:20:36.719 - INFO: Train epoch 371: [44800/94637 (47%)] Step: [2197266] | Lr: 0.000100 | Loss: 1.6518 | MSE loss: 0.0005 | Bpp loss: 0.92 | Aux loss: 81.48
24-04-02 15:21:10.727 - INFO: Train epoch 371: [46400/94637 (49%)] Step: [2197366] | Lr: 0.000100 | Loss: 0.8028 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 82.48
24-04-02 15:21:44.934 - INFO: Train epoch 371: [48000/94637 (51%)] Step: [2197466] | Lr: 0.000100 | Loss: 1.3742 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 74.40
24-04-02 15:22:21.189 - INFO: Train epoch 371: [49600/94637 (52%)] Step: [2197566] | Lr: 0.000100 | Loss: 1.6682 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 82.50
24-04-02 15:22:55.470 - INFO: Train epoch 371: [51200/94637 (54%)] Step: [2197666] | Lr: 0.000100 | Loss: 0.8543 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 82.84
24-04-02 15:23:29.787 - INFO: Train epoch 371: [52800/94637 (56%)] Step: [2197766] | Lr: 0.000100 | Loss: 1.0897 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 79.55
24-04-02 15:24:04.303 - INFO: Train epoch 371: [54400/94637 (57%)] Step: [2197866] | Lr: 0.000100 | Loss: 0.8407 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 79.85
24-04-02 15:24:38.593 - INFO: Train epoch 371: [56000/94637 (59%)] Step: [2197966] | Lr: 0.000100 | Loss: 1.1777 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 81.63
24-04-02 15:25:13.222 - INFO: Train epoch 371: [57600/94637 (61%)] Step: [2198066] | Lr: 0.000100 | Loss: 0.8556 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 79.28
24-04-02 15:25:47.577 - INFO: Train epoch 371: [59200/94637 (63%)] Step: [2198166] | Lr: 0.000100 | Loss: 1.3894 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 82.50
24-04-02 15:26:22.595 - INFO: Train epoch 371: [60800/94637 (64%)] Step: [2198266] | Lr: 0.000100 | Loss: 1.2815 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 77.17
24-04-02 15:26:57.431 - INFO: Train epoch 371: [62400/94637 (66%)] Step: [2198366] | Lr: 0.000100 | Loss: 1.3677 | MSE loss: 0.0004 | Bpp loss: 0.78 | Aux loss: 82.25
24-04-02 15:27:31.539 - INFO: Train epoch 371: [64000/94637 (68%)] Step: [2198466] | Lr: 0.000100 | Loss: 1.2470 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 84.19
24-04-02 15:28:05.725 - INFO: Train epoch 371: [65600/94637 (69%)] Step: [2198566] | Lr: 0.000100 | Loss: 0.8769 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 82.28
24-04-02 15:28:40.069 - INFO: Train epoch 371: [67200/94637 (71%)] Step: [2198666] | Lr: 0.000100 | Loss: 1.0225 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 77.14
24-04-02 15:29:14.275 - INFO: Train epoch 371: [68800/94637 (73%)] Step: [2198766] | Lr: 0.000100 | Loss: 1.4527 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 82.82
24-04-02 15:29:48.854 - INFO: Train epoch 371: [70400/94637 (74%)] Step: [2198866] | Lr: 0.000100 | Loss: 1.0625 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 81.99
24-04-02 15:30:22.989 - INFO: Train epoch 371: [72000/94637 (76%)] Step: [2198966] | Lr: 0.000100 | Loss: 1.0640 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 82.72
24-04-02 15:30:57.169 - INFO: Train epoch 371: [73600/94637 (78%)] Step: [2199066] | Lr: 0.000100 | Loss: 1.6088 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 81.83
24-04-02 15:31:31.388 - INFO: Train epoch 371: [75200/94637 (79%)] Step: [2199166] | Lr: 0.000100 | Loss: 1.3262 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 83.20
24-04-02 15:32:05.734 - INFO: Train epoch 371: [76800/94637 (81%)] Step: [2199266] | Lr: 0.000100 | Loss: 1.6767 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 86.23
24-04-02 15:32:40.280 - INFO: Train epoch 371: [78400/94637 (83%)] Step: [2199366] | Lr: 0.000100 | Loss: 0.7829 | MSE loss: 0.0002 | Bpp loss: 0.48 | Aux loss: 80.14
24-04-02 15:33:14.546 - INFO: Train epoch 371: [80000/94637 (85%)] Step: [2199466] | Lr: 0.000100 | Loss: 1.0321 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 80.90
24-04-02 15:33:49.469 - INFO: Train epoch 371: [81600/94637 (86%)] Step: [2199566] | Lr: 0.000100 | Loss: 1.3407 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 83.06
24-04-02 15:34:23.784 - INFO: Train epoch 371: [83200/94637 (88%)] Step: [2199666] | Lr: 0.000100 | Loss: 1.5849 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 78.19
24-04-02 15:34:58.445 - INFO: Train epoch 371: [84800/94637 (90%)] Step: [2199766] | Lr: 0.000100 | Loss: 1.3079 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 85.44
24-04-02 15:35:33.359 - INFO: Train epoch 371: [86400/94637 (91%)] Step: [2199866] | Lr: 0.000100 | Loss: 1.1350 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 81.00
24-04-02 15:36:08.566 - INFO: Train epoch 371: [88000/94637 (93%)] Step: [2199966] | Lr: 0.000100 | Loss: 0.9098 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 76.86
24-04-02 15:36:45.057 - INFO: Train epoch 371: [89600/94637 (95%)] Step: [2200066] | Lr: 0.000100 | Loss: 1.4681 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 79.89
24-04-02 15:37:19.669 - INFO: Train epoch 371: [91200/94637 (96%)] Step: [2200166] | Lr: 0.000100 | Loss: 1.5557 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 79.55
24-04-02 15:37:54.674 - INFO: Train epoch 371: [92800/94637 (98%)] Step: [2200266] | Lr: 0.000100 | Loss: 1.4167 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 78.17
24-04-02 15:38:29.320 - INFO: Train epoch 371: [94400/94637 (100%)] Step: [2200366] | Lr: 0.000100 | Loss: 1.0211 | MSE loss: 0.0003 | Bpp loss: 0.59 | Aux loss: 77.31
24-04-02 15:38:45.900 - INFO: Learning rate: 0.0001
24-04-02 15:38:47.443 - INFO: Train epoch 372: [    0/94637 (0%)] Step: [2200381] | Lr: 0.000100 | Loss: 1.3038 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 79.57
24-04-02 15:39:22.754 - INFO: Train epoch 372: [ 1600/94637 (2%)] Step: [2200481] | Lr: 0.000100 | Loss: 2.4403 | MSE loss: 0.0006 | Bpp loss: 1.42 | Aux loss: 76.35
24-04-02 15:39:57.545 - INFO: Train epoch 372: [ 3200/94637 (3%)] Step: [2200581] | Lr: 0.000100 | Loss: 1.6173 | MSE loss: 0.0005 | Bpp loss: 0.86 | Aux loss: 86.26
24-04-02 15:40:32.378 - INFO: Train epoch 372: [ 4800/94637 (5%)] Step: [2200681] | Lr: 0.000100 | Loss: 1.2669 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 75.46
24-04-02 15:41:06.594 - INFO: Train epoch 372: [ 6400/94637 (7%)] Step: [2200781] | Lr: 0.000100 | Loss: 1.1968 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 76.37
24-04-02 15:41:41.289 - INFO: Train epoch 372: [ 8000/94637 (8%)] Step: [2200881] | Lr: 0.000100 | Loss: 1.7223 | MSE loss: 0.0005 | Bpp loss: 0.98 | Aux loss: 79.51
24-04-02 15:42:15.635 - INFO: Train epoch 372: [ 9600/94637 (10%)] Step: [2200981] | Lr: 0.000100 | Loss: 1.4915 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 77.65
24-04-02 15:42:49.401 - INFO: Train epoch 372: [11200/94637 (12%)] Step: [2201081] | Lr: 0.000100 | Loss: 1.3661 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 74.51
24-04-02 15:43:23.621 - INFO: Train epoch 372: [12800/94637 (14%)] Step: [2201181] | Lr: 0.000100 | Loss: 1.2697 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 78.10
24-04-02 15:43:58.266 - INFO: Train epoch 372: [14400/94637 (15%)] Step: [2201281] | Lr: 0.000100 | Loss: 1.4186 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 70.69
24-04-02 15:44:33.385 - INFO: Train epoch 372: [16000/94637 (17%)] Step: [2201381] | Lr: 0.000100 | Loss: 1.1399 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 82.86
24-04-02 15:45:08.343 - INFO: Train epoch 372: [17600/94637 (19%)] Step: [2201481] | Lr: 0.000100 | Loss: 1.2843 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 76.28
24-04-02 15:45:43.966 - INFO: Train epoch 372: [19200/94637 (20%)] Step: [2201581] | Lr: 0.000100 | Loss: 1.2161 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 81.16
24-04-02 15:46:17.528 - INFO: Train epoch 372: [20800/94637 (22%)] Step: [2201681] | Lr: 0.000100 | Loss: 0.8519 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 77.81
24-04-02 15:46:52.771 - INFO: Train epoch 372: [22400/94637 (24%)] Step: [2201781] | Lr: 0.000100 | Loss: 1.4425 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 73.62
24-04-02 15:47:28.019 - INFO: Train epoch 372: [24000/94637 (25%)] Step: [2201881] | Lr: 0.000100 | Loss: 1.3490 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 80.96
24-04-02 15:48:03.506 - INFO: Train epoch 372: [25600/94637 (27%)] Step: [2201981] | Lr: 0.000100 | Loss: 0.9578 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 81.92
24-04-02 15:48:38.806 - INFO: Train epoch 372: [27200/94637 (29%)] Step: [2202081] | Lr: 0.000100 | Loss: 1.3613 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 74.18
24-04-02 15:49:13.511 - INFO: Train epoch 372: [28800/94637 (30%)] Step: [2202181] | Lr: 0.000100 | Loss: 1.1226 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 77.94
24-04-02 15:49:48.467 - INFO: Train epoch 372: [30400/94637 (32%)] Step: [2202281] | Lr: 0.000100 | Loss: 0.8634 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 80.83
24-04-02 15:50:23.158 - INFO: Train epoch 372: [32000/94637 (34%)] Step: [2202381] | Lr: 0.000100 | Loss: 1.3517 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 85.44
24-04-02 15:50:57.857 - INFO: Train epoch 372: [33600/94637 (36%)] Step: [2202481] | Lr: 0.000100 | Loss: 1.0001 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 85.52
24-04-02 15:51:34.744 - INFO: Train epoch 372: [35200/94637 (37%)] Step: [2202581] | Lr: 0.000100 | Loss: 1.1678 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 84.10
24-04-02 15:52:09.870 - INFO: Train epoch 372: [36800/94637 (39%)] Step: [2202681] | Lr: 0.000100 | Loss: 1.4834 | MSE loss: 0.0003 | Bpp loss: 0.96 | Aux loss: 75.89
24-04-02 15:52:44.663 - INFO: Train epoch 372: [38400/94637 (41%)] Step: [2202781] | Lr: 0.000100 | Loss: 1.4032 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 79.14
24-04-02 15:53:18.631 - INFO: Train epoch 372: [40000/94637 (42%)] Step: [2202881] | Lr: 0.000100 | Loss: 1.4893 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 78.18
24-04-02 15:53:53.525 - INFO: Train epoch 372: [41600/94637 (44%)] Step: [2202981] | Lr: 0.000100 | Loss: 1.3990 | MSE loss: 0.0004 | Bpp loss: 0.83 | Aux loss: 82.15
24-04-02 15:54:28.353 - INFO: Train epoch 372: [43200/94637 (46%)] Step: [2203081] | Lr: 0.000100 | Loss: 1.0882 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 74.85
24-04-02 15:55:03.430 - INFO: Train epoch 372: [44800/94637 (47%)] Step: [2203181] | Lr: 0.000100 | Loss: 1.1740 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 79.93
24-04-02 15:55:38.922 - INFO: Train epoch 372: [46400/94637 (49%)] Step: [2203281] | Lr: 0.000100 | Loss: 1.2870 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 77.51
24-04-02 15:56:13.399 - INFO: Train epoch 372: [48000/94637 (51%)] Step: [2203381] | Lr: 0.000100 | Loss: 1.1268 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 77.58
24-04-02 15:56:48.156 - INFO: Train epoch 372: [49600/94637 (52%)] Step: [2203481] | Lr: 0.000100 | Loss: 1.2085 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 81.62
24-04-02 15:57:23.307 - INFO: Train epoch 372: [51200/94637 (54%)] Step: [2203581] | Lr: 0.000100 | Loss: 1.5212 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 79.66
24-04-02 15:57:57.874 - INFO: Train epoch 372: [52800/94637 (56%)] Step: [2203681] | Lr: 0.000100 | Loss: 1.5495 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 75.74
24-04-02 15:58:32.481 - INFO: Train epoch 372: [54400/94637 (57%)] Step: [2203781] | Lr: 0.000100 | Loss: 1.5811 | MSE loss: 0.0003 | Bpp loss: 1.05 | Aux loss: 77.56
24-04-02 15:59:07.160 - INFO: Train epoch 372: [56000/94637 (59%)] Step: [2203881] | Lr: 0.000100 | Loss: 1.6435 | MSE loss: 0.0004 | Bpp loss: 1.06 | Aux loss: 79.60
24-04-02 15:59:42.399 - INFO: Train epoch 372: [57600/94637 (61%)] Step: [2203981] | Lr: 0.000100 | Loss: 0.8860 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 83.94
24-04-02 16:00:17.843 - INFO: Train epoch 372: [59200/94637 (63%)] Step: [2204081] | Lr: 0.000100 | Loss: 1.4903 | MSE loss: 0.0004 | Bpp loss: 0.88 | Aux loss: 77.71
24-04-02 16:00:52.675 - INFO: Train epoch 372: [60800/94637 (64%)] Step: [2204181] | Lr: 0.000100 | Loss: 1.5366 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 77.84
24-04-02 16:01:27.403 - INFO: Train epoch 372: [62400/94637 (66%)] Step: [2204281] | Lr: 0.000100 | Loss: 0.8815 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 77.03
24-04-02 16:02:02.422 - INFO: Train epoch 372: [64000/94637 (68%)] Step: [2204381] | Lr: 0.000100 | Loss: 1.0495 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 81.84
24-04-02 16:02:38.144 - INFO: Train epoch 372: [65600/94637 (69%)] Step: [2204481] | Lr: 0.000100 | Loss: 2.1573 | MSE loss: 0.0006 | Bpp loss: 1.22 | Aux loss: 76.87
24-04-02 16:03:12.866 - INFO: Train epoch 372: [67200/94637 (71%)] Step: [2204581] | Lr: 0.000100 | Loss: 0.9762 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 78.08
24-04-02 16:03:48.102 - INFO: Train epoch 372: [68800/94637 (73%)] Step: [2204681] | Lr: 0.000100 | Loss: 1.7523 | MSE loss: 0.0005 | Bpp loss: 1.02 | Aux loss: 78.35
24-04-02 16:04:22.320 - INFO: Train epoch 372: [70400/94637 (74%)] Step: [2204781] | Lr: 0.000100 | Loss: 1.3130 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 75.36
24-04-02 16:04:56.980 - INFO: Train epoch 372: [72000/94637 (76%)] Step: [2204881] | Lr: 0.000100 | Loss: 1.6136 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 77.39
24-04-02 16:05:30.449 - INFO: Train epoch 372: [73600/94637 (78%)] Step: [2204981] | Lr: 0.000100 | Loss: 0.8673 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 76.07
24-04-02 16:06:06.672 - INFO: Train epoch 372: [75200/94637 (79%)] Step: [2205081] | Lr: 0.000100 | Loss: 1.6073 | MSE loss: 0.0004 | Bpp loss: 0.99 | Aux loss: 77.86
24-04-02 16:06:40.978 - INFO: Train epoch 372: [76800/94637 (81%)] Step: [2205181] | Lr: 0.000100 | Loss: 0.9271 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 79.43
24-04-02 16:07:15.363 - INFO: Train epoch 372: [78400/94637 (83%)] Step: [2205281] | Lr: 0.000100 | Loss: 1.4293 | MSE loss: 0.0004 | Bpp loss: 0.79 | Aux loss: 87.60
24-04-02 16:07:50.569 - INFO: Train epoch 372: [80000/94637 (85%)] Step: [2205381] | Lr: 0.000100 | Loss: 1.3940 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 83.31
24-04-02 16:08:24.759 - INFO: Train epoch 372: [81600/94637 (86%)] Step: [2205481] | Lr: 0.000100 | Loss: 1.2944 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 84.71
24-04-02 16:08:59.170 - INFO: Train epoch 372: [83200/94637 (88%)] Step: [2205581] | Lr: 0.000100 | Loss: 1.1211 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 79.71
24-04-02 16:09:33.673 - INFO: Train epoch 372: [84800/94637 (90%)] Step: [2205681] | Lr: 0.000100 | Loss: 1.3100 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 73.29
24-04-02 16:10:08.471 - INFO: Train epoch 372: [86400/94637 (91%)] Step: [2205781] | Lr: 0.000100 | Loss: 1.1205 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 75.61
24-04-02 16:10:43.097 - INFO: Train epoch 372: [88000/94637 (93%)] Step: [2205881] | Lr: 0.000100 | Loss: 1.3245 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 82.76
24-04-02 16:11:17.557 - INFO: Train epoch 372: [89600/94637 (95%)] Step: [2205981] | Lr: 0.000100 | Loss: 0.8474 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 70.52
24-04-02 16:11:52.417 - INFO: Train epoch 372: [91200/94637 (96%)] Step: [2206081] | Lr: 0.000100 | Loss: 1.3407 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 74.77
24-04-02 16:12:27.286 - INFO: Train epoch 372: [92800/94637 (98%)] Step: [2206181] | Lr: 0.000100 | Loss: 2.4861 | MSE loss: 0.0009 | Bpp loss: 1.00 | Aux loss: 84.14
24-04-02 16:13:02.055 - INFO: Train epoch 372: [94400/94637 (100%)] Step: [2206281] | Lr: 0.000100 | Loss: 0.9657 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 75.65
24-04-02 16:13:23.806 - INFO: Learning rate: 0.0001
24-04-02 16:13:24.565 - INFO: Train epoch 373: [    0/94637 (0%)] Step: [2206296] | Lr: 0.000100 | Loss: 1.5046 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 80.64
24-04-02 16:13:59.228 - INFO: Train epoch 373: [ 1600/94637 (2%)] Step: [2206396] | Lr: 0.000100 | Loss: 1.2235 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 80.21
24-04-02 16:14:33.914 - INFO: Train epoch 373: [ 3200/94637 (3%)] Step: [2206496] | Lr: 0.000100 | Loss: 1.5710 | MSE loss: 0.0004 | Bpp loss: 0.99 | Aux loss: 74.96
24-04-02 16:15:09.012 - INFO: Train epoch 373: [ 4800/94637 (5%)] Step: [2206596] | Lr: 0.000100 | Loss: 1.4898 | MSE loss: 0.0004 | Bpp loss: 0.88 | Aux loss: 78.99
24-04-02 16:15:43.437 - INFO: Train epoch 373: [ 6400/94637 (7%)] Step: [2206696] | Lr: 0.000100 | Loss: 1.4994 | MSE loss: 0.0003 | Bpp loss: 0.96 | Aux loss: 80.96
24-04-02 16:16:18.792 - INFO: Train epoch 373: [ 8000/94637 (8%)] Step: [2206796] | Lr: 0.000100 | Loss: 1.2142 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 82.01
24-04-02 16:16:53.650 - INFO: Train epoch 373: [ 9600/94637 (10%)] Step: [2206896] | Lr: 0.000100 | Loss: 1.0277 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 83.32
24-04-02 16:17:28.882 - INFO: Train epoch 373: [11200/94637 (12%)] Step: [2206996] | Lr: 0.000100 | Loss: 0.6765 | MSE loss: 0.0001 | Bpp loss: 0.47 | Aux loss: 78.76
24-04-02 16:18:03.439 - INFO: Train epoch 373: [12800/94637 (14%)] Step: [2207096] | Lr: 0.000100 | Loss: 2.0162 | MSE loss: 0.0004 | Bpp loss: 1.31 | Aux loss: 70.78
24-04-02 16:18:37.462 - INFO: Train epoch 373: [14400/94637 (15%)] Step: [2207196] | Lr: 0.000100 | Loss: 1.1051 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 77.89
24-04-02 16:19:10.979 - INFO: Train epoch 373: [16000/94637 (17%)] Step: [2207296] | Lr: 0.000100 | Loss: 1.4200 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 80.74
24-04-02 16:19:44.567 - INFO: Train epoch 373: [17600/94637 (19%)] Step: [2207396] | Lr: 0.000100 | Loss: 1.0263 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 85.17
24-04-02 16:20:18.143 - INFO: Train epoch 373: [19200/94637 (20%)] Step: [2207496] | Lr: 0.000100 | Loss: 1.2707 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 75.11
24-04-02 16:20:54.226 - INFO: Train epoch 373: [20800/94637 (22%)] Step: [2207596] | Lr: 0.000100 | Loss: 1.4106 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 77.21
24-04-02 16:21:28.840 - INFO: Train epoch 373: [22400/94637 (24%)] Step: [2207696] | Lr: 0.000100 | Loss: 1.1009 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 82.82
24-04-02 16:22:03.426 - INFO: Train epoch 373: [24000/94637 (25%)] Step: [2207796] | Lr: 0.000100 | Loss: 1.3951 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 72.11
24-04-02 16:22:38.251 - INFO: Train epoch 373: [25600/94637 (27%)] Step: [2207896] | Lr: 0.000100 | Loss: 0.9159 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 74.52
24-04-02 16:23:13.726 - INFO: Train epoch 373: [27200/94637 (29%)] Step: [2207996] | Lr: 0.000100 | Loss: 1.1204 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 72.75
24-04-02 16:23:47.007 - INFO: Train epoch 373: [28800/94637 (30%)] Step: [2208096] | Lr: 0.000100 | Loss: 1.9098 | MSE loss: 0.0006 | Bpp loss: 0.97 | Aux loss: 77.03
24-04-02 16:24:22.340 - INFO: Train epoch 373: [30400/94637 (32%)] Step: [2208196] | Lr: 0.000100 | Loss: 1.4274 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 76.48
24-04-02 16:24:57.082 - INFO: Train epoch 373: [32000/94637 (34%)] Step: [2208296] | Lr: 0.000100 | Loss: 1.3792 | MSE loss: 0.0004 | Bpp loss: 0.78 | Aux loss: 72.26
24-04-02 16:25:31.815 - INFO: Train epoch 373: [33600/94637 (36%)] Step: [2208396] | Lr: 0.000100 | Loss: 1.1063 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 77.08
24-04-02 16:26:06.641 - INFO: Train epoch 373: [35200/94637 (37%)] Step: [2208496] | Lr: 0.000100 | Loss: 1.4109 | MSE loss: 0.0004 | Bpp loss: 0.83 | Aux loss: 71.64
24-04-02 16:26:41.864 - INFO: Train epoch 373: [36800/94637 (39%)] Step: [2208596] | Lr: 0.000100 | Loss: 0.8919 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 68.36
24-04-02 16:27:17.065 - INFO: Train epoch 373: [38400/94637 (41%)] Step: [2208696] | Lr: 0.000100 | Loss: 1.7982 | MSE loss: 0.0006 | Bpp loss: 0.84 | Aux loss: 75.21
24-04-02 16:27:51.470 - INFO: Train epoch 373: [40000/94637 (42%)] Step: [2208796] | Lr: 0.000100 | Loss: 1.2960 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 82.83
24-04-02 16:28:26.086 - INFO: Train epoch 373: [41600/94637 (44%)] Step: [2208896] | Lr: 0.000100 | Loss: 0.9604 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 71.59
24-04-02 16:29:01.189 - INFO: Train epoch 373: [43200/94637 (46%)] Step: [2208996] | Lr: 0.000100 | Loss: 0.9729 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 75.20
24-04-02 16:29:35.162 - INFO: Train epoch 373: [44800/94637 (47%)] Step: [2209096] | Lr: 0.000100 | Loss: 1.0697 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 68.94
24-04-02 16:30:10.021 - INFO: Train epoch 373: [46400/94637 (49%)] Step: [2209196] | Lr: 0.000100 | Loss: 1.2596 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 74.32
24-04-02 16:30:44.412 - INFO: Train epoch 373: [48000/94637 (51%)] Step: [2209296] | Lr: 0.000100 | Loss: 1.2102 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 77.05
24-04-02 16:31:18.393 - INFO: Train epoch 373: [49600/94637 (52%)] Step: [2209396] | Lr: 0.000100 | Loss: 0.9937 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 77.24
24-04-02 16:31:52.596 - INFO: Train epoch 373: [51200/94637 (54%)] Step: [2209496] | Lr: 0.000100 | Loss: 1.5529 | MSE loss: 0.0003 | Bpp loss: 0.99 | Aux loss: 76.20
24-04-02 16:32:26.753 - INFO: Train epoch 373: [52800/94637 (56%)] Step: [2209596] | Lr: 0.000100 | Loss: 1.0144 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 73.21
24-04-02 16:33:01.007 - INFO: Train epoch 373: [54400/94637 (57%)] Step: [2209696] | Lr: 0.000100 | Loss: 1.2371 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 76.16
24-04-02 16:33:35.701 - INFO: Train epoch 373: [56000/94637 (59%)] Step: [2209796] | Lr: 0.000100 | Loss: 1.3989 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 76.62
24-04-02 16:34:10.623 - INFO: Train epoch 373: [57600/94637 (61%)] Step: [2209896] | Lr: 0.000100 | Loss: 1.4664 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 76.12
24-04-02 16:34:45.887 - INFO: Train epoch 373: [59200/94637 (63%)] Step: [2209996] | Lr: 0.000100 | Loss: 1.6401 | MSE loss: 0.0004 | Bpp loss: 1.06 | Aux loss: 73.74
24-04-02 16:35:22.654 - INFO: Train epoch 373: [60800/94637 (64%)] Step: [2210096] | Lr: 0.000100 | Loss: 1.1899 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 78.12
24-04-02 16:35:57.480 - INFO: Train epoch 373: [62400/94637 (66%)] Step: [2210196] | Lr: 0.000100 | Loss: 1.7259 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 77.98
24-04-02 16:36:33.230 - INFO: Train epoch 373: [64000/94637 (68%)] Step: [2210296] | Lr: 0.000100 | Loss: 1.5292 | MSE loss: 0.0003 | Bpp loss: 1.01 | Aux loss: 75.15
24-04-02 16:37:09.010 - INFO: Train epoch 373: [65600/94637 (69%)] Step: [2210396] | Lr: 0.000100 | Loss: 0.8917 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 71.76
24-04-02 16:37:43.428 - INFO: Train epoch 373: [67200/94637 (71%)] Step: [2210496] | Lr: 0.000100 | Loss: 1.3064 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 76.03
24-04-02 16:38:18.364 - INFO: Train epoch 373: [68800/94637 (73%)] Step: [2210596] | Lr: 0.000100 | Loss: 1.3735 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 72.39
24-04-02 16:38:52.826 - INFO: Train epoch 373: [70400/94637 (74%)] Step: [2210696] | Lr: 0.000100 | Loss: 0.9953 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 79.83
24-04-02 16:39:27.483 - INFO: Train epoch 373: [72000/94637 (76%)] Step: [2210796] | Lr: 0.000100 | Loss: 1.2272 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 75.53
24-04-02 16:40:01.632 - INFO: Train epoch 373: [73600/94637 (78%)] Step: [2210896] | Lr: 0.000100 | Loss: 1.1544 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 74.32
24-04-02 16:40:36.263 - INFO: Train epoch 373: [75200/94637 (79%)] Step: [2210996] | Lr: 0.000100 | Loss: 1.1765 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 76.15
24-04-02 16:41:10.771 - INFO: Train epoch 373: [76800/94637 (81%)] Step: [2211096] | Lr: 0.000100 | Loss: 1.3516 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 77.93
24-04-02 16:41:45.835 - INFO: Train epoch 373: [78400/94637 (83%)] Step: [2211196] | Lr: 0.000100 | Loss: 1.1862 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 75.88
24-04-02 16:42:20.732 - INFO: Train epoch 373: [80000/94637 (85%)] Step: [2211296] | Lr: 0.000100 | Loss: 1.4162 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 75.01
24-04-02 16:42:55.531 - INFO: Train epoch 373: [81600/94637 (86%)] Step: [2211396] | Lr: 0.000100 | Loss: 1.9110 | MSE loss: 0.0005 | Bpp loss: 1.16 | Aux loss: 72.05
24-04-02 16:43:30.207 - INFO: Train epoch 373: [83200/94637 (88%)] Step: [2211496] | Lr: 0.000100 | Loss: 1.2203 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 79.63
24-04-02 16:44:05.380 - INFO: Train epoch 373: [84800/94637 (90%)] Step: [2211596] | Lr: 0.000100 | Loss: 2.1708 | MSE loss: 0.0006 | Bpp loss: 1.25 | Aux loss: 78.30
24-04-02 16:44:40.487 - INFO: Train epoch 373: [86400/94637 (91%)] Step: [2211696] | Lr: 0.000100 | Loss: 1.5087 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 76.40
24-04-02 16:45:14.799 - INFO: Train epoch 373: [88000/94637 (93%)] Step: [2211796] | Lr: 0.000100 | Loss: 1.2668 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 76.18
24-04-02 16:45:49.554 - INFO: Train epoch 373: [89600/94637 (95%)] Step: [2211896] | Lr: 0.000100 | Loss: 1.6309 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 76.82
24-04-02 16:46:23.459 - INFO: Train epoch 373: [91200/94637 (96%)] Step: [2211996] | Lr: 0.000100 | Loss: 1.3176 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 78.22
24-04-02 16:46:56.950 - INFO: Train epoch 373: [92800/94637 (98%)] Step: [2212096] | Lr: 0.000100 | Loss: 1.1633 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 71.94
24-04-02 16:47:31.358 - INFO: Train epoch 373: [94400/94637 (100%)] Step: [2212196] | Lr: 0.000100 | Loss: 0.9084 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 77.16
24-04-02 16:47:47.892 - INFO: Learning rate: 0.0001
24-04-02 16:47:48.760 - INFO: Train epoch 374: [    0/94637 (0%)] Step: [2212211] | Lr: 0.000100 | Loss: 1.2828 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 79.52
24-04-02 16:48:23.635 - INFO: Train epoch 374: [ 1600/94637 (2%)] Step: [2212311] | Lr: 0.000100 | Loss: 1.9219 | MSE loss: 0.0005 | Bpp loss: 1.16 | Aux loss: 78.51
24-04-02 16:48:57.488 - INFO: Train epoch 374: [ 3200/94637 (3%)] Step: [2212411] | Lr: 0.000100 | Loss: 1.4664 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 74.77
24-04-02 16:49:34.115 - INFO: Train epoch 374: [ 4800/94637 (5%)] Step: [2212511] | Lr: 0.000100 | Loss: 0.8078 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 72.66
24-04-02 16:50:09.321 - INFO: Train epoch 374: [ 6400/94637 (7%)] Step: [2212611] | Lr: 0.000100 | Loss: 1.0157 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 73.11
24-04-02 16:50:43.995 - INFO: Train epoch 374: [ 8000/94637 (8%)] Step: [2212711] | Lr: 0.000100 | Loss: 1.1931 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 76.35
24-04-02 16:51:18.893 - INFO: Train epoch 374: [ 9600/94637 (10%)] Step: [2212811] | Lr: 0.000100 | Loss: 1.4393 | MSE loss: 0.0004 | Bpp loss: 0.82 | Aux loss: 76.94
24-04-02 16:51:53.972 - INFO: Train epoch 374: [11200/94637 (12%)] Step: [2212911] | Lr: 0.000100 | Loss: 1.2399 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 77.48
24-04-02 16:52:27.642 - INFO: Train epoch 374: [12800/94637 (14%)] Step: [2213011] | Lr: 0.000100 | Loss: 1.5321 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 72.04
24-04-02 16:53:02.178 - INFO: Train epoch 374: [14400/94637 (15%)] Step: [2213111] | Lr: 0.000100 | Loss: 0.5159 | MSE loss: 0.0001 | Bpp loss: 0.36 | Aux loss: 72.33
24-04-02 16:53:37.229 - INFO: Train epoch 374: [16000/94637 (17%)] Step: [2213211] | Lr: 0.000100 | Loss: 0.8283 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 72.39
24-04-02 16:54:12.247 - INFO: Train epoch 374: [17600/94637 (19%)] Step: [2213311] | Lr: 0.000100 | Loss: 0.6364 | MSE loss: 0.0001 | Bpp loss: 0.41 | Aux loss: 72.57
24-04-02 16:54:46.779 - INFO: Train epoch 374: [19200/94637 (20%)] Step: [2213411] | Lr: 0.000100 | Loss: 0.8552 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 70.29
24-04-02 16:55:22.256 - INFO: Train epoch 374: [20800/94637 (22%)] Step: [2213511] | Lr: 0.000100 | Loss: 1.6602 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 79.57
24-04-02 16:55:57.534 - INFO: Train epoch 374: [22400/94637 (24%)] Step: [2213611] | Lr: 0.000100 | Loss: 1.3075 | MSE loss: 0.0004 | Bpp loss: 0.71 | Aux loss: 71.95
24-04-02 16:56:31.799 - INFO: Train epoch 374: [24000/94637 (25%)] Step: [2213711] | Lr: 0.000100 | Loss: 0.9431 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 75.38
24-04-02 16:57:05.948 - INFO: Train epoch 374: [25600/94637 (27%)] Step: [2213811] | Lr: 0.000100 | Loss: 1.7683 | MSE loss: 0.0004 | Bpp loss: 1.18 | Aux loss: 80.61
24-04-02 16:57:40.601 - INFO: Train epoch 374: [27200/94637 (29%)] Step: [2213911] | Lr: 0.000100 | Loss: 1.1785 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 82.08
24-04-02 16:58:14.849 - INFO: Train epoch 374: [28800/94637 (30%)] Step: [2214011] | Lr: 0.000100 | Loss: 1.1496 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 75.43
24-04-02 16:58:50.198 - INFO: Train epoch 374: [30400/94637 (32%)] Step: [2214111] | Lr: 0.000100 | Loss: 0.9685 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 73.93
24-04-02 16:59:24.803 - INFO: Train epoch 374: [32000/94637 (34%)] Step: [2214211] | Lr: 0.000100 | Loss: 1.0792 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 77.42
24-04-02 16:59:59.367 - INFO: Train epoch 374: [33600/94637 (36%)] Step: [2214311] | Lr: 0.000100 | Loss: 1.2417 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 72.79
24-04-02 17:00:34.278 - INFO: Train epoch 374: [35200/94637 (37%)] Step: [2214411] | Lr: 0.000100 | Loss: 0.9668 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 74.49
24-04-02 17:01:09.738 - INFO: Train epoch 374: [36800/94637 (39%)] Step: [2214511] | Lr: 0.000100 | Loss: 0.7370 | MSE loss: 0.0002 | Bpp loss: 0.43 | Aux loss: 71.82
24-04-02 17:01:44.100 - INFO: Train epoch 374: [38400/94637 (41%)] Step: [2214611] | Lr: 0.000100 | Loss: 1.0756 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 73.79
24-04-02 17:02:18.868 - INFO: Train epoch 374: [40000/94637 (42%)] Step: [2214711] | Lr: 0.000100 | Loss: 1.1394 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 75.91
24-04-02 17:02:53.513 - INFO: Train epoch 374: [41600/94637 (44%)] Step: [2214811] | Lr: 0.000100 | Loss: 1.5699 | MSE loss: 0.0004 | Bpp loss: 0.99 | Aux loss: 70.45
24-04-02 17:03:27.901 - INFO: Train epoch 374: [43200/94637 (46%)] Step: [2214911] | Lr: 0.000100 | Loss: 1.4344 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 71.74
24-04-02 17:04:04.181 - INFO: Train epoch 374: [44800/94637 (47%)] Step: [2215011] | Lr: 0.000100 | Loss: 1.9850 | MSE loss: 0.0005 | Bpp loss: 1.17 | Aux loss: 75.76
24-04-02 17:04:38.279 - INFO: Train epoch 374: [46400/94637 (49%)] Step: [2215111] | Lr: 0.000100 | Loss: 0.8415 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 74.54
24-04-02 17:05:13.200 - INFO: Train epoch 374: [48000/94637 (51%)] Step: [2215211] | Lr: 0.000100 | Loss: 1.4704 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 77.22
24-04-02 17:05:48.002 - INFO: Train epoch 374: [49600/94637 (52%)] Step: [2215311] | Lr: 0.000100 | Loss: 1.1047 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 77.56
24-04-02 17:06:23.121 - INFO: Train epoch 374: [51200/94637 (54%)] Step: [2215411] | Lr: 0.000100 | Loss: 1.4290 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 71.33
24-04-02 17:06:57.234 - INFO: Train epoch 374: [52800/94637 (56%)] Step: [2215511] | Lr: 0.000100 | Loss: 0.8644 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 77.24
24-04-02 17:07:31.020 - INFO: Train epoch 374: [54400/94637 (57%)] Step: [2215611] | Lr: 0.000100 | Loss: 1.6845 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 78.19
24-04-02 17:08:06.029 - INFO: Train epoch 374: [56000/94637 (59%)] Step: [2215711] | Lr: 0.000100 | Loss: 1.4943 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 76.22
24-04-02 17:08:39.875 - INFO: Train epoch 374: [57600/94637 (61%)] Step: [2215811] | Lr: 0.000100 | Loss: 1.4287 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 72.46
24-04-02 17:09:13.815 - INFO: Train epoch 374: [59200/94637 (63%)] Step: [2215911] | Lr: 0.000100 | Loss: 0.8823 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 73.63
24-04-02 17:09:47.990 - INFO: Train epoch 374: [60800/94637 (64%)] Step: [2216011] | Lr: 0.000100 | Loss: 0.9252 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 76.55
24-04-02 17:10:22.021 - INFO: Train epoch 374: [62400/94637 (66%)] Step: [2216111] | Lr: 0.000100 | Loss: 1.0176 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 72.37
24-04-02 17:10:56.848 - INFO: Train epoch 374: [64000/94637 (68%)] Step: [2216211] | Lr: 0.000100 | Loss: 1.7336 | MSE loss: 0.0005 | Bpp loss: 0.97 | Aux loss: 82.64
24-04-02 17:11:31.276 - INFO: Train epoch 374: [65600/94637 (69%)] Step: [2216311] | Lr: 0.000100 | Loss: 1.3067 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 73.56
24-04-02 17:12:06.135 - INFO: Train epoch 374: [67200/94637 (71%)] Step: [2216411] | Lr: 0.000100 | Loss: 1.4249 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 73.28
24-04-02 17:12:41.452 - INFO: Train epoch 374: [68800/94637 (73%)] Step: [2216511] | Lr: 0.000100 | Loss: 0.8917 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 75.57
24-04-02 17:13:16.265 - INFO: Train epoch 374: [70400/94637 (74%)] Step: [2216611] | Lr: 0.000100 | Loss: 1.2175 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 78.49
24-04-02 17:13:51.893 - INFO: Train epoch 374: [72000/94637 (76%)] Step: [2216711] | Lr: 0.000100 | Loss: 1.2553 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 75.60
24-04-02 17:14:26.734 - INFO: Train epoch 374: [73600/94637 (78%)] Step: [2216811] | Lr: 0.000100 | Loss: 1.7191 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 72.46
24-04-02 17:15:01.654 - INFO: Train epoch 374: [75200/94637 (79%)] Step: [2216911] | Lr: 0.000100 | Loss: 1.1363 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 74.75
24-04-02 17:15:36.930 - INFO: Train epoch 374: [76800/94637 (81%)] Step: [2217011] | Lr: 0.000100 | Loss: 1.0762 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 70.64
24-04-02 17:16:10.998 - INFO: Train epoch 374: [78400/94637 (83%)] Step: [2217111] | Lr: 0.000100 | Loss: 1.2063 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 76.05
24-04-02 17:16:45.846 - INFO: Train epoch 374: [80000/94637 (85%)] Step: [2217211] | Lr: 0.000100 | Loss: 1.5357 | MSE loss: 0.0004 | Bpp loss: 0.88 | Aux loss: 74.96
24-04-02 17:17:21.162 - INFO: Train epoch 374: [81600/94637 (86%)] Step: [2217311] | Lr: 0.000100 | Loss: 1.2843 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 71.78
24-04-02 17:17:56.198 - INFO: Train epoch 374: [83200/94637 (88%)] Step: [2217411] | Lr: 0.000100 | Loss: 0.9383 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 79.25
24-04-02 17:18:32.582 - INFO: Train epoch 374: [84800/94637 (90%)] Step: [2217511] | Lr: 0.000100 | Loss: 2.6317 | MSE loss: 0.0006 | Bpp loss: 1.62 | Aux loss: 79.58
24-04-02 17:19:07.746 - INFO: Train epoch 374: [86400/94637 (91%)] Step: [2217611] | Lr: 0.000100 | Loss: 1.1753 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 74.29
24-04-02 17:19:42.074 - INFO: Train epoch 374: [88000/94637 (93%)] Step: [2217711] | Lr: 0.000100 | Loss: 1.1787 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 77.10
24-04-02 17:20:17.472 - INFO: Train epoch 374: [89600/94637 (95%)] Step: [2217811] | Lr: 0.000100 | Loss: 1.2332 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 73.27
24-04-02 17:20:52.593 - INFO: Train epoch 374: [91200/94637 (96%)] Step: [2217911] | Lr: 0.000100 | Loss: 1.6492 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 78.46
24-04-02 17:21:27.271 - INFO: Train epoch 374: [92800/94637 (98%)] Step: [2218011] | Lr: 0.000100 | Loss: 1.2669 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 69.85
24-04-02 17:22:02.449 - INFO: Train epoch 374: [94400/94637 (100%)] Step: [2218111] | Lr: 0.000100 | Loss: 0.8794 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 76.20
24-04-02 17:22:24.662 - INFO: Learning rate: 0.0001
24-04-02 17:22:25.597 - INFO: Train epoch 375: [    0/94637 (0%)] Step: [2218126] | Lr: 0.000100 | Loss: 1.2991 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 74.41
24-04-02 17:22:59.826 - INFO: Train epoch 375: [ 1600/94637 (2%)] Step: [2218226] | Lr: 0.000100 | Loss: 1.4451 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 82.43
24-04-02 17:23:34.596 - INFO: Train epoch 375: [ 3200/94637 (3%)] Step: [2218326] | Lr: 0.000100 | Loss: 1.6401 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 74.39
24-04-02 17:24:09.130 - INFO: Train epoch 375: [ 4800/94637 (5%)] Step: [2218426] | Lr: 0.000100 | Loss: 1.4107 | MSE loss: 0.0004 | Bpp loss: 0.81 | Aux loss: 74.26
24-04-02 17:24:42.989 - INFO: Train epoch 375: [ 6400/94637 (7%)] Step: [2218526] | Lr: 0.000100 | Loss: 1.3392 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 76.48
24-04-02 17:25:17.451 - INFO: Train epoch 375: [ 8000/94637 (8%)] Step: [2218626] | Lr: 0.000100 | Loss: 1.5714 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 72.36
24-04-02 17:25:52.496 - INFO: Train epoch 375: [ 9600/94637 (10%)] Step: [2218726] | Lr: 0.000100 | Loss: 1.1978 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 77.27
24-04-02 17:26:27.174 - INFO: Train epoch 375: [11200/94637 (12%)] Step: [2218826] | Lr: 0.000100 | Loss: 0.9785 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 73.51
24-04-02 17:27:01.523 - INFO: Train epoch 375: [12800/94637 (14%)] Step: [2218926] | Lr: 0.000100 | Loss: 1.3776 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 78.07
24-04-02 17:27:35.214 - INFO: Train epoch 375: [14400/94637 (15%)] Step: [2219026] | Lr: 0.000100 | Loss: 1.1301 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 78.50
24-04-02 17:28:10.708 - INFO: Train epoch 375: [16000/94637 (17%)] Step: [2219126] | Lr: 0.000100 | Loss: 1.2531 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 79.78
24-04-02 17:28:45.189 - INFO: Train epoch 375: [17600/94637 (19%)] Step: [2219226] | Lr: 0.000100 | Loss: 0.8007 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 72.65
24-04-02 17:29:19.804 - INFO: Train epoch 375: [19200/94637 (20%)] Step: [2219326] | Lr: 0.000100 | Loss: 1.2945 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 81.09
24-04-02 17:29:53.617 - INFO: Train epoch 375: [20800/94637 (22%)] Step: [2219426] | Lr: 0.000100 | Loss: 1.1976 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 72.52
24-04-02 17:30:27.921 - INFO: Train epoch 375: [22400/94637 (24%)] Step: [2219526] | Lr: 0.000100 | Loss: 0.8670 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 70.25
24-04-02 17:31:02.025 - INFO: Train epoch 375: [24000/94637 (25%)] Step: [2219626] | Lr: 0.000100 | Loss: 1.3150 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 70.25
24-04-02 17:31:35.496 - INFO: Train epoch 375: [25600/94637 (27%)] Step: [2219726] | Lr: 0.000100 | Loss: 1.5675 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 76.03
24-04-02 17:32:09.439 - INFO: Train epoch 375: [27200/94637 (29%)] Step: [2219826] | Lr: 0.000100 | Loss: 1.1809 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 74.70
24-04-02 17:32:43.848 - INFO: Train epoch 375: [28800/94637 (30%)] Step: [2219926] | Lr: 0.000100 | Loss: 0.7998 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 74.48
24-04-02 17:33:20.432 - INFO: Train epoch 375: [30400/94637 (32%)] Step: [2220026] | Lr: 0.000100 | Loss: 0.8906 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 80.07
24-04-02 17:33:53.993 - INFO: Train epoch 375: [32000/94637 (34%)] Step: [2220126] | Lr: 0.000100 | Loss: 1.6313 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 71.06
24-04-02 17:34:28.916 - INFO: Train epoch 375: [33600/94637 (36%)] Step: [2220226] | Lr: 0.000100 | Loss: 0.9416 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 82.46
24-04-02 17:35:03.644 - INFO: Train epoch 375: [35200/94637 (37%)] Step: [2220326] | Lr: 0.000100 | Loss: 1.2667 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 73.72
24-04-02 17:35:38.080 - INFO: Train epoch 375: [36800/94637 (39%)] Step: [2220426] | Lr: 0.000100 | Loss: 1.1180 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 74.85
24-04-02 17:36:12.212 - INFO: Train epoch 375: [38400/94637 (41%)] Step: [2220526] | Lr: 0.000100 | Loss: 0.9773 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 76.67
24-04-02 17:36:46.622 - INFO: Train epoch 375: [40000/94637 (42%)] Step: [2220626] | Lr: 0.000100 | Loss: 1.1035 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 83.75
24-04-02 17:37:20.782 - INFO: Train epoch 375: [41600/94637 (44%)] Step: [2220726] | Lr: 0.000100 | Loss: 1.1016 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 75.34
24-04-02 17:37:54.831 - INFO: Train epoch 375: [43200/94637 (46%)] Step: [2220826] | Lr: 0.000100 | Loss: 1.0706 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 77.41
24-04-02 17:38:29.897 - INFO: Train epoch 375: [44800/94637 (47%)] Step: [2220926] | Lr: 0.000100 | Loss: 1.5401 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 77.53
24-04-02 17:39:03.587 - INFO: Train epoch 375: [46400/94637 (49%)] Step: [2221026] | Lr: 0.000100 | Loss: 1.9194 | MSE loss: 0.0004 | Bpp loss: 1.22 | Aux loss: 74.04
24-04-02 17:39:36.735 - INFO: Train epoch 375: [48000/94637 (51%)] Step: [2221126] | Lr: 0.000100 | Loss: 1.3469 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 71.45
24-04-02 17:40:11.705 - INFO: Train epoch 375: [49600/94637 (52%)] Step: [2221226] | Lr: 0.000100 | Loss: 1.5404 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 79.55
24-04-02 17:40:46.400 - INFO: Train epoch 375: [51200/94637 (54%)] Step: [2221326] | Lr: 0.000100 | Loss: 0.9325 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 79.74
24-04-02 17:41:22.050 - INFO: Train epoch 375: [52800/94637 (56%)] Step: [2221426] | Lr: 0.000100 | Loss: 0.9355 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 75.56
24-04-02 17:41:56.739 - INFO: Train epoch 375: [54400/94637 (57%)] Step: [2221526] | Lr: 0.000100 | Loss: 1.3598 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 81.77
24-04-02 17:42:31.688 - INFO: Train epoch 375: [56000/94637 (59%)] Step: [2221626] | Lr: 0.000100 | Loss: 1.1555 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 70.00
24-04-02 17:43:06.090 - INFO: Train epoch 375: [57600/94637 (61%)] Step: [2221726] | Lr: 0.000100 | Loss: 1.2660 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 80.44
24-04-02 17:43:41.056 - INFO: Train epoch 375: [59200/94637 (63%)] Step: [2221826] | Lr: 0.000100 | Loss: 1.2371 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 81.00
24-04-02 17:44:16.392 - INFO: Train epoch 375: [60800/94637 (64%)] Step: [2221926] | Lr: 0.000100 | Loss: 1.3818 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 76.79
24-04-02 17:44:50.942 - INFO: Train epoch 375: [62400/94637 (66%)] Step: [2222026] | Lr: 0.000100 | Loss: 1.2930 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 76.22
24-04-02 17:45:25.617 - INFO: Train epoch 375: [64000/94637 (68%)] Step: [2222126] | Lr: 0.000100 | Loss: 1.1751 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 75.78
24-04-02 17:46:00.696 - INFO: Train epoch 375: [65600/94637 (69%)] Step: [2222226] | Lr: 0.000100 | Loss: 1.0830 | MSE loss: 0.0003 | Bpp loss: 0.62 | Aux loss: 74.57
24-04-02 17:46:35.740 - INFO: Train epoch 375: [67200/94637 (71%)] Step: [2222326] | Lr: 0.000100 | Loss: 1.4528 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 78.48
24-04-02 17:47:10.544 - INFO: Train epoch 375: [68800/94637 (73%)] Step: [2222426] | Lr: 0.000100 | Loss: 1.3308 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 73.79
24-04-02 17:47:46.989 - INFO: Train epoch 375: [70400/94637 (74%)] Step: [2222526] | Lr: 0.000100 | Loss: 0.7754 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 74.24
24-04-02 17:48:21.692 - INFO: Train epoch 375: [72000/94637 (76%)] Step: [2222626] | Lr: 0.000100 | Loss: 1.1780 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 82.59
24-04-02 17:48:55.990 - INFO: Train epoch 375: [73600/94637 (78%)] Step: [2222726] | Lr: 0.000100 | Loss: 1.3935 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 77.01
24-04-02 17:49:31.124 - INFO: Train epoch 375: [75200/94637 (79%)] Step: [2222826] | Lr: 0.000100 | Loss: 1.4095 | MSE loss: 0.0004 | Bpp loss: 0.81 | Aux loss: 72.77
24-04-02 17:50:05.289 - INFO: Train epoch 375: [76800/94637 (81%)] Step: [2222926] | Lr: 0.000100 | Loss: 1.4807 | MSE loss: 0.0004 | Bpp loss: 0.88 | Aux loss: 74.29
24-04-02 17:50:39.879 - INFO: Train epoch 375: [78400/94637 (83%)] Step: [2223026] | Lr: 0.000100 | Loss: 1.2544 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 78.22
24-04-02 17:51:14.293 - INFO: Train epoch 375: [80000/94637 (85%)] Step: [2223126] | Lr: 0.000100 | Loss: 1.3364 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 72.68
24-04-02 17:51:49.179 - INFO: Train epoch 375: [81600/94637 (86%)] Step: [2223226] | Lr: 0.000100 | Loss: 1.1705 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 77.20
24-04-02 17:52:24.316 - INFO: Train epoch 375: [83200/94637 (88%)] Step: [2223326] | Lr: 0.000100 | Loss: 1.3407 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 72.70
24-04-02 17:52:58.432 - INFO: Train epoch 375: [84800/94637 (90%)] Step: [2223426] | Lr: 0.000100 | Loss: 0.9086 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 73.14
24-04-02 17:53:32.965 - INFO: Train epoch 375: [86400/94637 (91%)] Step: [2223526] | Lr: 0.000100 | Loss: 1.1060 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 76.97
24-04-02 17:54:07.670 - INFO: Train epoch 375: [88000/94637 (93%)] Step: [2223626] | Lr: 0.000100 | Loss: 1.0903 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 71.43
24-04-02 17:54:42.634 - INFO: Train epoch 375: [89600/94637 (95%)] Step: [2223726] | Lr: 0.000100 | Loss: 0.9868 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 77.62
24-04-02 17:55:17.518 - INFO: Train epoch 375: [91200/94637 (96%)] Step: [2223826] | Lr: 0.000100 | Loss: 1.2236 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 71.68
24-04-02 17:55:52.422 - INFO: Train epoch 375: [92800/94637 (98%)] Step: [2223926] | Lr: 0.000100 | Loss: 1.4518 | MSE loss: 0.0003 | Bpp loss: 0.97 | Aux loss: 77.01
24-04-02 17:56:26.857 - INFO: Train epoch 375: [94400/94637 (100%)] Step: [2224026] | Lr: 0.000100 | Loss: 1.3395 | MSE loss: 0.0004 | Bpp loss: 0.75 | Aux loss: 71.86
24-04-02 17:56:43.622 - INFO: Learning rate: 0.0001
24-04-02 17:56:44.945 - INFO: Train epoch 376: [    0/94637 (0%)] Step: [2224041] | Lr: 0.000100 | Loss: 0.7639 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 70.73
24-04-02 17:57:18.905 - INFO: Train epoch 376: [ 1600/94637 (2%)] Step: [2224141] | Lr: 0.000100 | Loss: 0.9507 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 77.92
24-04-02 17:57:53.207 - INFO: Train epoch 376: [ 3200/94637 (3%)] Step: [2224241] | Lr: 0.000100 | Loss: 1.4718 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 71.72
24-04-02 17:58:26.596 - INFO: Train epoch 376: [ 4800/94637 (5%)] Step: [2224341] | Lr: 0.000100 | Loss: 0.9944 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 78.73
24-04-02 17:59:00.724 - INFO: Train epoch 376: [ 6400/94637 (7%)] Step: [2224441] | Lr: 0.000100 | Loss: 0.9108 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 78.84
24-04-02 17:59:34.576 - INFO: Train epoch 376: [ 8000/94637 (8%)] Step: [2224541] | Lr: 0.000100 | Loss: 1.1706 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 71.30
24-04-02 18:00:09.189 - INFO: Train epoch 376: [ 9600/94637 (10%)] Step: [2224641] | Lr: 0.000100 | Loss: 1.1364 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 74.02
24-04-02 18:00:43.676 - INFO: Train epoch 376: [11200/94637 (12%)] Step: [2224741] | Lr: 0.000100 | Loss: 1.7840 | MSE loss: 0.0004 | Bpp loss: 1.09 | Aux loss: 74.40
24-04-02 18:01:18.027 - INFO: Train epoch 376: [12800/94637 (14%)] Step: [2224841] | Lr: 0.000100 | Loss: 1.2462 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 74.22
24-04-02 18:01:51.798 - INFO: Train epoch 376: [14400/94637 (15%)] Step: [2224941] | Lr: 0.000100 | Loss: 1.1031 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 71.39
24-04-02 18:02:28.997 - INFO: Train epoch 376: [16000/94637 (17%)] Step: [2225041] | Lr: 0.000100 | Loss: 0.6616 | MSE loss: 0.0001 | Bpp loss: 0.43 | Aux loss: 72.89
24-04-02 18:03:03.392 - INFO: Train epoch 376: [17600/94637 (19%)] Step: [2225141] | Lr: 0.000100 | Loss: 1.2717 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 75.27
24-04-02 18:03:37.610 - INFO: Train epoch 376: [19200/94637 (20%)] Step: [2225241] | Lr: 0.000100 | Loss: 1.5616 | MSE loss: 0.0003 | Bpp loss: 1.01 | Aux loss: 72.41
24-04-02 18:04:11.845 - INFO: Train epoch 376: [20800/94637 (22%)] Step: [2225341] | Lr: 0.000100 | Loss: 1.8741 | MSE loss: 0.0005 | Bpp loss: 1.12 | Aux loss: 72.62
24-04-02 18:04:46.635 - INFO: Train epoch 376: [22400/94637 (24%)] Step: [2225441] | Lr: 0.000100 | Loss: 1.0964 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 72.90
24-04-02 18:05:20.786 - INFO: Train epoch 376: [24000/94637 (25%)] Step: [2225541] | Lr: 0.000100 | Loss: 1.2735 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 70.21
24-04-02 18:05:54.576 - INFO: Train epoch 376: [25600/94637 (27%)] Step: [2225641] | Lr: 0.000100 | Loss: 1.1849 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 65.88
24-04-02 18:06:28.737 - INFO: Train epoch 376: [27200/94637 (29%)] Step: [2225741] | Lr: 0.000100 | Loss: 1.3450 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 71.54
24-04-02 18:07:03.130 - INFO: Train epoch 376: [28800/94637 (30%)] Step: [2225841] | Lr: 0.000100 | Loss: 1.0279 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 79.78
24-04-02 18:07:37.114 - INFO: Train epoch 376: [30400/94637 (32%)] Step: [2225941] | Lr: 0.000100 | Loss: 1.3068 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 80.33
24-04-02 18:08:12.140 - INFO: Train epoch 376: [32000/94637 (34%)] Step: [2226041] | Lr: 0.000100 | Loss: 1.4746 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 70.62
24-04-02 18:08:47.168 - INFO: Train epoch 376: [33600/94637 (36%)] Step: [2226141] | Lr: 0.000100 | Loss: 1.4777 | MSE loss: 0.0004 | Bpp loss: 0.85 | Aux loss: 72.97
24-04-02 18:09:21.666 - INFO: Train epoch 376: [35200/94637 (37%)] Step: [2226241] | Lr: 0.000100 | Loss: 1.5596 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 73.91
24-04-02 18:09:56.209 - INFO: Train epoch 376: [36800/94637 (39%)] Step: [2226341] | Lr: 0.000100 | Loss: 1.2151 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 74.85
24-04-02 18:10:31.716 - INFO: Train epoch 376: [38400/94637 (41%)] Step: [2226441] | Lr: 0.000100 | Loss: 1.5593 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 69.07
24-04-02 18:11:06.260 - INFO: Train epoch 376: [40000/94637 (42%)] Step: [2226541] | Lr: 0.000100 | Loss: 1.1633 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 72.92
24-04-02 18:11:41.161 - INFO: Train epoch 376: [41600/94637 (44%)] Step: [2226641] | Lr: 0.000100 | Loss: 1.4907 | MSE loss: 0.0003 | Bpp loss: 0.97 | Aux loss: 69.30
24-04-02 18:12:15.939 - INFO: Train epoch 376: [43200/94637 (46%)] Step: [2226741] | Lr: 0.000100 | Loss: 1.5635 | MSE loss: 0.0004 | Bpp loss: 0.86 | Aux loss: 72.30
24-04-02 18:12:51.215 - INFO: Train epoch 376: [44800/94637 (47%)] Step: [2226841] | Lr: 0.000100 | Loss: 1.2399 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 72.10
24-04-02 18:13:26.444 - INFO: Train epoch 376: [46400/94637 (49%)] Step: [2226941] | Lr: 0.000100 | Loss: 1.1537 | MSE loss: 0.0002 | Bpp loss: 0.76 | Aux loss: 74.52
24-04-02 18:14:00.918 - INFO: Train epoch 376: [48000/94637 (51%)] Step: [2227041] | Lr: 0.000100 | Loss: 1.4818 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 65.80
24-04-02 18:14:35.790 - INFO: Train epoch 376: [49600/94637 (52%)] Step: [2227141] | Lr: 0.000100 | Loss: 0.8171 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 69.56
24-04-02 18:15:09.543 - INFO: Train epoch 376: [51200/94637 (54%)] Step: [2227241] | Lr: 0.000100 | Loss: 0.8285 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 69.15
24-04-02 18:15:44.354 - INFO: Train epoch 376: [52800/94637 (56%)] Step: [2227341] | Lr: 0.000100 | Loss: 1.1610 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 68.58
24-04-02 18:16:19.260 - INFO: Train epoch 376: [54400/94637 (57%)] Step: [2227441] | Lr: 0.000100 | Loss: 1.5765 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 69.50
24-04-02 18:16:55.460 - INFO: Train epoch 376: [56000/94637 (59%)] Step: [2227541] | Lr: 0.000100 | Loss: 1.5611 | MSE loss: 0.0003 | Bpp loss: 1.02 | Aux loss: 71.43
24-04-02 18:17:30.527 - INFO: Train epoch 376: [57600/94637 (61%)] Step: [2227641] | Lr: 0.000100 | Loss: 0.9646 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 65.84
24-04-02 18:18:05.226 - INFO: Train epoch 376: [59200/94637 (63%)] Step: [2227741] | Lr: 0.000100 | Loss: 1.5488 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 69.77
24-04-02 18:18:40.469 - INFO: Train epoch 376: [60800/94637 (64%)] Step: [2227841] | Lr: 0.000100 | Loss: 1.0603 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 69.34
24-04-02 18:19:15.298 - INFO: Train epoch 376: [62400/94637 (66%)] Step: [2227941] | Lr: 0.000100 | Loss: 0.9417 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 73.64
24-04-02 18:19:50.063 - INFO: Train epoch 376: [64000/94637 (68%)] Step: [2228041] | Lr: 0.000100 | Loss: 1.0482 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 71.59
24-04-02 18:20:24.776 - INFO: Train epoch 376: [65600/94637 (69%)] Step: [2228141] | Lr: 0.000100 | Loss: 1.8517 | MSE loss: 0.0005 | Bpp loss: 1.03 | Aux loss: 70.29
24-04-02 18:21:00.021 - INFO: Train epoch 376: [67200/94637 (71%)] Step: [2228241] | Lr: 0.000100 | Loss: 1.3304 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 72.38
24-04-02 18:21:35.263 - INFO: Train epoch 376: [68800/94637 (73%)] Step: [2228341] | Lr: 0.000100 | Loss: 0.6448 | MSE loss: 0.0001 | Bpp loss: 0.41 | Aux loss: 72.45
24-04-02 18:22:10.202 - INFO: Train epoch 376: [70400/94637 (74%)] Step: [2228441] | Lr: 0.000100 | Loss: 1.5514 | MSE loss: 0.0004 | Bpp loss: 0.88 | Aux loss: 72.02
24-04-02 18:22:45.159 - INFO: Train epoch 376: [72000/94637 (76%)] Step: [2228541] | Lr: 0.000100 | Loss: 1.2039 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 68.16
24-04-02 18:23:21.158 - INFO: Train epoch 376: [73600/94637 (78%)] Step: [2228641] | Lr: 0.000100 | Loss: 1.2563 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 71.33
24-04-02 18:23:55.937 - INFO: Train epoch 376: [75200/94637 (79%)] Step: [2228741] | Lr: 0.000100 | Loss: 1.9499 | MSE loss: 0.0006 | Bpp loss: 0.93 | Aux loss: 75.71
24-04-02 18:24:30.790 - INFO: Train epoch 376: [76800/94637 (81%)] Step: [2228841] | Lr: 0.000100 | Loss: 0.8318 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 70.09
24-04-02 18:25:05.738 - INFO: Train epoch 376: [78400/94637 (83%)] Step: [2228941] | Lr: 0.000100 | Loss: 1.1852 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 72.92
24-04-02 18:25:40.534 - INFO: Train epoch 376: [80000/94637 (85%)] Step: [2229041] | Lr: 0.000100 | Loss: 0.8224 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 70.63
24-04-02 18:26:15.778 - INFO: Train epoch 376: [81600/94637 (86%)] Step: [2229141] | Lr: 0.000100 | Loss: 1.3604 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 78.12
24-04-02 18:26:50.197 - INFO: Train epoch 376: [83200/94637 (88%)] Step: [2229241] | Lr: 0.000100 | Loss: 0.7110 | MSE loss: 0.0002 | Bpp loss: 0.46 | Aux loss: 72.09
24-04-02 18:27:24.131 - INFO: Train epoch 376: [84800/94637 (90%)] Step: [2229341] | Lr: 0.000100 | Loss: 1.5006 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 66.91
24-04-02 18:27:58.488 - INFO: Train epoch 376: [86400/94637 (91%)] Step: [2229441] | Lr: 0.000100 | Loss: 1.1772 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 70.60
24-04-02 18:28:32.830 - INFO: Train epoch 376: [88000/94637 (93%)] Step: [2229541] | Lr: 0.000100 | Loss: 0.8742 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 68.61
24-04-02 18:29:06.159 - INFO: Train epoch 376: [89600/94637 (95%)] Step: [2229641] | Lr: 0.000100 | Loss: 1.8487 | MSE loss: 0.0005 | Bpp loss: 1.04 | Aux loss: 73.73
24-04-02 18:29:40.210 - INFO: Train epoch 376: [91200/94637 (96%)] Step: [2229741] | Lr: 0.000100 | Loss: 0.9999 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 73.26
24-04-02 18:30:14.434 - INFO: Train epoch 376: [92800/94637 (98%)] Step: [2229841] | Lr: 0.000100 | Loss: 1.3862 | MSE loss: 0.0004 | Bpp loss: 0.80 | Aux loss: 70.89
24-04-02 18:30:48.977 - INFO: Train epoch 376: [94400/94637 (100%)] Step: [2229941] | Lr: 0.000100 | Loss: 1.5555 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 67.72
24-04-02 18:31:05.616 - INFO: Learning rate: 0.0001
24-04-02 18:31:06.595 - INFO: Train epoch 377: [    0/94637 (0%)] Step: [2229956] | Lr: 0.000100 | Loss: 1.8697 | MSE loss: 0.0004 | Bpp loss: 1.14 | Aux loss: 65.93
24-04-02 18:31:42.533 - INFO: Train epoch 377: [ 1600/94637 (2%)] Step: [2230056] | Lr: 0.000100 | Loss: 1.6193 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 68.98
24-04-02 18:32:17.597 - INFO: Train epoch 377: [ 3200/94637 (3%)] Step: [2230156] | Lr: 0.000100 | Loss: 1.4683 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 74.11
24-04-02 18:32:52.348 - INFO: Train epoch 377: [ 4800/94637 (5%)] Step: [2230256] | Lr: 0.000100 | Loss: 1.3073 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 70.30
24-04-02 18:33:26.013 - INFO: Train epoch 377: [ 6400/94637 (7%)] Step: [2230356] | Lr: 0.000100 | Loss: 1.2545 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 74.97
24-04-02 18:34:00.342 - INFO: Train epoch 377: [ 8000/94637 (8%)] Step: [2230456] | Lr: 0.000100 | Loss: 0.8653 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 64.90
24-04-02 18:34:34.182 - INFO: Train epoch 377: [ 9600/94637 (10%)] Step: [2230556] | Lr: 0.000100 | Loss: 1.0684 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 69.25
24-04-02 18:35:09.537 - INFO: Train epoch 377: [11200/94637 (12%)] Step: [2230656] | Lr: 0.000100 | Loss: 1.2420 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 75.49
24-04-02 18:35:43.873 - INFO: Train epoch 377: [12800/94637 (14%)] Step: [2230756] | Lr: 0.000100 | Loss: 1.4812 | MSE loss: 0.0004 | Bpp loss: 0.88 | Aux loss: 67.08
24-04-02 18:36:18.092 - INFO: Train epoch 377: [14400/94637 (15%)] Step: [2230856] | Lr: 0.000100 | Loss: 1.3865 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 69.06
24-04-02 18:36:52.922 - INFO: Train epoch 377: [16000/94637 (17%)] Step: [2230956] | Lr: 0.000100 | Loss: 1.2811 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 65.86
24-04-02 18:37:26.607 - INFO: Train epoch 377: [17600/94637 (19%)] Step: [2231056] | Lr: 0.000100 | Loss: 1.3585 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 68.57
24-04-02 18:38:01.587 - INFO: Train epoch 377: [19200/94637 (20%)] Step: [2231156] | Lr: 0.000100 | Loss: 1.3469 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 69.53
24-04-02 18:38:36.869 - INFO: Train epoch 377: [20800/94637 (22%)] Step: [2231256] | Lr: 0.000100 | Loss: 1.8086 | MSE loss: 0.0004 | Bpp loss: 1.08 | Aux loss: 70.70
24-04-02 18:39:11.535 - INFO: Train epoch 377: [22400/94637 (24%)] Step: [2231356] | Lr: 0.000100 | Loss: 1.9853 | MSE loss: 0.0006 | Bpp loss: 1.06 | Aux loss: 68.40
24-04-02 18:39:46.059 - INFO: Train epoch 377: [24000/94637 (25%)] Step: [2231456] | Lr: 0.000100 | Loss: 1.7442 | MSE loss: 0.0005 | Bpp loss: 0.94 | Aux loss: 70.73
24-04-02 18:40:20.868 - INFO: Train epoch 377: [25600/94637 (27%)] Step: [2231556] | Lr: 0.000100 | Loss: 0.9804 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 75.83
24-04-02 18:40:55.163 - INFO: Train epoch 377: [27200/94637 (29%)] Step: [2231656] | Lr: 0.000100 | Loss: 0.9878 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 69.38
24-04-02 18:41:29.913 - INFO: Train epoch 377: [28800/94637 (30%)] Step: [2231756] | Lr: 0.000100 | Loss: 1.3427 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 69.31
24-04-02 18:42:04.881 - INFO: Train epoch 377: [30400/94637 (32%)] Step: [2231856] | Lr: 0.000100 | Loss: 1.2037 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 69.30
24-04-02 18:42:39.939 - INFO: Train epoch 377: [32000/94637 (34%)] Step: [2231956] | Lr: 0.000100 | Loss: 0.9328 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 67.19
24-04-02 18:43:14.575 - INFO: Train epoch 377: [33600/94637 (36%)] Step: [2232056] | Lr: 0.000100 | Loss: 1.5993 | MSE loss: 0.0004 | Bpp loss: 0.99 | Aux loss: 73.83
24-04-02 18:43:48.895 - INFO: Train epoch 377: [35200/94637 (37%)] Step: [2232156] | Lr: 0.000100 | Loss: 1.5804 | MSE loss: 0.0005 | Bpp loss: 0.85 | Aux loss: 66.89
24-04-02 18:44:23.455 - INFO: Train epoch 377: [36800/94637 (39%)] Step: [2232256] | Lr: 0.000100 | Loss: 0.9872 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 67.35
24-04-02 18:44:58.245 - INFO: Train epoch 377: [38400/94637 (41%)] Step: [2232356] | Lr: 0.000100 | Loss: 1.4202 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 76.25
24-04-02 18:45:32.612 - INFO: Train epoch 377: [40000/94637 (42%)] Step: [2232456] | Lr: 0.000100 | Loss: 1.5242 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 74.14
24-04-02 18:46:09.240 - INFO: Train epoch 377: [41600/94637 (44%)] Step: [2232556] | Lr: 0.000100 | Loss: 1.5228 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 73.15
24-04-02 18:46:42.967 - INFO: Train epoch 377: [43200/94637 (46%)] Step: [2232656] | Lr: 0.000100 | Loss: 1.5295 | MSE loss: 0.0003 | Bpp loss: 0.97 | Aux loss: 65.40
24-04-02 18:47:18.129 - INFO: Train epoch 377: [44800/94637 (47%)] Step: [2232756] | Lr: 0.000100 | Loss: 1.5839 | MSE loss: 0.0004 | Bpp loss: 0.93 | Aux loss: 70.09
24-04-02 18:47:51.978 - INFO: Train epoch 377: [46400/94637 (49%)] Step: [2232856] | Lr: 0.000100 | Loss: 1.5472 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 67.86
24-04-02 18:48:26.104 - INFO: Train epoch 377: [48000/94637 (51%)] Step: [2232956] | Lr: 0.000100 | Loss: 1.1643 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 72.39
24-04-02 18:49:00.260 - INFO: Train epoch 377: [49600/94637 (52%)] Step: [2233056] | Lr: 0.000100 | Loss: 2.0719 | MSE loss: 0.0005 | Bpp loss: 1.26 | Aux loss: 74.58
24-04-02 18:49:34.357 - INFO: Train epoch 377: [51200/94637 (54%)] Step: [2233156] | Lr: 0.000100 | Loss: 1.2476 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 75.16
24-04-02 18:50:08.730 - INFO: Train epoch 377: [52800/94637 (56%)] Step: [2233256] | Lr: 0.000100 | Loss: 0.8303 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 68.51
24-04-02 18:50:42.826 - INFO: Train epoch 377: [54400/94637 (57%)] Step: [2233356] | Lr: 0.000100 | Loss: 1.3323 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 70.73
24-04-02 18:51:17.572 - INFO: Train epoch 377: [56000/94637 (59%)] Step: [2233456] | Lr: 0.000100 | Loss: 1.8645 | MSE loss: 0.0005 | Bpp loss: 1.11 | Aux loss: 70.24
24-04-02 18:51:51.940 - INFO: Train epoch 377: [57600/94637 (61%)] Step: [2233556] | Lr: 0.000100 | Loss: 0.8603 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 69.55
24-04-02 18:52:26.867 - INFO: Train epoch 377: [59200/94637 (63%)] Step: [2233656] | Lr: 0.000100 | Loss: 0.9651 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 66.34
24-04-02 18:53:01.618 - INFO: Train epoch 377: [60800/94637 (64%)] Step: [2233756] | Lr: 0.000100 | Loss: 1.6238 | MSE loss: 0.0004 | Bpp loss: 0.93 | Aux loss: 67.86
24-04-02 18:53:36.479 - INFO: Train epoch 377: [62400/94637 (66%)] Step: [2233856] | Lr: 0.000100 | Loss: 1.0361 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 71.02
24-04-02 18:54:11.165 - INFO: Train epoch 377: [64000/94637 (68%)] Step: [2233956] | Lr: 0.000100 | Loss: 1.1034 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 69.79
24-04-02 18:54:45.847 - INFO: Train epoch 377: [65600/94637 (69%)] Step: [2234056] | Lr: 0.000100 | Loss: 1.1707 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 75.14
24-04-02 18:55:20.207 - INFO: Train epoch 377: [67200/94637 (71%)] Step: [2234156] | Lr: 0.000100 | Loss: 1.0859 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 69.63
24-04-02 18:55:54.431 - INFO: Train epoch 377: [68800/94637 (73%)] Step: [2234256] | Lr: 0.000100 | Loss: 1.2250 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 67.44
24-04-02 18:56:28.920 - INFO: Train epoch 377: [70400/94637 (74%)] Step: [2234356] | Lr: 0.000100 | Loss: 1.2543 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 74.89
24-04-02 18:57:03.453 - INFO: Train epoch 377: [72000/94637 (76%)] Step: [2234456] | Lr: 0.000100 | Loss: 1.3215 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 69.94
24-04-02 18:57:37.445 - INFO: Train epoch 377: [73600/94637 (78%)] Step: [2234556] | Lr: 0.000100 | Loss: 1.2922 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 72.73
24-04-02 18:58:12.274 - INFO: Train epoch 377: [75200/94637 (79%)] Step: [2234656] | Lr: 0.000100 | Loss: 0.7532 | MSE loss: 0.0001 | Bpp loss: 0.52 | Aux loss: 71.74
24-04-02 18:58:45.932 - INFO: Train epoch 377: [76800/94637 (81%)] Step: [2234756] | Lr: 0.000100 | Loss: 1.0334 | MSE loss: 0.0003 | Bpp loss: 0.60 | Aux loss: 66.66
24-04-02 18:59:19.428 - INFO: Train epoch 377: [78400/94637 (83%)] Step: [2234856] | Lr: 0.000100 | Loss: 2.0932 | MSE loss: 0.0005 | Bpp loss: 1.26 | Aux loss: 69.25
24-04-02 18:59:53.550 - INFO: Train epoch 377: [80000/94637 (85%)] Step: [2234956] | Lr: 0.000100 | Loss: 1.6973 | MSE loss: 0.0004 | Bpp loss: 1.06 | Aux loss: 68.40
24-04-02 19:00:29.826 - INFO: Train epoch 377: [81600/94637 (86%)] Step: [2235056] | Lr: 0.000100 | Loss: 1.6147 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 68.52
24-04-02 19:01:04.404 - INFO: Train epoch 377: [83200/94637 (88%)] Step: [2235156] | Lr: 0.000100 | Loss: 1.4959 | MSE loss: 0.0004 | Bpp loss: 0.83 | Aux loss: 75.25
24-04-02 19:01:39.341 - INFO: Train epoch 377: [84800/94637 (90%)] Step: [2235256] | Lr: 0.000100 | Loss: 1.2224 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 70.46
24-04-02 19:02:13.725 - INFO: Train epoch 377: [86400/94637 (91%)] Step: [2235356] | Lr: 0.000100 | Loss: 1.4751 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 68.52
24-04-02 19:02:48.947 - INFO: Train epoch 377: [88000/94637 (93%)] Step: [2235456] | Lr: 0.000100 | Loss: 0.7571 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 74.50
24-04-02 19:03:24.073 - INFO: Train epoch 377: [89600/94637 (95%)] Step: [2235556] | Lr: 0.000100 | Loss: 1.2898 | MSE loss: 0.0004 | Bpp loss: 0.71 | Aux loss: 63.45
24-04-02 19:03:58.784 - INFO: Train epoch 377: [91200/94637 (96%)] Step: [2235656] | Lr: 0.000100 | Loss: 1.3821 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 73.43
24-04-02 19:04:33.162 - INFO: Train epoch 377: [92800/94637 (98%)] Step: [2235756] | Lr: 0.000100 | Loss: 0.9756 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 71.24
24-04-02 19:05:07.767 - INFO: Train epoch 377: [94400/94637 (100%)] Step: [2235856] | Lr: 0.000100 | Loss: 1.7955 | MSE loss: 0.0004 | Bpp loss: 1.12 | Aux loss: 74.23
24-04-02 19:05:24.230 - INFO: Learning rate: 0.0001
24-04-02 19:05:25.178 - INFO: Train epoch 378: [    0/94637 (0%)] Step: [2235871] | Lr: 0.000100 | Loss: 1.4051 | MSE loss: 0.0004 | Bpp loss: 0.82 | Aux loss: 68.51
24-04-02 19:05:59.459 - INFO: Train epoch 378: [ 1600/94637 (2%)] Step: [2235971] | Lr: 0.000100 | Loss: 0.8447 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 74.42
24-04-02 19:06:33.562 - INFO: Train epoch 378: [ 3200/94637 (3%)] Step: [2236071] | Lr: 0.000100 | Loss: 0.9383 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 70.38
24-04-02 19:07:07.641 - INFO: Train epoch 378: [ 4800/94637 (5%)] Step: [2236171] | Lr: 0.000100 | Loss: 0.9231 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 72.34
24-04-02 19:07:42.161 - INFO: Train epoch 378: [ 6400/94637 (7%)] Step: [2236271] | Lr: 0.000100 | Loss: 1.6598 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 70.92
24-04-02 19:08:17.028 - INFO: Train epoch 378: [ 8000/94637 (8%)] Step: [2236371] | Lr: 0.000100 | Loss: 1.6334 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 69.00
24-04-02 19:08:52.008 - INFO: Train epoch 378: [ 9600/94637 (10%)] Step: [2236471] | Lr: 0.000100 | Loss: 1.3993 | MSE loss: 0.0004 | Bpp loss: 0.82 | Aux loss: 70.93
24-04-02 19:09:25.790 - INFO: Train epoch 378: [11200/94637 (12%)] Step: [2236571] | Lr: 0.000100 | Loss: 1.0705 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 72.62
24-04-02 19:09:59.558 - INFO: Train epoch 378: [12800/94637 (14%)] Step: [2236671] | Lr: 0.000100 | Loss: 1.8881 | MSE loss: 0.0005 | Bpp loss: 1.15 | Aux loss: 72.78
24-04-02 19:10:33.816 - INFO: Train epoch 378: [14400/94637 (15%)] Step: [2236771] | Lr: 0.000100 | Loss: 1.4651 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 69.11
24-04-02 19:11:08.498 - INFO: Train epoch 378: [16000/94637 (17%)] Step: [2236871] | Lr: 0.000100 | Loss: 1.0263 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 64.68
24-04-02 19:11:42.971 - INFO: Train epoch 378: [17600/94637 (19%)] Step: [2236971] | Lr: 0.000100 | Loss: 1.0835 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 70.62
24-04-02 19:12:18.103 - INFO: Train epoch 378: [19200/94637 (20%)] Step: [2237071] | Lr: 0.000100 | Loss: 1.1421 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 69.26
24-04-02 19:12:52.384 - INFO: Train epoch 378: [20800/94637 (22%)] Step: [2237171] | Lr: 0.000100 | Loss: 1.3376 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 73.00
24-04-02 19:13:27.609 - INFO: Train epoch 378: [22400/94637 (24%)] Step: [2237271] | Lr: 0.000100 | Loss: 1.4154 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 74.55
24-04-02 19:14:02.749 - INFO: Train epoch 378: [24000/94637 (25%)] Step: [2237371] | Lr: 0.000100 | Loss: 1.7620 | MSE loss: 0.0004 | Bpp loss: 1.09 | Aux loss: 71.62
24-04-02 19:14:38.275 - INFO: Train epoch 378: [25600/94637 (27%)] Step: [2237471] | Lr: 0.000100 | Loss: 1.3531 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 73.32
24-04-02 19:15:15.855 - INFO: Train epoch 378: [27200/94637 (29%)] Step: [2237571] | Lr: 0.000100 | Loss: 1.2410 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 70.45
24-04-02 19:15:51.070 - INFO: Train epoch 378: [28800/94637 (30%)] Step: [2237671] | Lr: 0.000100 | Loss: 0.9710 | MSE loss: 0.0003 | Bpp loss: 0.56 | Aux loss: 66.56
24-04-02 19:16:26.305 - INFO: Train epoch 378: [30400/94637 (32%)] Step: [2237771] | Lr: 0.000100 | Loss: 1.6364 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 70.72
24-04-02 19:17:00.820 - INFO: Train epoch 378: [32000/94637 (34%)] Step: [2237871] | Lr: 0.000100 | Loss: 0.8985 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 73.12
24-04-02 19:17:35.914 - INFO: Train epoch 378: [33600/94637 (36%)] Step: [2237971] | Lr: 0.000100 | Loss: 1.3728 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 70.13
24-04-02 19:18:10.538 - INFO: Train epoch 378: [35200/94637 (37%)] Step: [2238071] | Lr: 0.000100 | Loss: 1.2825 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 68.57
24-04-02 19:18:45.266 - INFO: Train epoch 378: [36800/94637 (39%)] Step: [2238171] | Lr: 0.000100 | Loss: 2.0205 | MSE loss: 0.0006 | Bpp loss: 1.10 | Aux loss: 65.92
24-04-02 19:19:19.575 - INFO: Train epoch 378: [38400/94637 (41%)] Step: [2238271] | Lr: 0.000100 | Loss: 1.5086 | MSE loss: 0.0005 | Bpp loss: 0.71 | Aux loss: 73.32
24-04-02 19:19:54.340 - INFO: Train epoch 378: [40000/94637 (42%)] Step: [2238371] | Lr: 0.000100 | Loss: 1.2855 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 71.54
24-04-02 19:20:29.208 - INFO: Train epoch 378: [41600/94637 (44%)] Step: [2238471] | Lr: 0.000100 | Loss: 1.2586 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 68.91
24-04-02 19:21:03.705 - INFO: Train epoch 378: [43200/94637 (46%)] Step: [2238571] | Lr: 0.000100 | Loss: 1.3074 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 70.96
24-04-02 19:21:38.360 - INFO: Train epoch 378: [44800/94637 (47%)] Step: [2238671] | Lr: 0.000100 | Loss: 1.5649 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 65.94
24-04-02 19:22:13.252 - INFO: Train epoch 378: [46400/94637 (49%)] Step: [2238771] | Lr: 0.000100 | Loss: 1.7460 | MSE loss: 0.0004 | Bpp loss: 1.03 | Aux loss: 67.44
24-04-02 19:22:48.022 - INFO: Train epoch 378: [48000/94637 (51%)] Step: [2238871] | Lr: 0.000100 | Loss: 0.9563 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 66.00
24-04-02 19:23:23.165 - INFO: Train epoch 378: [49600/94637 (52%)] Step: [2238971] | Lr: 0.000100 | Loss: 1.2754 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 68.57
24-04-02 19:23:57.745 - INFO: Train epoch 378: [51200/94637 (54%)] Step: [2239071] | Lr: 0.000100 | Loss: 1.3080 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 70.32
24-04-02 19:24:32.421 - INFO: Train epoch 378: [52800/94637 (56%)] Step: [2239171] | Lr: 0.000100 | Loss: 1.7163 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 67.71
24-04-02 19:25:07.204 - INFO: Train epoch 378: [54400/94637 (57%)] Step: [2239271] | Lr: 0.000100 | Loss: 1.4617 | MSE loss: 0.0004 | Bpp loss: 0.82 | Aux loss: 74.46
24-04-02 19:25:41.955 - INFO: Train epoch 378: [56000/94637 (59%)] Step: [2239371] | Lr: 0.000100 | Loss: 1.7260 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 71.05
24-04-02 19:26:16.365 - INFO: Train epoch 378: [57600/94637 (61%)] Step: [2239471] | Lr: 0.000100 | Loss: 1.3809 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 69.01
24-04-02 19:26:51.647 - INFO: Train epoch 378: [59200/94637 (63%)] Step: [2239571] | Lr: 0.000100 | Loss: 0.9186 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 74.76
24-04-02 19:27:26.701 - INFO: Train epoch 378: [60800/94637 (64%)] Step: [2239671] | Lr: 0.000100 | Loss: 0.8310 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 72.76
24-04-02 19:28:01.110 - INFO: Train epoch 378: [62400/94637 (66%)] Step: [2239771] | Lr: 0.000100 | Loss: 2.0225 | MSE loss: 0.0005 | Bpp loss: 1.19 | Aux loss: 69.02
24-04-02 19:28:35.727 - INFO: Train epoch 378: [64000/94637 (68%)] Step: [2239871] | Lr: 0.000100 | Loss: 1.4800 | MSE loss: 0.0004 | Bpp loss: 0.88 | Aux loss: 71.49
24-04-02 19:29:10.709 - INFO: Train epoch 378: [65600/94637 (69%)] Step: [2239971] | Lr: 0.000100 | Loss: 1.4940 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 69.82
24-04-02 19:29:48.628 - INFO: Train epoch 378: [67200/94637 (71%)] Step: [2240071] | Lr: 0.000100 | Loss: 1.1788 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 68.51
24-04-02 19:30:23.835 - INFO: Train epoch 378: [68800/94637 (73%)] Step: [2240171] | Lr: 0.000100 | Loss: 1.7722 | MSE loss: 0.0005 | Bpp loss: 1.01 | Aux loss: 67.94
24-04-02 19:30:59.250 - INFO: Train epoch 378: [70400/94637 (74%)] Step: [2240271] | Lr: 0.000100 | Loss: 1.4574 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 68.92
24-04-02 19:31:33.896 - INFO: Train epoch 378: [72000/94637 (76%)] Step: [2240371] | Lr: 0.000100 | Loss: 1.2443 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 70.07
24-04-02 19:32:07.685 - INFO: Train epoch 378: [73600/94637 (78%)] Step: [2240471] | Lr: 0.000100 | Loss: 1.2423 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 75.91
24-04-02 19:32:42.564 - INFO: Train epoch 378: [75200/94637 (79%)] Step: [2240571] | Lr: 0.000100 | Loss: 0.8296 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 70.00
24-04-02 19:33:16.609 - INFO: Train epoch 378: [76800/94637 (81%)] Step: [2240671] | Lr: 0.000100 | Loss: 1.6381 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 75.51
24-04-02 19:33:50.817 - INFO: Train epoch 378: [78400/94637 (83%)] Step: [2240771] | Lr: 0.000100 | Loss: 0.8312 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 68.65
24-04-02 19:34:25.341 - INFO: Train epoch 378: [80000/94637 (85%)] Step: [2240871] | Lr: 0.000100 | Loss: 1.3285 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 62.87
24-04-02 19:34:58.552 - INFO: Train epoch 378: [81600/94637 (86%)] Step: [2240971] | Lr: 0.000100 | Loss: 1.7418 | MSE loss: 0.0004 | Bpp loss: 1.07 | Aux loss: 66.86
24-04-02 19:35:32.196 - INFO: Train epoch 378: [83200/94637 (88%)] Step: [2241071] | Lr: 0.000100 | Loss: 1.2812 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 66.42
24-04-02 19:36:06.354 - INFO: Train epoch 378: [84800/94637 (90%)] Step: [2241171] | Lr: 0.000100 | Loss: 1.2979 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 69.07
24-04-02 19:36:39.881 - INFO: Train epoch 378: [86400/94637 (91%)] Step: [2241271] | Lr: 0.000100 | Loss: 1.0292 | MSE loss: 0.0003 | Bpp loss: 0.62 | Aux loss: 70.06
24-04-02 19:37:13.684 - INFO: Train epoch 378: [88000/94637 (93%)] Step: [2241371] | Lr: 0.000100 | Loss: 0.9675 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 66.81
24-04-02 19:37:48.057 - INFO: Train epoch 378: [89600/94637 (95%)] Step: [2241471] | Lr: 0.000100 | Loss: 1.2655 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 61.23
24-04-02 19:38:22.566 - INFO: Train epoch 378: [91200/94637 (96%)] Step: [2241571] | Lr: 0.000100 | Loss: 1.4672 | MSE loss: 0.0003 | Bpp loss: 0.97 | Aux loss: 65.77
24-04-02 19:38:56.853 - INFO: Train epoch 378: [92800/94637 (98%)] Step: [2241671] | Lr: 0.000100 | Loss: 0.9017 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 60.39
24-04-02 19:39:31.341 - INFO: Train epoch 378: [94400/94637 (100%)] Step: [2241771] | Lr: 0.000100 | Loss: 1.0861 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 60.69
24-04-02 19:39:47.792 - INFO: Learning rate: 0.0001
24-04-02 19:39:48.783 - INFO: Train epoch 379: [    0/94637 (0%)] Step: [2241786] | Lr: 0.000100 | Loss: 1.3632 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 58.51
24-04-02 19:40:23.370 - INFO: Train epoch 379: [ 1600/94637 (2%)] Step: [2241886] | Lr: 0.000100 | Loss: 1.3660 | MSE loss: 0.0004 | Bpp loss: 0.77 | Aux loss: 60.05
24-04-02 19:40:57.917 - INFO: Train epoch 379: [ 3200/94637 (3%)] Step: [2241986] | Lr: 0.000100 | Loss: 1.7416 | MSE loss: 0.0004 | Bpp loss: 1.11 | Aux loss: 60.61
24-04-02 19:41:32.462 - INFO: Train epoch 379: [ 4800/94637 (5%)] Step: [2242086] | Lr: 0.000100 | Loss: 1.2973 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 60.02
24-04-02 19:42:07.108 - INFO: Train epoch 379: [ 6400/94637 (7%)] Step: [2242186] | Lr: 0.000100 | Loss: 0.8163 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 62.84
24-04-02 19:42:41.758 - INFO: Train epoch 379: [ 8000/94637 (8%)] Step: [2242286] | Lr: 0.000100 | Loss: 1.5237 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 60.89
24-04-02 19:43:17.412 - INFO: Train epoch 379: [ 9600/94637 (10%)] Step: [2242386] | Lr: 0.000100 | Loss: 0.8837 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 64.59
24-04-02 19:43:51.862 - INFO: Train epoch 379: [11200/94637 (12%)] Step: [2242486] | Lr: 0.000100 | Loss: 1.2165 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 62.47
24-04-02 19:44:28.382 - INFO: Train epoch 379: [12800/94637 (14%)] Step: [2242586] | Lr: 0.000100 | Loss: 1.2860 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 61.51
24-04-02 19:45:02.384 - INFO: Train epoch 379: [14400/94637 (15%)] Step: [2242686] | Lr: 0.000100 | Loss: 1.4489 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 63.80
24-04-02 19:45:36.465 - INFO: Train epoch 379: [16000/94637 (17%)] Step: [2242786] | Lr: 0.000100 | Loss: 0.9335 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 66.28
24-04-02 19:46:10.321 - INFO: Train epoch 379: [17600/94637 (19%)] Step: [2242886] | Lr: 0.000100 | Loss: 0.9682 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 58.91
24-04-02 19:46:45.347 - INFO: Train epoch 379: [19200/94637 (20%)] Step: [2242986] | Lr: 0.000100 | Loss: 0.7878 | MSE loss: 0.0002 | Bpp loss: 0.48 | Aux loss: 63.37
24-04-02 19:47:19.902 - INFO: Train epoch 379: [20800/94637 (22%)] Step: [2243086] | Lr: 0.000100 | Loss: 1.1031 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 60.09
24-04-02 19:47:54.118 - INFO: Train epoch 379: [22400/94637 (24%)] Step: [2243186] | Lr: 0.000100 | Loss: 1.3680 | MSE loss: 0.0004 | Bpp loss: 0.70 | Aux loss: 66.75
24-04-02 19:48:28.401 - INFO: Train epoch 379: [24000/94637 (25%)] Step: [2243286] | Lr: 0.000100 | Loss: 1.7226 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 60.95
24-04-02 19:49:02.309 - INFO: Train epoch 379: [25600/94637 (27%)] Step: [2243386] | Lr: 0.000100 | Loss: 2.3737 | MSE loss: 0.0006 | Bpp loss: 1.33 | Aux loss: 62.64
24-04-02 19:49:37.098 - INFO: Train epoch 379: [27200/94637 (29%)] Step: [2243486] | Lr: 0.000100 | Loss: 0.7357 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 64.28
24-04-02 19:50:11.847 - INFO: Train epoch 379: [28800/94637 (30%)] Step: [2243586] | Lr: 0.000100 | Loss: 1.2484 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 72.61
24-04-02 19:50:46.429 - INFO: Train epoch 379: [30400/94637 (32%)] Step: [2243686] | Lr: 0.000100 | Loss: 0.8334 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 61.60
24-04-02 19:51:20.131 - INFO: Train epoch 379: [32000/94637 (34%)] Step: [2243786] | Lr: 0.000100 | Loss: 0.8957 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 67.44
24-04-02 19:51:55.141 - INFO: Train epoch 379: [33600/94637 (36%)] Step: [2243886] | Lr: 0.000100 | Loss: 1.3239 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 61.96
24-04-02 19:52:29.557 - INFO: Train epoch 379: [35200/94637 (37%)] Step: [2243986] | Lr: 0.000100 | Loss: 1.3517 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 61.01
24-04-02 19:53:04.402 - INFO: Train epoch 379: [36800/94637 (39%)] Step: [2244086] | Lr: 0.000100 | Loss: 1.0858 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 62.58
24-04-02 19:53:39.163 - INFO: Train epoch 379: [38400/94637 (41%)] Step: [2244186] | Lr: 0.000100 | Loss: 1.1117 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 60.93
24-04-02 19:54:13.700 - INFO: Train epoch 379: [40000/94637 (42%)] Step: [2244286] | Lr: 0.000100 | Loss: 1.0864 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 64.47
24-04-02 19:54:48.934 - INFO: Train epoch 379: [41600/94637 (44%)] Step: [2244386] | Lr: 0.000100 | Loss: 1.6349 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 58.91
24-04-02 19:55:24.120 - INFO: Train epoch 379: [43200/94637 (46%)] Step: [2244486] | Lr: 0.000100 | Loss: 1.0313 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 60.77
24-04-02 19:55:59.102 - INFO: Train epoch 379: [44800/94637 (47%)] Step: [2244586] | Lr: 0.000100 | Loss: 0.6140 | MSE loss: 0.0001 | Bpp loss: 0.43 | Aux loss: 62.41
24-04-02 19:56:34.898 - INFO: Train epoch 379: [46400/94637 (49%)] Step: [2244686] | Lr: 0.000100 | Loss: 1.5071 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 54.35
24-04-02 19:57:09.802 - INFO: Train epoch 379: [48000/94637 (51%)] Step: [2244786] | Lr: 0.000100 | Loss: 1.6116 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 60.30
24-04-02 19:57:44.543 - INFO: Train epoch 379: [49600/94637 (52%)] Step: [2244886] | Lr: 0.000100 | Loss: 1.2729 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 65.84
24-04-02 19:58:19.256 - INFO: Train epoch 379: [51200/94637 (54%)] Step: [2244986] | Lr: 0.000100 | Loss: 1.0004 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 61.84
24-04-02 19:58:55.881 - INFO: Train epoch 379: [52800/94637 (56%)] Step: [2245086] | Lr: 0.000100 | Loss: 0.7005 | MSE loss: 0.0002 | Bpp loss: 0.43 | Aux loss: 68.89
24-04-02 19:59:30.619 - INFO: Train epoch 379: [54400/94637 (57%)] Step: [2245186] | Lr: 0.000100 | Loss: 1.2527 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 60.24
24-04-02 20:00:04.875 - INFO: Train epoch 379: [56000/94637 (59%)] Step: [2245286] | Lr: 0.000100 | Loss: 1.2573 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 63.05
24-04-02 20:00:39.269 - INFO: Train epoch 379: [57600/94637 (61%)] Step: [2245386] | Lr: 0.000100 | Loss: 1.6000 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 59.70
24-04-02 20:01:14.089 - INFO: Train epoch 379: [59200/94637 (63%)] Step: [2245486] | Lr: 0.000100 | Loss: 1.2635 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 63.19
24-04-02 20:01:48.469 - INFO: Train epoch 379: [60800/94637 (64%)] Step: [2245586] | Lr: 0.000100 | Loss: 1.3366 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 65.24
24-04-02 20:02:23.826 - INFO: Train epoch 379: [62400/94637 (66%)] Step: [2245686] | Lr: 0.000100 | Loss: 0.7145 | MSE loss: 0.0002 | Bpp loss: 0.43 | Aux loss: 63.70
24-04-02 20:02:58.019 - INFO: Train epoch 379: [64000/94637 (68%)] Step: [2245786] | Lr: 0.000100 | Loss: 0.9881 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 61.22
24-04-02 20:03:32.535 - INFO: Train epoch 379: [65600/94637 (69%)] Step: [2245886] | Lr: 0.000100 | Loss: 0.9474 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 63.16
24-04-02 20:04:07.562 - INFO: Train epoch 379: [67200/94637 (71%)] Step: [2245986] | Lr: 0.000100 | Loss: 1.3471 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 62.66
24-04-02 20:04:41.993 - INFO: Train epoch 379: [68800/94637 (73%)] Step: [2246086] | Lr: 0.000100 | Loss: 1.5037 | MSE loss: 0.0003 | Bpp loss: 0.97 | Aux loss: 64.43
24-04-02 20:05:16.470 - INFO: Train epoch 379: [70400/94637 (74%)] Step: [2246186] | Lr: 0.000100 | Loss: 1.4853 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 62.03
24-04-02 20:05:50.485 - INFO: Train epoch 379: [72000/94637 (76%)] Step: [2246286] | Lr: 0.000100 | Loss: 1.2696 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 66.12
24-04-02 20:06:24.718 - INFO: Train epoch 379: [73600/94637 (78%)] Step: [2246386] | Lr: 0.000100 | Loss: 1.1063 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 61.61
24-04-02 20:06:58.499 - INFO: Train epoch 379: [75200/94637 (79%)] Step: [2246486] | Lr: 0.000100 | Loss: 1.2719 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 64.30
24-04-02 20:07:32.429 - INFO: Train epoch 379: [76800/94637 (81%)] Step: [2246586] | Lr: 0.000100 | Loss: 1.4997 | MSE loss: 0.0003 | Bpp loss: 0.96 | Aux loss: 65.84
24-04-02 20:08:07.472 - INFO: Train epoch 379: [78400/94637 (83%)] Step: [2246686] | Lr: 0.000100 | Loss: 1.2370 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 65.21
24-04-02 20:08:42.615 - INFO: Train epoch 379: [80000/94637 (85%)] Step: [2246786] | Lr: 0.000100 | Loss: 1.4091 | MSE loss: 0.0004 | Bpp loss: 0.83 | Aux loss: 60.24
24-04-02 20:09:17.482 - INFO: Train epoch 379: [81600/94637 (86%)] Step: [2246886] | Lr: 0.000100 | Loss: 1.3358 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 61.87
24-04-02 20:09:51.629 - INFO: Train epoch 379: [83200/94637 (88%)] Step: [2246986] | Lr: 0.000100 | Loss: 0.8801 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 62.58
24-04-02 20:10:24.938 - INFO: Train epoch 379: [84800/94637 (90%)] Step: [2247086] | Lr: 0.000100 | Loss: 1.2696 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 64.02
24-04-02 20:10:58.960 - INFO: Train epoch 379: [86400/94637 (91%)] Step: [2247186] | Lr: 0.000100 | Loss: 0.7698 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 67.38
24-04-02 20:11:33.912 - INFO: Train epoch 379: [88000/94637 (93%)] Step: [2247286] | Lr: 0.000100 | Loss: 1.1095 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 63.29
24-04-02 20:12:08.484 - INFO: Train epoch 379: [89600/94637 (95%)] Step: [2247386] | Lr: 0.000100 | Loss: 1.4589 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 65.50
24-04-02 20:12:43.674 - INFO: Train epoch 379: [91200/94637 (96%)] Step: [2247486] | Lr: 0.000100 | Loss: 1.8019 | MSE loss: 0.0004 | Bpp loss: 1.10 | Aux loss: 65.88
24-04-02 20:13:20.809 - INFO: Train epoch 379: [92800/94637 (98%)] Step: [2247586] | Lr: 0.000100 | Loss: 1.1536 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 64.07
24-04-02 20:13:55.691 - INFO: Train epoch 379: [94400/94637 (100%)] Step: [2247686] | Lr: 0.000100 | Loss: 0.6553 | MSE loss: 0.0001 | Bpp loss: 0.44 | Aux loss: 68.24
24-04-02 20:14:12.170 - INFO: Learning rate: 0.0001
24-04-02 20:14:12.996 - INFO: Train epoch 380: [    0/94637 (0%)] Step: [2247701] | Lr: 0.000100 | Loss: 1.1400 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 63.12
24-04-02 20:14:46.979 - INFO: Train epoch 380: [ 1600/94637 (2%)] Step: [2247801] | Lr: 0.000100 | Loss: 1.0637 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 61.66
24-04-02 20:15:21.343 - INFO: Train epoch 380: [ 3200/94637 (3%)] Step: [2247901] | Lr: 0.000100 | Loss: 0.9289 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 63.20
24-04-02 20:15:56.436 - INFO: Train epoch 380: [ 4800/94637 (5%)] Step: [2248001] | Lr: 0.000100 | Loss: 1.1883 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 64.91
24-04-02 20:16:31.334 - INFO: Train epoch 380: [ 6400/94637 (7%)] Step: [2248101] | Lr: 0.000100 | Loss: 1.3243 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 62.61
24-04-02 20:17:05.483 - INFO: Train epoch 380: [ 8000/94637 (8%)] Step: [2248201] | Lr: 0.000100 | Loss: 1.6361 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 65.72
24-04-02 20:17:40.428 - INFO: Train epoch 380: [ 9600/94637 (10%)] Step: [2248301] | Lr: 0.000100 | Loss: 1.4759 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 65.43
24-04-02 20:18:14.901 - INFO: Train epoch 380: [11200/94637 (12%)] Step: [2248401] | Lr: 0.000100 | Loss: 1.7954 | MSE loss: 0.0004 | Bpp loss: 1.13 | Aux loss: 59.91
24-04-02 20:18:49.073 - INFO: Train epoch 380: [12800/94637 (14%)] Step: [2248501] | Lr: 0.000100 | Loss: 0.7129 | MSE loss: 0.0002 | Bpp loss: 0.41 | Aux loss: 60.02
24-04-02 20:19:22.600 - INFO: Train epoch 380: [14400/94637 (15%)] Step: [2248601] | Lr: 0.000100 | Loss: 1.4356 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 61.94
24-04-02 20:19:56.747 - INFO: Train epoch 380: [16000/94637 (17%)] Step: [2248701] | Lr: 0.000100 | Loss: 1.5945 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 62.42
24-04-02 20:20:31.714 - INFO: Train epoch 380: [17600/94637 (19%)] Step: [2248801] | Lr: 0.000100 | Loss: 1.6280 | MSE loss: 0.0005 | Bpp loss: 0.89 | Aux loss: 64.15
24-04-02 20:21:06.585 - INFO: Train epoch 380: [19200/94637 (20%)] Step: [2248901] | Lr: 0.000100 | Loss: 0.8319 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 67.01
24-04-02 20:21:41.395 - INFO: Train epoch 380: [20800/94637 (22%)] Step: [2249001] | Lr: 0.000100 | Loss: 1.2017 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 65.27
24-04-02 20:22:16.370 - INFO: Train epoch 380: [22400/94637 (24%)] Step: [2249101] | Lr: 0.000100 | Loss: 1.0871 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 58.33
24-04-02 20:22:51.524 - INFO: Train epoch 380: [24000/94637 (25%)] Step: [2249201] | Lr: 0.000100 | Loss: 1.4853 | MSE loss: 0.0004 | Bpp loss: 0.85 | Aux loss: 65.45
24-04-02 20:23:26.031 - INFO: Train epoch 380: [25600/94637 (27%)] Step: [2249301] | Lr: 0.000100 | Loss: 0.5647 | MSE loss: 0.0001 | Bpp loss: 0.39 | Aux loss: 58.39
24-04-02 20:24:00.815 - INFO: Train epoch 380: [27200/94637 (29%)] Step: [2249401] | Lr: 0.000100 | Loss: 1.4900 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 63.15
24-04-02 20:24:35.563 - INFO: Train epoch 380: [28800/94637 (30%)] Step: [2249501] | Lr: 0.000100 | Loss: 1.2785 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 66.38
24-04-02 20:25:10.113 - INFO: Train epoch 380: [30400/94637 (32%)] Step: [2249601] | Lr: 0.000100 | Loss: 1.5109 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 60.36
24-04-02 20:25:44.618 - INFO: Train epoch 380: [32000/94637 (34%)] Step: [2249701] | Lr: 0.000100 | Loss: 1.1395 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 60.11
24-04-02 20:26:19.892 - INFO: Train epoch 380: [33600/94637 (36%)] Step: [2249801] | Lr: 0.000100 | Loss: 1.3233 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 59.52
24-04-02 20:26:54.579 - INFO: Train epoch 380: [35200/94637 (37%)] Step: [2249901] | Lr: 0.000100 | Loss: 1.0452 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 59.26
24-04-02 20:27:31.519 - INFO: Train epoch 380: [36800/94637 (39%)] Step: [2250001] | Lr: 0.000100 | Loss: 0.8256 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 63.00
24-04-02 20:28:05.634 - INFO: Train epoch 380: [38400/94637 (41%)] Step: [2250101] | Lr: 0.000100 | Loss: 1.9481 | MSE loss: 0.0005 | Bpp loss: 1.11 | Aux loss: 63.38
24-04-02 20:28:39.957 - INFO: Train epoch 380: [40000/94637 (42%)] Step: [2250201] | Lr: 0.000100 | Loss: 1.0676 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 62.59
24-04-02 20:29:15.098 - INFO: Train epoch 380: [41600/94637 (44%)] Step: [2250301] | Lr: 0.000100 | Loss: 1.5112 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 59.56
24-04-02 20:29:49.678 - INFO: Train epoch 380: [43200/94637 (46%)] Step: [2250401] | Lr: 0.000100 | Loss: 1.0788 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 63.77
24-04-02 20:30:25.658 - INFO: Train epoch 380: [44800/94637 (47%)] Step: [2250501] | Lr: 0.000100 | Loss: 1.1341 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 68.71
24-04-02 20:31:01.603 - INFO: Train epoch 380: [46400/94637 (49%)] Step: [2250601] | Lr: 0.000100 | Loss: 1.2331 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 63.07
24-04-02 20:31:36.599 - INFO: Train epoch 380: [48000/94637 (51%)] Step: [2250701] | Lr: 0.000100 | Loss: 1.1945 | MSE loss: 0.0002 | Bpp loss: 0.82 | Aux loss: 64.11
24-04-02 20:32:10.509 - INFO: Train epoch 380: [49600/94637 (52%)] Step: [2250801] | Lr: 0.000100 | Loss: 1.2762 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 63.00
24-04-02 20:32:44.470 - INFO: Train epoch 380: [51200/94637 (54%)] Step: [2250901] | Lr: 0.000100 | Loss: 1.1830 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 67.54
24-04-02 20:33:18.906 - INFO: Train epoch 380: [52800/94637 (56%)] Step: [2251001] | Lr: 0.000100 | Loss: 1.3221 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 63.96
24-04-02 20:33:52.577 - INFO: Train epoch 380: [54400/94637 (57%)] Step: [2251101] | Lr: 0.000100 | Loss: 1.1123 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 60.28
24-04-02 20:34:25.994 - INFO: Train epoch 380: [56000/94637 (59%)] Step: [2251201] | Lr: 0.000100 | Loss: 1.4875 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 61.80
24-04-02 20:34:59.807 - INFO: Train epoch 380: [57600/94637 (61%)] Step: [2251301] | Lr: 0.000100 | Loss: 1.3979 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 61.59
24-04-02 20:35:33.579 - INFO: Train epoch 380: [59200/94637 (63%)] Step: [2251401] | Lr: 0.000100 | Loss: 2.7161 | MSE loss: 0.0009 | Bpp loss: 1.18 | Aux loss: 70.78
24-04-02 20:36:07.732 - INFO: Train epoch 380: [60800/94637 (64%)] Step: [2251501] | Lr: 0.000100 | Loss: 0.7594 | MSE loss: 0.0002 | Bpp loss: 0.48 | Aux loss: 63.14
24-04-02 20:36:42.074 - INFO: Train epoch 380: [62400/94637 (66%)] Step: [2251601] | Lr: 0.000100 | Loss: 1.5343 | MSE loss: 0.0003 | Bpp loss: 0.99 | Aux loss: 63.53
24-04-02 20:37:16.470 - INFO: Train epoch 380: [64000/94637 (68%)] Step: [2251701] | Lr: 0.000100 | Loss: 1.7428 | MSE loss: 0.0004 | Bpp loss: 1.07 | Aux loss: 58.75
24-04-02 20:37:50.722 - INFO: Train epoch 380: [65600/94637 (69%)] Step: [2251801] | Lr: 0.000100 | Loss: 1.4153 | MSE loss: 0.0004 | Bpp loss: 0.74 | Aux loss: 56.88
24-04-02 20:38:25.061 - INFO: Train epoch 380: [67200/94637 (71%)] Step: [2251901] | Lr: 0.000100 | Loss: 1.7969 | MSE loss: 0.0005 | Bpp loss: 1.04 | Aux loss: 58.53
24-04-02 20:38:58.525 - INFO: Train epoch 380: [68800/94637 (73%)] Step: [2252001] | Lr: 0.000100 | Loss: 1.3625 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 57.57
24-04-02 20:39:33.737 - INFO: Train epoch 380: [70400/94637 (74%)] Step: [2252101] | Lr: 0.000100 | Loss: 1.5215 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 60.98
24-04-02 20:40:08.362 - INFO: Train epoch 380: [72000/94637 (76%)] Step: [2252201] | Lr: 0.000100 | Loss: 1.3832 | MSE loss: 0.0004 | Bpp loss: 0.78 | Aux loss: 59.17
24-04-02 20:40:43.026 - INFO: Train epoch 380: [73600/94637 (78%)] Step: [2252301] | Lr: 0.000100 | Loss: 1.6226 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 55.94
24-04-02 20:41:18.164 - INFO: Train epoch 380: [75200/94637 (79%)] Step: [2252401] | Lr: 0.000100 | Loss: 1.1665 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 58.00
24-04-02 20:41:55.259 - INFO: Train epoch 380: [76800/94637 (81%)] Step: [2252501] | Lr: 0.000100 | Loss: 1.0568 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 56.43
24-04-02 20:42:30.363 - INFO: Train epoch 380: [78400/94637 (83%)] Step: [2252601] | Lr: 0.000100 | Loss: 1.0553 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 57.88
24-04-02 20:43:04.897 - INFO: Train epoch 380: [80000/94637 (85%)] Step: [2252701] | Lr: 0.000100 | Loss: 1.3020 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 59.09
24-04-02 20:43:40.176 - INFO: Train epoch 380: [81600/94637 (86%)] Step: [2252801] | Lr: 0.000100 | Loss: 1.0607 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 56.72
24-04-02 20:44:15.722 - INFO: Train epoch 380: [83200/94637 (88%)] Step: [2252901] | Lr: 0.000100 | Loss: 1.1420 | MSE loss: 0.0002 | Bpp loss: 0.76 | Aux loss: 60.01
24-04-02 20:44:50.090 - INFO: Train epoch 380: [84800/94637 (90%)] Step: [2253001] | Lr: 0.000100 | Loss: 1.2641 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 63.50
24-04-02 20:45:25.297 - INFO: Train epoch 380: [86400/94637 (91%)] Step: [2253101] | Lr: 0.000100 | Loss: 0.8566 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 61.67
24-04-02 20:45:59.637 - INFO: Train epoch 380: [88000/94637 (93%)] Step: [2253201] | Lr: 0.000100 | Loss: 0.9284 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 60.12
24-04-02 20:46:34.170 - INFO: Train epoch 380: [89600/94637 (95%)] Step: [2253301] | Lr: 0.000100 | Loss: 0.9488 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 61.90
24-04-02 20:47:09.523 - INFO: Train epoch 380: [91200/94637 (96%)] Step: [2253401] | Lr: 0.000100 | Loss: 1.0961 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 61.56
24-04-02 20:47:44.909 - INFO: Train epoch 380: [92800/94637 (98%)] Step: [2253501] | Lr: 0.000100 | Loss: 1.5659 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 58.73
24-04-02 20:48:20.393 - INFO: Train epoch 380: [94400/94637 (100%)] Step: [2253601] | Lr: 0.000100 | Loss: 1.3286 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 60.88
24-04-02 20:48:37.471 - INFO: Learning rate: 0.0001
24-04-02 20:48:38.351 - INFO: Train epoch 381: [    0/94637 (0%)] Step: [2253616] | Lr: 0.000100 | Loss: 1.8655 | MSE loss: 0.0005 | Bpp loss: 1.13 | Aux loss: 68.41
24-04-02 20:49:13.094 - INFO: Train epoch 381: [ 1600/94637 (2%)] Step: [2253716] | Lr: 0.000100 | Loss: 1.7124 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 56.92
24-04-02 20:49:48.140 - INFO: Train epoch 381: [ 3200/94637 (3%)] Step: [2253816] | Lr: 0.000100 | Loss: 1.1860 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 65.72
24-04-02 20:50:22.969 - INFO: Train epoch 381: [ 4800/94637 (5%)] Step: [2253916] | Lr: 0.000100 | Loss: 1.2226 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 62.08
24-04-02 20:50:57.667 - INFO: Train epoch 381: [ 6400/94637 (7%)] Step: [2254016] | Lr: 0.000100 | Loss: 1.2407 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 62.45
24-04-02 20:51:32.576 - INFO: Train epoch 381: [ 8000/94637 (8%)] Step: [2254116] | Lr: 0.000100 | Loss: 1.4202 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 62.35
24-04-02 20:52:06.815 - INFO: Train epoch 381: [ 9600/94637 (10%)] Step: [2254216] | Lr: 0.000100 | Loss: 0.4932 | MSE loss: 0.0001 | Bpp loss: 0.35 | Aux loss: 59.53
24-04-02 20:52:41.832 - INFO: Train epoch 381: [11200/94637 (12%)] Step: [2254316] | Lr: 0.000100 | Loss: 1.8313 | MSE loss: 0.0004 | Bpp loss: 1.17 | Aux loss: 64.92
24-04-02 20:53:16.709 - INFO: Train epoch 381: [12800/94637 (14%)] Step: [2254416] | Lr: 0.000100 | Loss: 1.9277 | MSE loss: 0.0005 | Bpp loss: 1.18 | Aux loss: 65.17
24-04-02 20:53:51.670 - INFO: Train epoch 381: [14400/94637 (15%)] Step: [2254516] | Lr: 0.000100 | Loss: 0.8826 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 63.45
24-04-02 20:54:26.237 - INFO: Train epoch 381: [16000/94637 (17%)] Step: [2254616] | Lr: 0.000100 | Loss: 0.8216 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 61.29
24-04-02 20:55:01.744 - INFO: Train epoch 381: [17600/94637 (19%)] Step: [2254716] | Lr: 0.000100 | Loss: 1.6440 | MSE loss: 0.0004 | Bpp loss: 1.05 | Aux loss: 65.31
24-04-02 20:55:36.784 - INFO: Train epoch 381: [19200/94637 (20%)] Step: [2254816] | Lr: 0.000100 | Loss: 0.9186 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 64.66
24-04-02 20:56:11.993 - INFO: Train epoch 381: [20800/94637 (22%)] Step: [2254916] | Lr: 0.000100 | Loss: 1.2420 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 64.57
24-04-02 20:56:48.730 - INFO: Train epoch 381: [22400/94637 (24%)] Step: [2255016] | Lr: 0.000100 | Loss: 1.3459 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 61.53
24-04-02 20:57:22.530 - INFO: Train epoch 381: [24000/94637 (25%)] Step: [2255116] | Lr: 0.000100 | Loss: 1.8750 | MSE loss: 0.0005 | Bpp loss: 1.03 | Aux loss: 63.83
24-04-02 20:57:57.776 - INFO: Train epoch 381: [25600/94637 (27%)] Step: [2255216] | Lr: 0.000100 | Loss: 1.2352 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 61.52
24-04-02 20:58:32.098 - INFO: Train epoch 381: [27200/94637 (29%)] Step: [2255316] | Lr: 0.000100 | Loss: 1.6595 | MSE loss: 0.0004 | Bpp loss: 1.05 | Aux loss: 60.82
24-04-02 20:59:07.406 - INFO: Train epoch 381: [28800/94637 (30%)] Step: [2255416] | Lr: 0.000100 | Loss: 1.2364 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 58.85
24-04-02 20:59:42.548 - INFO: Train epoch 381: [30400/94637 (32%)] Step: [2255516] | Lr: 0.000100 | Loss: 1.4682 | MSE loss: 0.0004 | Bpp loss: 0.83 | Aux loss: 64.68
24-04-02 21:00:16.771 - INFO: Train epoch 381: [32000/94637 (34%)] Step: [2255616] | Lr: 0.000100 | Loss: 1.4609 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 63.34
24-04-02 21:00:51.262 - INFO: Train epoch 381: [33600/94637 (36%)] Step: [2255716] | Lr: 0.000100 | Loss: 1.5086 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 60.48
24-04-02 21:01:26.197 - INFO: Train epoch 381: [35200/94637 (37%)] Step: [2255816] | Lr: 0.000100 | Loss: 0.9960 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 62.73
24-04-02 21:02:01.162 - INFO: Train epoch 381: [36800/94637 (39%)] Step: [2255916] | Lr: 0.000100 | Loss: 1.1862 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 61.13
24-04-02 21:02:35.657 - INFO: Train epoch 381: [38400/94637 (41%)] Step: [2256016] | Lr: 0.000100 | Loss: 1.0578 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 61.43
24-04-02 21:03:10.573 - INFO: Train epoch 381: [40000/94637 (42%)] Step: [2256116] | Lr: 0.000100 | Loss: 1.2718 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 64.03
24-04-02 21:03:45.635 - INFO: Train epoch 381: [41600/94637 (44%)] Step: [2256216] | Lr: 0.000100 | Loss: 1.7572 | MSE loss: 0.0004 | Bpp loss: 1.09 | Aux loss: 62.28
24-04-02 21:04:21.051 - INFO: Train epoch 381: [43200/94637 (46%)] Step: [2256316] | Lr: 0.000100 | Loss: 0.7978 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 60.54
24-04-02 21:04:55.901 - INFO: Train epoch 381: [44800/94637 (47%)] Step: [2256416] | Lr: 0.000100 | Loss: 0.9074 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 62.17
24-04-02 21:05:30.001 - INFO: Train epoch 381: [46400/94637 (49%)] Step: [2256516] | Lr: 0.000100 | Loss: 0.7591 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 61.35
24-04-02 21:06:05.833 - INFO: Train epoch 381: [48000/94637 (51%)] Step: [2256616] | Lr: 0.000100 | Loss: 2.1545 | MSE loss: 0.0005 | Bpp loss: 1.34 | Aux loss: 63.14
24-04-02 21:06:40.608 - INFO: Train epoch 381: [49600/94637 (52%)] Step: [2256716] | Lr: 0.000100 | Loss: 1.2746 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 61.67
24-04-02 21:07:14.622 - INFO: Train epoch 381: [51200/94637 (54%)] Step: [2256816] | Lr: 0.000100 | Loss: 1.3646 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 58.97
24-04-02 21:07:49.367 - INFO: Train epoch 381: [52800/94637 (56%)] Step: [2256916] | Lr: 0.000100 | Loss: 1.2588 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 66.66
24-04-02 21:08:24.534 - INFO: Train epoch 381: [54400/94637 (57%)] Step: [2257016] | Lr: 0.000100 | Loss: 1.0611 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 63.62
24-04-02 21:08:59.712 - INFO: Train epoch 381: [56000/94637 (59%)] Step: [2257116] | Lr: 0.000100 | Loss: 1.1364 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 64.38
24-04-02 21:09:34.106 - INFO: Train epoch 381: [57600/94637 (61%)] Step: [2257216] | Lr: 0.000100 | Loss: 0.9906 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 60.20
24-04-02 21:10:09.037 - INFO: Train epoch 381: [59200/94637 (63%)] Step: [2257316] | Lr: 0.000100 | Loss: 1.2583 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 66.90
24-04-02 21:10:43.719 - INFO: Train epoch 381: [60800/94637 (64%)] Step: [2257416] | Lr: 0.000100 | Loss: 1.1657 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 61.69
24-04-02 21:11:20.170 - INFO: Train epoch 381: [62400/94637 (66%)] Step: [2257516] | Lr: 0.000100 | Loss: 1.4645 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 63.60
24-04-02 21:11:54.494 - INFO: Train epoch 381: [64000/94637 (68%)] Step: [2257616] | Lr: 0.000100 | Loss: 1.1756 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 62.78
24-04-02 21:12:28.499 - INFO: Train epoch 381: [65600/94637 (69%)] Step: [2257716] | Lr: 0.000100 | Loss: 0.8001 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 61.16
24-04-02 21:13:02.559 - INFO: Train epoch 381: [67200/94637 (71%)] Step: [2257816] | Lr: 0.000100 | Loss: 1.9226 | MSE loss: 0.0006 | Bpp loss: 0.97 | Aux loss: 66.00
24-04-02 21:13:36.566 - INFO: Train epoch 381: [68800/94637 (73%)] Step: [2257916] | Lr: 0.000100 | Loss: 3.1220 | MSE loss: 0.0012 | Bpp loss: 1.11 | Aux loss: 66.17
24-04-02 21:14:11.833 - INFO: Train epoch 381: [70400/94637 (74%)] Step: [2258016] | Lr: 0.000100 | Loss: 1.6165 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 59.22
24-04-02 21:14:46.121 - INFO: Train epoch 381: [72000/94637 (76%)] Step: [2258116] | Lr: 0.000100 | Loss: 0.5961 | MSE loss: 0.0001 | Bpp loss: 0.41 | Aux loss: 57.04
24-04-02 21:15:21.026 - INFO: Train epoch 381: [73600/94637 (78%)] Step: [2258216] | Lr: 0.000100 | Loss: 1.0576 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 61.36
24-04-02 21:15:56.055 - INFO: Train epoch 381: [75200/94637 (79%)] Step: [2258316] | Lr: 0.000100 | Loss: 0.8969 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 59.10
24-04-02 21:16:31.001 - INFO: Train epoch 381: [76800/94637 (81%)] Step: [2258416] | Lr: 0.000100 | Loss: 1.7722 | MSE loss: 0.0004 | Bpp loss: 1.09 | Aux loss: 57.23
24-04-02 21:17:05.903 - INFO: Train epoch 381: [78400/94637 (83%)] Step: [2258516] | Lr: 0.000100 | Loss: 1.2963 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 59.64
24-04-02 21:17:40.701 - INFO: Train epoch 381: [80000/94637 (85%)] Step: [2258616] | Lr: 0.000100 | Loss: 1.6313 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 59.60
24-04-02 21:18:16.628 - INFO: Train epoch 381: [81600/94637 (86%)] Step: [2258716] | Lr: 0.000100 | Loss: 1.6267 | MSE loss: 0.0004 | Bpp loss: 1.03 | Aux loss: 59.55
24-04-02 21:18:51.121 - INFO: Train epoch 381: [83200/94637 (88%)] Step: [2258816] | Lr: 0.000100 | Loss: 2.1022 | MSE loss: 0.0005 | Bpp loss: 1.29 | Aux loss: 58.25
24-04-02 21:19:25.873 - INFO: Train epoch 381: [84800/94637 (90%)] Step: [2258916] | Lr: 0.000100 | Loss: 1.1080 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 57.97
24-04-02 21:20:00.202 - INFO: Train epoch 381: [86400/94637 (91%)] Step: [2259016] | Lr: 0.000100 | Loss: 1.2788 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 57.77
24-04-02 21:20:35.223 - INFO: Train epoch 381: [88000/94637 (93%)] Step: [2259116] | Lr: 0.000100 | Loss: 1.4658 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 56.72
24-04-02 21:21:09.277 - INFO: Train epoch 381: [89600/94637 (95%)] Step: [2259216] | Lr: 0.000100 | Loss: 1.2466 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 61.41
24-04-02 21:21:43.606 - INFO: Train epoch 381: [91200/94637 (96%)] Step: [2259316] | Lr: 0.000100 | Loss: 1.0593 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 59.70
24-04-02 21:22:17.714 - INFO: Train epoch 381: [92800/94637 (98%)] Step: [2259416] | Lr: 0.000100 | Loss: 1.3786 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 58.72
24-04-02 21:22:52.102 - INFO: Train epoch 381: [94400/94637 (100%)] Step: [2259516] | Lr: 0.000100 | Loss: 1.1198 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 62.41
24-04-02 21:23:08.789 - INFO: Learning rate: 0.0001
24-04-02 21:23:09.684 - INFO: Train epoch 382: [    0/94637 (0%)] Step: [2259531] | Lr: 0.000100 | Loss: 1.3771 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 63.53
24-04-02 21:23:44.117 - INFO: Train epoch 382: [ 1600/94637 (2%)] Step: [2259631] | Lr: 0.000100 | Loss: 0.8815 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 58.50
24-04-02 21:24:18.511 - INFO: Train epoch 382: [ 3200/94637 (3%)] Step: [2259731] | Lr: 0.000100 | Loss: 0.9890 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 62.50
24-04-02 21:24:52.980 - INFO: Train epoch 382: [ 4800/94637 (5%)] Step: [2259831] | Lr: 0.000100 | Loss: 0.7880 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 62.10
24-04-02 21:25:27.742 - INFO: Train epoch 382: [ 6400/94637 (7%)] Step: [2259931] | Lr: 0.000100 | Loss: 1.8280 | MSE loss: 0.0005 | Bpp loss: 1.07 | Aux loss: 60.96
24-04-02 21:26:05.270 - INFO: Train epoch 382: [ 8000/94637 (8%)] Step: [2260031] | Lr: 0.000100 | Loss: 0.8870 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 62.75
24-04-02 21:26:39.837 - INFO: Train epoch 382: [ 9600/94637 (10%)] Step: [2260131] | Lr: 0.000100 | Loss: 1.4423 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 59.45
24-04-02 21:27:14.606 - INFO: Train epoch 382: [11200/94637 (12%)] Step: [2260231] | Lr: 0.000100 | Loss: 1.3041 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 58.95
24-04-02 21:27:48.909 - INFO: Train epoch 382: [12800/94637 (14%)] Step: [2260331] | Lr: 0.000100 | Loss: 0.7701 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 63.51
24-04-02 21:28:23.769 - INFO: Train epoch 382: [14400/94637 (15%)] Step: [2260431] | Lr: 0.000100 | Loss: 1.3247 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 59.01
24-04-02 21:28:58.343 - INFO: Train epoch 382: [16000/94637 (17%)] Step: [2260531] | Lr: 0.000100 | Loss: 1.2088 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 60.27
24-04-02 21:29:32.293 - INFO: Train epoch 382: [17600/94637 (19%)] Step: [2260631] | Lr: 0.000100 | Loss: 2.1895 | MSE loss: 0.0006 | Bpp loss: 1.27 | Aux loss: 60.52
24-04-02 21:30:06.846 - INFO: Train epoch 382: [19200/94637 (20%)] Step: [2260731] | Lr: 0.000100 | Loss: 1.3289 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 57.73
24-04-02 21:30:40.952 - INFO: Train epoch 382: [20800/94637 (22%)] Step: [2260831] | Lr: 0.000100 | Loss: 1.2100 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 59.09
24-04-02 21:31:15.290 - INFO: Train epoch 382: [22400/94637 (24%)] Step: [2260931] | Lr: 0.000100 | Loss: 1.4844 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 61.41
24-04-02 21:31:49.058 - INFO: Train epoch 382: [24000/94637 (25%)] Step: [2261031] | Lr: 0.000100 | Loss: 1.0250 | MSE loss: 0.0003 | Bpp loss: 0.61 | Aux loss: 62.50
24-04-02 21:32:23.821 - INFO: Train epoch 382: [25600/94637 (27%)] Step: [2261131] | Lr: 0.000100 | Loss: 1.4974 | MSE loss: 0.0003 | Bpp loss: 0.99 | Aux loss: 60.36
24-04-02 21:32:58.432 - INFO: Train epoch 382: [27200/94637 (29%)] Step: [2261231] | Lr: 0.000100 | Loss: 1.2144 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 62.98
24-04-02 21:33:32.512 - INFO: Train epoch 382: [28800/94637 (30%)] Step: [2261331] | Lr: 0.000100 | Loss: 1.8598 | MSE loss: 0.0005 | Bpp loss: 1.12 | Aux loss: 57.70
24-04-02 21:34:06.855 - INFO: Train epoch 382: [30400/94637 (32%)] Step: [2261431] | Lr: 0.000100 | Loss: 1.3604 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 65.50
24-04-02 21:34:41.084 - INFO: Train epoch 382: [32000/94637 (34%)] Step: [2261531] | Lr: 0.000100 | Loss: 1.0769 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 59.37
24-04-02 21:35:15.205 - INFO: Train epoch 382: [33600/94637 (36%)] Step: [2261631] | Lr: 0.000100 | Loss: 1.0786 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 58.23
24-04-02 21:35:49.516 - INFO: Train epoch 382: [35200/94637 (37%)] Step: [2261731] | Lr: 0.000100 | Loss: 1.7317 | MSE loss: 0.0004 | Bpp loss: 1.09 | Aux loss: 60.28
24-04-02 21:36:23.311 - INFO: Train epoch 382: [36800/94637 (39%)] Step: [2261831] | Lr: 0.000100 | Loss: 0.7436 | MSE loss: 0.0001 | Bpp loss: 0.51 | Aux loss: 57.90
24-04-02 21:36:57.199 - INFO: Train epoch 382: [38400/94637 (41%)] Step: [2261931] | Lr: 0.000100 | Loss: 1.0474 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 62.90
24-04-02 21:37:31.160 - INFO: Train epoch 382: [40000/94637 (42%)] Step: [2262031] | Lr: 0.000100 | Loss: 1.3972 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 61.97
24-04-02 21:38:05.224 - INFO: Train epoch 382: [41600/94637 (44%)] Step: [2262131] | Lr: 0.000100 | Loss: 1.1246 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 63.33
24-04-02 21:38:38.991 - INFO: Train epoch 382: [43200/94637 (46%)] Step: [2262231] | Lr: 0.000100 | Loss: 0.9743 | MSE loss: 0.0003 | Bpp loss: 0.55 | Aux loss: 59.61
24-04-02 21:39:13.191 - INFO: Train epoch 382: [44800/94637 (47%)] Step: [2262331] | Lr: 0.000100 | Loss: 0.9765 | MSE loss: 0.0003 | Bpp loss: 0.57 | Aux loss: 57.75
24-04-02 21:39:46.906 - INFO: Train epoch 382: [46400/94637 (49%)] Step: [2262431] | Lr: 0.000100 | Loss: 1.0233 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 58.21
24-04-02 21:40:23.755 - INFO: Train epoch 382: [48000/94637 (51%)] Step: [2262531] | Lr: 0.000100 | Loss: 0.8694 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 57.25
24-04-02 21:40:58.068 - INFO: Train epoch 382: [49600/94637 (52%)] Step: [2262631] | Lr: 0.000100 | Loss: 1.3643 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 61.69
24-04-02 21:41:32.175 - INFO: Train epoch 382: [51200/94637 (54%)] Step: [2262731] | Lr: 0.000100 | Loss: 1.1063 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 58.21
24-04-02 21:42:06.107 - INFO: Train epoch 382: [52800/94637 (56%)] Step: [2262831] | Lr: 0.000100 | Loss: 1.7517 | MSE loss: 0.0004 | Bpp loss: 1.08 | Aux loss: 58.63
24-04-02 21:42:40.791 - INFO: Train epoch 382: [54400/94637 (57%)] Step: [2262931] | Lr: 0.000100 | Loss: 1.4276 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 55.01
24-04-02 21:43:15.329 - INFO: Train epoch 382: [56000/94637 (59%)] Step: [2263031] | Lr: 0.000100 | Loss: 2.0582 | MSE loss: 0.0005 | Bpp loss: 1.18 | Aux loss: 59.76
24-04-02 21:43:49.388 - INFO: Train epoch 382: [57600/94637 (61%)] Step: [2263131] | Lr: 0.000100 | Loss: 1.1367 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 58.73
24-04-02 21:44:23.910 - INFO: Train epoch 382: [59200/94637 (63%)] Step: [2263231] | Lr: 0.000100 | Loss: 1.0451 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 60.60
24-04-02 21:44:58.327 - INFO: Train epoch 382: [60800/94637 (64%)] Step: [2263331] | Lr: 0.000100 | Loss: 1.7950 | MSE loss: 0.0005 | Bpp loss: 1.01 | Aux loss: 62.83
24-04-02 21:45:32.791 - INFO: Train epoch 382: [62400/94637 (66%)] Step: [2263431] | Lr: 0.000100 | Loss: 1.2878 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 60.38
24-04-02 21:46:06.486 - INFO: Train epoch 382: [64000/94637 (68%)] Step: [2263531] | Lr: 0.000100 | Loss: 1.0641 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 63.84
24-04-02 21:46:41.270 - INFO: Train epoch 382: [65600/94637 (69%)] Step: [2263631] | Lr: 0.000100 | Loss: 0.9923 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 56.98
24-04-02 21:47:15.823 - INFO: Train epoch 382: [67200/94637 (71%)] Step: [2263731] | Lr: 0.000100 | Loss: 1.0923 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 60.74
24-04-02 21:47:49.450 - INFO: Train epoch 382: [68800/94637 (73%)] Step: [2263831] | Lr: 0.000100 | Loss: 1.3116 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 61.50
24-04-02 21:48:23.261 - INFO: Train epoch 382: [70400/94637 (74%)] Step: [2263931] | Lr: 0.000100 | Loss: 1.4189 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 64.35
24-04-02 21:48:57.674 - INFO: Train epoch 382: [72000/94637 (76%)] Step: [2264031] | Lr: 0.000100 | Loss: 1.2383 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 64.01
24-04-02 21:49:30.952 - INFO: Train epoch 382: [73600/94637 (78%)] Step: [2264131] | Lr: 0.000100 | Loss: 1.4628 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 57.62
24-04-02 21:50:04.618 - INFO: Train epoch 382: [75200/94637 (79%)] Step: [2264231] | Lr: 0.000100 | Loss: 1.1079 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 57.76
24-04-02 21:50:39.201 - INFO: Train epoch 382: [76800/94637 (81%)] Step: [2264331] | Lr: 0.000100 | Loss: 1.3885 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 59.70
24-04-02 21:51:13.839 - INFO: Train epoch 382: [78400/94637 (83%)] Step: [2264431] | Lr: 0.000100 | Loss: 0.7613 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 61.05
24-04-02 21:51:48.902 - INFO: Train epoch 382: [80000/94637 (85%)] Step: [2264531] | Lr: 0.000100 | Loss: 0.9231 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 60.11
24-04-02 21:52:22.446 - INFO: Train epoch 382: [81600/94637 (86%)] Step: [2264631] | Lr: 0.000100 | Loss: 1.1715 | MSE loss: 0.0002 | Bpp loss: 0.78 | Aux loss: 60.34
24-04-02 21:52:57.327 - INFO: Train epoch 382: [83200/94637 (88%)] Step: [2264731] | Lr: 0.000100 | Loss: 1.0727 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 58.41
24-04-02 21:53:31.183 - INFO: Train epoch 382: [84800/94637 (90%)] Step: [2264831] | Lr: 0.000100 | Loss: 1.4544 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 60.72
24-04-02 21:54:06.799 - INFO: Train epoch 382: [86400/94637 (91%)] Step: [2264931] | Lr: 0.000100 | Loss: 1.3311 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 61.10
24-04-02 21:54:43.111 - INFO: Train epoch 382: [88000/94637 (93%)] Step: [2265031] | Lr: 0.000100 | Loss: 1.3397 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 56.83
24-04-02 21:55:17.549 - INFO: Train epoch 382: [89600/94637 (95%)] Step: [2265131] | Lr: 0.000100 | Loss: 1.1119 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 61.55
24-04-02 21:55:52.364 - INFO: Train epoch 382: [91200/94637 (96%)] Step: [2265231] | Lr: 0.000100 | Loss: 1.1580 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 56.79
24-04-02 21:56:26.587 - INFO: Train epoch 382: [92800/94637 (98%)] Step: [2265331] | Lr: 0.000100 | Loss: 1.0696 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 71.31
24-04-02 21:57:01.411 - INFO: Train epoch 382: [94400/94637 (100%)] Step: [2265431] | Lr: 0.000100 | Loss: 1.5832 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 60.98
24-04-02 21:57:17.682 - INFO: Learning rate: 0.0001
24-04-02 21:57:18.504 - INFO: Train epoch 383: [    0/94637 (0%)] Step: [2265446] | Lr: 0.000100 | Loss: 1.7422 | MSE loss: 0.0004 | Bpp loss: 1.05 | Aux loss: 59.88
24-04-02 21:57:52.300 - INFO: Train epoch 383: [ 1600/94637 (2%)] Step: [2265546] | Lr: 0.000100 | Loss: 1.1942 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 57.64
24-04-02 21:58:26.384 - INFO: Train epoch 383: [ 3200/94637 (3%)] Step: [2265646] | Lr: 0.000100 | Loss: 2.0673 | MSE loss: 0.0005 | Bpp loss: 1.29 | Aux loss: 56.03
24-04-02 21:59:00.258 - INFO: Train epoch 383: [ 4800/94637 (5%)] Step: [2265746] | Lr: 0.000100 | Loss: 1.6612 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 55.68
24-04-02 21:59:34.194 - INFO: Train epoch 383: [ 6400/94637 (7%)] Step: [2265846] | Lr: 0.000100 | Loss: 1.7927 | MSE loss: 0.0004 | Bpp loss: 1.09 | Aux loss: 55.76
24-04-02 22:00:08.227 - INFO: Train epoch 383: [ 8000/94637 (8%)] Step: [2265946] | Lr: 0.000100 | Loss: 0.8560 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 56.09
24-04-02 22:00:42.249 - INFO: Train epoch 383: [ 9600/94637 (10%)] Step: [2266046] | Lr: 0.000100 | Loss: 0.8776 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 56.32
24-04-02 22:01:16.478 - INFO: Train epoch 383: [11200/94637 (12%)] Step: [2266146] | Lr: 0.000100 | Loss: 1.4941 | MSE loss: 0.0003 | Bpp loss: 0.97 | Aux loss: 60.60
24-04-02 22:01:51.581 - INFO: Train epoch 383: [12800/94637 (14%)] Step: [2266246] | Lr: 0.000100 | Loss: 3.2281 | MSE loss: 0.0013 | Bpp loss: 1.18 | Aux loss: 57.17
24-04-02 22:02:25.693 - INFO: Train epoch 383: [14400/94637 (15%)] Step: [2266346] | Lr: 0.000100 | Loss: 0.9990 | MSE loss: 0.0003 | Bpp loss: 0.59 | Aux loss: 53.52
24-04-02 22:03:00.139 - INFO: Train epoch 383: [16000/94637 (17%)] Step: [2266446] | Lr: 0.000100 | Loss: 0.8293 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 54.88
24-04-02 22:03:34.903 - INFO: Train epoch 383: [17600/94637 (19%)] Step: [2266546] | Lr: 0.000100 | Loss: 1.2120 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 56.43
24-04-02 22:04:09.757 - INFO: Train epoch 383: [19200/94637 (20%)] Step: [2266646] | Lr: 0.000100 | Loss: 1.0979 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 55.80
24-04-02 22:04:44.483 - INFO: Train epoch 383: [20800/94637 (22%)] Step: [2266746] | Lr: 0.000100 | Loss: 0.9462 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 56.80
24-04-02 22:05:19.090 - INFO: Train epoch 383: [22400/94637 (24%)] Step: [2266846] | Lr: 0.000100 | Loss: 1.2223 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 53.29
24-04-02 22:05:54.529 - INFO: Train epoch 383: [24000/94637 (25%)] Step: [2266946] | Lr: 0.000100 | Loss: 0.7716 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 56.81
24-04-02 22:06:30.114 - INFO: Train epoch 383: [25600/94637 (27%)] Step: [2267046] | Lr: 0.000100 | Loss: 1.2187 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 57.25
24-04-02 22:07:05.133 - INFO: Train epoch 383: [27200/94637 (29%)] Step: [2267146] | Lr: 0.000100 | Loss: 2.0138 | MSE loss: 0.0005 | Bpp loss: 1.20 | Aux loss: 57.92
24-04-02 22:07:40.132 - INFO: Train epoch 383: [28800/94637 (30%)] Step: [2267246] | Lr: 0.000100 | Loss: 1.5645 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 60.34
24-04-02 22:08:14.835 - INFO: Train epoch 383: [30400/94637 (32%)] Step: [2267346] | Lr: 0.000100 | Loss: 1.3533 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 59.04
24-04-02 22:08:49.612 - INFO: Train epoch 383: [32000/94637 (34%)] Step: [2267446] | Lr: 0.000100 | Loss: 1.1767 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 60.40
24-04-02 22:09:27.046 - INFO: Train epoch 383: [33600/94637 (36%)] Step: [2267546] | Lr: 0.000100 | Loss: 0.9772 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 56.84
24-04-02 22:10:02.280 - INFO: Train epoch 383: [35200/94637 (37%)] Step: [2267646] | Lr: 0.000100 | Loss: 1.2774 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 58.21
24-04-02 22:10:36.765 - INFO: Train epoch 383: [36800/94637 (39%)] Step: [2267746] | Lr: 0.000100 | Loss: 1.2331 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 57.45
24-04-02 22:11:11.501 - INFO: Train epoch 383: [38400/94637 (41%)] Step: [2267846] | Lr: 0.000100 | Loss: 0.7988 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 57.14
24-04-02 22:11:45.710 - INFO: Train epoch 383: [40000/94637 (42%)] Step: [2267946] | Lr: 0.000100 | Loss: 0.8516 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 58.84
24-04-02 22:12:20.424 - INFO: Train epoch 383: [41600/94637 (44%)] Step: [2268046] | Lr: 0.000100 | Loss: 1.9650 | MSE loss: 0.0005 | Bpp loss: 1.21 | Aux loss: 60.82
24-04-02 22:12:54.828 - INFO: Train epoch 383: [43200/94637 (46%)] Step: [2268146] | Lr: 0.000100 | Loss: 0.9289 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 59.79
24-04-02 22:13:29.457 - INFO: Train epoch 383: [44800/94637 (47%)] Step: [2268246] | Lr: 0.000100 | Loss: 1.1818 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 62.43
24-04-02 22:14:03.656 - INFO: Train epoch 383: [46400/94637 (49%)] Step: [2268346] | Lr: 0.000100 | Loss: 0.9453 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 59.85
24-04-02 22:14:39.089 - INFO: Train epoch 383: [48000/94637 (51%)] Step: [2268446] | Lr: 0.000100 | Loss: 1.2960 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 58.82
24-04-02 22:15:14.352 - INFO: Train epoch 383: [49600/94637 (52%)] Step: [2268546] | Lr: 0.000100 | Loss: 1.4130 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 58.51
24-04-02 22:15:49.869 - INFO: Train epoch 383: [51200/94637 (54%)] Step: [2268646] | Lr: 0.000100 | Loss: 1.3071 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 56.09
24-04-02 22:16:24.967 - INFO: Train epoch 383: [52800/94637 (56%)] Step: [2268746] | Lr: 0.000100 | Loss: 1.8835 | MSE loss: 0.0005 | Bpp loss: 1.15 | Aux loss: 59.71
24-04-02 22:17:00.215 - INFO: Train epoch 383: [54400/94637 (57%)] Step: [2268846] | Lr: 0.000100 | Loss: 1.5032 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 55.81
24-04-02 22:17:35.038 - INFO: Train epoch 383: [56000/94637 (59%)] Step: [2268946] | Lr: 0.000100 | Loss: 0.9177 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 62.26
24-04-02 22:18:10.490 - INFO: Train epoch 383: [57600/94637 (61%)] Step: [2269046] | Lr: 0.000100 | Loss: 1.3269 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 62.76
24-04-02 22:18:45.742 - INFO: Train epoch 383: [59200/94637 (63%)] Step: [2269146] | Lr: 0.000100 | Loss: 1.4092 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 59.10
24-04-02 22:19:21.538 - INFO: Train epoch 383: [60800/94637 (64%)] Step: [2269246] | Lr: 0.000100 | Loss: 1.4328 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 56.89
24-04-02 22:19:56.272 - INFO: Train epoch 383: [62400/94637 (66%)] Step: [2269346] | Lr: 0.000100 | Loss: 1.5615 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 58.59
24-04-02 22:20:30.717 - INFO: Train epoch 383: [64000/94637 (68%)] Step: [2269446] | Lr: 0.000100 | Loss: 1.0093 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 70.56
24-04-02 22:21:04.710 - INFO: Train epoch 383: [65600/94637 (69%)] Step: [2269546] | Lr: 0.000100 | Loss: 1.0294 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 60.40
24-04-02 22:21:38.654 - INFO: Train epoch 383: [67200/94637 (71%)] Step: [2269646] | Lr: 0.000100 | Loss: 1.4441 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 56.30
24-04-02 22:22:13.218 - INFO: Train epoch 383: [68800/94637 (73%)] Step: [2269746] | Lr: 0.000100 | Loss: 1.3787 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 56.17
24-04-02 22:22:47.731 - INFO: Train epoch 383: [70400/94637 (74%)] Step: [2269846] | Lr: 0.000100 | Loss: 1.0285 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 51.38
24-04-02 22:23:21.297 - INFO: Train epoch 383: [72000/94637 (76%)] Step: [2269946] | Lr: 0.000100 | Loss: 1.0244 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 54.82
24-04-02 22:23:57.075 - INFO: Train epoch 383: [73600/94637 (78%)] Step: [2270046] | Lr: 0.000100 | Loss: 1.0527 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 55.03
24-04-02 22:24:30.832 - INFO: Train epoch 383: [75200/94637 (79%)] Step: [2270146] | Lr: 0.000100 | Loss: 1.2471 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 58.77
24-04-02 22:25:04.089 - INFO: Train epoch 383: [76800/94637 (81%)] Step: [2270246] | Lr: 0.000100 | Loss: 1.4179 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 55.31
24-04-02 22:25:38.327 - INFO: Train epoch 383: [78400/94637 (83%)] Step: [2270346] | Lr: 0.000100 | Loss: 1.6492 | MSE loss: 0.0003 | Bpp loss: 1.08 | Aux loss: 54.45
24-04-02 22:26:12.752 - INFO: Train epoch 383: [80000/94637 (85%)] Step: [2270446] | Lr: 0.000100 | Loss: 1.5570 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 55.50
24-04-02 22:26:46.927 - INFO: Train epoch 383: [81600/94637 (86%)] Step: [2270546] | Lr: 0.000100 | Loss: 1.6838 | MSE loss: 0.0005 | Bpp loss: 0.94 | Aux loss: 57.77
24-04-02 22:27:21.705 - INFO: Train epoch 383: [83200/94637 (88%)] Step: [2270646] | Lr: 0.000100 | Loss: 1.0712 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 52.27
24-04-02 22:27:56.269 - INFO: Train epoch 383: [84800/94637 (90%)] Step: [2270746] | Lr: 0.000100 | Loss: 0.7969 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 52.98
24-04-02 22:28:30.968 - INFO: Train epoch 383: [86400/94637 (91%)] Step: [2270846] | Lr: 0.000100 | Loss: 1.1554 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 55.79
24-04-02 22:29:04.714 - INFO: Train epoch 383: [88000/94637 (93%)] Step: [2270946] | Lr: 0.000100 | Loss: 1.3107 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 57.92
24-04-02 22:29:38.993 - INFO: Train epoch 383: [89600/94637 (95%)] Step: [2271046] | Lr: 0.000100 | Loss: 1.9972 | MSE loss: 0.0005 | Bpp loss: 1.16 | Aux loss: 57.23
24-04-02 22:30:12.901 - INFO: Train epoch 383: [91200/94637 (96%)] Step: [2271146] | Lr: 0.000100 | Loss: 1.0109 | MSE loss: 0.0003 | Bpp loss: 0.59 | Aux loss: 54.15
24-04-02 22:30:46.228 - INFO: Train epoch 383: [92800/94637 (98%)] Step: [2271246] | Lr: 0.000100 | Loss: 1.1717 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 54.81
24-04-02 22:31:20.655 - INFO: Train epoch 383: [94400/94637 (100%)] Step: [2271346] | Lr: 0.000100 | Loss: 1.1521 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 56.34
24-04-02 22:31:37.494 - INFO: Learning rate: 0.0001
24-04-02 22:31:38.314 - INFO: Train epoch 384: [    0/94637 (0%)] Step: [2271361] | Lr: 0.000100 | Loss: 1.1978 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 54.78
24-04-02 22:32:11.890 - INFO: Train epoch 384: [ 1600/94637 (2%)] Step: [2271461] | Lr: 0.000100 | Loss: 0.8642 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 59.07
24-04-02 22:32:46.196 - INFO: Train epoch 384: [ 3200/94637 (3%)] Step: [2271561] | Lr: 0.000100 | Loss: 1.6248 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 59.13
24-04-02 22:33:21.347 - INFO: Train epoch 384: [ 4800/94637 (5%)] Step: [2271661] | Lr: 0.000100 | Loss: 0.9230 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 57.22
24-04-02 22:33:57.042 - INFO: Train epoch 384: [ 6400/94637 (7%)] Step: [2271761] | Lr: 0.000100 | Loss: 1.4904 | MSE loss: 0.0003 | Bpp loss: 1.00 | Aux loss: 58.52
24-04-02 22:34:32.168 - INFO: Train epoch 384: [ 8000/94637 (8%)] Step: [2271861] | Lr: 0.000100 | Loss: 1.2430 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 58.35
24-04-02 22:35:07.622 - INFO: Train epoch 384: [ 9600/94637 (10%)] Step: [2271961] | Lr: 0.000100 | Loss: 2.0359 | MSE loss: 0.0005 | Bpp loss: 1.24 | Aux loss: 59.24
24-04-02 22:35:42.323 - INFO: Train epoch 384: [11200/94637 (12%)] Step: [2272061] | Lr: 0.000100 | Loss: 1.1099 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 58.88
24-04-02 22:36:17.029 - INFO: Train epoch 384: [12800/94637 (14%)] Step: [2272161] | Lr: 0.000100 | Loss: 0.9870 | MSE loss: 0.0003 | Bpp loss: 0.55 | Aux loss: 58.26
24-04-02 22:36:52.212 - INFO: Train epoch 384: [14400/94637 (15%)] Step: [2272261] | Lr: 0.000100 | Loss: 0.9455 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 57.94
24-04-02 22:37:27.478 - INFO: Train epoch 384: [16000/94637 (17%)] Step: [2272361] | Lr: 0.000100 | Loss: 1.7434 | MSE loss: 0.0004 | Bpp loss: 1.03 | Aux loss: 58.00
24-04-02 22:38:03.172 - INFO: Train epoch 384: [17600/94637 (19%)] Step: [2272461] | Lr: 0.000100 | Loss: 1.6908 | MSE loss: 0.0004 | Bpp loss: 1.06 | Aux loss: 59.93
24-04-02 22:38:39.588 - INFO: Train epoch 384: [19200/94637 (20%)] Step: [2272561] | Lr: 0.000100 | Loss: 1.2405 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 57.67
24-04-02 22:39:15.065 - INFO: Train epoch 384: [20800/94637 (22%)] Step: [2272661] | Lr: 0.000100 | Loss: 1.0305 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 56.25
24-04-02 22:39:50.121 - INFO: Train epoch 384: [22400/94637 (24%)] Step: [2272761] | Lr: 0.000100 | Loss: 1.2396 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 60.52
24-04-02 22:40:25.302 - INFO: Train epoch 384: [24000/94637 (25%)] Step: [2272861] | Lr: 0.000100 | Loss: 1.1094 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 59.41
24-04-02 22:41:00.100 - INFO: Train epoch 384: [25600/94637 (27%)] Step: [2272961] | Lr: 0.000100 | Loss: 0.9099 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 54.49
24-04-02 22:41:34.323 - INFO: Train epoch 384: [27200/94637 (29%)] Step: [2273061] | Lr: 0.000100 | Loss: 1.3593 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 50.57
24-04-02 22:42:08.896 - INFO: Train epoch 384: [28800/94637 (30%)] Step: [2273161] | Lr: 0.000100 | Loss: 1.8440 | MSE loss: 0.0005 | Bpp loss: 1.04 | Aux loss: 48.96
24-04-02 22:42:43.820 - INFO: Train epoch 384: [30400/94637 (32%)] Step: [2273261] | Lr: 0.000100 | Loss: 1.1581 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 55.37
24-04-02 22:43:18.797 - INFO: Train epoch 384: [32000/94637 (34%)] Step: [2273361] | Lr: 0.000100 | Loss: 1.7778 | MSE loss: 0.0004 | Bpp loss: 1.17 | Aux loss: 56.52
24-04-02 22:43:52.645 - INFO: Train epoch 384: [33600/94637 (36%)] Step: [2273461] | Lr: 0.000100 | Loss: 0.6439 | MSE loss: 0.0001 | Bpp loss: 0.42 | Aux loss: 52.70
24-04-02 22:44:28.077 - INFO: Train epoch 384: [35200/94637 (37%)] Step: [2273561] | Lr: 0.000100 | Loss: 1.4935 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 55.83
24-04-02 22:45:03.113 - INFO: Train epoch 384: [36800/94637 (39%)] Step: [2273661] | Lr: 0.000100 | Loss: 1.0800 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 54.42
24-04-02 22:45:37.959 - INFO: Train epoch 384: [38400/94637 (41%)] Step: [2273761] | Lr: 0.000100 | Loss: 1.1770 | MSE loss: 0.0002 | Bpp loss: 0.78 | Aux loss: 54.47
24-04-02 22:46:12.699 - INFO: Train epoch 384: [40000/94637 (42%)] Step: [2273861] | Lr: 0.000100 | Loss: 0.9737 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 56.52
24-04-02 22:46:47.929 - INFO: Train epoch 384: [41600/94637 (44%)] Step: [2273961] | Lr: 0.000100 | Loss: 1.0124 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 57.49
24-04-02 22:47:23.088 - INFO: Train epoch 384: [43200/94637 (46%)] Step: [2274061] | Lr: 0.000100 | Loss: 1.1381 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 55.07
24-04-02 22:47:57.945 - INFO: Train epoch 384: [44800/94637 (47%)] Step: [2274161] | Lr: 0.000100 | Loss: 2.0735 | MSE loss: 0.0005 | Bpp loss: 1.32 | Aux loss: 55.47
24-04-02 22:48:32.324 - INFO: Train epoch 384: [46400/94637 (49%)] Step: [2274261] | Lr: 0.000100 | Loss: 1.2870 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 59.47
24-04-02 22:49:06.714 - INFO: Train epoch 384: [48000/94637 (51%)] Step: [2274361] | Lr: 0.000100 | Loss: 1.8121 | MSE loss: 0.0004 | Bpp loss: 1.12 | Aux loss: 55.87
24-04-02 22:49:42.005 - INFO: Train epoch 384: [49600/94637 (52%)] Step: [2274461] | Lr: 0.000100 | Loss: 0.6633 | MSE loss: 0.0002 | Bpp loss: 0.41 | Aux loss: 61.14
24-04-02 22:50:16.708 - INFO: Train epoch 384: [51200/94637 (54%)] Step: [2274561] | Lr: 0.000100 | Loss: 1.4012 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 53.75
24-04-02 22:50:51.813 - INFO: Train epoch 384: [52800/94637 (56%)] Step: [2274661] | Lr: 0.000100 | Loss: 1.0704 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 61.02
24-04-02 22:51:27.780 - INFO: Train epoch 384: [54400/94637 (57%)] Step: [2274761] | Lr: 0.000100 | Loss: 1.5753 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 58.01
24-04-02 22:52:02.535 - INFO: Train epoch 384: [56000/94637 (59%)] Step: [2274861] | Lr: 0.000100 | Loss: 1.2784 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 57.61
24-04-02 22:52:37.445 - INFO: Train epoch 384: [57600/94637 (61%)] Step: [2274961] | Lr: 0.000100 | Loss: 1.7931 | MSE loss: 0.0005 | Bpp loss: 1.04 | Aux loss: 61.43
24-04-02 22:53:14.064 - INFO: Train epoch 384: [59200/94637 (63%)] Step: [2275061] | Lr: 0.000100 | Loss: 1.1754 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 58.33
24-04-02 22:53:49.884 - INFO: Train epoch 384: [60800/94637 (64%)] Step: [2275161] | Lr: 0.000100 | Loss: 0.9939 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 58.95
24-04-02 22:54:25.579 - INFO: Train epoch 384: [62400/94637 (66%)] Step: [2275261] | Lr: 0.000100 | Loss: 1.2288 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 59.94
24-04-02 22:55:00.682 - INFO: Train epoch 384: [64000/94637 (68%)] Step: [2275361] | Lr: 0.000100 | Loss: 1.0890 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 61.12
24-04-02 22:55:36.741 - INFO: Train epoch 384: [65600/94637 (69%)] Step: [2275461] | Lr: 0.000100 | Loss: 1.2463 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 58.92
24-04-02 22:56:12.173 - INFO: Train epoch 384: [67200/94637 (71%)] Step: [2275561] | Lr: 0.000100 | Loss: 1.5913 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 59.84
24-04-02 22:56:46.483 - INFO: Train epoch 384: [68800/94637 (73%)] Step: [2275661] | Lr: 0.000100 | Loss: 0.9837 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 57.30
24-04-02 22:57:20.950 - INFO: Train epoch 384: [70400/94637 (74%)] Step: [2275761] | Lr: 0.000100 | Loss: 1.0566 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 61.29
24-04-02 22:57:54.510 - INFO: Train epoch 384: [72000/94637 (76%)] Step: [2275861] | Lr: 0.000100 | Loss: 1.1872 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 62.01
24-04-02 22:58:31.650 - INFO: Train epoch 384: [73600/94637 (78%)] Step: [2275961] | Lr: 0.000100 | Loss: 1.9532 | MSE loss: 0.0004 | Bpp loss: 1.24 | Aux loss: 57.70
24-04-02 22:59:11.736 - INFO: Train epoch 384: [75200/94637 (79%)] Step: [2276061] | Lr: 0.000100 | Loss: 0.5353 | MSE loss: 0.0001 | Bpp loss: 0.33 | Aux loss: 58.44
24-04-02 22:59:50.787 - INFO: Train epoch 384: [76800/94637 (81%)] Step: [2276161] | Lr: 0.000100 | Loss: 1.3497 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 54.39
24-04-02 23:00:27.829 - INFO: Train epoch 384: [78400/94637 (83%)] Step: [2276261] | Lr: 0.000100 | Loss: 1.5323 | MSE loss: 0.0003 | Bpp loss: 0.98 | Aux loss: 58.20
24-04-02 23:01:01.828 - INFO: Train epoch 384: [80000/94637 (85%)] Step: [2276361] | Lr: 0.000100 | Loss: 1.7692 | MSE loss: 0.0004 | Bpp loss: 1.12 | Aux loss: 62.92
24-04-02 23:01:35.305 - INFO: Train epoch 384: [81600/94637 (86%)] Step: [2276461] | Lr: 0.000100 | Loss: 1.5687 | MSE loss: 0.0004 | Bpp loss: 0.93 | Aux loss: 60.06
24-04-02 23:02:08.971 - INFO: Train epoch 384: [83200/94637 (88%)] Step: [2276561] | Lr: 0.000100 | Loss: 1.4394 | MSE loss: 0.0004 | Bpp loss: 0.81 | Aux loss: 56.21
24-04-02 23:02:43.120 - INFO: Train epoch 384: [84800/94637 (90%)] Step: [2276661] | Lr: 0.000100 | Loss: 1.0115 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 59.58
24-04-02 23:03:17.545 - INFO: Train epoch 384: [86400/94637 (91%)] Step: [2276761] | Lr: 0.000100 | Loss: 0.9914 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 60.34
24-04-02 23:03:52.129 - INFO: Train epoch 384: [88000/94637 (93%)] Step: [2276861] | Lr: 0.000100 | Loss: 1.1762 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 61.67
24-04-02 23:04:26.766 - INFO: Train epoch 384: [89600/94637 (95%)] Step: [2276961] | Lr: 0.000100 | Loss: 1.0687 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 57.89
24-04-02 23:05:01.596 - INFO: Train epoch 384: [91200/94637 (96%)] Step: [2277061] | Lr: 0.000100 | Loss: 0.8601 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 58.13
24-04-02 23:05:36.057 - INFO: Train epoch 384: [92800/94637 (98%)] Step: [2277161] | Lr: 0.000100 | Loss: 2.3912 | MSE loss: 0.0006 | Bpp loss: 1.42 | Aux loss: 55.97
24-04-02 23:06:11.132 - INFO: Train epoch 384: [94400/94637 (100%)] Step: [2277261] | Lr: 0.000100 | Loss: 1.6721 | MSE loss: 0.0004 | Bpp loss: 1.08 | Aux loss: 54.04
24-04-02 23:06:27.921 - INFO: Learning rate: 0.0001
24-04-02 23:06:28.825 - INFO: Train epoch 385: [    0/94637 (0%)] Step: [2277276] | Lr: 0.000100 | Loss: 1.1223 | MSE loss: 0.0003 | Bpp loss: 0.60 | Aux loss: 59.28
24-04-02 23:07:03.819 - INFO: Train epoch 385: [ 1600/94637 (2%)] Step: [2277376] | Lr: 0.000100 | Loss: 1.0152 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 58.38
24-04-02 23:07:39.211 - INFO: Train epoch 385: [ 3200/94637 (3%)] Step: [2277476] | Lr: 0.000100 | Loss: 1.6031 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 56.82
24-04-02 23:08:15.171 - INFO: Train epoch 385: [ 4800/94637 (5%)] Step: [2277576] | Lr: 0.000100 | Loss: 0.8638 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 59.74
24-04-02 23:08:49.325 - INFO: Train epoch 385: [ 6400/94637 (7%)] Step: [2277676] | Lr: 0.000100 | Loss: 1.2587 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 55.03
24-04-02 23:09:23.865 - INFO: Train epoch 385: [ 8000/94637 (8%)] Step: [2277776] | Lr: 0.000100 | Loss: 1.3759 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 58.18
24-04-02 23:09:57.484 - INFO: Train epoch 385: [ 9600/94637 (10%)] Step: [2277876] | Lr: 0.000100 | Loss: 1.0839 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 60.25
24-04-02 23:10:31.869 - INFO: Train epoch 385: [11200/94637 (12%)] Step: [2277976] | Lr: 0.000100 | Loss: 1.2110 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 59.36
24-04-02 23:11:06.001 - INFO: Train epoch 385: [12800/94637 (14%)] Step: [2278076] | Lr: 0.000100 | Loss: 2.3712 | MSE loss: 0.0006 | Bpp loss: 1.45 | Aux loss: 57.27
24-04-02 23:11:40.371 - INFO: Train epoch 385: [14400/94637 (15%)] Step: [2278176] | Lr: 0.000100 | Loss: 1.0487 | MSE loss: 0.0003 | Bpp loss: 0.60 | Aux loss: 58.86
24-04-02 23:12:14.158 - INFO: Train epoch 385: [16000/94637 (17%)] Step: [2278276] | Lr: 0.000100 | Loss: 1.0439 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 54.50
24-04-02 23:12:48.157 - INFO: Train epoch 385: [17600/94637 (19%)] Step: [2278376] | Lr: 0.000100 | Loss: 0.8066 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 61.36
24-04-02 23:13:22.141 - INFO: Train epoch 385: [19200/94637 (20%)] Step: [2278476] | Lr: 0.000100 | Loss: 1.3065 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 60.91
24-04-02 23:13:56.120 - INFO: Train epoch 385: [20800/94637 (22%)] Step: [2278576] | Lr: 0.000100 | Loss: 0.8278 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 59.00
24-04-02 23:14:30.360 - INFO: Train epoch 385: [22400/94637 (24%)] Step: [2278676] | Lr: 0.000100 | Loss: 1.0474 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 56.85
24-04-02 23:15:04.430 - INFO: Train epoch 385: [24000/94637 (25%)] Step: [2278776] | Lr: 0.000100 | Loss: 0.8299 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 55.72
24-04-02 23:15:38.251 - INFO: Train epoch 385: [25600/94637 (27%)] Step: [2278876] | Lr: 0.000100 | Loss: 1.0720 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 63.66
24-04-02 23:16:12.658 - INFO: Train epoch 385: [27200/94637 (29%)] Step: [2278976] | Lr: 0.000100 | Loss: 1.7493 | MSE loss: 0.0004 | Bpp loss: 1.14 | Aux loss: 58.56
24-04-02 23:16:46.767 - INFO: Train epoch 385: [28800/94637 (30%)] Step: [2279076] | Lr: 0.000100 | Loss: 1.0108 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 66.30
24-04-02 23:17:21.474 - INFO: Train epoch 385: [30400/94637 (32%)] Step: [2279176] | Lr: 0.000100 | Loss: 1.1786 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 57.59
24-04-02 23:17:56.043 - INFO: Train epoch 385: [32000/94637 (34%)] Step: [2279276] | Lr: 0.000100 | Loss: 0.9461 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 58.98
24-04-02 23:18:30.871 - INFO: Train epoch 385: [33600/94637 (36%)] Step: [2279376] | Lr: 0.000100 | Loss: 1.4649 | MSE loss: 0.0004 | Bpp loss: 0.85 | Aux loss: 59.30
24-04-02 23:19:05.338 - INFO: Train epoch 385: [35200/94637 (37%)] Step: [2279476] | Lr: 0.000100 | Loss: 1.2810 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 60.30
24-04-02 23:19:40.199 - INFO: Train epoch 385: [36800/94637 (39%)] Step: [2279576] | Lr: 0.000100 | Loss: 1.5530 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 55.47
24-04-02 23:20:14.315 - INFO: Train epoch 385: [38400/94637 (41%)] Step: [2279676] | Lr: 0.000100 | Loss: 1.2845 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 62.47
24-04-02 23:20:48.641 - INFO: Train epoch 385: [40000/94637 (42%)] Step: [2279776] | Lr: 0.000100 | Loss: 1.1516 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 62.11
24-04-02 23:21:22.319 - INFO: Train epoch 385: [41600/94637 (44%)] Step: [2279876] | Lr: 0.000100 | Loss: 1.0786 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 60.98
24-04-02 23:21:56.625 - INFO: Train epoch 385: [43200/94637 (46%)] Step: [2279976] | Lr: 0.000100 | Loss: 1.2140 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 58.40
24-04-02 23:22:31.924 - INFO: Train epoch 385: [44800/94637 (47%)] Step: [2280076] | Lr: 0.000100 | Loss: 1.3621 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 59.42
24-04-02 23:23:04.854 - INFO: Train epoch 385: [46400/94637 (49%)] Step: [2280176] | Lr: 0.000100 | Loss: 1.1340 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 55.40
24-04-02 23:23:38.085 - INFO: Train epoch 385: [48000/94637 (51%)] Step: [2280276] | Lr: 0.000100 | Loss: 1.7229 | MSE loss: 0.0004 | Bpp loss: 0.99 | Aux loss: 62.86
24-04-02 23:24:11.759 - INFO: Train epoch 385: [49600/94637 (52%)] Step: [2280376] | Lr: 0.000100 | Loss: 1.4571 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 61.71
24-04-02 23:24:46.543 - INFO: Train epoch 385: [51200/94637 (54%)] Step: [2280476] | Lr: 0.000100 | Loss: 1.1142 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 61.37
24-04-02 23:25:21.227 - INFO: Train epoch 385: [52800/94637 (56%)] Step: [2280576] | Lr: 0.000100 | Loss: 1.8763 | MSE loss: 0.0004 | Bpp loss: 1.18 | Aux loss: 61.54
24-04-02 23:25:55.664 - INFO: Train epoch 385: [54400/94637 (57%)] Step: [2280676] | Lr: 0.000100 | Loss: 0.8216 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 55.76
24-04-02 23:26:29.886 - INFO: Train epoch 385: [56000/94637 (59%)] Step: [2280776] | Lr: 0.000100 | Loss: 1.6684 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 55.83
24-04-02 23:27:04.498 - INFO: Train epoch 385: [57600/94637 (61%)] Step: [2280876] | Lr: 0.000100 | Loss: 0.8613 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 61.49
24-04-02 23:27:38.911 - INFO: Train epoch 385: [59200/94637 (63%)] Step: [2280976] | Lr: 0.000100 | Loss: 1.4402 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 57.63
24-04-02 23:28:13.659 - INFO: Train epoch 385: [60800/94637 (64%)] Step: [2281076] | Lr: 0.000100 | Loss: 1.0990 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 57.49
24-04-02 23:28:48.613 - INFO: Train epoch 385: [62400/94637 (66%)] Step: [2281176] | Lr: 0.000100 | Loss: 1.4669 | MSE loss: 0.0004 | Bpp loss: 0.84 | Aux loss: 60.41
24-04-02 23:29:22.951 - INFO: Train epoch 385: [64000/94637 (68%)] Step: [2281276] | Lr: 0.000100 | Loss: 0.9029 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 61.48
24-04-02 23:29:57.928 - INFO: Train epoch 385: [65600/94637 (69%)] Step: [2281376] | Lr: 0.000100 | Loss: 1.3221 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 57.87
24-04-02 23:30:32.937 - INFO: Train epoch 385: [67200/94637 (71%)] Step: [2281476] | Lr: 0.000100 | Loss: 1.5998 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 66.86
24-04-02 23:31:06.769 - INFO: Train epoch 385: [68800/94637 (73%)] Step: [2281576] | Lr: 0.000100 | Loss: 1.1047 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 63.90
24-04-02 23:31:42.267 - INFO: Train epoch 385: [70400/94637 (74%)] Step: [2281676] | Lr: 0.000100 | Loss: 1.1996 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 59.81
24-04-02 23:32:16.867 - INFO: Train epoch 385: [72000/94637 (76%)] Step: [2281776] | Lr: 0.000100 | Loss: 1.4098 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 59.97
24-04-02 23:32:51.026 - INFO: Train epoch 385: [73600/94637 (78%)] Step: [2281876] | Lr: 0.000100 | Loss: 1.1681 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 59.30
24-04-02 23:33:25.364 - INFO: Train epoch 385: [75200/94637 (79%)] Step: [2281976] | Lr: 0.000100 | Loss: 0.9278 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 58.66
24-04-02 23:34:00.715 - INFO: Train epoch 385: [76800/94637 (81%)] Step: [2282076] | Lr: 0.000100 | Loss: 1.2112 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 64.99
24-04-02 23:34:35.673 - INFO: Train epoch 385: [78400/94637 (83%)] Step: [2282176] | Lr: 0.000100 | Loss: 1.4254 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 60.34
24-04-02 23:35:09.918 - INFO: Train epoch 385: [80000/94637 (85%)] Step: [2282276] | Lr: 0.000100 | Loss: 1.4660 | MSE loss: 0.0003 | Bpp loss: 0.96 | Aux loss: 61.25
24-04-02 23:35:45.396 - INFO: Train epoch 385: [81600/94637 (86%)] Step: [2282376] | Lr: 0.000100 | Loss: 1.0891 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 56.81
24-04-02 23:36:20.332 - INFO: Train epoch 385: [83200/94637 (88%)] Step: [2282476] | Lr: 0.000100 | Loss: 1.1429 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 59.56
24-04-02 23:36:57.332 - INFO: Train epoch 385: [84800/94637 (90%)] Step: [2282576] | Lr: 0.000100 | Loss: 1.6955 | MSE loss: 0.0004 | Bpp loss: 1.05 | Aux loss: 61.98
24-04-02 23:37:32.142 - INFO: Train epoch 385: [86400/94637 (91%)] Step: [2282676] | Lr: 0.000100 | Loss: 1.1343 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 59.35
24-04-02 23:38:07.113 - INFO: Train epoch 385: [88000/94637 (93%)] Step: [2282776] | Lr: 0.000100 | Loss: 1.0847 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 60.55
24-04-02 23:38:41.901 - INFO: Train epoch 385: [89600/94637 (95%)] Step: [2282876] | Lr: 0.000100 | Loss: 1.0015 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 63.12
24-04-02 23:39:16.070 - INFO: Train epoch 385: [91200/94637 (96%)] Step: [2282976] | Lr: 0.000100 | Loss: 0.9229 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 58.00
24-04-02 23:39:49.966 - INFO: Train epoch 385: [92800/94637 (98%)] Step: [2283076] | Lr: 0.000100 | Loss: 1.0759 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 63.98
24-04-02 23:40:24.631 - INFO: Train epoch 385: [94400/94637 (100%)] Step: [2283176] | Lr: 0.000100 | Loss: 1.0073 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 62.84
24-04-02 23:40:41.075 - INFO: Learning rate: 0.0001
24-04-02 23:40:41.960 - INFO: Train epoch 386: [    0/94637 (0%)] Step: [2283191] | Lr: 0.000100 | Loss: 1.3841 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 60.53
24-04-02 23:41:16.533 - INFO: Train epoch 386: [ 1600/94637 (2%)] Step: [2283291] | Lr: 0.000100 | Loss: 1.6688 | MSE loss: 0.0005 | Bpp loss: 0.86 | Aux loss: 57.91
24-04-02 23:41:50.271 - INFO: Train epoch 386: [ 3200/94637 (3%)] Step: [2283391] | Lr: 0.000100 | Loss: 1.2347 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 61.35
24-04-02 23:42:23.981 - INFO: Train epoch 386: [ 4800/94637 (5%)] Step: [2283491] | Lr: 0.000100 | Loss: 1.4520 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 60.30
24-04-02 23:42:57.495 - INFO: Train epoch 386: [ 6400/94637 (7%)] Step: [2283591] | Lr: 0.000100 | Loss: 1.7821 | MSE loss: 0.0004 | Bpp loss: 1.15 | Aux loss: 64.55
24-04-02 23:43:31.653 - INFO: Train epoch 386: [ 8000/94637 (8%)] Step: [2283691] | Lr: 0.000100 | Loss: 0.9735 | MSE loss: 0.0003 | Bpp loss: 0.53 | Aux loss: 60.25
24-04-02 23:44:05.876 - INFO: Train epoch 386: [ 9600/94637 (10%)] Step: [2283791] | Lr: 0.000100 | Loss: 0.7962 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 60.52
24-04-02 23:44:40.713 - INFO: Train epoch 386: [11200/94637 (12%)] Step: [2283891] | Lr: 0.000100 | Loss: 1.6515 | MSE loss: 0.0004 | Bpp loss: 1.05 | Aux loss: 64.21
24-04-02 23:45:14.551 - INFO: Train epoch 386: [12800/94637 (14%)] Step: [2283991] | Lr: 0.000100 | Loss: 1.7790 | MSE loss: 0.0004 | Bpp loss: 1.11 | Aux loss: 64.72
24-04-02 23:45:48.722 - INFO: Train epoch 386: [14400/94637 (15%)] Step: [2284091] | Lr: 0.000100 | Loss: 1.3353 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 63.72
24-04-02 23:46:22.558 - INFO: Train epoch 386: [16000/94637 (17%)] Step: [2284191] | Lr: 0.000100 | Loss: 1.0938 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 57.10
24-04-02 23:46:56.264 - INFO: Train epoch 386: [17600/94637 (19%)] Step: [2284291] | Lr: 0.000100 | Loss: 1.0727 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 59.97
24-04-02 23:47:31.356 - INFO: Train epoch 386: [19200/94637 (20%)] Step: [2284391] | Lr: 0.000100 | Loss: 1.0413 | MSE loss: 0.0003 | Bpp loss: 0.56 | Aux loss: 56.32
24-04-02 23:48:06.161 - INFO: Train epoch 386: [20800/94637 (22%)] Step: [2284491] | Lr: 0.000100 | Loss: 1.4053 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 58.14
24-04-02 23:48:40.890 - INFO: Train epoch 386: [22400/94637 (24%)] Step: [2284591] | Lr: 0.000100 | Loss: 1.0331 | MSE loss: 0.0003 | Bpp loss: 0.59 | Aux loss: 62.41
24-04-02 23:49:15.538 - INFO: Train epoch 386: [24000/94637 (25%)] Step: [2284691] | Lr: 0.000100 | Loss: 1.3778 | MSE loss: 0.0004 | Bpp loss: 0.78 | Aux loss: 58.21
24-04-02 23:49:50.885 - INFO: Train epoch 386: [25600/94637 (27%)] Step: [2284791] | Lr: 0.000100 | Loss: 0.6085 | MSE loss: 0.0001 | Bpp loss: 0.41 | Aux loss: 66.00
24-04-02 23:50:25.603 - INFO: Train epoch 386: [27200/94637 (29%)] Step: [2284891] | Lr: 0.000100 | Loss: 1.0196 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 60.20
24-04-02 23:51:00.514 - INFO: Train epoch 386: [28800/94637 (30%)] Step: [2284991] | Lr: 0.000100 | Loss: 0.8877 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 62.09
24-04-02 23:51:37.622 - INFO: Train epoch 386: [30400/94637 (32%)] Step: [2285091] | Lr: 0.000100 | Loss: 0.9096 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 59.27
24-04-02 23:52:12.216 - INFO: Train epoch 386: [32000/94637 (34%)] Step: [2285191] | Lr: 0.000100 | Loss: 1.4399 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 64.11
24-04-02 23:52:46.895 - INFO: Train epoch 386: [33600/94637 (36%)] Step: [2285291] | Lr: 0.000100 | Loss: 0.7510 | MSE loss: 0.0002 | Bpp loss: 0.47 | Aux loss: 60.26
24-04-02 23:53:20.829 - INFO: Train epoch 386: [35200/94637 (37%)] Step: [2285391] | Lr: 0.000100 | Loss: 2.3286 | MSE loss: 0.0007 | Bpp loss: 1.21 | Aux loss: 62.53
24-04-02 23:53:55.321 - INFO: Train epoch 386: [36800/94637 (39%)] Step: [2285491] | Lr: 0.000100 | Loss: 1.0997 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 59.37
24-04-02 23:54:30.104 - INFO: Train epoch 386: [38400/94637 (41%)] Step: [2285591] | Lr: 0.000100 | Loss: 1.6054 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 64.74
24-04-02 23:55:04.797 - INFO: Train epoch 386: [40000/94637 (42%)] Step: [2285691] | Lr: 0.000100 | Loss: 0.9065 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 63.80
24-04-02 23:55:39.218 - INFO: Train epoch 386: [41600/94637 (44%)] Step: [2285791] | Lr: 0.000100 | Loss: 1.1124 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 59.78
24-04-02 23:56:14.127 - INFO: Train epoch 386: [43200/94637 (46%)] Step: [2285891] | Lr: 0.000100 | Loss: 1.3909 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 57.68
24-04-02 23:56:49.117 - INFO: Train epoch 386: [44800/94637 (47%)] Step: [2285991] | Lr: 0.000100 | Loss: 0.9635 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 58.30
24-04-02 23:57:23.530 - INFO: Train epoch 386: [46400/94637 (49%)] Step: [2286091] | Lr: 0.000100 | Loss: 0.9269 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 56.94
24-04-02 23:57:58.091 - INFO: Train epoch 386: [48000/94637 (51%)] Step: [2286191] | Lr: 0.000100 | Loss: 0.8816 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 59.50
24-04-02 23:58:32.343 - INFO: Train epoch 386: [49600/94637 (52%)] Step: [2286291] | Lr: 0.000100 | Loss: 0.9583 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 56.68
24-04-02 23:59:07.093 - INFO: Train epoch 386: [51200/94637 (54%)] Step: [2286391] | Lr: 0.000100 | Loss: 1.2926 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 58.63
24-04-02 23:59:41.209 - INFO: Train epoch 386: [52800/94637 (56%)] Step: [2286491] | Lr: 0.000100 | Loss: 0.6903 | MSE loss: 0.0001 | Bpp loss: 0.45 | Aux loss: 55.69
24-04-03 00:00:16.333 - INFO: Train epoch 386: [54400/94637 (57%)] Step: [2286591] | Lr: 0.000100 | Loss: 1.2064 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 62.22
24-04-03 00:00:51.988 - INFO: Train epoch 386: [56000/94637 (59%)] Step: [2286691] | Lr: 0.000100 | Loss: 1.6659 | MSE loss: 0.0004 | Bpp loss: 1.07 | Aux loss: 58.25
24-04-03 00:01:26.968 - INFO: Train epoch 386: [57600/94637 (61%)] Step: [2286791] | Lr: 0.000100 | Loss: 0.9750 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 55.64
24-04-03 00:02:02.131 - INFO: Train epoch 386: [59200/94637 (63%)] Step: [2286891] | Lr: 0.000100 | Loss: 1.2720 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 58.80
24-04-03 00:02:36.676 - INFO: Train epoch 386: [60800/94637 (64%)] Step: [2286991] | Lr: 0.000100 | Loss: 1.6370 | MSE loss: 0.0004 | Bpp loss: 1.03 | Aux loss: 57.40
24-04-03 00:03:11.267 - INFO: Train epoch 386: [62400/94637 (66%)] Step: [2287091] | Lr: 0.000100 | Loss: 1.9424 | MSE loss: 0.0005 | Bpp loss: 1.21 | Aux loss: 60.14
24-04-03 00:03:46.001 - INFO: Train epoch 386: [64000/94637 (68%)] Step: [2287191] | Lr: 0.000100 | Loss: 1.4259 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 57.89
24-04-03 00:04:20.498 - INFO: Train epoch 386: [65600/94637 (69%)] Step: [2287291] | Lr: 0.000100 | Loss: 1.1162 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 55.50
24-04-03 00:04:54.667 - INFO: Train epoch 386: [67200/94637 (71%)] Step: [2287391] | Lr: 0.000100 | Loss: 1.1983 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 60.81
24-04-03 00:05:29.640 - INFO: Train epoch 386: [68800/94637 (73%)] Step: [2287491] | Lr: 0.000100 | Loss: 1.1797 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 57.30
24-04-03 00:06:06.208 - INFO: Train epoch 386: [70400/94637 (74%)] Step: [2287591] | Lr: 0.000100 | Loss: 1.3572 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 57.83
24-04-03 00:06:40.703 - INFO: Train epoch 386: [72000/94637 (76%)] Step: [2287691] | Lr: 0.000100 | Loss: 1.8041 | MSE loss: 0.0005 | Bpp loss: 1.06 | Aux loss: 59.78
24-04-03 00:07:15.163 - INFO: Train epoch 386: [73600/94637 (78%)] Step: [2287791] | Lr: 0.000100 | Loss: 1.0209 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 57.78
24-04-03 00:07:49.607 - INFO: Train epoch 386: [75200/94637 (79%)] Step: [2287891] | Lr: 0.000100 | Loss: 2.1232 | MSE loss: 0.0006 | Bpp loss: 1.22 | Aux loss: 62.39
24-04-03 00:08:23.700 - INFO: Train epoch 386: [76800/94637 (81%)] Step: [2287991] | Lr: 0.000100 | Loss: 0.9497 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 57.51
24-04-03 00:08:57.872 - INFO: Train epoch 386: [78400/94637 (83%)] Step: [2288091] | Lr: 0.000100 | Loss: 1.4906 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 56.85
24-04-03 00:09:32.059 - INFO: Train epoch 386: [80000/94637 (85%)] Step: [2288191] | Lr: 0.000100 | Loss: 1.1364 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 60.51
24-04-03 00:10:06.150 - INFO: Train epoch 386: [81600/94637 (86%)] Step: [2288291] | Lr: 0.000100 | Loss: 1.7719 | MSE loss: 0.0004 | Bpp loss: 1.12 | Aux loss: 59.89
24-04-03 00:10:41.770 - INFO: Train epoch 386: [83200/94637 (88%)] Step: [2288391] | Lr: 0.000100 | Loss: 0.6647 | MSE loss: 0.0002 | Bpp loss: 0.41 | Aux loss: 60.41
24-04-03 00:11:16.350 - INFO: Train epoch 386: [84800/94637 (90%)] Step: [2288491] | Lr: 0.000100 | Loss: 1.2639 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 62.98
24-04-03 00:11:51.036 - INFO: Train epoch 386: [86400/94637 (91%)] Step: [2288591] | Lr: 0.000100 | Loss: 1.5019 | MSE loss: 0.0004 | Bpp loss: 0.79 | Aux loss: 56.51
24-04-03 00:12:26.322 - INFO: Train epoch 386: [88000/94637 (93%)] Step: [2288691] | Lr: 0.000100 | Loss: 1.5249 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 61.12
24-04-03 00:12:59.613 - INFO: Train epoch 386: [89600/94637 (95%)] Step: [2288791] | Lr: 0.000100 | Loss: 1.4495 | MSE loss: 0.0004 | Bpp loss: 0.84 | Aux loss: 57.89
24-04-03 00:13:33.192 - INFO: Train epoch 386: [91200/94637 (96%)] Step: [2288891] | Lr: 0.000100 | Loss: 1.2743 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 59.29
24-04-03 00:14:07.034 - INFO: Train epoch 386: [92800/94637 (98%)] Step: [2288991] | Lr: 0.000100 | Loss: 1.3485 | MSE loss: 0.0004 | Bpp loss: 0.77 | Aux loss: 61.23
24-04-03 00:14:40.825 - INFO: Train epoch 386: [94400/94637 (100%)] Step: [2289091] | Lr: 0.000100 | Loss: 1.4741 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 59.59
24-04-03 00:14:57.545 - INFO: Learning rate: 0.0001
24-04-03 00:14:58.801 - INFO: Train epoch 387: [    0/94637 (0%)] Step: [2289106] | Lr: 0.000100 | Loss: 1.8594 | MSE loss: 0.0004 | Bpp loss: 1.25 | Aux loss: 62.78
24-04-03 00:15:33.222 - INFO: Train epoch 387: [ 1600/94637 (2%)] Step: [2289206] | Lr: 0.000100 | Loss: 0.9831 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 57.24
24-04-03 00:16:07.633 - INFO: Train epoch 387: [ 3200/94637 (3%)] Step: [2289306] | Lr: 0.000100 | Loss: 1.1951 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 60.13
24-04-03 00:16:42.677 - INFO: Train epoch 387: [ 4800/94637 (5%)] Step: [2289406] | Lr: 0.000100 | Loss: 1.7148 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 57.48
24-04-03 00:17:17.049 - INFO: Train epoch 387: [ 6400/94637 (7%)] Step: [2289506] | Lr: 0.000100 | Loss: 0.8798 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 58.85
24-04-03 00:17:51.434 - INFO: Train epoch 387: [ 8000/94637 (8%)] Step: [2289606] | Lr: 0.000100 | Loss: 2.2769 | MSE loss: 0.0006 | Bpp loss: 1.25 | Aux loss: 61.73
24-04-03 00:18:26.017 - INFO: Train epoch 387: [ 9600/94637 (10%)] Step: [2289706] | Lr: 0.000100 | Loss: 1.2679 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 64.35
24-04-03 00:19:00.435 - INFO: Train epoch 387: [11200/94637 (12%)] Step: [2289806] | Lr: 0.000100 | Loss: 1.7259 | MSE loss: 0.0004 | Bpp loss: 1.10 | Aux loss: 56.18
24-04-03 00:19:35.113 - INFO: Train epoch 387: [12800/94637 (14%)] Step: [2289906] | Lr: 0.000100 | Loss: 1.3843 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 65.16
24-04-03 00:20:11.372 - INFO: Train epoch 387: [14400/94637 (15%)] Step: [2290006] | Lr: 0.000100 | Loss: 1.3188 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 60.50
24-04-03 00:20:46.058 - INFO: Train epoch 387: [16000/94637 (17%)] Step: [2290106] | Lr: 0.000100 | Loss: 1.4007 | MSE loss: 0.0004 | Bpp loss: 0.83 | Aux loss: 64.66
24-04-03 00:21:20.748 - INFO: Train epoch 387: [17600/94637 (19%)] Step: [2290206] | Lr: 0.000100 | Loss: 1.3047 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 58.11
24-04-03 00:21:55.134 - INFO: Train epoch 387: [19200/94637 (20%)] Step: [2290306] | Lr: 0.000100 | Loss: 0.6528 | MSE loss: 0.0001 | Bpp loss: 0.45 | Aux loss: 61.23
24-04-03 00:22:29.952 - INFO: Train epoch 387: [20800/94637 (22%)] Step: [2290406] | Lr: 0.000100 | Loss: 1.7032 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 60.74
24-04-03 00:23:04.658 - INFO: Train epoch 387: [22400/94637 (24%)] Step: [2290506] | Lr: 0.000100 | Loss: 1.2687 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 64.54
24-04-03 00:23:38.908 - INFO: Train epoch 387: [24000/94637 (25%)] Step: [2290606] | Lr: 0.000100 | Loss: 1.0165 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 62.13
24-04-03 00:24:13.169 - INFO: Train epoch 387: [25600/94637 (27%)] Step: [2290706] | Lr: 0.000100 | Loss: 1.3472 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 57.64
24-04-03 00:24:47.184 - INFO: Train epoch 387: [27200/94637 (29%)] Step: [2290806] | Lr: 0.000100 | Loss: 1.4867 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 65.81
24-04-03 00:25:20.965 - INFO: Train epoch 387: [28800/94637 (30%)] Step: [2290906] | Lr: 0.000100 | Loss: 1.3008 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 62.40
24-04-03 00:25:55.171 - INFO: Train epoch 387: [30400/94637 (32%)] Step: [2291006] | Lr: 0.000100 | Loss: 1.4148 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 63.42
24-04-03 00:26:29.554 - INFO: Train epoch 387: [32000/94637 (34%)] Step: [2291106] | Lr: 0.000100 | Loss: 1.9899 | MSE loss: 0.0005 | Bpp loss: 1.23 | Aux loss: 62.24
24-04-03 00:27:03.959 - INFO: Train epoch 387: [33600/94637 (36%)] Step: [2291206] | Lr: 0.000100 | Loss: 1.3716 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 57.78
24-04-03 00:27:38.788 - INFO: Train epoch 387: [35200/94637 (37%)] Step: [2291306] | Lr: 0.000100 | Loss: 1.1673 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 60.27
24-04-03 00:28:13.874 - INFO: Train epoch 387: [36800/94637 (39%)] Step: [2291406] | Lr: 0.000100 | Loss: 1.4964 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 62.52
24-04-03 00:28:48.614 - INFO: Train epoch 387: [38400/94637 (41%)] Step: [2291506] | Lr: 0.000100 | Loss: 0.7303 | MSE loss: 0.0002 | Bpp loss: 0.47 | Aux loss: 59.00
24-04-03 00:29:22.551 - INFO: Train epoch 387: [40000/94637 (42%)] Step: [2291606] | Lr: 0.000100 | Loss: 1.2862 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 60.12
24-04-03 00:29:57.428 - INFO: Train epoch 387: [41600/94637 (44%)] Step: [2291706] | Lr: 0.000100 | Loss: 1.7249 | MSE loss: 0.0004 | Bpp loss: 1.09 | Aux loss: 59.26
24-04-03 00:30:31.702 - INFO: Train epoch 387: [43200/94637 (46%)] Step: [2291806] | Lr: 0.000100 | Loss: 0.8011 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 61.59
24-04-03 00:31:06.370 - INFO: Train epoch 387: [44800/94637 (47%)] Step: [2291906] | Lr: 0.000100 | Loss: 1.3547 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 63.75
24-04-03 00:31:41.097 - INFO: Train epoch 387: [46400/94637 (49%)] Step: [2292006] | Lr: 0.000100 | Loss: 1.4194 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 61.12
24-04-03 00:32:15.721 - INFO: Train epoch 387: [48000/94637 (51%)] Step: [2292106] | Lr: 0.000100 | Loss: 2.2561 | MSE loss: 0.0005 | Bpp loss: 1.41 | Aux loss: 60.66
24-04-03 00:32:50.376 - INFO: Train epoch 387: [49600/94637 (52%)] Step: [2292206] | Lr: 0.000100 | Loss: 1.1058 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 60.91
24-04-03 00:33:25.012 - INFO: Train epoch 387: [51200/94637 (54%)] Step: [2292306] | Lr: 0.000100 | Loss: 1.1025 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 61.80
