24-04-05 23:53:54.841 - INFO: Namespace(experiment='mlicpp_mse_0250', dataset='/mnt/bn/jiangwei-lvc3/dataset/image', epochs=50000, learning_rate=3e-05, num_workers=8, lmbda=0.025, metrics='mse', batch_size=8, test_batch_size=1, aux_learning_rate=0.001, patch_size=[512, 512], gpu_id=0, cuda=True, save=True, seed=1984.0, clip_max_norm=1.0, checkpoint='/mnt/bn/jiangwei-lvc3/work_space/MLICPlusPlus/playground/experiments/mlicpp_mse_0250/checkpoints', world_size=4, dist_url='env://', rank=2, gpu=2, distributed=True, dist_backend='nccl')
24-04-05 23:53:54.841 - INFO: {'N': 192, 'M': 320, 'enc_dims': [3, 192, 192, 192, 320], 'dec_dims': [320, 192, 192, 192, 16, 3], 'slice_num': 10, 'context_window': 5, 'slice_ch': [8, 8, 8, 8, 16, 16, 32, 32, 96, 96], 'max_support_slices': 5, 'quant': 'ste', 'lambda_list': [0.07, 0.08, 0.09], 'use_hyper_gain': False, 'interpolated_type': 'exponential', 'act': <class 'torch.nn.modules.activation.GELU'>, 'L': 10, 'target_bpp': [0.0761, 0.1854, 0.2752, 0.3652, 0.4282, 0.5238, 0.5653, 0.6334, 0.745], 'bpp_threshold': [0.02, 0.02, 0.02, 0.02, 0.03, 0.02, 0.02, 0.02, 0.02], 'min_lmbda': 0.001, 'init_lmbda': [0.001, 0.0018, 0.0035, 0.0035, 0.0067, 0.0067, 0.013, 0.013, 0.025, 0.0483], 'lower_bound': 1e-09, 'ki': 0.1, 'kp': 0.1}
24-04-05 23:53:54.841 - INFO: DistributedDataParallel(
  (module): MLICPlusPlus(
    (entropy_bottleneck): EntropyBottleneck(
      (likelihood_lower_bound): LowerBound()
    )
    (g_a): AnalysisTransform(
      (analysis_transform): Sequential(
        (0): ResidualBlockWithStride(
          (conv1): Conv2d(3, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (gdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (skip): Conv2d(3, 192, kernel_size=(1, 1), stride=(2, 2))
        )
        (1): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (2): ResidualBlockWithStride(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (gdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (skip): Conv2d(192, 192, kernel_size=(1, 1), stride=(2, 2))
        )
        (3): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (4): ResidualBlockWithStride(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (gdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (skip): Conv2d(192, 192, kernel_size=(1, 1), stride=(2, 2))
        )
        (5): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (6): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      )
    )
    (g_s): SynthesisTransform(
      (synthesis_transform): Sequential(
        (0): ResidualBlock(
          (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (1): ResidualBlockUpsample(
          (subpel_conv): Sequential(
            (0): Conv2d(320, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
          (act): GELU(approximate='none')
          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (igdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (upsample): Sequential(
            (0): Conv2d(320, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
        )
        (2): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (3): ResidualBlockUpsample(
          (subpel_conv): Sequential(
            (0): Conv2d(192, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
          (act): GELU(approximate='none')
          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (igdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (upsample): Sequential(
            (0): Conv2d(192, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
        )
        (4): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (5): ResidualBlockUpsample(
          (subpel_conv): Sequential(
            (0): Conv2d(192, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
          (act): GELU(approximate='none')
          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (igdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (upsample): Sequential(
            (0): Conv2d(192, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
        )
        (6): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (7): Sequential(
          (0): Conv2d(192, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): PixelShuffle(upscale_factor=2)
        )
      )
    )
    (h_a): HyperAnalysis(
      (reduction): Sequential(
        (0): Conv2d(320, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): GELU(approximate='none')
        (2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): GELU(approximate='none')
        (4): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (5): GELU(approximate='none')
        (6): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): GELU(approximate='none')
        (8): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      )
    )
    (h_s): HyperSynthesis(
      (increase): Sequential(
        (0): Conv2d(192, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): GELU(approximate='none')
        (2): Sequential(
          (0): Conv2d(320, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): PixelShuffle(upscale_factor=2)
        )
        (3): GELU(approximate='none')
        (4): Conv2d(320, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): GELU(approximate='none')
        (6): Sequential(
          (0): Conv2d(480, 1920, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): PixelShuffle(upscale_factor=2)
        )
        (7): GELU(approximate='none')
        (8): Conv2d(480, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (gaussian_conditional): GaussianConditional(
      (likelihood_lower_bound): LowerBound()
      (lower_bound_scale): LowerBound()
    )
    (local_context): ModuleList(
      (0-9): 10 x LocalContext(
        (qkv_proj): Linear(in_features=32, out_features=96, bias=True)
        (unfold): Unfold(kernel_size=5, dilation=1, padding=2, stride=1)
        (softmax): Softmax(dim=-1)
        (proj): Linear(in_features=64, out_features=64, bias=True)
        (mlp): MLP(
          (fc1): Linear(in_features=64, out_features=128, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=128, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (fusion): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
      )
    )
    (channel_context): ModuleList(
      (0): None
      (1): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(32, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (2): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (3): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (4): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (5): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(160, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (6): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (7): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(224, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (8): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (9): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(288, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (global_inter_context): ModuleList(
      (0): None
      (1): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (queries): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (values): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (reprojection): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
        )
        (queries): Sequential(
          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
        )
        (values): Sequential(
          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
        )
        (reprojection): Conv2d(64, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (3): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
        )
        (queries): Sequential(
          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
        )
        (values): Sequential(
          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
        )
        (reprojection): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (4): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
        )
        (queries): Sequential(
          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
        )
        (values): Sequential(
          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
        )
        (reprojection): Conv2d(128, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (5): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)
        )
        (queries): Sequential(
          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)
        )
        (values): Sequential(
          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)
        )
        (reprojection): Conv2d(160, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (6): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
        )
        (queries): Sequential(
          (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
        )
        (values): Sequential(
          (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
        )
        (reprojection): Conv2d(192, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (7): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(224, 224, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=224)
        )
        (queries): Sequential(
          (0): Conv2d(224, 224, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=224)
        )
        (values): Sequential(
          (0): Conv2d(224, 224, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=224)
        )
        (reprojection): Conv2d(224, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (8): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
        )
        (queries): Sequential(
          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
        )
        (values): Sequential(
          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
        )
        (reprojection): Conv2d(256, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (9): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)
        )
        (queries): Sequential(
          (0): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)
        )
        (values): Sequential(
          (0): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)
        )
        (reprojection): Conv2d(288, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (global_intra_context): ModuleList(
      (0): None
      (1-9): 9 x LinearGlobalIntraContext(
        (keys): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (queries): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (values): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (reprojection): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
    (entropy_parameters_anchor): ModuleList(
      (0): EntropyParameters(
        (fusion): Sequential(
          (0): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
          (5): GELU(approximate='none')
          (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (1-9): 9 x EntropyParameters(
        (fusion): Sequential(
          (0): Conv2d(832, 320, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
          (5): GELU(approximate='none')
          (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
    (entropy_parameters_nonanchor): ModuleList(
      (0): EntropyParameters(
        (fusion): Sequential(
          (0): Conv2d(704, 320, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
          (5): GELU(approximate='none')
          (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (1-9): 9 x EntropyParameters(
        (fusion): Sequential(
          (0): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
          (5): GELU(approximate='none')
          (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
    (lrp_anchor): ModuleList(
      (0): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(352, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (1): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(384, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (2): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(416, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (3): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(448, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (4): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(480, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (5): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(512, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (6): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(544, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (7): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(576, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (8): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(608, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (9): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(640, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (lrp_nonanchor): ModuleList(
      (0): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(352, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (1): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(384, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (2): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(416, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (3): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(448, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (4): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(480, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (5): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(512, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (6): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(544, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (7): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(576, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (8): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(608, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (9): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(640, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
  )
)
24-04-05 23:53:54.850 - INFO: Learning rate: 3e-05
24-04-06 00:18:17.424 - INFO: Learning rate: 3e-05
24-04-06 00:42:26.344 - INFO: Learning rate: 3e-05
24-04-06 01:06:43.534 - INFO: Learning rate: 3e-05
24-04-06 01:30:51.785 - INFO: Learning rate: 3e-05
24-04-06 01:54:48.557 - INFO: Learning rate: 3e-05
24-04-06 02:18:54.908 - INFO: Learning rate: 3e-05
24-04-06 02:43:18.276 - INFO: Learning rate: 3e-05
24-04-06 03:07:31.060 - INFO: Learning rate: 3e-05
24-04-06 03:31:29.590 - INFO: Learning rate: 3e-05
24-04-06 03:55:47.628 - INFO: Learning rate: 3e-05
24-04-06 04:19:47.954 - INFO: Learning rate: 3e-05
24-04-06 04:43:53.948 - INFO: Learning rate: 3e-05
24-04-06 05:08:01.885 - INFO: Learning rate: 3e-05
24-04-06 05:32:01.749 - INFO: Learning rate: 3e-05
24-04-06 05:55:52.473 - INFO: Learning rate: 3e-05
24-04-06 06:19:55.483 - INFO: Learning rate: 3e-05
24-04-06 06:43:54.567 - INFO: Learning rate: 3e-05
24-04-06 07:07:49.306 - INFO: Learning rate: 3e-05
24-04-06 07:31:35.936 - INFO: Learning rate: 3e-05
24-04-06 07:55:36.367 - INFO: Learning rate: 3e-05
24-04-06 08:19:23.800 - INFO: Learning rate: 3e-05
24-04-06 08:43:43.438 - INFO: Learning rate: 3e-05
24-04-06 09:08:20.232 - INFO: Learning rate: 3e-05
24-04-06 09:32:20.263 - INFO: Learning rate: 3e-05
24-04-06 09:56:32.477 - INFO: Learning rate: 3e-05
24-04-06 10:20:54.824 - INFO: Learning rate: 3e-05
24-04-06 10:45:02.640 - INFO: Learning rate: 3e-05
24-04-06 11:09:05.409 - INFO: Learning rate: 3e-05
24-04-06 11:33:18.569 - INFO: Learning rate: 3e-05
24-04-06 11:57:20.194 - INFO: Learning rate: 3e-05
24-04-06 12:21:27.531 - INFO: Learning rate: 3e-05
24-04-06 12:45:48.462 - INFO: Learning rate: 3e-05
24-04-06 13:10:03.487 - INFO: Learning rate: 3e-05
24-04-06 13:34:08.020 - INFO: Learning rate: 3e-05
24-04-06 13:58:19.313 - INFO: Learning rate: 3e-05
24-04-06 14:22:44.774 - INFO: Learning rate: 3e-05
24-04-06 14:46:56.758 - INFO: Learning rate: 3e-05
24-04-06 15:11:11.212 - INFO: Learning rate: 3e-05
24-04-06 15:35:09.210 - INFO: Learning rate: 3e-05
24-04-06 15:59:09.757 - INFO: Learning rate: 3e-05
24-04-06 16:23:17.655 - INFO: Learning rate: 3e-05
24-04-06 16:47:12.704 - INFO: Learning rate: 3e-05
24-04-06 17:11:05.782 - INFO: Learning rate: 3e-05
24-04-06 17:34:58.781 - INFO: Learning rate: 3e-05
24-04-06 17:59:03.259 - INFO: Learning rate: 3e-05
24-04-06 18:23:05.073 - INFO: Learning rate: 3e-05
24-04-06 18:47:02.291 - INFO: Learning rate: 3e-05
24-04-06 19:11:00.472 - INFO: Learning rate: 3e-05
24-04-06 19:35:06.635 - INFO: Learning rate: 3e-05
24-04-06 19:59:24.848 - INFO: Learning rate: 3e-05
24-04-06 20:23:29.360 - INFO: Learning rate: 3e-05
24-04-06 20:47:39.707 - INFO: Learning rate: 3e-05
24-04-06 21:11:40.933 - INFO: Learning rate: 3e-05
24-04-06 21:35:45.242 - INFO: Learning rate: 3e-05
24-04-06 21:59:56.210 - INFO: Learning rate: 3e-05
24-04-06 22:24:24.801 - INFO: Learning rate: 3e-05
24-04-06 22:48:56.913 - INFO: Learning rate: 3e-05
24-04-06 23:13:21.789 - INFO: Learning rate: 3e-05
s: 0.0003 | Bpp loss: 0.96 | Aux loss: 28.08
24-04-06 00:08:55.063 - INFO: Train epoch 524: [57600/94637 (61%)] Step: [2705187] | Lr: 0.000030 | Loss: 1.1851 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 27.83
24-04-06 00:09:44.286 - INFO: Train epoch 524: [60800/94637 (64%)] Step: [2705287] | Lr: 0.000030 | Loss: 0.8609 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 31.36
24-04-06 00:10:32.540 - INFO: Train epoch 524: [64000/94637 (68%)] Step: [2705387] | Lr: 0.000030 | Loss: 0.9768 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 30.01
24-04-06 00:11:20.937 - INFO: Train epoch 524: [67200/94637 (71%)] Step: [2705487] | Lr: 0.000030 | Loss: 1.2495 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 28.46
24-04-06 00:12:09.574 - INFO: Train epoch 524: [70400/94637 (74%)] Step: [2705587] | Lr: 0.000030 | Loss: 1.2365 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 31.39
24-04-06 00:12:58.483 - INFO: Train epoch 524: [73600/94637 (78%)] Step: [2705687] | Lr: 0.000030 | Loss: 1.2048 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 28.79
24-04-06 00:13:47.327 - INFO: Train epoch 524: [76800/94637 (81%)] Step: [2705787] | Lr: 0.000030 | Loss: 1.2404 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 27.24
24-04-06 00:14:36.086 - INFO: Train epoch 524: [80000/94637 (85%)] Step: [2705887] | Lr: 0.000030 | Loss: 1.7445 | MSE loss: 0.0004 | Bpp loss: 1.07 | Aux loss: 29.52
24-04-06 00:15:24.429 - INFO: Train epoch 524: [83200/94637 (88%)] Step: [2705987] | Lr: 0.000030 | Loss: 1.3576 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 28.92
24-04-06 00:16:12.980 - INFO: Train epoch 524: [86400/94637 (91%)] Step: [2706087] | Lr: 0.000030 | Loss: 1.0432 | MSE loss: 0.0003 | Bpp loss: 0.61 | Aux loss: 30.70
24-04-06 00:17:01.498 - INFO: Train epoch 524: [89600/94637 (95%)] Step: [2706187] | Lr: 0.000030 | Loss: 1.2659 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 30.19
24-04-06 00:17:49.910 - INFO: Train epoch 524: [92800/94637 (98%)] Step: [2706287] | Lr: 0.000030 | Loss: 1.0256 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 33.14
24-04-06 00:18:35.367 - INFO: Learning rate: 3e-05
24-04-06 00:18:36.611 - INFO: Train epoch 525: [    0/94637 (0%)] Step: [2706344] | Lr: 0.000030 | Loss: 1.2513 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 30.32
24-04-06 00:19:24.951 - INFO: Train epoch 525: [ 3200/94637 (3%)] Step: [2706444] | Lr: 0.000030 | Loss: 1.4347 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 31.41
24-04-06 00:20:13.348 - INFO: Train epoch 525: [ 6400/94637 (7%)] Step: [2706544] | Lr: 0.000030 | Loss: 1.0061 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 32.21
24-04-06 00:21:01.301 - INFO: Train epoch 525: [ 9600/94637 (10%)] Step: [2706644] | Lr: 0.000030 | Loss: 1.4165 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 33.15
24-04-06 00:21:49.669 - INFO: Train epoch 525: [12800/94637 (14%)] Step: [2706744] | Lr: 0.000030 | Loss: 1.4800 | MSE loss: 0.0004 | Bpp loss: 0.80 | Aux loss: 31.70
24-04-06 00:22:38.267 - INFO: Train epoch 525: [16000/94637 (17%)] Step: [2706844] | Lr: 0.000030 | Loss: 1.0223 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 31.97
24-04-06 00:23:26.251 - INFO: Train epoch 525: [19200/94637 (20%)] Step: [2706944] | Lr: 0.000030 | Loss: 1.4877 | MSE loss: 0.0004 | Bpp loss: 0.83 | Aux loss: 30.92
24-04-06 00:24:14.508 - INFO: Train epoch 525: [22400/94637 (24%)] Step: [2707044] | Lr: 0.000030 | Loss: 1.3175 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 32.72
24-04-06 00:25:02.522 - INFO: Train epoch 525: [25600/94637 (27%)] Step: [2707144] | Lr: 0.000030 | Loss: 1.2092 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 31.28
24-04-06 00:25:50.497 - INFO: Train epoch 525: [28800/94637 (30%)] Step: [2707244] | Lr: 0.000030 | Loss: 1.0526 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 31.25
24-04-06 00:26:38.779 - INFO: Train epoch 525: [32000/94637 (34%)] Step: [2707344] | Lr: 0.000030 | Loss: 1.1699 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 33.33
24-04-06 00:27:26.219 - INFO: Train epoch 525: [35200/94637 (37%)] Step: [2707444] | Lr: 0.000030 | Loss: 1.5750 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 35.49
24-04-06 00:28:16.484 - INFO: Train epoch 525: [38400/94637 (41%)] Step: [2707544] | Lr: 0.000030 | Loss: 1.1623 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 32.85
24-04-06 00:29:04.085 - INFO: Train epoch 525: [41600/94637 (44%)] Step: [2707644] | Lr: 0.000030 | Loss: 1.4149 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 34.23
24-04-06 00:29:52.015 - INFO: Train epoch 525: [44800/94637 (47%)] Step: [2707744] | Lr: 0.000030 | Loss: 1.2437 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 31.30
24-04-06 00:30:40.206 - INFO: Train epoch 525: [48000/94637 (51%)] Step: [2707844] | Lr: 0.000030 | Loss: 1.3719 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 33.31
24-04-06 00:31:28.488 - INFO: Train epoch 525: [51200/94637 (54%)] Step: [2707944] | Lr: 0.000030 | Loss: 1.4112 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 34.15
24-04-06 00:32:17.325 - INFO: Train epoch 525: [54400/94637 (57%)] Step: [2708044] | Lr: 0.000030 | Loss: 1.6944 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 31.63
24-04-06 00:33:05.905 - INFO: Train epoch 525: [57600/94637 (61%)] Step: [2708144] | Lr: 0.000030 | Loss: 1.0456 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 34.30
24-04-06 00:33:54.473 - INFO: Train epoch 525: [60800/94637 (64%)] Step: [2708244] | Lr: 0.000030 | Loss: 1.1103 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 32.88
24-04-06 00:34:42.973 - INFO: Train epoch 525: [64000/94637 (68%)] Step: [2708344] | Lr: 0.000030 | Loss: 1.1641 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 30.41
24-04-06 00:35:31.526 - INFO: Train epoch 525: [67200/94637 (71%)] Step: [2708444] | Lr: 0.000030 | Loss: 1.3830 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 33.05
24-04-06 00:36:20.363 - INFO: Train epoch 525: [70400/94637 (74%)] Step: [2708544] | Lr: 0.000030 | Loss: 1.2100 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 32.42
24-04-06 00:37:09.242 - INFO: Train epoch 525: [73600/94637 (78%)] Step: [2708644] | Lr: 0.000030 | Loss: 1.3313 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 35.71
24-04-06 00:37:57.657 - INFO: Train epoch 525: [76800/94637 (81%)] Step: [2708744] | Lr: 0.000030 | Loss: 1.0546 | MSE loss: 0.0003 | Bpp loss: 0.62 | Aux loss: 32.74
24-04-06 00:38:45.544 - INFO: Train epoch 525: [80000/94637 (85%)] Step: [2708844] | Lr: 0.000030 | Loss: 1.2360 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 33.98
24-04-06 00:39:33.791 - INFO: Train epoch 525: [83200/94637 (88%)] Step: [2708944] | Lr: 0.000030 | Loss: 1.1460 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 29.80
24-04-06 00:40:21.758 - INFO: Train epoch 525: [86400/94637 (91%)] Step: [2709044] | Lr: 0.000030 | Loss: 1.3607 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 29.39
24-04-06 00:41:10.043 - INFO: Train epoch 525: [89600/94637 (95%)] Step: [2709144] | Lr: 0.000030 | Loss: 1.2125 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 32.33
24-04-06 00:41:58.637 - INFO: Train epoch 525: [92800/94637 (98%)] Step: [2709244] | Lr: 0.000030 | Loss: 1.4426 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 33.86
24-04-06 00:42:43.446 - INFO: Learning rate: 3e-05
24-04-06 00:42:44.508 - INFO: Train epoch 526: [    0/94637 (0%)] Step: [2709301] | Lr: 0.000030 | Loss: 1.0608 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 36.05
24-04-06 00:43:32.508 - INFO: Train epoch 526: [ 3200/94637 (3%)] Step: [2709401] | Lr: 0.000030 | Loss: 1.1116 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 33.41
24-04-06 00:44:21.090 - INFO: Train epoch 526: [ 6400/94637 (7%)] Step: [2709501] | Lr: 0.000030 | Loss: 1.1868 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 33.36
24-04-06 00:45:09.015 - INFO: Train epoch 526: [ 9600/94637 (10%)] Step: [2709601] | Lr: 0.000030 | Loss: 1.5789 | MSE loss: 0.0003 | Bpp loss: 1.01 | Aux loss: 36.21
24-04-06 00:45:56.471 - INFO: Train epoch 526: [12800/94637 (14%)] Step: [2709701] | Lr: 0.000030 | Loss: 1.1816 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 33.30
24-04-06 00:46:44.143 - INFO: Train epoch 526: [16000/94637 (17%)] Step: [2709801] | Lr: 0.000030 | Loss: 1.0052 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 33.73
24-04-06 00:47:32.014 - INFO: Train epoch 526: [19200/94637 (20%)] Step: [2709901] | Lr: 0.000030 | Loss: 1.2139 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 34.09
24-04-06 00:48:22.371 - INFO: Train epoch 526: [22400/94637 (24%)] Step: [2710001] | Lr: 0.000030 | Loss: 1.2698 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 34.71
24-04-06 00:49:10.540 - INFO: Train epoch 526: [25600/94637 (27%)] Step: [2710101] | Lr: 0.000030 | Loss: 0.9080 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 32.41
24-04-06 00:49:58.762 - INFO: Train epoch 526: [28800/94637 (30%)] Step: [2710201] | Lr: 0.000030 | Loss: 0.8391 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 31.32
24-04-06 00:50:46.643 - INFO: Train epoch 526: [32000/94637 (34%)] Step: [2710301] | Lr: 0.000030 | Loss: 1.6581 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 33.94
24-04-06 00:51:34.909 - INFO: Train epoch 526: [35200/94637 (37%)] Step: [2710401] | Lr: 0.000030 | Loss: 0.9768 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 35.13
24-04-06 00:52:23.578 - INFO: Train epoch 526: [38400/94637 (41%)] Step: [2710501] | Lr: 0.000030 | Loss: 1.4614 | MSE loss: 0.0004 | Bpp loss: 0.79 | Aux loss: 35.71
24-04-06 00:53:12.671 - INFO: Train epoch 526: [41600/94637 (44%)] Step: [2710601] | Lr: 0.000030 | Loss: 1.4137 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 34.06
24-04-06 00:54:01.940 - INFO: Train epoch 526: [44800/94637 (47%)] Step: [2710701] | Lr: 0.000030 | Loss: 1.2641 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 33.89
24-04-06 00:54:50.551 - INFO: Train epoch 526: [48000/94637 (51%)] Step: [2710801] | Lr: 0.000030 | Loss: 1.6925 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 34.61
24-04-06 00:55:39.120 - INFO: Train epoch 526: [51200/94637 (54%)] Step: [2710901] | Lr: 0.000030 | Loss: 0.8781 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 32.49
24-04-06 00:56:27.670 - INFO: Train epoch 526: [54400/94637 (57%)] Step: [2711001] | Lr: 0.000030 | Loss: 1.0431 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 35.89
24-04-06 00:57:16.295 - INFO: Train epoch 526: [57600/94637 (61%)] Step: [2711101] | Lr: 0.000030 | Loss: 1.2029 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 36.78
24-04-06 00:58:05.435 - INFO: Train epoch 526: [60800/94637 (64%)] Step: [2711201] | Lr: 0.000030 | Loss: 0.9748 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 31.52
24-04-06 00:58:54.280 - INFO: Train epoch 526: [64000/94637 (68%)] Step: [2711301] | Lr: 0.000030 | Loss: 1.4159 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 35.96
24-04-06 00:59:42.997 - INFO: Train epoch 526: [67200/94637 (71%)] Step: [2711401] | Lr: 0.000030 | Loss: 0.9627 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 34.74
24-04-06 01:00:31.982 - INFO: Train epoch 526: [70400/94637 (74%)] Step: [2711501] | Lr: 0.000030 | Loss: 1.4246 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 35.51
24-04-06 01:01:20.977 - INFO: Train epoch 526: [73600/94637 (78%)] Step: [2711601] | Lr: 0.000030 | Loss: 0.9093 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 34.51
24-04-06 01:02:10.130 - INFO: Train epoch 526: [76800/94637 (81%)] Step: [2711701] | Lr: 0.000030 | Loss: 1.2031 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 37.80
24-04-06 01:02:59.451 - INFO: Train epoch 526: [80000/94637 (85%)] Step: [2711801] | Lr: 0.000030 | Loss: 1.3201 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 36.79
24-04-06 01:03:48.935 - INFO: Train epoch 526: [83200/94637 (88%)] Step: [2711901] | Lr: 0.000030 | Loss: 1.4380 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 37.93
24-04-06 01:04:37.817 - INFO: Train epoch 526: [86400/94637 (91%)] Step: [2712001] | Lr: 0.000030 | Loss: 1.1737 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 33.77
24-04-06 01:05:27.021 - INFO: Train epoch 526: [89600/94637 (95%)] Step: [2712101] | Lr: 0.000030 | Loss: 1.6645 | MSE loss: 0.0003 | Bpp loss: 1.10 | Aux loss: 35.96
24-04-06 01:06:15.857 - INFO: Train epoch 526: [92800/94637 (98%)] Step: [2712201] | Lr: 0.000030 | Loss: 1.4625 | MSE loss: 0.0004 | Bpp loss: 0.81 | Aux loss: 36.12
24-04-06 01:06:54.801 - INFO: Learning rate: 3e-05
24-04-06 01:06:55.946 - INFO: Train epoch 527: [    0/94637 (0%)] Step: [2712258] | Lr: 0.000030 | Loss: 0.9284 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 34.43
24-04-06 01:07:44.541 - INFO: Train epoch 527: [ 3200/94637 (3%)] Step: [2712358] | Lr: 0.000030 | Loss: 1.0828 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 36.54
24-04-06 01:08:32.836 - INFO: Train epoch 527: [ 6400/94637 (7%)] Step: [2712458] | Lr: 0.000030 | Loss: 1.0588 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 37.34
24-04-06 01:09:23.596 - INFO: Train epoch 527: [ 9600/94637 (10%)] Step: [2712558] | Lr: 0.000030 | Loss: 1.0424 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 39.29
24-04-06 01:10:13.014 - INFO: Train epoch 527: [12800/94637 (14%)] Step: [2712658] | Lr: 0.000030 | Loss: 1.1198 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 36.30
24-04-06 01:11:01.795 - INFO: Train epoch 527: [16000/94637 (17%)] Step: [2712758] | Lr: 0.000030 | Loss: 1.0564 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 33.54
24-04-06 01:11:50.276 - INFO: Train epoch 527: [19200/94637 (20%)] Step: [2712858] | Lr: 0.000030 | Loss: 1.0281 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 36.91
24-04-06 01:12:38.586 - INFO: Train epoch 527: [22400/94637 (24%)] Step: [2712958] | Lr: 0.000030 | Loss: 1.6442 | MSE loss: 0.0004 | Bpp loss: 1.06 | Aux loss: 35.98
24-04-06 01:13:27.159 - INFO: Train epoch 527: [25600/94637 (27%)] Step: [2713058] | Lr: 0.000030 | Loss: 0.9483 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 38.20
24-04-06 01:14:15.819 - INFO: Train epoch 527: [28800/94637 (30%)] Step: [2713158] | Lr: 0.000030 | Loss: 1.5003 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 36.85
24-04-06 01:15:04.426 - INFO: Train epoch 527: [32000/94637 (34%)] Step: [2713258] | Lr: 0.000030 | Loss: 1.3574 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 36.94
24-04-06 01:15:52.812 - INFO: Train epoch 527: [35200/94637 (37%)] Step: [2713358] | Lr: 0.000030 | Loss: 1.0194 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 35.42
24-04-06 01:16:41.387 - INFO: Train epoch 527: [38400/94637 (41%)] Step: [2713458] | Lr: 0.000030 | Loss: 1.0021 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 36.64
24-04-06 01:17:29.120 - INFO: Train epoch 527: [41600/94637 (44%)] Step: [2713558] | Lr: 0.000030 | Loss: 1.2699 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 37.66
24-04-06 01:18:16.906 - INFO: Train epoch 527: [44800/94637 (47%)] Step: [2713658] | Lr: 0.000030 | Loss: 0.8167 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 37.68
24-04-06 01:19:04.752 - INFO: Train epoch 527: [48000/94637 (51%)] Step: [2713758] | Lr: 0.000030 | Loss: 1.1418 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 38.45
24-04-06 01:19:52.602 - INFO: Train epoch 527: [51200/94637 (54%)] Step: [2713858] | Lr: 0.000030 | Loss: 1.2759 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 36.83
24-04-06 01:20:40.817 - INFO: Train epoch 527: [54400/94637 (57%)] Step: [2713958] | Lr: 0.000030 | Loss: 1.2472 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 36.42
24-04-06 01:21:29.385 - INFO: Train epoch 527: [57600/94637 (61%)] Step: [2714058] | Lr: 0.000030 | Loss: 1.7210 | MSE loss: 0.0004 | Bpp loss: 1.07 | Aux loss: 38.18
24-04-06 01:22:17.928 - INFO: Train epoch 527: [60800/94637 (64%)] Step: [2714158] | Lr: 0.000030 | Loss: 1.0570 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 39.37
24-04-06 01:23:07.252 - INFO: Train epoch 527: [64000/94637 (68%)] Step: [2714258] | Lr: 0.000030 | Loss: 0.8536 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 39.57
24-04-06 01:23:56.308 - INFO: Train epoch 527: [67200/94637 (71%)] Step: [2714358] | Lr: 0.000030 | Loss: 1.3097 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 37.44
24-04-06 01:24:44.974 - INFO: Train epoch 527: [70400/94637 (74%)] Step: [2714458] | Lr: 0.000030 | Loss: 0.9950 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 36.04
24-04-06 01:25:34.187 - INFO: Train epoch 527: [73600/94637 (78%)] Step: [2714558] | Lr: 0.000030 | Loss: 1.1898 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 37.41
24-04-06 01:26:22.308 - INFO: Train epoch 527: [76800/94637 (81%)] Step: [2714658] | Lr: 0.000030 | Loss: 1.2153 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 37.19
24-04-06 01:27:10.525 - INFO: Train epoch 527: [80000/94637 (85%)] Step: [2714758] | Lr: 0.000030 | Loss: 1.2467 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 38.57
24-04-06 01:27:58.845 - INFO: Train epoch 527: [83200/94637 (88%)] Step: [2714858] | Lr: 0.000030 | Loss: 1.0141 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 37.14
24-04-06 01:28:46.817 - INFO: Train epoch 527: [86400/94637 (91%)] Step: [2714958] | Lr: 0.000030 | Loss: 1.0334 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 38.93
24-04-06 01:29:37.060 - INFO: Train epoch 527: [89600/94637 (95%)] Step: [2715058] | Lr: 0.000030 | Loss: 1.2179 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 39.53
24-04-06 01:30:24.882 - INFO: Train epoch 527: [92800/94637 (98%)] Step: [2715158] | Lr: 0.000030 | Loss: 0.8820 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 36.89
24-04-06 01:31:02.870 - INFO: Learning rate: 3e-05
24-04-06 01:31:04.165 - INFO: Train epoch 528: [    0/94637 (0%)] Step: [2715215] | Lr: 0.000030 | Loss: 1.0192 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 38.14
24-04-06 01:31:51.863 - INFO: Train epoch 528: [ 3200/94637 (3%)] Step: [2715315] | Lr: 0.000030 | Loss: 1.1200 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 38.68
24-04-06 01:32:39.788 - INFO: Train epoch 528: [ 6400/94637 (7%)] Step: [2715415] | Lr: 0.000030 | Loss: 0.8890 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 38.26
24-04-06 01:33:27.999 - INFO: Train epoch 528: [ 9600/94637 (10%)] Step: [2715515] | Lr: 0.000030 | Loss: 1.3175 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 39.22
24-04-06 01:34:16.102 - INFO: Train epoch 528: [12800/94637 (14%)] Step: [2715615] | Lr: 0.000030 | Loss: 1.4408 | MSE loss: 0.0004 | Bpp loss: 0.84 | Aux loss: 38.48
24-04-06 01:35:04.525 - INFO: Train epoch 528: [16000/94637 (17%)] Step: [2715715] | Lr: 0.000030 | Loss: 1.0664 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 39.07
24-04-06 01:35:52.905 - INFO: Train epoch 528: [19200/94637 (20%)] Step: [2715815] | Lr: 0.000030 | Loss: 1.0881 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 41.39
24-04-06 01:36:40.775 - INFO: Train epoch 528: [22400/94637 (24%)] Step: [2715915] | Lr: 0.000030 | Loss: 1.2061 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 37.84
24-04-06 01:37:28.727 - INFO: Train epoch 528: [25600/94637 (27%)] Step: [2716015] | Lr: 0.000030 | Loss: 1.4395 | MSE loss: 0.0004 | Bpp loss: 0.85 | Aux loss: 38.86
24-04-06 01:38:16.413 - INFO: Train epoch 528: [28800/94637 (30%)] Step: [2716115] | Lr: 0.000030 | Loss: 0.8347 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 39.43
24-04-06 01:39:04.853 - INFO: Train epoch 528: [32000/94637 (34%)] Step: [2716215] | Lr: 0.000030 | Loss: 1.3809 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 42.52
24-04-06 01:39:53.502 - INFO: Train epoch 528: [35200/94637 (37%)] Step: [2716315] | Lr: 0.000030 | Loss: 1.1294 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 37.86
24-04-06 01:40:41.536 - INFO: Train epoch 528: [38400/94637 (41%)] Step: [2716415] | Lr: 0.000030 | Loss: 1.1812 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 36.66
24-04-06 01:41:29.431 - INFO: Train epoch 528: [41600/94637 (44%)] Step: [2716515] | Lr: 0.000030 | Loss: 1.1136 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 42.36
24-04-06 01:42:17.520 - INFO: Train epoch 528: [44800/94637 (47%)] Step: [2716615] | Lr: 0.000030 | Loss: 1.1876 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 40.03
24-04-06 01:43:05.782 - INFO: Train epoch 528: [48000/94637 (51%)] Step: [2716715] | Lr: 0.000030 | Loss: 1.4412 | MSE loss: 0.0004 | Bpp loss: 0.86 | Aux loss: 38.82
24-04-06 01:43:53.620 - INFO: Train epoch 528: [51200/94637 (54%)] Step: [2716815] | Lr: 0.000030 | Loss: 1.1125 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 39.02
24-04-06 01:44:42.094 - INFO: Train epoch 528: [54400/94637 (57%)] Step: [2716915] | Lr: 0.000030 | Loss: 1.3543 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 42.57
24-04-06 01:45:30.448 - INFO: Train epoch 528: [57600/94637 (61%)] Step: [2717015] | Lr: 0.000030 | Loss: 1.3505 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 42.89
24-04-06 01:46:18.116 - INFO: Train epoch 528: [60800/94637 (64%)] Step: [2717115] | Lr: 0.000030 | Loss: 0.9991 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 40.53
24-04-06 01:47:05.522 - INFO: Train epoch 528: [64000/94637 (68%)] Step: [2717215] | Lr: 0.000030 | Loss: 1.4681 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 39.31
24-04-06 01:47:52.997 - INFO: Train epoch 528: [67200/94637 (71%)] Step: [2717315] | Lr: 0.000030 | Loss: 0.9456 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 39.00
24-04-06 01:48:41.878 - INFO: Train epoch 528: [70400/94637 (74%)] Step: [2717415] | Lr: 0.000030 | Loss: 1.1739 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 41.83
24-04-06 01:49:31.765 - INFO: Train epoch 528: [73600/94637 (78%)] Step: [2717515] | Lr: 0.000030 | Loss: 0.9758 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 38.48
24-04-06 01:50:20.361 - INFO: Train epoch 528: [76800/94637 (81%)] Step: [2717615] | Lr: 0.000030 | Loss: 1.1033 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 38.78
24-04-06 01:51:07.737 - INFO: Train epoch 528: [80000/94637 (85%)] Step: [2717715] | Lr: 0.000030 | Loss: 1.1702 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 37.64
24-04-06 01:51:55.809 - INFO: Train epoch 528: [83200/94637 (88%)] Step: [2717815] | Lr: 0.000030 | Loss: 1.1019 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 39.58
24-04-06 01:52:43.989 - INFO: Train epoch 528: [86400/94637 (91%)] Step: [2717915] | Lr: 0.000030 | Loss: 1.1849 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 39.93
24-04-06 01:53:32.521 - INFO: Train epoch 528: [89600/94637 (95%)] Step: [2718015] | Lr: 0.000030 | Loss: 1.1987 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 43.18
24-04-06 01:54:21.376 - INFO: Train epoch 528: [92800/94637 (98%)] Step: [2718115] | Lr: 0.000030 | Loss: 1.2047 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 40.47
24-04-06 01:55:00.029 - INFO: Learning rate: 3e-05
24-04-06 01:55:01.891 - INFO: Train epoch 529: [    0/94637 (0%)] Step: [2718172] | Lr: 0.000030 | Loss: 0.8860 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 41.09
24-04-06 01:55:49.280 - INFO: Train epoch 529: [ 3200/94637 (3%)] Step: [2718272] | Lr: 0.000030 | Loss: 1.1023 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 39.93
24-04-06 01:56:37.580 - INFO: Train epoch 529: [ 6400/94637 (7%)] Step: [2718372] | Lr: 0.000030 | Loss: 1.5376 | MSE loss: 0.0003 | Bpp loss: 0.98 | Aux loss: 40.56
24-04-06 01:57:25.796 - INFO: Train epoch 529: [ 9600/94637 (10%)] Step: [2718472] | Lr: 0.000030 | Loss: 1.2555 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 41.17
24-04-06 01:58:13.204 - INFO: Train epoch 529: [12800/94637 (14%)] Step: [2718572] | Lr: 0.000030 | Loss: 1.1960 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 39.88
24-04-06 01:59:00.807 - INFO: Train epoch 529: [16000/94637 (17%)] Step: [2718672] | Lr: 0.000030 | Loss: 1.1296 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 41.78
24-04-06 01:59:49.466 - INFO: Train epoch 529: [19200/94637 (20%)] Step: [2718772] | Lr: 0.000030 | Loss: 1.1829 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 40.87
24-04-06 02:00:37.716 - INFO: Train epoch 529: [22400/94637 (24%)] Step: [2718872] | Lr: 0.000030 | Loss: 1.3102 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 42.98
24-04-06 02:01:25.676 - INFO: Train epoch 529: [25600/94637 (27%)] Step: [2718972] | Lr: 0.000030 | Loss: 0.9342 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 37.27
24-04-06 02:02:12.860 - INFO: Train epoch 529: [28800/94637 (30%)] Step: [2719072] | Lr: 0.000030 | Loss: 0.8186 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 40.06
24-04-06 02:03:00.297 - INFO: Train epoch 529: [32000/94637 (34%)] Step: [2719172] | Lr: 0.000030 | Loss: 1.5043 | MSE loss: 0.0003 | Bpp loss: 0.98 | Aux loss: 43.33
24-04-06 02:03:48.403 - INFO: Train epoch 529: [35200/94637 (37%)] Step: [2719272] | Lr: 0.000030 | Loss: 1.2990 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 40.59
24-04-06 02:04:36.753 - INFO: Train epoch 529: [38400/94637 (41%)] Step: [2719372] | Lr: 0.000030 | Loss: 0.9571 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 38.88
24-04-06 02:05:25.091 - INFO: Train epoch 529: [41600/94637 (44%)] Step: [2719472] | Lr: 0.000030 | Loss: 0.8900 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 39.17
24-04-06 02:06:13.409 - INFO: Train epoch 529: [44800/94637 (47%)] Step: [2719572] | Lr: 0.000030 | Loss: 1.1739 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 40.32
24-04-06 02:07:02.149 - INFO: Train epoch 529: [48000/94637 (51%)] Step: [2719672] | Lr: 0.000030 | Loss: 1.6622 | MSE loss: 0.0004 | Bpp loss: 1.03 | Aux loss: 40.31
24-04-06 02:07:50.393 - INFO: Train epoch 529: [51200/94637 (54%)] Step: [2719772] | Lr: 0.000030 | Loss: 1.0501 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 41.66
24-04-06 02:08:38.853 - INFO: Train epoch 529: [54400/94637 (57%)] Step: [2719872] | Lr: 0.000030 | Loss: 1.3212 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 43.07
24-04-06 02:09:26.683 - INFO: Train epoch 529: [57600/94637 (61%)] Step: [2719972] | Lr: 0.000030 | Loss: 0.9710 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 41.06
24-04-06 02:10:17.304 - INFO: Train epoch 529: [60800/94637 (64%)] Step: [2720072] | Lr: 0.000030 | Loss: 1.6894 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 43.51
24-04-06 02:11:05.655 - INFO: Train epoch 529: [64000/94637 (68%)] Step: [2720172] | Lr: 0.000030 | Loss: 1.2182 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 39.37
24-04-06 02:11:54.543 - INFO: Train epoch 529: [67200/94637 (71%)] Step: [2720272] | Lr: 0.000030 | Loss: 1.5053 | MSE loss: 0.0003 | Bpp loss: 0.96 | Aux loss: 42.14
24-04-06 02:12:43.127 - INFO: Train epoch 529: [70400/94637 (74%)] Step: [2720372] | Lr: 0.000030 | Loss: 0.8663 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 41.51
24-04-06 02:13:32.047 - INFO: Train epoch 529: [73600/94637 (78%)] Step: [2720472] | Lr: 0.000030 | Loss: 1.0603 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 40.07
24-04-06 02:14:20.553 - INFO: Train epoch 529: [76800/94637 (81%)] Step: [2720572] | Lr: 0.000030 | Loss: 1.2383 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 41.38
24-04-06 02:15:09.615 - INFO: Train epoch 529: [80000/94637 (85%)] Step: [2720672] | Lr: 0.000030 | Loss: 1.1426 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 41.74
24-04-06 02:15:59.000 - INFO: Train epoch 529: [83200/94637 (88%)] Step: [2720772] | Lr: 0.000030 | Loss: 0.7509 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 44.11
24-04-06 02:16:48.493 - INFO: Train epoch 529: [86400/94637 (91%)] Step: [2720872] | Lr: 0.000030 | Loss: 1.5021 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 38.74
24-04-06 02:17:38.073 - INFO: Train epoch 529: [89600/94637 (95%)] Step: [2720972] | Lr: 0.000030 | Loss: 1.3296 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 45.55
24-04-06 02:18:27.268 - INFO: Train epoch 529: [92800/94637 (98%)] Step: [2721072] | Lr: 0.000030 | Loss: 1.2761 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 42.65
24-04-06 02:19:06.163 - INFO: Learning rate: 3e-05
24-04-06 02:19:07.576 - INFO: Train epoch 530: [    0/94637 (0%)] Step: [2721129] | Lr: 0.000030 | Loss: 1.5533 | MSE loss: 0.0003 | Bpp loss: 0.99 | Aux loss: 40.56
24-04-06 02:19:56.578 - INFO: Train epoch 530: [ 3200/94637 (3%)] Step: [2721229] | Lr: 0.000030 | Loss: 1.6605 | MSE loss: 0.0004 | Bpp loss: 1.07 | Aux loss: 47.58
24-04-06 02:20:45.496 - INFO: Train epoch 530: [ 6400/94637 (7%)] Step: [2721329] | Lr: 0.000030 | Loss: 0.9474 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 42.57
24-04-06 02:21:34.296 - INFO: Train epoch 530: [ 9600/94637 (10%)] Step: [2721429] | Lr: 0.000030 | Loss: 1.0976 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 44.60
24-04-06 02:22:22.898 - INFO: Train epoch 530: [12800/94637 (14%)] Step: [2721529] | Lr: 0.000030 | Loss: 1.3802 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 42.12
24-04-06 02:23:11.929 - INFO: Train epoch 530: [16000/94637 (17%)] Step: [2721629] | Lr: 0.000030 | Loss: 0.8872 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 44.71
24-04-06 02:24:00.730 - INFO: Train epoch 530: [19200/94637 (20%)] Step: [2721729] | Lr: 0.000030 | Loss: 1.2308 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 43.43
24-04-06 02:24:49.750 - INFO: Train epoch 530: [22400/94637 (24%)] Step: [2721829] | Lr: 0.000030 | Loss: 1.6023 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 43.92
24-04-06 02:25:38.775 - INFO: Train epoch 530: [25600/94637 (27%)] Step: [2721929] | Lr: 0.000030 | Loss: 0.9782 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 45.60
24-04-06 02:26:27.985 - INFO: Train epoch 530: [28800/94637 (30%)] Step: [2722029] | Lr: 0.000030 | Loss: 1.0502 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 43.51
24-04-06 02:27:17.290 - INFO: Train epoch 530: [32000/94637 (34%)] Step: [2722129] | Lr: 0.000030 | Loss: 1.3667 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 39.64
24-04-06 02:28:05.945 - INFO: Train epoch 530: [35200/94637 (37%)] Step: [2722229] | Lr: 0.000030 | Loss: 1.1557 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 42.75
24-04-06 02:28:54.889 - INFO: Train epoch 530: [38400/94637 (41%)] Step: [2722329] | Lr: 0.000030 | Loss: 1.3331 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 39.94
24-04-06 02:29:43.378 - INFO: Train epoch 530: [41600/94637 (44%)] Step: [2722429] | Lr: 0.000030 | Loss: 1.2470 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 42.47
24-04-06 02:30:34.948 - INFO: Train epoch 530: [44800/94637 (47%)] Step: [2722529] | Lr: 0.000030 | Loss: 1.3938 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 41.08
24-04-06 02:31:23.795 - INFO: Train epoch 530: [48000/94637 (51%)] Step: [2722629] | Lr: 0.000030 | Loss: 1.0429 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 45.44
24-04-06 02:32:13.103 - INFO: Train epoch 530: [51200/94637 (54%)] Step: [2722729] | Lr: 0.000030 | Loss: 1.5718 | MSE loss: 0.0003 | Bpp loss: 1.01 | Aux loss: 43.04
24-04-06 02:33:02.086 - INFO: Train epoch 530: [54400/94637 (57%)] Step: [2722829] | Lr: 0.000030 | Loss: 0.9209 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 46.26
24-04-06 02:33:51.584 - INFO: Train epoch 530: [57600/94637 (61%)] Step: [2722929] | Lr: 0.000030 | Loss: 1.1886 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 42.95
24-04-06 02:34:40.488 - INFO: Train epoch 530: [60800/94637 (64%)] Step: [2723029] | Lr: 0.000030 | Loss: 1.5083 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 44.55
24-04-06 02:35:29.360 - INFO: Train epoch 530: [64000/94637 (68%)] Step: [2723129] | Lr: 0.000030 | Loss: 1.2618 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 45.55
24-04-06 02:36:18.607 - INFO: Train epoch 530: [67200/94637 (71%)] Step: [2723229] | Lr: 0.000030 | Loss: 1.3635 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 41.18
24-04-06 02:37:07.400 - INFO: Train epoch 530: [70400/94637 (74%)] Step: [2723329] | Lr: 0.000030 | Loss: 1.6200 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 41.03
24-04-06 02:37:56.159 - INFO: Train epoch 530: [73600/94637 (78%)] Step: [2723429] | Lr: 0.000030 | Loss: 1.1415 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 45.34
24-04-06 02:38:44.893 - INFO: Train epoch 530: [76800/94637 (81%)] Step: [2723529] | Lr: 0.000030 | Loss: 1.0818 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 44.49
24-04-06 02:39:34.296 - INFO: Train epoch 530: [80000/94637 (85%)] Step: [2723629] | Lr: 0.000030 | Loss: 1.2224 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 43.59
24-04-06 02:40:23.577 - INFO: Train epoch 530: [83200/94637 (88%)] Step: [2723729] | Lr: 0.000030 | Loss: 1.4014 | MSE loss: 0.0004 | Bpp loss: 0.80 | Aux loss: 44.37
24-04-06 02:41:12.425 - INFO: Train epoch 530: [86400/94637 (91%)] Step: [2723829] | Lr: 0.000030 | Loss: 1.0996 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 42.21
24-04-06 02:42:01.360 - INFO: Train epoch 530: [89600/94637 (95%)] Step: [2723929] | Lr: 0.000030 | Loss: 0.8920 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 42.35
24-04-06 02:42:50.465 - INFO: Train epoch 530: [92800/94637 (98%)] Step: [2724029] | Lr: 0.000030 | Loss: 1.4448 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 42.08
24-04-06 02:43:35.552 - INFO: Learning rate: 3e-05
24-04-06 02:43:36.631 - INFO: Train epoch 531: [    0/94637 (0%)] Step: [2724086] | Lr: 0.000030 | Loss: 1.4038 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 46.85
24-04-06 02:44:25.424 - INFO: Train epoch 531: [ 3200/94637 (3%)] Step: [2724186] | Lr: 0.000030 | Loss: 0.7622 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 44.96
24-04-06 02:45:13.984 - INFO: Train epoch 531: [ 6400/94637 (7%)] Step: [2724286] | Lr: 0.000030 | Loss: 1.4513 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 39.86
24-04-06 02:46:01.984 - INFO: Train epoch 531: [ 9600/94637 (10%)] Step: [2724386] | Lr: 0.000030 | Loss: 1.0473 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 44.17
24-04-06 02:46:50.636 - INFO: Train epoch 531: [12800/94637 (14%)] Step: [2724486] | Lr: 0.000030 | Loss: 1.3058 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 47.36
24-04-06 02:47:39.089 - INFO: Train epoch 531: [16000/94637 (17%)] Step: [2724586] | Lr: 0.000030 | Loss: 1.0207 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 43.37
24-04-06 02:48:27.588 - INFO: Train epoch 531: [19200/94637 (20%)] Step: [2724686] | Lr: 0.000030 | Loss: 1.0268 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 46.72
24-04-06 02:49:16.212 - INFO: Train epoch 531: [22400/94637 (24%)] Step: [2724786] | Lr: 0.000030 | Loss: 0.9414 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 42.83
24-04-06 02:50:04.709 - INFO: Train epoch 531: [25600/94637 (27%)] Step: [2724886] | Lr: 0.000030 | Loss: 1.5912 | MSE loss: 0.0003 | Bpp loss: 1.03 | Aux loss: 49.84
24-04-06 02:50:53.306 - INFO: Train epoch 531: [28800/94637 (30%)] Step: [2724986] | Lr: 0.000030 | Loss: 1.5912 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 43.95
24-04-06 02:51:43.672 - INFO: Train epoch 531: [32000/94637 (34%)] Step: [2725086] | Lr: 0.000030 | Loss: 1.5655 | MSE loss: 0.0003 | Bpp loss: 1.00 | Aux loss: 47.73
24-04-06 02:52:32.522 - INFO: Train epoch 531: [35200/94637 (37%)] Step: [2725186] | Lr: 0.000030 | Loss: 1.2789 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 46.96
24-04-06 02:53:21.199 - INFO: Train epoch 531: [38400/94637 (41%)] Step: [2725286] | Lr: 0.000030 | Loss: 0.8950 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 45.12
24-04-06 02:54:09.817 - INFO: Train epoch 531: [41600/94637 (44%)] Step: [2725386] | Lr: 0.000030 | Loss: 1.0387 | MSE loss: 0.0003 | Bpp loss: 0.62 | Aux loss: 49.78
24-04-06 02:54:58.268 - INFO: Train epoch 531: [44800/94637 (47%)] Step: [2725486] | Lr: 0.000030 | Loss: 1.3319 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 48.64
24-04-06 02:55:47.044 - INFO: Train epoch 531: [48000/94637 (51%)] Step: [2725586] | Lr: 0.000030 | Loss: 1.3926 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 46.59
24-04-06 02:56:35.505 - INFO: Train epoch 531: [51200/94637 (54%)] Step: [2725686] | Lr: 0.000030 | Loss: 1.2757 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 47.24
24-04-06 02:57:24.197 - INFO: Train epoch 531: [54400/94637 (57%)] Step: [2725786] | Lr: 0.000030 | Loss: 0.8212 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 43.57
24-04-06 02:58:12.582 - INFO: Train epoch 531: [57600/94637 (61%)] Step: [2725886] | Lr: 0.000030 | Loss: 1.3897 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 45.70
24-04-06 02:59:01.041 - INFO: Train epoch 531: [60800/94637 (64%)] Step: [2725986] | Lr: 0.000030 | Loss: 1.0144 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 45.98
24-04-06 02:59:49.086 - INFO: Train epoch 531: [64000/94637 (68%)] Step: [2726086] | Lr: 0.000030 | Loss: 1.4139 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 45.99
24-04-06 03:00:37.830 - INFO: Train epoch 531: [67200/94637 (71%)] Step: [2726186] | Lr: 0.000030 | Loss: 0.8701 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 45.43
24-04-06 03:01:26.370 - INFO: Train epoch 531: [70400/94637 (74%)] Step: [2726286] | Lr: 0.000030 | Loss: 1.3389 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 42.70
24-04-06 03:02:14.873 - INFO: Train epoch 531: [73600/94637 (78%)] Step: [2726386] | Lr: 0.000030 | Loss: 1.2479 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 46.25
24-04-06 03:03:03.666 - INFO: Train epoch 531: [76800/94637 (81%)] Step: [2726486] | Lr: 0.000030 | Loss: 1.6190 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 46.61
24-04-06 03:03:51.846 - INFO: Train epoch 531: [80000/94637 (85%)] Step: [2726586] | Lr: 0.000030 | Loss: 0.9749 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 47.32
24-04-06 03:04:39.503 - INFO: Train epoch 531: [83200/94637 (88%)] Step: [2726686] | Lr: 0.000030 | Loss: 1.3530 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 42.93
24-04-06 03:05:27.545 - INFO: Train epoch 531: [86400/94637 (91%)] Step: [2726786] | Lr: 0.000030 | Loss: 1.5675 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 48.35
24-04-06 03:06:15.741 - INFO: Train epoch 531: [89600/94637 (95%)] Step: [2726886] | Lr: 0.000030 | Loss: 1.0112 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 48.68
24-04-06 03:07:04.018 - INFO: Train epoch 531: [92800/94637 (98%)] Step: [2726986] | Lr: 0.000030 | Loss: 1.1360 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 51.61
24-04-06 03:07:47.921 - INFO: Learning rate: 3e-05
24-04-06 03:07:49.712 - INFO: Train epoch 532: [    0/94637 (0%)] Step: [2727043] | Lr: 0.000030 | Loss: 1.1812 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 43.00
24-04-06 03:08:37.201 - INFO: Train epoch 532: [ 3200/94637 (3%)] Step: [2727143] | Lr: 0.000030 | Loss: 0.9842 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 51.76
24-04-06 03:09:25.083 - INFO: Train epoch 532: [ 6400/94637 (7%)] Step: [2727243] | Lr: 0.000030 | Loss: 0.8378 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 43.58
24-04-06 03:10:13.329 - INFO: Train epoch 532: [ 9600/94637 (10%)] Step: [2727343] | Lr: 0.000030 | Loss: 1.3366 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 44.35
24-04-06 03:11:01.346 - INFO: Train epoch 532: [12800/94637 (14%)] Step: [2727443] | Lr: 0.000030 | Loss: 1.0999 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 43.23
24-04-06 03:11:51.947 - INFO: Train epoch 532: [16000/94637 (17%)] Step: [2727543] | Lr: 0.000030 | Loss: 1.1581 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 45.02
24-04-06 03:12:39.616 - INFO: Train epoch 532: [19200/94637 (20%)] Step: [2727643] | Lr: 0.000030 | Loss: 1.1005 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 46.70
24-04-06 03:13:27.336 - INFO: Train epoch 532: [22400/94637 (24%)] Step: [2727743] | Lr: 0.000030 | Loss: 1.2029 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 45.34
24-04-06 03:14:14.223 - INFO: Train epoch 532: [25600/94637 (27%)] Step: [2727843] | Lr: 0.000030 | Loss: 1.4432 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 45.54
24-04-06 03:15:01.218 - INFO: Train epoch 532: [28800/94637 (30%)] Step: [2727943] | Lr: 0.000030 | Loss: 1.3448 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 47.10
24-04-06 03:15:48.427 - INFO: Train epoch 532: [32000/94637 (34%)] Step: [2728043] | Lr: 0.000030 | Loss: 0.9634 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 48.89
24-04-06 03:16:35.875 - INFO: Train epoch 532: [35200/94637 (37%)] Step: [2728143] | Lr: 0.000030 | Loss: 1.1239 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 44.45
24-04-06 03:17:23.262 - INFO: Train epoch 532: [38400/94637 (41%)] Step: [2728243] | Lr: 0.000030 | Loss: 1.3273 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 49.22
24-04-06 03:18:10.814 - INFO: Train epoch 532: [41600/94637 (44%)] Step: [2728343] | Lr: 0.000030 | Loss: 1.2970 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 48.23
24-04-06 03:18:58.514 - INFO: Train epoch 532: [44800/94637 (47%)] Step: [2728443] | Lr: 0.000030 | Loss: 1.5331 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 43.63
24-04-06 03:19:46.156 - INFO: Train epoch 532: [48000/94637 (51%)] Step: [2728543] | Lr: 0.000030 | Loss: 1.3206 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 44.91
24-04-06 03:20:34.171 - INFO: Train epoch 532: [51200/94637 (54%)] Step: [2728643] | Lr: 0.000030 | Loss: 0.9683 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 43.79
24-04-06 03:21:21.517 - INFO: Train epoch 532: [54400/94637 (57%)] Step: [2728743] | Lr: 0.000030 | Loss: 1.2486 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 48.62
24-04-06 03:22:09.117 - INFO: Train epoch 532: [57600/94637 (61%)] Step: [2728843] | Lr: 0.000030 | Loss: 1.0287 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 45.09
24-04-06 03:22:56.757 - INFO: Train epoch 532: [60800/94637 (64%)] Step: [2728943] | Lr: 0.000030 | Loss: 1.2660 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 48.54
24-04-06 03:23:44.618 - INFO: Train epoch 532: [64000/94637 (68%)] Step: [2729043] | Lr: 0.000030 | Loss: 1.1166 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 47.01
24-04-06 03:24:33.054 - INFO: Train epoch 532: [67200/94637 (71%)] Step: [2729143] | Lr: 0.000030 | Loss: 1.1096 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 48.39
24-04-06 03:25:21.641 - INFO: Train epoch 532: [70400/94637 (74%)] Step: [2729243] | Lr: 0.000030 | Loss: 1.2396 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 48.87
24-04-06 03:26:09.968 - INFO: Train epoch 532: [73600/94637 (78%)] Step: [2729343] | Lr: 0.000030 | Loss: 1.2888 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 49.29
24-04-06 03:26:58.748 - INFO: Train epoch 532: [76800/94637 (81%)] Step: [2729443] | Lr: 0.000030 | Loss: 1.1465 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 46.80
24-04-06 03:27:47.901 - INFO: Train epoch 532: [80000/94637 (85%)] Step: [2729543] | Lr: 0.000030 | Loss: 1.1327 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 52.52
24-04-06 03:28:36.720 - INFO: Train epoch 532: [83200/94637 (88%)] Step: [2729643] | Lr: 0.000030 | Loss: 1.1412 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 48.88
24-04-06 03:29:25.093 - INFO: Train epoch 532: [86400/94637 (91%)] Step: [2729743] | Lr: 0.000030 | Loss: 1.3078 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 47.42
24-04-06 03:30:13.492 - INFO: Train epoch 532: [89600/94637 (95%)] Step: [2729843] | Lr: 0.000030 | Loss: 0.9472 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 49.49
24-04-06 03:31:02.153 - INFO: Train epoch 532: [92800/94637 (98%)] Step: [2729943] | Lr: 0.000030 | Loss: 1.6133 | MSE loss: 0.0004 | Bpp loss: 0.99 | Aux loss: 48.73
24-04-06 03:31:41.337 - INFO: Learning rate: 3e-05
24-04-06 03:31:42.562 - INFO: Train epoch 533: [    0/94637 (0%)] Step: [2730000] | Lr: 0.000030 | Loss: 1.3953 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 48.81
24-04-06 03:32:32.323 - INFO: Train epoch 533: [ 3200/94637 (3%)] Step: [2730100] | Lr: 0.000030 | Loss: 1.3404 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 45.81
24-04-06 03:33:20.885 - INFO: Train epoch 533: [ 6400/94637 (7%)] Step: [2730200] | Lr: 0.000030 | Loss: 1.1303 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 50.78
24-04-06 03:34:09.574 - INFO: Train epoch 533: [ 9600/94637 (10%)] Step: [2730300] | Lr: 0.000030 | Loss: 1.3779 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 49.01
24-04-06 03:34:57.910 - INFO: Train epoch 533: [12800/94637 (14%)] Step: [2730400] | Lr: 0.000030 | Loss: 1.2932 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 43.30
24-04-06 03:35:46.039 - INFO: Train epoch 533: [16000/94637 (17%)] Step: [2730500] | Lr: 0.000030 | Loss: 1.4332 | MSE loss: 0.0004 | Bpp loss: 0.84 | Aux loss: 47.31
24-04-06 03:36:34.505 - INFO: Train epoch 533: [19200/94637 (20%)] Step: [2730600] | Lr: 0.000030 | Loss: 1.3663 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 46.30
24-04-06 03:37:23.072 - INFO: Train epoch 533: [22400/94637 (24%)] Step: [2730700] | Lr: 0.000030 | Loss: 1.3183 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 48.19
24-04-06 03:38:11.546 - INFO: Train epoch 533: [25600/94637 (27%)] Step: [2730800] | Lr: 0.000030 | Loss: 1.1220 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 47.83
24-04-06 03:38:59.901 - INFO: Train epoch 533: [28800/94637 (30%)] Step: [2730900] | Lr: 0.000030 | Loss: 1.6081 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 45.52
24-04-06 03:39:48.778 - INFO: Train epoch 533: [32000/94637 (34%)] Step: [2731000] | Lr: 0.000030 | Loss: 1.4991 | MSE loss: 0.0003 | Bpp loss: 0.96 | Aux loss: 46.30
24-04-06 03:40:38.092 - INFO: Train epoch 533: [35200/94637 (37%)] Step: [2731100] | Lr: 0.000030 | Loss: 1.0460 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 48.64
24-04-06 03:41:26.165 - INFO: Train epoch 533: [38400/94637 (41%)] Step: [2731200] | Lr: 0.000030 | Loss: 0.8324 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 53.43
24-04-06 03:42:14.565 - INFO: Train epoch 533: [41600/94637 (44%)] Step: [2731300] | Lr: 0.000030 | Loss: 1.0322 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 49.61
24-04-06 03:43:03.252 - INFO: Train epoch 533: [44800/94637 (47%)] Step: [2731400] | Lr: 0.000030 | Loss: 0.9590 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 50.25
24-04-06 03:43:52.503 - INFO: Train epoch 533: [48000/94637 (51%)] Step: [2731500] | Lr: 0.000030 | Loss: 1.1848 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 45.76
24-04-06 03:44:41.522 - INFO: Train epoch 533: [51200/94637 (54%)] Step: [2731600] | Lr: 0.000030 | Loss: 0.7788 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 51.23
24-04-06 03:45:29.892 - INFO: Train epoch 533: [54400/94637 (57%)] Step: [2731700] | Lr: 0.000030 | Loss: 1.2086 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 44.97
24-04-06 03:46:19.001 - INFO: Train epoch 533: [57600/94637 (61%)] Step: [2731800] | Lr: 0.000030 | Loss: 1.2727 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 50.03
24-04-06 03:47:07.933 - INFO: Train epoch 533: [60800/94637 (64%)] Step: [2731900] | Lr: 0.000030 | Loss: 1.0815 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 46.96
24-04-06 03:47:56.850 - INFO: Train epoch 533: [64000/94637 (68%)] Step: [2732000] | Lr: 0.000030 | Loss: 1.1991 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 46.59
24-04-06 03:48:45.889 - INFO: Train epoch 533: [67200/94637 (71%)] Step: [2732100] | Lr: 0.000030 | Loss: 1.5100 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 47.95
24-04-06 03:49:34.978 - INFO: Train epoch 533: [70400/94637 (74%)] Step: [2732200] | Lr: 0.000030 | Loss: 1.0455 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 47.28
24-04-06 03:50:24.288 - INFO: Train epoch 533: [73600/94637 (78%)] Step: [2732300] | Lr: 0.000030 | Loss: 1.2926 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 45.21
24-04-06 03:51:13.170 - INFO: Train epoch 533: [76800/94637 (81%)] Step: [2732400] | Lr: 0.000030 | Loss: 1.2862 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 47.51
24-04-06 03:52:02.222 - INFO: Train epoch 533: [80000/94637 (85%)] Step: [2732500] | Lr: 0.000030 | Loss: 1.4391 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 46.99
24-04-06 03:52:53.693 - INFO: Train epoch 533: [83200/94637 (88%)] Step: [2732600] | Lr: 0.000030 | Loss: 1.1023 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 50.82
24-04-06 03:53:43.008 - INFO: Train epoch 533: [86400/94637 (91%)] Step: [2732700] | Lr: 0.000030 | Loss: 1.3156 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 51.24
24-04-06 03:54:32.194 - INFO: Train epoch 533: [89600/94637 (95%)] Step: [2732800] | Lr: 0.000030 | Loss: 1.2348 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 51.16
24-04-06 03:55:20.565 - INFO: Train epoch 533: [92800/94637 (98%)] Step: [2732900] | Lr: 0.000030 | Loss: 1.2642 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 50.59
24-04-06 03:55:58.984 - INFO: Learning rate: 3e-05
24-04-06 03:56:00.153 - INFO: Train epoch 534: [    0/94637 (0%)] Step: [2732957] | Lr: 0.000030 | Loss: 1.2167 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 49.24
24-04-06 03:56:48.546 - INFO: Train epoch 534: [ 3200/94637 (3%)] Step: [2733057] | Lr: 0.000030 | Loss: 1.6233 | MSE loss: 0.0003 | Bpp loss: 1.05 | Aux loss: 50.22
24-04-06 03:57:37.201 - INFO: Train epoch 534: [ 6400/94637 (7%)] Step: [2733157] | Lr: 0.000030 | Loss: 1.1596 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 50.18
24-04-06 03:58:25.115 - INFO: Train epoch 534: [ 9600/94637 (10%)] Step: [2733257] | Lr: 0.000030 | Loss: 1.1134 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 50.93
24-04-06 03:59:13.345 - INFO: Train epoch 534: [12800/94637 (14%)] Step: [2733357] | Lr: 0.000030 | Loss: 0.8595 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 46.51
24-04-06 04:00:02.667 - INFO: Train epoch 534: [16000/94637 (17%)] Step: [2733457] | Lr: 0.000030 | Loss: 0.8481 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 51.25
24-04-06 04:00:51.527 - INFO: Train epoch 534: [19200/94637 (20%)] Step: [2733557] | Lr: 0.000030 | Loss: 1.4266 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 49.69
24-04-06 04:01:39.765 - INFO: Train epoch 534: [22400/94637 (24%)] Step: [2733657] | Lr: 0.000030 | Loss: 1.2874 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 52.35
24-04-06 04:02:28.142 - INFO: Train epoch 534: [25600/94637 (27%)] Step: [2733757] | Lr: 0.000030 | Loss: 0.8867 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 55.61
24-04-06 04:03:15.990 - INFO: Train epoch 534: [28800/94637 (30%)] Step: [2733857] | Lr: 0.000030 | Loss: 1.0434 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 52.37
24-04-06 04:04:04.508 - INFO: Train epoch 534: [32000/94637 (34%)] Step: [2733957] | Lr: 0.000030 | Loss: 1.0843 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 48.98
24-04-06 04:04:52.611 - INFO: Train epoch 534: [35200/94637 (37%)] Step: [2734057] | Lr: 0.000030 | Loss: 1.1260 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 49.66
24-04-06 04:05:41.088 - INFO: Train epoch 534: [38400/94637 (41%)] Step: [2734157] | Lr: 0.000030 | Loss: 1.1064 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 50.38
24-04-06 04:06:29.287 - INFO: Train epoch 534: [41600/94637 (44%)] Step: [2734257] | Lr: 0.000030 | Loss: 1.0273 | MSE loss: 0.0003 | Bpp loss: 0.61 | Aux loss: 48.10
24-04-06 04:07:17.989 - INFO: Train epoch 534: [44800/94637 (47%)] Step: [2734357] | Lr: 0.000030 | Loss: 1.3502 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 48.57
24-04-06 04:08:06.563 - INFO: Train epoch 534: [48000/94637 (51%)] Step: [2734457] | Lr: 0.000030 | Loss: 0.9742 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 52.87
24-04-06 04:08:54.692 - INFO: Train epoch 534: [51200/94637 (54%)] Step: [2734557] | Lr: 0.000030 | Loss: 1.2930 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 47.79
24-04-06 04:09:43.005 - INFO: Train epoch 534: [54400/94637 (57%)] Step: [2734657] | Lr: 0.000030 | Loss: 0.9326 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 51.64
24-04-06 04:10:30.805 - INFO: Train epoch 534: [57600/94637 (61%)] Step: [2734757] | Lr: 0.000030 | Loss: 1.5560 | MSE loss: 0.0003 | Bpp loss: 1.00 | Aux loss: 47.51
24-04-06 04:11:18.220 - INFO: Train epoch 534: [60800/94637 (64%)] Step: [2734857] | Lr: 0.000030 | Loss: 1.1385 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 49.83
24-04-06 04:12:05.837 - INFO: Train epoch 534: [64000/94637 (68%)] Step: [2734957] | Lr: 0.000030 | Loss: 1.1011 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 51.48
24-04-06 04:12:55.585 - INFO: Train epoch 534: [67200/94637 (71%)] Step: [2735057] | Lr: 0.000030 | Loss: 1.1813 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 51.87
24-04-06 04:13:43.965 - INFO: Train epoch 534: [70400/94637 (74%)] Step: [2735157] | Lr: 0.000030 | Loss: 1.2022 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 50.99
24-04-06 04:14:32.071 - INFO: Train epoch 534: [73600/94637 (78%)] Step: [2735257] | Lr: 0.000030 | Loss: 1.2735 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 46.54
24-04-06 04:15:20.107 - INFO: Train epoch 534: [76800/94637 (81%)] Step: [2735357] | Lr: 0.000030 | Loss: 1.2750 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 48.10
24-04-06 04:16:08.433 - INFO: Train epoch 534: [80000/94637 (85%)] Step: [2735457] | Lr: 0.000030 | Loss: 1.0339 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 46.91
24-04-06 04:16:56.836 - INFO: Train epoch 534: [83200/94637 (88%)] Step: [2735557] | Lr: 0.000030 | Loss: 1.5974 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 49.30
24-04-06 04:17:44.854 - INFO: Train epoch 534: [86400/94637 (91%)] Step: [2735657] | Lr: 0.000030 | Loss: 1.2086 | MSE loss: 0.0002 | Bpp loss: 0.80 | Aux loss: 48.12
24-04-06 04:18:33.342 - INFO: Train epoch 534: [89600/94637 (95%)] Step: [2735757] | Lr: 0.000030 | Loss: 1.0817 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 49.93
24-04-06 04:19:20.976 - INFO: Train epoch 534: [92800/94637 (98%)] Step: [2735857] | Lr: 0.000030 | Loss: 0.9771 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 49.09
24-04-06 04:19:58.936 - INFO: Learning rate: 3e-05
24-04-06 04:20:00.355 - INFO: Train epoch 535: [    0/94637 (0%)] Step: [2735914] | Lr: 0.000030 | Loss: 0.7913 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 48.82
24-04-06 04:20:47.846 - INFO: Train epoch 535: [ 3200/94637 (3%)] Step: [2736014] | Lr: 0.000030 | Loss: 0.7613 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 52.40
24-04-06 04:21:35.980 - INFO: Train epoch 535: [ 6400/94637 (7%)] Step: [2736114] | Lr: 0.000030 | Loss: 1.4504 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 49.44
24-04-06 04:22:23.201 - INFO: Train epoch 535: [ 9600/94637 (10%)] Step: [2736214] | Lr: 0.000030 | Loss: 0.7146 | MSE loss: 0.0002 | Bpp loss: 0.45 | Aux loss: 54.01
24-04-06 04:23:11.020 - INFO: Train epoch 535: [12800/94637 (14%)] Step: [2736314] | Lr: 0.000030 | Loss: 1.0591 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 54.52
24-04-06 04:23:59.077 - INFO: Train epoch 535: [16000/94637 (17%)] Step: [2736414] | Lr: 0.000030 | Loss: 1.4630 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 50.51
24-04-06 04:24:47.423 - INFO: Train epoch 535: [19200/94637 (20%)] Step: [2736514] | Lr: 0.000030 | Loss: 0.7636 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 51.54
24-04-06 04:25:35.711 - INFO: Train epoch 535: [22400/94637 (24%)] Step: [2736614] | Lr: 0.000030 | Loss: 1.3072 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 52.70
24-04-06 04:26:24.230 - INFO: Train epoch 535: [25600/94637 (27%)] Step: [2736714] | Lr: 0.000030 | Loss: 1.0188 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 49.27
24-04-06 04:27:12.388 - INFO: Train epoch 535: [28800/94637 (30%)] Step: [2736814] | Lr: 0.000030 | Loss: 1.2800 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 49.72
24-04-06 04:28:01.411 - INFO: Train epoch 535: [32000/94637 (34%)] Step: [2736914] | Lr: 0.000030 | Loss: 1.1594 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 49.97
24-04-06 04:28:50.263 - INFO: Train epoch 535: [35200/94637 (37%)] Step: [2737014] | Lr: 0.000030 | Loss: 1.2240 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 53.71
24-04-06 04:29:38.792 - INFO: Train epoch 535: [38400/94637 (41%)] Step: [2737114] | Lr: 0.000030 | Loss: 1.1393 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 47.48
24-04-06 04:30:26.992 - INFO: Train epoch 535: [41600/94637 (44%)] Step: [2737214] | Lr: 0.000030 | Loss: 1.0513 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 52.21
24-04-06 04:31:14.921 - INFO: Train epoch 535: [44800/94637 (47%)] Step: [2737314] | Lr: 0.000030 | Loss: 1.4762 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 50.19
24-04-06 04:32:03.178 - INFO: Train epoch 535: [48000/94637 (51%)] Step: [2737414] | Lr: 0.000030 | Loss: 1.0122 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 45.87
24-04-06 04:32:53.853 - INFO: Train epoch 535: [51200/94637 (54%)] Step: [2737514] | Lr: 0.000030 | Loss: 1.0785 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 52.98
24-04-06 04:33:42.834 - INFO: Train epoch 535: [54400/94637 (57%)] Step: [2737614] | Lr: 0.000030 | Loss: 0.9323 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 50.54
24-04-06 04:34:31.684 - INFO: Train epoch 535: [57600/94637 (61%)] Step: [2737714] | Lr: 0.000030 | Loss: 1.1039 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 50.70
24-04-06 04:35:21.177 - INFO: Train epoch 535: [60800/94637 (64%)] Step: [2737814] | Lr: 0.000030 | Loss: 1.2258 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 53.77
24-04-06 04:36:11.800 - INFO: Train epoch 535: [64000/94637 (68%)] Step: [2737914] | Lr: 0.000030 | Loss: 0.8032 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 52.07
24-04-06 04:37:00.813 - INFO: Train epoch 535: [67200/94637 (71%)] Step: [2738014] | Lr: 0.000030 | Loss: 0.7051 | MSE loss: 0.0001 | Bpp loss: 0.47 | Aux loss: 47.66
24-04-06 04:37:49.432 - INFO: Train epoch 535: [70400/94637 (74%)] Step: [2738114] | Lr: 0.000030 | Loss: 1.1464 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 51.85
24-04-06 04:38:37.520 - INFO: Train epoch 535: [73600/94637 (78%)] Step: [2738214] | Lr: 0.000030 | Loss: 0.9235 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 51.23
24-04-06 04:39:25.367 - INFO: Train epoch 535: [76800/94637 (81%)] Step: [2738314] | Lr: 0.000030 | Loss: 1.2697 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 50.48
24-04-06 04:40:13.037 - INFO: Train epoch 535: [80000/94637 (85%)] Step: [2738414] | Lr: 0.000030 | Loss: 1.1542 | MSE loss: 0.0002 | Bpp loss: 0.77 | Aux loss: 53.72
24-04-06 04:41:01.404 - INFO: Train epoch 535: [83200/94637 (88%)] Step: [2738514] | Lr: 0.000030 | Loss: 1.5259 | MSE loss: 0.0003 | Bpp loss: 0.99 | Aux loss: 50.82
24-04-06 04:41:50.078 - INFO: Train epoch 535: [86400/94637 (91%)] Step: [2738614] | Lr: 0.000030 | Loss: 1.0054 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 53.28
24-04-06 04:42:38.449 - INFO: Train epoch 535: [89600/94637 (95%)] Step: [2738714] | Lr: 0.000030 | Loss: 0.8975 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 56.40
24-04-06 04:43:26.969 - INFO: Train epoch 535: [92800/94637 (98%)] Step: [2738814] | Lr: 0.000030 | Loss: 0.8596 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 50.58
24-04-06 04:44:05.419 - INFO: Learning rate: 3e-05
24-04-06 04:44:07.295 - INFO: Train epoch 536: [    0/94637 (0%)] Step: [2738871] | Lr: 0.000030 | Loss: 1.4156 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 47.27
24-04-06 04:44:56.307 - INFO: Train epoch 536: [ 3200/94637 (3%)] Step: [2738971] | Lr: 0.000030 | Loss: 1.1096 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 50.52
24-04-06 04:45:44.477 - INFO: Train epoch 536: [ 6400/94637 (7%)] Step: [2739071] | Lr: 0.000030 | Loss: 0.9397 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 48.55
24-04-06 04:46:32.213 - INFO: Train epoch 536: [ 9600/94637 (10%)] Step: [2739171] | Lr: 0.000030 | Loss: 1.1881 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 52.37
24-04-06 04:47:20.643 - INFO: Train epoch 536: [12800/94637 (14%)] Step: [2739271] | Lr: 0.000030 | Loss: 1.4948 | MSE loss: 0.0004 | Bpp loss: 0.79 | Aux loss: 50.53
24-04-06 04:48:09.340 - INFO: Train epoch 536: [16000/94637 (17%)] Step: [2739371] | Lr: 0.000030 | Loss: 1.7043 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 52.70
24-04-06 04:48:58.369 - INFO: Train epoch 536: [19200/94637 (20%)] Step: [2739471] | Lr: 0.000030 | Loss: 1.2841 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 51.43
24-04-06 04:49:47.119 - INFO: Train epoch 536: [22400/94637 (24%)] Step: [2739571] | Lr: 0.000030 | Loss: 1.5687 | MSE loss: 0.0003 | Bpp loss: 1.00 | Aux loss: 49.63
24-04-06 04:50:36.233 - INFO: Train epoch 536: [25600/94637 (27%)] Step: [2739671] | Lr: 0.000030 | Loss: 1.1138 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 49.15
24-04-06 04:51:25.378 - INFO: Train epoch 536: [28800/94637 (30%)] Step: [2739771] | Lr: 0.000030 | Loss: 1.3320 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 51.95
24-04-06 04:52:14.793 - INFO: Train epoch 536: [32000/94637 (34%)] Step: [2739871] | Lr: 0.000030 | Loss: 0.9803 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 54.24
24-04-06 04:53:03.727 - INFO: Train epoch 536: [35200/94637 (37%)] Step: [2739971] | Lr: 0.000030 | Loss: 1.4155 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 52.88
24-04-06 04:53:54.233 - INFO: Train epoch 536: [38400/94637 (41%)] Step: [2740071] | Lr: 0.000030 | Loss: 1.5124 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 54.37
24-04-06 04:54:42.672 - INFO: Train epoch 536: [41600/94637 (44%)] Step: [2740171] | Lr: 0.000030 | Loss: 1.1577 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 52.29
24-04-06 04:55:30.997 - INFO: Train epoch 536: [44800/94637 (47%)] Step: [2740271] | Lr: 0.000030 | Loss: 1.2602 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 54.72
24-04-06 04:56:18.762 - INFO: Train epoch 536: [48000/94637 (51%)] Step: [2740371] | Lr: 0.000030 | Loss: 1.4466 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 51.60
24-04-06 04:57:06.572 - INFO: Train epoch 536: [51200/94637 (54%)] Step: [2740471] | Lr: 0.000030 | Loss: 1.0670 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 57.84
24-04-06 04:57:54.266 - INFO: Train epoch 536: [54400/94637 (57%)] Step: [2740571] | Lr: 0.000030 | Loss: 1.4340 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 56.70
24-04-06 04:58:41.579 - INFO: Train epoch 536: [57600/94637 (61%)] Step: [2740671] | Lr: 0.000030 | Loss: 1.3324 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 52.76
24-04-06 04:59:29.346 - INFO: Train epoch 536: [60800/94637 (64%)] Step: [2740771] | Lr: 0.000030 | Loss: 1.0116 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 53.47
24-04-06 05:00:17.148 - INFO: Train epoch 536: [64000/94637 (68%)] Step: [2740871] | Lr: 0.000030 | Loss: 1.0884 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 56.58
24-04-06 05:01:04.978 - INFO: Train epoch 536: [67200/94637 (71%)] Step: [2740971] | Lr: 0.000030 | Loss: 1.2193 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 54.54
24-04-06 05:01:53.053 - INFO: Train epoch 536: [70400/94637 (74%)] Step: [2741071] | Lr: 0.000030 | Loss: 1.3128 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 50.46
24-04-06 05:02:40.956 - INFO: Train epoch 536: [73600/94637 (78%)] Step: [2741171] | Lr: 0.000030 | Loss: 1.0522 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 51.62
24-04-06 05:03:29.331 - INFO: Train epoch 536: [76800/94637 (81%)] Step: [2741271] | Lr: 0.000030 | Loss: 1.3243 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 50.46
24-04-06 05:04:18.378 - INFO: Train epoch 536: [80000/94637 (85%)] Step: [2741371] | Lr: 0.000030 | Loss: 0.9799 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 53.22
24-04-06 05:05:06.644 - INFO: Train epoch 536: [83200/94637 (88%)] Step: [2741471] | Lr: 0.000030 | Loss: 1.1904 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 56.58
24-04-06 05:05:55.813 - INFO: Train epoch 536: [86400/94637 (91%)] Step: [2741571] | Lr: 0.000030 | Loss: 0.9761 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 51.54
24-04-06 05:06:44.801 - INFO: Train epoch 536: [89600/94637 (95%)] Step: [2741671] | Lr: 0.000030 | Loss: 1.3018 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 54.64
24-04-06 05:07:34.247 - INFO: Train epoch 536: [92800/94637 (98%)] Step: [2741771] | Lr: 0.000030 | Loss: 1.3630 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 55.40
24-04-06 05:08:13.116 - INFO: Learning rate: 3e-05
24-04-06 05:08:14.219 - INFO: Train epoch 537: [    0/94637 (0%)] Step: [2741828] | Lr: 0.000030 | Loss: 0.9072 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 56.06
24-04-06 05:09:02.512 - INFO: Train epoch 537: [ 3200/94637 (3%)] Step: [2741928] | Lr: 0.000030 | Loss: 1.3299 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 52.51
24-04-06 05:09:52.018 - INFO: Train epoch 537: [ 6400/94637 (7%)] Step: [2742028] | Lr: 0.000030 | Loss: 1.1308 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 51.68
24-04-06 05:10:40.444 - INFO: Train epoch 537: [ 9600/94637 (10%)] Step: [2742128] | Lr: 0.000030 | Loss: 1.2629 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 50.70
24-04-06 05:11:28.658 - INFO: Train epoch 537: [12800/94637 (14%)] Step: [2742228] | Lr: 0.000030 | Loss: 1.2409 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 53.53
24-04-06 05:12:17.148 - INFO: Train epoch 537: [16000/94637 (17%)] Step: [2742328] | Lr: 0.000030 | Loss: 0.9534 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 55.17
24-04-06 05:13:05.963 - INFO: Train epoch 537: [19200/94637 (20%)] Step: [2742428] | Lr: 0.000030 | Loss: 1.2994 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 51.06
24-04-06 05:13:56.277 - INFO: Train epoch 537: [22400/94637 (24%)] Step: [2742528] | Lr: 0.000030 | Loss: 1.2150 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 52.46
24-04-06 05:14:44.751 - INFO: Train epoch 537: [25600/94637 (27%)] Step: [2742628] | Lr: 0.000030 | Loss: 1.0288 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 51.52
24-04-06 05:15:33.227 - INFO: Train epoch 537: [28800/94637 (30%)] Step: [2742728] | Lr: 0.000030 | Loss: 1.2946 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 56.24
24-04-06 05:16:21.678 - INFO: Train epoch 537: [32000/94637 (34%)] Step: [2742828] | Lr: 0.000030 | Loss: 1.1360 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 49.63
24-04-06 05:17:10.707 - INFO: Train epoch 537: [35200/94637 (37%)] Step: [2742928] | Lr: 0.000030 | Loss: 1.2879 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 51.18
24-04-06 05:17:59.060 - INFO: Train epoch 537: [38400/94637 (41%)] Step: [2743028] | Lr: 0.000030 | Loss: 1.2360 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 57.97
24-04-06 05:18:47.998 - INFO: Train epoch 537: [41600/94637 (44%)] Step: [2743128] | Lr: 0.000030 | Loss: 0.8664 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 57.19
24-04-06 05:19:36.344 - INFO: Train epoch 537: [44800/94637 (47%)] Step: [2743228] | Lr: 0.000030 | Loss: 1.4499 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 53.48
24-04-06 05:20:24.630 - INFO: Train epoch 537: [48000/94637 (51%)] Step: [2743328] | Lr: 0.000030 | Loss: 0.9755 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 52.90
24-04-06 05:21:12.730 - INFO: Train epoch 537: [51200/94637 (54%)] Step: [2743428] | Lr: 0.000030 | Loss: 1.0848 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 51.01
24-04-06 05:22:00.341 - INFO: Train epoch 537: [54400/94637 (57%)] Step: [2743528] | Lr: 0.000030 | Loss: 1.2010 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 53.65
24-04-06 05:22:48.295 - INFO: Train epoch 537: [57600/94637 (61%)] Step: [2743628] | Lr: 0.000030 | Loss: 1.4314 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 50.77
24-04-06 05:23:35.806 - INFO: Train epoch 537: [60800/94637 (64%)] Step: [2743728] | Lr: 0.000030 | Loss: 1.1469 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 50.81
24-04-06 05:24:23.204 - INFO: Train epoch 537: [64000/94637 (68%)] Step: [2743828] | Lr: 0.000030 | Loss: 1.5306 | MSE loss: 0.0003 | Bpp loss: 0.97 | Aux loss: 51.35
24-04-06 05:25:10.547 - INFO: Train epoch 537: [67200/94637 (71%)] Step: [2743928] | Lr: 0.000030 | Loss: 1.1527 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 55.71
24-04-06 05:25:58.088 - INFO: Train epoch 537: [70400/94637 (74%)] Step: [2744028] | Lr: 0.000030 | Loss: 1.3003 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 54.62
24-04-06 05:26:46.365 - INFO: Train epoch 537: [73600/94637 (78%)] Step: [2744128] | Lr: 0.000030 | Loss: 1.2212 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 54.79
24-04-06 05:27:34.303 - INFO: Train epoch 537: [76800/94637 (81%)] Step: [2744228] | Lr: 0.000030 | Loss: 1.2854 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 51.54
24-04-06 05:28:22.442 - INFO: Train epoch 537: [80000/94637 (85%)] Step: [2744328] | Lr: 0.000030 | Loss: 1.0706 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 52.46
24-04-06 05:29:10.657 - INFO: Train epoch 537: [83200/94637 (88%)] Step: [2744428] | Lr: 0.000030 | Loss: 1.2345 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 56.98
24-04-06 05:29:58.783 - INFO: Train epoch 537: [86400/94637 (91%)] Step: [2744528] | Lr: 0.000030 | Loss: 1.3278 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 50.80
24-04-06 05:30:46.615 - INFO: Train epoch 537: [89600/94637 (95%)] Step: [2744628] | Lr: 0.000030 | Loss: 1.2201 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 51.52
24-04-06 05:31:34.575 - INFO: Train epoch 537: [92800/94637 (98%)] Step: [2744728] | Lr: 0.000030 | Loss: 1.4359 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 52.07
24-04-06 05:32:13.059 - INFO: Learning rate: 3e-05
24-04-06 05:32:14.273 - INFO: Train epoch 538: [    0/94637 (0%)] Step: [2744785] | Lr: 0.000030 | Loss: 1.3453 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 52.90
24-04-06 05:33:01.926 - INFO: Train epoch 538: [ 3200/94637 (3%)] Step: [2744885] | Lr: 0.000030 | Loss: 0.8108 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 50.04
24-04-06 05:33:49.392 - INFO: Train epoch 538: [ 6400/94637 (7%)] Step: [2744985] | Lr: 0.000030 | Loss: 1.0385 | MSE loss: 0.0003 | Bpp loss: 0.62 | Aux loss: 55.80
24-04-06 05:34:38.382 - INFO: Train epoch 538: [ 9600/94637 (10%)] Step: [2745085] | Lr: 0.000030 | Loss: 1.2179 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 51.58
24-04-06 05:35:26.243 - INFO: Train epoch 538: [12800/94637 (14%)] Step: [2745185] | Lr: 0.000030 | Loss: 0.9727 | MSE loss: 0.0003 | Bpp loss: 0.56 | Aux loss: 56.52
24-04-06 05:36:14.478 - INFO: Train epoch 538: [16000/94637 (17%)] Step: [2745285] | Lr: 0.000030 | Loss: 1.3257 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 56.70
24-04-06 05:37:02.211 - INFO: Train epoch 538: [19200/94637 (20%)] Step: [2745385] | Lr: 0.000030 | Loss: 1.4529 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 48.41
24-04-06 05:37:50.054 - INFO: Train epoch 538: [22400/94637 (24%)] Step: [2745485] | Lr: 0.000030 | Loss: 1.3923 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 55.23
24-04-06 05:38:37.601 - INFO: Train epoch 538: [25600/94637 (27%)] Step: [2745585] | Lr: 0.000030 | Loss: 1.3409 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 53.07
24-04-06 05:39:25.496 - INFO: Train epoch 538: [28800/94637 (30%)] Step: [2745685] | Lr: 0.000030 | Loss: 0.8818 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 55.10
24-04-06 05:40:13.466 - INFO: Train epoch 538: [32000/94637 (34%)] Step: [2745785] | Lr: 0.000030 | Loss: 1.1870 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 52.52
24-04-06 05:41:02.092 - INFO: Train epoch 538: [35200/94637 (37%)] Step: [2745885] | Lr: 0.000030 | Loss: 1.0175 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 56.99
24-04-06 05:41:50.655 - INFO: Train epoch 538: [38400/94637 (41%)] Step: [2745985] | Lr: 0.000030 | Loss: 1.0212 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 52.06
24-04-06 05:42:38.553 - INFO: Train epoch 538: [41600/94637 (44%)] Step: [2746085] | Lr: 0.000030 | Loss: 1.1025 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 52.96
24-04-06 05:43:25.882 - INFO: Train epoch 538: [44800/94637 (47%)] Step: [2746185] | Lr: 0.000030 | Loss: 1.1741 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 56.68
24-04-06 05:44:13.410 - INFO: Train epoch 538: [48000/94637 (51%)] Step: [2746285] | Lr: 0.000030 | Loss: 1.0406 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 51.54
24-04-06 05:45:01.395 - INFO: Train epoch 538: [51200/94637 (54%)] Step: [2746385] | Lr: 0.000030 | Loss: 1.3448 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 54.53
24-04-06 05:45:49.261 - INFO: Train epoch 538: [54400/94637 (57%)] Step: [2746485] | Lr: 0.000030 | Loss: 1.1976 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 54.58
24-04-06 05:46:37.298 - INFO: Train epoch 538: [57600/94637 (61%)] Step: [2746585] | Lr: 0.000030 | Loss: 1.2269 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 55.73
24-04-06 05:47:24.623 - INFO: Train epoch 538: [60800/94637 (64%)] Step: [2746685] | Lr: 0.000030 | Loss: 1.5506 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 58.38
24-04-06 05:48:12.746 - INFO: Train epoch 538: [64000/94637 (68%)] Step: [2746785] | Lr: 0.000030 | Loss: 1.2490 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 54.25
24-04-06 05:49:00.586 - INFO: Train epoch 538: [67200/94637 (71%)] Step: [2746885] | Lr: 0.000030 | Loss: 1.2047 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 51.15
24-04-06 05:49:48.399 - INFO: Train epoch 538: [70400/94637 (74%)] Step: [2746985] | Lr: 0.000030 | Loss: 1.1366 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 54.07
24-04-06 05:50:36.631 - INFO: Train epoch 538: [73600/94637 (78%)] Step: [2747085] | Lr: 0.000030 | Loss: 0.7519 | MSE loss: 0.0002 | Bpp loss: 0.48 | Aux loss: 56.44
24-04-06 05:51:24.102 - INFO: Train epoch 538: [76800/94637 (81%)] Step: [2747185] | Lr: 0.000030 | Loss: 1.0302 | MSE loss: 0.0003 | Bpp loss: 0.62 | Aux loss: 54.54
24-04-06 05:52:11.806 - INFO: Train epoch 538: [80000/94637 (85%)] Step: [2747285] | Lr: 0.000030 | Loss: 1.0134 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 57.57
24-04-06 05:52:59.036 - INFO: Train epoch 538: [83200/94637 (88%)] Step: [2747385] | Lr: 0.000030 | Loss: 1.6936 | MSE loss: 0.0004 | Bpp loss: 1.05 | Aux loss: 52.06
24-04-06 05:53:47.478 - INFO: Train epoch 538: [86400/94637 (91%)] Step: [2747485] | Lr: 0.000030 | Loss: 1.4163 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 53.18
24-04-06 05:54:37.108 - INFO: Train epoch 538: [89600/94637 (95%)] Step: [2747585] | Lr: 0.000030 | Loss: 1.4161 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 60.38
24-04-06 05:55:24.950 - INFO: Train epoch 538: [92800/94637 (98%)] Step: [2747685] | Lr: 0.000030 | Loss: 1.5605 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 53.98
24-04-06 05:56:03.767 - INFO: Learning rate: 3e-05
24-04-06 05:56:05.314 - INFO: Train epoch 539: [    0/94637 (0%)] Step: [2747742] | Lr: 0.000030 | Loss: 1.4118 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 54.03
24-04-06 05:56:52.584 - INFO: Train epoch 539: [ 3200/94637 (3%)] Step: [2747842] | Lr: 0.000030 | Loss: 1.1604 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 54.18
24-04-06 05:57:40.736 - INFO: Train epoch 539: [ 6400/94637 (7%)] Step: [2747942] | Lr: 0.000030 | Loss: 1.0618 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 54.89
24-04-06 05:58:27.961 - INFO: Train epoch 539: [ 9600/94637 (10%)] Step: [2748042] | Lr: 0.000030 | Loss: 1.1044 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 55.83
24-04-06 05:59:15.713 - INFO: Train epoch 539: [12800/94637 (14%)] Step: [2748142] | Lr: 0.000030 | Loss: 0.8969 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 56.14
24-04-06 06:00:03.230 - INFO: Train epoch 539: [16000/94637 (17%)] Step: [2748242] | Lr: 0.000030 | Loss: 0.8820 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 54.39
24-04-06 06:00:50.430 - INFO: Train epoch 539: [19200/94637 (20%)] Step: [2748342] | Lr: 0.000030 | Loss: 1.4822 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 57.98
24-04-06 06:01:38.242 - INFO: Train epoch 539: [22400/94637 (24%)] Step: [2748442] | Lr: 0.000030 | Loss: 1.2482 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 56.54
24-04-06 06:02:25.780 - INFO: Train epoch 539: [25600/94637 (27%)] Step: [2748542] | Lr: 0.000030 | Loss: 1.0705 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 55.55
24-04-06 06:03:14.637 - INFO: Train epoch 539: [28800/94637 (30%)] Step: [2748642] | Lr: 0.000030 | Loss: 1.6130 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 56.03
24-04-06 06:04:02.829 - INFO: Train epoch 539: [32000/94637 (34%)] Step: [2748742] | Lr: 0.000030 | Loss: 0.9898 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 57.87
24-04-06 06:04:50.935 - INFO: Train epoch 539: [35200/94637 (37%)] Step: [2748842] | Lr: 0.000030 | Loss: 1.4382 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 55.11
24-04-06 06:05:39.140 - INFO: Train epoch 539: [38400/94637 (41%)] Step: [2748942] | Lr: 0.000030 | Loss: 1.2174 | MSE loss: 0.0002 | Bpp loss: 0.82 | Aux loss: 53.95
24-04-06 06:06:27.595 - INFO: Train epoch 539: [41600/94637 (44%)] Step: [2749042] | Lr: 0.000030 | Loss: 0.8162 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 55.91
24-04-06 06:07:15.566 - INFO: Train epoch 539: [44800/94637 (47%)] Step: [2749142] | Lr: 0.000030 | Loss: 1.5504 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 52.04
24-04-06 06:08:03.269 - INFO: Train epoch 539: [48000/94637 (51%)] Step: [2749242] | Lr: 0.000030 | Loss: 0.9085 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 56.85
24-04-06 06:08:51.104 - INFO: Train epoch 539: [51200/94637 (54%)] Step: [2749342] | Lr: 0.000030 | Loss: 1.3524 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 55.13
24-04-06 06:09:39.685 - INFO: Train epoch 539: [54400/94637 (57%)] Step: [2749442] | Lr: 0.000030 | Loss: 1.3452 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 52.47
24-04-06 06:10:28.763 - INFO: Train epoch 539: [57600/94637 (61%)] Step: [2749542] | Lr: 0.000030 | Loss: 1.1346 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 56.64
24-04-06 06:11:17.404 - INFO: Train epoch 539: [60800/94637 (64%)] Step: [2749642] | Lr: 0.000030 | Loss: 1.3541 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 52.95
24-04-06 06:12:06.358 - INFO: Train epoch 539: [64000/94637 (68%)] Step: [2749742] | Lr: 0.000030 | Loss: 1.3009 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 56.48
24-04-06 06:12:55.016 - INFO: Train epoch 539: [67200/94637 (71%)] Step: [2749842] | Lr: 0.000030 | Loss: 1.5887 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 55.82
24-04-06 06:13:43.497 - INFO: Train epoch 539: [70400/94637 (74%)] Step: [2749942] | Lr: 0.000030 | Loss: 1.3653 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 62.31
24-04-06 06:14:34.471 - INFO: Train epoch 539: [73600/94637 (78%)] Step: [2750042] | Lr: 0.000030 | Loss: 0.8376 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 56.33
24-04-06 06:15:22.961 - INFO: Train epoch 539: [76800/94637 (81%)] Step: [2750142] | Lr: 0.000030 | Loss: 1.0944 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 56.18
24-04-06 06:16:11.939 - INFO: Train epoch 539: [80000/94637 (85%)] Step: [2750242] | Lr: 0.000030 | Loss: 1.0694 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 58.55
24-04-06 06:17:00.802 - INFO: Train epoch 539: [83200/94637 (88%)] Step: [2750342] | Lr: 0.000030 | Loss: 1.7568 | MSE loss: 0.0004 | Bpp loss: 1.05 | Aux loss: 52.90
24-04-06 06:17:50.023 - INFO: Train epoch 539: [86400/94637 (91%)] Step: [2750442] | Lr: 0.000030 | Loss: 0.8688 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 53.08
24-04-06 06:18:39.070 - INFO: Train epoch 539: [89600/94637 (95%)] Step: [2750542] | Lr: 0.000030 | Loss: 0.9814 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 52.07
24-04-06 06:19:27.666 - INFO: Train epoch 539: [92800/94637 (98%)] Step: [2750642] | Lr: 0.000030 | Loss: 0.9263 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 59.71
24-04-06 06:20:06.771 - INFO: Learning rate: 3e-05
24-04-06 06:20:07.919 - INFO: Train epoch 540: [    0/94637 (0%)] Step: [2750699] | Lr: 0.000030 | Loss: 1.1343 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 59.76
24-04-06 06:20:55.887 - INFO: Train epoch 540: [ 3200/94637 (3%)] Step: [2750799] | Lr: 0.000030 | Loss: 1.0858 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 55.87
24-04-06 06:21:44.213 - INFO: Train epoch 540: [ 6400/94637 (7%)] Step: [2750899] | Lr: 0.000030 | Loss: 1.3901 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 56.69
24-04-06 06:22:32.621 - INFO: Train epoch 540: [ 9600/94637 (10%)] Step: [2750999] | Lr: 0.000030 | Loss: 1.3243 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 63.88
24-04-06 06:23:21.040 - INFO: Train epoch 540: [12800/94637 (14%)] Step: [2751099] | Lr: 0.000030 | Loss: 1.2362 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 57.94
24-04-06 06:24:09.590 - INFO: Train epoch 540: [16000/94637 (17%)] Step: [2751199] | Lr: 0.000030 | Loss: 1.0160 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 57.60
24-04-06 06:24:57.605 - INFO: Train epoch 540: [19200/94637 (20%)] Step: [2751299] | Lr: 0.000030 | Loss: 1.1869 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 56.52
24-04-06 06:25:45.756 - INFO: Train epoch 540: [22400/94637 (24%)] Step: [2751399] | Lr: 0.000030 | Loss: 1.2556 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 57.77
24-04-06 06:26:34.117 - INFO: Train epoch 540: [25600/94637 (27%)] Step: [2751499] | Lr: 0.000030 | Loss: 1.5274 | MSE loss: 0.0003 | Bpp loss: 0.97 | Aux loss: 56.36
24-04-06 06:27:22.088 - INFO: Train epoch 540: [28800/94637 (30%)] Step: [2751599] | Lr: 0.000030 | Loss: 1.1717 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 59.31
24-04-06 06:28:10.031 - INFO: Train epoch 540: [32000/94637 (34%)] Step: [2751699] | Lr: 0.000030 | Loss: 1.2808 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 56.81
24-04-06 06:28:58.537 - INFO: Train epoch 540: [35200/94637 (37%)] Step: [2751799] | Lr: 0.000030 | Loss: 1.3839 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 58.57
24-04-06 06:29:46.618 - INFO: Train epoch 540: [38400/94637 (41%)] Step: [2751899] | Lr: 0.000030 | Loss: 1.4746 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 53.29
24-04-06 06:30:34.797 - INFO: Train epoch 540: [41600/94637 (44%)] Step: [2751999] | Lr: 0.000030 | Loss: 0.8373 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 56.22
24-04-06 06:31:23.246 - INFO: Train epoch 540: [44800/94637 (47%)] Step: [2752099] | Lr: 0.000030 | Loss: 1.2194 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 55.07
24-04-06 06:32:11.347 - INFO: Train epoch 540: [48000/94637 (51%)] Step: [2752199] | Lr: 0.000030 | Loss: 1.2971 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 53.35
24-04-06 06:32:59.238 - INFO: Train epoch 540: [51200/94637 (54%)] Step: [2752299] | Lr: 0.000030 | Loss: 1.5154 | MSE loss: 0.0004 | Bpp loss: 0.93 | Aux loss: 59.09
24-04-06 06:33:47.584 - INFO: Train epoch 540: [54400/94637 (57%)] Step: [2752399] | Lr: 0.000030 | Loss: 1.2168 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 56.40
24-04-06 06:34:35.943 - INFO: Train epoch 540: [57600/94637 (61%)] Step: [2752499] | Lr: 0.000030 | Loss: 0.9287 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 57.91
24-04-06 06:35:26.101 - INFO: Train epoch 540: [60800/94637 (64%)] Step: [2752599] | Lr: 0.000030 | Loss: 1.1345 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 60.00
24-04-06 06:36:13.983 - INFO: Train epoch 540: [64000/94637 (68%)] Step: [2752699] | Lr: 0.000030 | Loss: 1.1066 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 56.91
24-04-06 06:37:02.707 - INFO: Train epoch 540: [67200/94637 (71%)] Step: [2752799] | Lr: 0.000030 | Loss: 1.1746 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 57.40
24-04-06 06:37:50.646 - INFO: Train epoch 540: [70400/94637 (74%)] Step: [2752899] | Lr: 0.000030 | Loss: 0.8644 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 57.19
24-04-06 06:38:38.732 - INFO: Train epoch 540: [73600/94637 (78%)] Step: [2752999] | Lr: 0.000030 | Loss: 1.0006 | MSE loss: 0.0003 | Bpp loss: 0.57 | Aux loss: 58.24
24-04-06 06:39:26.864 - INFO: Train epoch 540: [76800/94637 (81%)] Step: [2753099] | Lr: 0.000030 | Loss: 1.5565 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 57.98
24-04-06 06:40:14.824 - INFO: Train epoch 540: [80000/94637 (85%)] Step: [2753199] | Lr: 0.000030 | Loss: 1.2048 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 58.19
24-04-06 06:41:03.094 - INFO: Train epoch 540: [83200/94637 (88%)] Step: [2753299] | Lr: 0.000030 | Loss: 1.3394 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 52.72
24-04-06 06:41:50.930 - INFO: Train epoch 540: [86400/94637 (91%)] Step: [2753399] | Lr: 0.000030 | Loss: 1.1835 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 55.21
24-04-06 06:42:39.409 - INFO: Train epoch 540: [89600/94637 (95%)] Step: [2753499] | Lr: 0.000030 | Loss: 1.7390 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 57.66
24-04-06 06:43:27.320 - INFO: Train epoch 540: [92800/94637 (98%)] Step: [2753599] | Lr: 0.000030 | Loss: 1.0817 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 58.55
24-04-06 06:44:05.626 - INFO: Learning rate: 3e-05
24-04-06 06:44:07.107 - INFO: Train epoch 541: [    0/94637 (0%)] Step: [2753656] | Lr: 0.000030 | Loss: 1.2930 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 59.44
24-04-06 06:44:55.735 - INFO: Train epoch 541: [ 3200/94637 (3%)] Step: [2753756] | Lr: 0.000030 | Loss: 0.9741 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 53.32
24-04-06 06:45:44.087 - INFO: Train epoch 541: [ 6400/94637 (7%)] Step: [2753856] | Lr: 0.000030 | Loss: 0.8773 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 52.03
24-04-06 06:46:31.789 - INFO: Train epoch 541: [ 9600/94637 (10%)] Step: [2753956] | Lr: 0.000030 | Loss: 0.9988 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 55.78
24-04-06 06:47:19.787 - INFO: Train epoch 541: [12800/94637 (14%)] Step: [2754056] | Lr: 0.000030 | Loss: 0.8335 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 55.16
24-04-06 06:48:07.775 - INFO: Train epoch 541: [16000/94637 (17%)] Step: [2754156] | Lr: 0.000030 | Loss: 0.8769 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 56.34
24-04-06 06:48:56.174 - INFO: Train epoch 541: [19200/94637 (20%)] Step: [2754256] | Lr: 0.000030 | Loss: 0.8728 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 56.48
24-04-06 06:49:44.194 - INFO: Train epoch 541: [22400/94637 (24%)] Step: [2754356] | Lr: 0.000030 | Loss: 1.1366 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 56.40
24-04-06 06:50:32.372 - INFO: Train epoch 541: [25600/94637 (27%)] Step: [2754456] | Lr: 0.000030 | Loss: 0.8714 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 54.98
24-04-06 06:51:20.809 - INFO: Train epoch 541: [28800/94637 (30%)] Step: [2754556] | Lr: 0.000030 | Loss: 1.3593 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 51.37
24-04-06 06:52:09.012 - INFO: Train epoch 541: [32000/94637 (34%)] Step: [2754656] | Lr: 0.000030 | Loss: 1.2264 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 55.66
24-04-06 06:52:57.438 - INFO: Train epoch 541: [35200/94637 (37%)] Step: [2754756] | Lr: 0.000030 | Loss: 0.9217 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 60.94
24-04-06 06:53:45.869 - INFO: Train epoch 541: [38400/94637 (41%)] Step: [2754856] | Lr: 0.000030 | Loss: 1.4639 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 57.49
24-04-06 06:54:34.281 - INFO: Train epoch 541: [41600/94637 (44%)] Step: [2754956] | Lr: 0.000030 | Loss: 0.9814 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 54.75
24-04-06 06:55:24.633 - INFO: Train epoch 541: [44800/94637 (47%)] Step: [2755056] | Lr: 0.000030 | Loss: 0.9668 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 60.83
24-04-06 06:56:13.044 - INFO: Train epoch 541: [48000/94637 (51%)] Step: [2755156] | Lr: 0.000030 | Loss: 1.1070 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 66.13
24-04-06 06:57:01.651 - INFO: Train epoch 541: [51200/94637 (54%)] Step: [2755256] | Lr: 0.000030 | Loss: 1.3101 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 60.39
24-04-06 06:57:50.339 - INFO: Train epoch 541: [54400/94637 (57%)] Step: [2755356] | Lr: 0.000030 | Loss: 1.3180 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 60.35
24-04-06 06:58:39.023 - INFO: Train epoch 541: [57600/94637 (61%)] Step: [2755456] | Lr: 0.000030 | Loss: 1.0127 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 63.50
24-04-06 06:59:27.247 - INFO: Train epoch 541: [60800/94637 (64%)] Step: [2755556] | Lr: 0.000030 | Loss: 1.1316 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 60.68
24-04-06 07:00:13.927 - INFO: Train epoch 541: [64000/94637 (68%)] Step: [2755656] | Lr: 0.000030 | Loss: 1.1698 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 59.43
24-04-06 07:01:01.385 - INFO: Train epoch 541: [67200/94637 (71%)] Step: [2755756] | Lr: 0.000030 | Loss: 1.1695 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 57.16
24-04-06 07:01:48.632 - INFO: Train epoch 541: [70400/94637 (74%)] Step: [2755856] | Lr: 0.000030 | Loss: 1.4442 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 58.84
24-04-06 07:02:36.117 - INFO: Train epoch 541: [73600/94637 (78%)] Step: [2755956] | Lr: 0.000030 | Loss: 1.0760 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 60.38
24-04-06 07:03:23.163 - INFO: Train epoch 541: [76800/94637 (81%)] Step: [2756056] | Lr: 0.000030 | Loss: 1.6533 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 56.18
24-04-06 07:04:10.448 - INFO: Train epoch 541: [80000/94637 (85%)] Step: [2756156] | Lr: 0.000030 | Loss: 1.0260 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 60.02
24-04-06 07:04:58.390 - INFO: Train epoch 541: [83200/94637 (88%)] Step: [2756256] | Lr: 0.000030 | Loss: 1.5086 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 57.89
24-04-06 07:05:46.177 - INFO: Train epoch 541: [86400/94637 (91%)] Step: [2756356] | Lr: 0.000030 | Loss: 1.0881 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 59.81
24-04-06 07:06:34.380 - INFO: Train epoch 541: [89600/94637 (95%)] Step: [2756456] | Lr: 0.000030 | Loss: 1.2832 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 57.40
24-04-06 07:07:22.221 - INFO: Train epoch 541: [92800/94637 (98%)] Step: [2756556] | Lr: 0.000030 | Loss: 1.1847 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 58.55
24-04-06 07:08:00.324 - INFO: Learning rate: 3e-05
24-04-06 07:08:01.997 - INFO: Train epoch 542: [    0/94637 (0%)] Step: [2756613] | Lr: 0.000030 | Loss: 1.1171 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 52.72
24-04-06 07:08:49.163 - INFO: Train epoch 542: [ 3200/94637 (3%)] Step: [2756713] | Lr: 0.000030 | Loss: 1.1245 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 57.08
24-04-06 07:09:36.588 - INFO: Train epoch 542: [ 6400/94637 (7%)] Step: [2756813] | Lr: 0.000030 | Loss: 0.8826 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 51.90
24-04-06 07:10:24.152 - INFO: Train epoch 542: [ 9600/94637 (10%)] Step: [2756913] | Lr: 0.000030 | Loss: 1.2673 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 59.03
24-04-06 07:11:11.022 - INFO: Train epoch 542: [12800/94637 (14%)] Step: [2757013] | Lr: 0.000030 | Loss: 1.0172 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 57.94
24-04-06 07:11:58.202 - INFO: Train epoch 542: [16000/94637 (17%)] Step: [2757113] | Lr: 0.000030 | Loss: 2.0533 | MSE loss: 0.0007 | Bpp loss: 0.91 | Aux loss: 58.79
24-04-06 07:12:45.661 - INFO: Train epoch 542: [19200/94637 (20%)] Step: [2757213] | Lr: 0.000030 | Loss: 1.6231 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 49.15
24-04-06 07:13:32.841 - INFO: Train epoch 542: [22400/94637 (24%)] Step: [2757313] | Lr: 0.000030 | Loss: 0.9208 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 58.76
24-04-06 07:14:20.336 - INFO: Train epoch 542: [25600/94637 (27%)] Step: [2757413] | Lr: 0.000030 | Loss: 1.1834 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 58.42
24-04-06 07:15:10.177 - INFO: Train epoch 542: [28800/94637 (30%)] Step: [2757513] | Lr: 0.000030 | Loss: 1.3276 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 59.49
24-04-06 07:15:57.795 - INFO: Train epoch 542: [32000/94637 (34%)] Step: [2757613] | Lr: 0.000030 | Loss: 1.6232 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 57.17
24-04-06 07:16:45.413 - INFO: Train epoch 542: [35200/94637 (37%)] Step: [2757713] | Lr: 0.000030 | Loss: 1.1892 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 57.83
24-04-06 07:17:32.560 - INFO: Train epoch 542: [38400/94637 (41%)] Step: [2757813] | Lr: 0.000030 | Loss: 1.2239 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 54.43
24-04-06 07:18:19.743 - INFO: Train epoch 542: [41600/94637 (44%)] Step: [2757913] | Lr: 0.000030 | Loss: 0.8227 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 55.68
24-04-06 07:19:07.506 - INFO: Train epoch 542: [44800/94637 (47%)] Step: [2758013] | Lr: 0.000030 | Loss: 0.9329 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 57.44
24-04-06 07:19:55.342 - INFO: Train epoch 542: [48000/94637 (51%)] Step: [2758113] | Lr: 0.000030 | Loss: 1.1383 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 58.62
24-04-06 07:20:42.691 - INFO: Train epoch 542: [51200/94637 (54%)] Step: [2758213] | Lr: 0.000030 | Loss: 1.2516 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 56.68
24-04-06 07:21:29.602 - INFO: Train epoch 542: [54400/94637 (57%)] Step: [2758313] | Lr: 0.000030 | Loss: 0.9672 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 57.15
24-04-06 07:22:16.705 - INFO: Train epoch 542: [57600/94637 (61%)] Step: [2758413] | Lr: 0.000030 | Loss: 0.8304 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 56.84
24-04-06 07:23:03.832 - INFO: Train epoch 542: [60800/94637 (64%)] Step: [2758513] | Lr: 0.000030 | Loss: 1.3921 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 58.72
24-04-06 07:23:51.568 - INFO: Train epoch 542: [64000/94637 (68%)] Step: [2758613] | Lr: 0.000030 | Loss: 1.2175 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 60.89
24-04-06 07:24:40.295 - INFO: Train epoch 542: [67200/94637 (71%)] Step: [2758713] | Lr: 0.000030 | Loss: 1.3192 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 58.52
24-04-06 07:25:28.931 - INFO: Train epoch 542: [70400/94637 (74%)] Step: [2758813] | Lr: 0.000030 | Loss: 1.1293 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 60.77
24-04-06 07:26:17.911 - INFO: Train epoch 542: [73600/94637 (78%)] Step: [2758913] | Lr: 0.000030 | Loss: 1.1694 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 61.36
24-04-06 07:27:06.832 - INFO: Train epoch 542: [76800/94637 (81%)] Step: [2759013] | Lr: 0.000030 | Loss: 1.0564 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 61.73
24-04-06 07:27:55.534 - INFO: Train epoch 542: [80000/94637 (85%)] Step: [2759113] | Lr: 0.000030 | Loss: 1.1217 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 57.57
24-04-06 07:28:44.210 - INFO: Train epoch 542: [83200/94637 (88%)] Step: [2759213] | Lr: 0.000030 | Loss: 0.7413 | MSE loss: 0.0002 | Bpp loss: 0.47 | Aux loss: 55.64
24-04-06 07:29:32.657 - INFO: Train epoch 542: [86400/94637 (91%)] Step: [2759313] | Lr: 0.000030 | Loss: 0.8307 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 55.58
24-04-06 07:30:21.015 - INFO: Train epoch 542: [89600/94637 (95%)] Step: [2759413] | Lr: 0.000030 | Loss: 1.1424 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 57.57
24-04-06 07:31:09.004 - INFO: Train epoch 542: [92800/94637 (98%)] Step: [2759513] | Lr: 0.000030 | Loss: 1.1929 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 58.15
24-04-06 07:31:47.177 - INFO: Learning rate: 3e-05
24-04-06 07:31:48.344 - INFO: Train epoch 543: [    0/94637 (0%)] Step: [2759570] | Lr: 0.000030 | Loss: 1.0571 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 59.61
24-04-06 07:32:36.743 - INFO: Train epoch 543: [ 3200/94637 (3%)] Step: [2759670] | Lr: 0.000030 | Loss: 1.0656 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 58.49
24-04-06 07:33:24.459 - INFO: Train epoch 543: [ 6400/94637 (7%)] Step: [2759770] | Lr: 0.000030 | Loss: 1.4072 | MSE loss: 0.0004 | Bpp loss: 0.80 | Aux loss: 54.41
24-04-06 07:34:12.551 - INFO: Train epoch 543: [ 9600/94637 (10%)] Step: [2759870] | Lr: 0.000030 | Loss: 1.0251 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 53.51
24-04-06 07:35:00.405 - INFO: Train epoch 543: [12800/94637 (14%)] Step: [2759970] | Lr: 0.000030 | Loss: 1.3969 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 61.24
24-04-06 07:35:50.245 - INFO: Train epoch 543: [16000/94637 (17%)] Step: [2760070] | Lr: 0.000030 | Loss: 1.2190 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 54.58
24-04-06 07:36:39.255 - INFO: Train epoch 543: [19200/94637 (20%)] Step: [2760170] | Lr: 0.000030 | Loss: 1.0937 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 56.84
24-04-06 07:37:27.487 - INFO: Train epoch 543: [22400/94637 (24%)] Step: [2760270] | Lr: 0.000030 | Loss: 1.3573 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 61.75
24-04-06 07:38:15.710 - INFO: Train epoch 543: [25600/94637 (27%)] Step: [2760370] | Lr: 0.000030 | Loss: 1.4053 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 60.53
24-04-06 07:39:03.455 - INFO: Train epoch 543: [28800/94637 (30%)] Step: [2760470] | Lr: 0.000030 | Loss: 1.0819 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 54.01
24-04-06 07:39:51.797 - INFO: Train epoch 543: [32000/94637 (34%)] Step: [2760570] | Lr: 0.000030 | Loss: 1.0388 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 57.40
24-04-06 07:40:39.858 - INFO: Train epoch 543: [35200/94637 (37%)] Step: [2760670] | Lr: 0.000030 | Loss: 1.2892 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 63.24
24-04-06 07:41:28.131 - INFO: Train epoch 543: [38400/94637 (41%)] Step: [2760770] | Lr: 0.000030 | Loss: 1.0408 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 54.66
24-04-06 07:42:16.190 - INFO: Train epoch 543: [41600/94637 (44%)] Step: [2760870] | Lr: 0.000030 | Loss: 1.2111 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 58.80
24-04-06 07:43:04.334 - INFO: Train epoch 543: [44800/94637 (47%)] Step: [2760970] | Lr: 0.000030 | Loss: 1.0469 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 58.63
24-04-06 07:43:52.432 - INFO: Train epoch 543: [48000/94637 (51%)] Step: [2761070] | Lr: 0.000030 | Loss: 1.0140 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 63.42
24-04-06 07:44:40.332 - INFO: Train epoch 543: [51200/94637 (54%)] Step: [2761170] | Lr: 0.000030 | Loss: 1.3720 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 59.96
24-04-06 07:45:28.970 - INFO: Train epoch 543: [54400/94637 (57%)] Step: [2761270] | Lr: 0.000030 | Loss: 0.9511 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 57.96
24-04-06 07:46:17.265 - INFO: Train epoch 543: [57600/94637 (61%)] Step: [2761370] | Lr: 0.000030 | Loss: 1.3848 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 56.56
24-04-06 07:47:05.295 - INFO: Train epoch 543: [60800/94637 (64%)] Step: [2761470] | Lr: 0.000030 | Loss: 1.2785 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 54.07
24-04-06 07:47:53.689 - INFO: Train epoch 543: [64000/94637 (68%)] Step: [2761570] | Lr: 0.000030 | Loss: 0.9131 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 56.77
24-04-06 07:48:42.104 - INFO: Train epoch 543: [67200/94637 (71%)] Step: [2761670] | Lr: 0.000030 | Loss: 1.1694 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 59.18
24-04-06 07:49:30.742 - INFO: Train epoch 543: [70400/94637 (74%)] Step: [2761770] | Lr: 0.000030 | Loss: 1.1071 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 61.95
24-04-06 07:50:18.526 - INFO: Train epoch 543: [73600/94637 (78%)] Step: [2761870] | Lr: 0.000030 | Loss: 1.3315 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 63.55
24-04-06 07:51:06.805 - INFO: Train epoch 543: [76800/94637 (81%)] Step: [2761970] | Lr: 0.000030 | Loss: 1.1045 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 60.19
24-04-06 07:51:54.734 - INFO: Train epoch 543: [80000/94637 (85%)] Step: [2762070] | Lr: 0.000030 | Loss: 1.1434 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 57.34
24-04-06 07:52:42.760 - INFO: Train epoch 543: [83200/94637 (88%)] Step: [2762170] | Lr: 0.000030 | Loss: 0.9582 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 53.95
24-04-06 07:53:30.692 - INFO: Train epoch 543: [86400/94637 (91%)] Step: [2762270] | Lr: 0.000030 | Loss: 1.0995 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 58.34
24-04-06 07:54:19.008 - INFO: Train epoch 543: [89600/94637 (95%)] Step: [2762370] | Lr: 0.000030 | Loss: 0.7906 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 57.56
24-04-06 07:55:07.370 - INFO: Train epoch 543: [92800/94637 (98%)] Step: [2762470] | Lr: 0.000030 | Loss: 1.5006 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 56.94
24-04-06 07:55:47.756 - INFO: Learning rate: 3e-05
24-04-06 07:55:48.931 - INFO: Train epoch 544: [    0/94637 (0%)] Step: [2762527] | Lr: 0.000030 | Loss: 1.0667 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 61.54
24-04-06 07:56:37.486 - INFO: Train epoch 544: [ 3200/94637 (3%)] Step: [2762627] | Lr: 0.000030 | Loss: 1.2040 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 57.83
24-04-06 07:57:25.780 - INFO: Train epoch 544: [ 6400/94637 (7%)] Step: [2762727] | Lr: 0.000030 | Loss: 0.8679 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 60.53
24-04-06 07:58:13.761 - INFO: Train epoch 544: [ 9600/94637 (10%)] Step: [2762827] | Lr: 0.000030 | Loss: 1.2698 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 56.49
24-04-06 07:59:00.686 - INFO: Train epoch 544: [12800/94637 (14%)] Step: [2762927] | Lr: 0.000030 | Loss: 1.0710 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 60.54
24-04-06 07:59:48.455 - INFO: Train epoch 544: [16000/94637 (17%)] Step: [2763027] | Lr: 0.000030 | Loss: 1.1454 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 58.60
24-04-06 08:00:35.789 - INFO: Train epoch 544: [19200/94637 (20%)] Step: [2763127] | Lr: 0.000030 | Loss: 1.3918 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 55.03
24-04-06 08:01:22.955 - INFO: Train epoch 544: [22400/94637 (24%)] Step: [2763227] | Lr: 0.000030 | Loss: 0.9758 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 56.54
24-04-06 08:02:10.067 - INFO: Train epoch 544: [25600/94637 (27%)] Step: [2763327] | Lr: 0.000030 | Loss: 1.3880 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 58.92
24-04-06 08:02:57.138 - INFO: Train epoch 544: [28800/94637 (30%)] Step: [2763427] | Lr: 0.000030 | Loss: 1.1266 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 58.93
24-04-06 08:03:44.845 - INFO: Train epoch 544: [32000/94637 (34%)] Step: [2763527] | Lr: 0.000030 | Loss: 1.2603 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 57.07
24-04-06 08:04:32.021 - INFO: Train epoch 544: [35200/94637 (37%)] Step: [2763627] | Lr: 0.000030 | Loss: 0.9011 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 56.52
24-04-06 08:05:19.408 - INFO: Train epoch 544: [38400/94637 (41%)] Step: [2763727] | Lr: 0.000030 | Loss: 0.8942 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 57.35
24-04-06 08:06:06.924 - INFO: Train epoch 544: [41600/94637 (44%)] Step: [2763827] | Lr: 0.000030 | Loss: 1.3123 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 60.79
24-04-06 08:06:54.784 - INFO: Train epoch 544: [44800/94637 (47%)] Step: [2763927] | Lr: 0.000030 | Loss: 1.1008 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 60.00
24-04-06 08:07:42.341 - INFO: Train epoch 544: [48000/94637 (51%)] Step: [2764027] | Lr: 0.000030 | Loss: 1.0737 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 59.86
24-04-06 08:08:30.159 - INFO: Train epoch 544: [51200/94637 (54%)] Step: [2764127] | Lr: 0.000030 | Loss: 1.5027 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 62.12
24-04-06 08:09:18.122 - INFO: Train epoch 544: [54400/94637 (57%)] Step: [2764227] | Lr: 0.000030 | Loss: 1.4113 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 59.13
24-04-06 08:10:06.338 - INFO: Train epoch 544: [57600/94637 (61%)] Step: [2764327] | Lr: 0.000030 | Loss: 1.0347 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 56.05
24-04-06 08:10:54.667 - INFO: Train epoch 544: [60800/94637 (64%)] Step: [2764427] | Lr: 0.000030 | Loss: 1.1739 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 59.92
24-04-06 08:11:43.253 - INFO: Train epoch 544: [64000/94637 (68%)] Step: [2764527] | Lr: 0.000030 | Loss: 1.4443 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 57.49
24-04-06 08:12:31.775 - INFO: Train epoch 544: [67200/94637 (71%)] Step: [2764627] | Lr: 0.000030 | Loss: 0.8958 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 60.21
24-04-06 08:13:19.950 - INFO: Train epoch 544: [70400/94637 (74%)] Step: [2764727] | Lr: 0.000030 | Loss: 1.3362 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 61.35
24-04-06 08:14:07.747 - INFO: Train epoch 544: [73600/94637 (78%)] Step: [2764827] | Lr: 0.000030 | Loss: 1.6065 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 57.04
24-04-06 08:14:55.756 - INFO: Train epoch 544: [76800/94637 (81%)] Step: [2764927] | Lr: 0.000030 | Loss: 1.4252 | MSE loss: 0.0004 | Bpp loss: 0.84 | Aux loss: 61.83
24-04-06 08:15:45.678 - INFO: Train epoch 544: [80000/94637 (85%)] Step: [2765027] | Lr: 0.000030 | Loss: 1.1132 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 57.37
24-04-06 08:16:34.050 - INFO: Train epoch 544: [83200/94637 (88%)] Step: [2765127] | Lr: 0.000030 | Loss: 1.4991 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 60.88
24-04-06 08:17:21.621 - INFO: Train epoch 544: [86400/94637 (91%)] Step: [2765227] | Lr: 0.000030 | Loss: 0.9101 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 59.14
24-04-06 08:18:09.795 - INFO: Train epoch 544: [89600/94637 (95%)] Step: [2765327] | Lr: 0.000030 | Loss: 1.0297 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 56.23
24-04-06 08:18:57.270 - INFO: Train epoch 544: [92800/94637 (98%)] Step: [2765427] | Lr: 0.000030 | Loss: 0.9447 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 63.08
24-04-06 08:19:40.432 - INFO: Learning rate: 3e-05
24-04-06 08:19:41.549 - INFO: Train epoch 545: [    0/94637 (0%)] Step: [2765484] | Lr: 0.000030 | Loss: 1.3324 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 56.91
24-04-06 08:20:29.368 - INFO: Train epoch 545: [ 3200/94637 (3%)] Step: [2765584] | Lr: 0.000030 | Loss: 1.2592 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 56.27
24-04-06 08:21:16.069 - INFO: Train epoch 545: [ 6400/94637 (7%)] Step: [2765684] | Lr: 0.000030 | Loss: 1.1645 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 58.25
24-04-06 08:22:03.366 - INFO: Train epoch 545: [ 9600/94637 (10%)] Step: [2765784] | Lr: 0.000030 | Loss: 1.3213 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 55.45
24-04-06 08:22:50.298 - INFO: Train epoch 545: [12800/94637 (14%)] Step: [2765884] | Lr: 0.000030 | Loss: 1.1412 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 55.82
24-04-06 08:23:38.229 - INFO: Train epoch 545: [16000/94637 (17%)] Step: [2765984] | Lr: 0.000030 | Loss: 1.3649 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 58.99
24-04-06 08:24:25.719 - INFO: Train epoch 545: [19200/94637 (20%)] Step: [2766084] | Lr: 0.000030 | Loss: 1.0937 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 59.19
24-04-06 08:25:13.122 - INFO: Train epoch 545: [22400/94637 (24%)] Step: [2766184] | Lr: 0.000030 | Loss: 1.1901 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 57.04
24-04-06 08:26:01.178 - INFO: Train epoch 545: [25600/94637 (27%)] Step: [2766284] | Lr: 0.000030 | Loss: 1.1321 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 57.28
24-04-06 08:26:49.098 - INFO: Train epoch 545: [28800/94637 (30%)] Step: [2766384] | Lr: 0.000030 | Loss: 1.2980 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 56.85
24-04-06 08:27:38.440 - INFO: Train epoch 545: [32000/94637 (34%)] Step: [2766484] | Lr: 0.000030 | Loss: 1.1942 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 58.17
24-04-06 08:28:27.429 - INFO: Train epoch 545: [35200/94637 (37%)] Step: [2766584] | Lr: 0.000030 | Loss: 1.2182 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 61.88
24-04-06 08:29:16.466 - INFO: Train epoch 545: [38400/94637 (41%)] Step: [2766684] | Lr: 0.000030 | Loss: 1.2014 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 63.10
24-04-06 08:30:05.372 - INFO: Train epoch 545: [41600/94637 (44%)] Step: [2766784] | Lr: 0.000030 | Loss: 1.2141 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 60.91
24-04-06 08:30:54.347 - INFO: Train epoch 545: [44800/94637 (47%)] Step: [2766884] | Lr: 0.000030 | Loss: 1.1573 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 63.63
24-04-06 08:31:44.776 - INFO: Train epoch 545: [48000/94637 (51%)] Step: [2766984] | Lr: 0.000030 | Loss: 1.2828 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 59.93
24-04-06 08:32:34.676 - INFO: Train epoch 545: [51200/94637 (54%)] Step: [2767084] | Lr: 0.000030 | Loss: 1.3705 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 64.15
24-04-06 08:33:24.475 - INFO: Train epoch 545: [54400/94637 (57%)] Step: [2767184] | Lr: 0.000030 | Loss: 0.9507 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 61.67
24-04-06 08:34:13.327 - INFO: Train epoch 545: [57600/94637 (61%)] Step: [2767284] | Lr: 0.000030 | Loss: 1.1662 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 60.96
24-04-06 08:35:02.504 - INFO: Train epoch 545: [60800/94637 (64%)] Step: [2767384] | Lr: 0.000030 | Loss: 1.0815 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 64.52
24-04-06 08:35:51.485 - INFO: Train epoch 545: [64000/94637 (68%)] Step: [2767484] | Lr: 0.000030 | Loss: 1.1921 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 58.23
24-04-06 08:36:42.775 - INFO: Train epoch 545: [67200/94637 (71%)] Step: [2767584] | Lr: 0.000030 | Loss: 0.9926 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 58.85
24-04-06 08:37:31.884 - INFO: Train epoch 545: [70400/94637 (74%)] Step: [2767684] | Lr: 0.000030 | Loss: 1.1735 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 61.72
24-04-06 08:38:20.872 - INFO: Train epoch 545: [73600/94637 (78%)] Step: [2767784] | Lr: 0.000030 | Loss: 0.9057 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 61.67
24-04-06 08:39:10.490 - INFO: Train epoch 545: [76800/94637 (81%)] Step: [2767884] | Lr: 0.000030 | Loss: 0.9894 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 59.22
24-04-06 08:39:59.755 - INFO: Train epoch 545: [80000/94637 (85%)] Step: [2767984] | Lr: 0.000030 | Loss: 1.1091 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 57.35
24-04-06 08:40:49.456 - INFO: Train epoch 545: [83200/94637 (88%)] Step: [2768084] | Lr: 0.000030 | Loss: 1.1021 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 59.24
24-04-06 08:41:38.528 - INFO: Train epoch 545: [86400/94637 (91%)] Step: [2768184] | Lr: 0.000030 | Loss: 0.9653 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 67.46
24-04-06 08:42:27.050 - INFO: Train epoch 545: [89600/94637 (95%)] Step: [2768284] | Lr: 0.000030 | Loss: 1.1840 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 63.15
24-04-06 08:43:16.089 - INFO: Train epoch 545: [92800/94637 (98%)] Step: [2768384] | Lr: 0.000030 | Loss: 1.2370 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 62.27
24-04-06 08:43:54.878 - INFO: Learning rate: 3e-05
24-04-06 08:43:56.584 - INFO: Train epoch 546: [    0/94637 (0%)] Step: [2768441] | Lr: 0.000030 | Loss: 0.8301 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 60.93
24-04-06 08:44:44.604 - INFO: Train epoch 546: [ 3200/94637 (3%)] Step: [2768541] | Lr: 0.000030 | Loss: 1.4023 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 63.95
24-04-06 08:45:32.819 - INFO: Train epoch 546: [ 6400/94637 (7%)] Step: [2768641] | Lr: 0.000030 | Loss: 1.4153 | MSE loss: 0.0004 | Bpp loss: 0.83 | Aux loss: 59.21
24-04-06 08:46:21.311 - INFO: Train epoch 546: [ 9600/94637 (10%)] Step: [2768741] | Lr: 0.000030 | Loss: 1.3418 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 60.90
24-04-06 08:47:10.325 - INFO: Train epoch 546: [12800/94637 (14%)] Step: [2768841] | Lr: 0.000030 | Loss: 1.2179 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 58.95
24-04-06 08:47:58.698 - INFO: Train epoch 546: [16000/94637 (17%)] Step: [2768941] | Lr: 0.000030 | Loss: 0.8344 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 59.49
24-04-06 08:48:47.391 - INFO: Train epoch 546: [19200/94637 (20%)] Step: [2769041] | Lr: 0.000030 | Loss: 1.1512 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 56.51
24-04-06 08:49:36.150 - INFO: Train epoch 546: [22400/94637 (24%)] Step: [2769141] | Lr: 0.000030 | Loss: 1.2927 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 63.48
24-04-06 08:50:24.774 - INFO: Train epoch 546: [25600/94637 (27%)] Step: [2769241] | Lr: 0.000030 | Loss: 1.0763 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 59.89
24-04-06 08:51:13.028 - INFO: Train epoch 546: [28800/94637 (30%)] Step: [2769341] | Lr: 0.000030 | Loss: 1.4492 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 58.35
24-04-06 08:52:01.668 - INFO: Train epoch 546: [32000/94637 (34%)] Step: [2769441] | Lr: 0.000030 | Loss: 1.1326 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 65.94
24-04-06 08:52:50.241 - INFO: Train epoch 546: [35200/94637 (37%)] Step: [2769541] | Lr: 0.000030 | Loss: 1.4015 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 59.54
24-04-06 08:53:39.219 - INFO: Train epoch 546: [38400/94637 (41%)] Step: [2769641] | Lr: 0.000030 | Loss: 1.2040 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 61.65
24-04-06 08:54:28.746 - INFO: Train epoch 546: [41600/94637 (44%)] Step: [2769741] | Lr: 0.000030 | Loss: 1.3177 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 60.71
24-04-06 08:55:18.045 - INFO: Train epoch 546: [44800/94637 (47%)] Step: [2769841] | Lr: 0.000030 | Loss: 1.1518 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 61.68
24-04-06 08:56:07.423 - INFO: Train epoch 546: [48000/94637 (51%)] Step: [2769941] | Lr: 0.000030 | Loss: 1.4018 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 63.14
24-04-06 08:56:58.478 - INFO: Train epoch 546: [51200/94637 (54%)] Step: [2770041] | Lr: 0.000030 | Loss: 1.6550 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 61.83
24-04-06 08:57:47.708 - INFO: Train epoch 546: [54400/94637 (57%)] Step: [2770141] | Lr: 0.000030 | Loss: 1.2082 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 61.34
24-04-06 08:58:36.975 - INFO: Train epoch 546: [57600/94637 (61%)] Step: [2770241] | Lr: 0.000030 | Loss: 1.3325 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 64.68
24-04-06 08:59:25.979 - INFO: Train epoch 546: [60800/94637 (64%)] Step: [2770341] | Lr: 0.000030 | Loss: 1.1287 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 62.44
24-04-06 09:00:29.050 - INFO: Train epoch 546: [64000/94637 (68%)] Step: [2770441] | Lr: 0.000030 | Loss: 1.3615 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 54.71
24-04-06 09:01:18.016 - INFO: Train epoch 546: [67200/94637 (71%)] Step: [2770541] | Lr: 0.000030 | Loss: 1.2406 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 58.32
24-04-06 09:02:07.585 - INFO: Train epoch 546: [70400/94637 (74%)] Step: [2770641] | Lr: 0.000030 | Loss: 1.1895 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 58.73
24-04-06 09:02:56.940 - INFO: Train epoch 546: [73600/94637 (78%)] Step: [2770741] | Lr: 0.000030 | Loss: 1.0808 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 64.24
24-04-06 09:03:46.018 - INFO: Train epoch 546: [76800/94637 (81%)] Step: [2770841] | Lr: 0.000030 | Loss: 1.3676 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 60.90
24-04-06 09:04:35.483 - INFO: Train epoch 546: [80000/94637 (85%)] Step: [2770941] | Lr: 0.000030 | Loss: 0.9898 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 58.57
24-04-06 09:05:24.502 - INFO: Train epoch 546: [83200/94637 (88%)] Step: [2771041] | Lr: 0.000030 | Loss: 1.4571 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 64.20
24-04-06 09:06:13.756 - INFO: Train epoch 546: [86400/94637 (91%)] Step: [2771141] | Lr: 0.000030 | Loss: 0.9756 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 60.86
24-04-06 09:07:03.083 - INFO: Train epoch 546: [89600/94637 (95%)] Step: [2771241] | Lr: 0.000030 | Loss: 0.8862 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 61.05
24-04-06 09:07:52.579 - INFO: Train epoch 546: [92800/94637 (98%)] Step: [2771341] | Lr: 0.000030 | Loss: 1.2771 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 60.74
24-04-06 09:08:31.641 - INFO: Learning rate: 3e-05
24-04-06 09:08:32.839 - INFO: Train epoch 547: [    0/94637 (0%)] Step: [2771398] | Lr: 0.000030 | Loss: 1.2410 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 64.66
24-04-06 09:09:21.517 - INFO: Train epoch 547: [ 3200/94637 (3%)] Step: [2771498] | Lr: 0.000030 | Loss: 1.3317 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 56.06
24-04-06 09:10:10.479 - INFO: Train epoch 547: [ 6400/94637 (7%)] Step: [2771598] | Lr: 0.000030 | Loss: 1.9357 | MSE loss: 0.0005 | Bpp loss: 1.20 | Aux loss: 58.48
24-04-06 09:10:59.164 - INFO: Train epoch 547: [ 9600/94637 (10%)] Step: [2771698] | Lr: 0.000030 | Loss: 1.4689 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 58.31
24-04-06 09:11:47.354 - INFO: Train epoch 547: [12800/94637 (14%)] Step: [2771798] | Lr: 0.000030 | Loss: 1.2728 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 55.66
24-04-06 09:12:35.723 - INFO: Train epoch 547: [16000/94637 (17%)] Step: [2771898] | Lr: 0.000030 | Loss: 1.3035 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 60.32
24-04-06 09:13:23.400 - INFO: Train epoch 547: [19200/94637 (20%)] Step: [2771998] | Lr: 0.000030 | Loss: 2.6466 | MSE loss: 0.0008 | Bpp loss: 1.31 | Aux loss: 57.75
24-04-06 09:14:11.725 - INFO: Train epoch 547: [22400/94637 (24%)] Step: [2772098] | Lr: 0.000030 | Loss: 1.2026 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 58.88
24-04-06 09:14:59.967 - INFO: Train epoch 547: [25600/94637 (27%)] Step: [2772198] | Lr: 0.000030 | Loss: 1.8833 | MSE loss: 0.0004 | Bpp loss: 1.17 | Aux loss: 62.20
24-04-06 09:15:48.010 - INFO: Train epoch 547: [28800/94637 (30%)] Step: [2772298] | Lr: 0.000030 | Loss: 1.0625 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 60.57
24-04-06 09:16:35.916 - INFO: Train epoch 547: [32000/94637 (34%)] Step: [2772398] | Lr: 0.000030 | Loss: 1.4076 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 60.58
24-04-06 09:17:24.196 - INFO: Train epoch 547: [35200/94637 (37%)] Step: [2772498] | Lr: 0.000030 | Loss: 0.9302 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 62.12
24-04-06 09:18:14.482 - INFO: Train epoch 547: [38400/94637 (41%)] Step: [2772598] | Lr: 0.000030 | Loss: 1.4242 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 58.58
24-04-06 09:19:02.294 - INFO: Train epoch 547: [41600/94637 (44%)] Step: [2772698] | Lr: 0.000030 | Loss: 1.2509 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 63.68
24-04-06 09:19:50.444 - INFO: Train epoch 547: [44800/94637 (47%)] Step: [2772798] | Lr: 0.000030 | Loss: 1.4127 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 60.95
24-04-06 09:20:38.481 - INFO: Train epoch 547: [48000/94637 (51%)] Step: [2772898] | Lr: 0.000030 | Loss: 1.2623 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 64.18
24-04-06 09:21:27.240 - INFO: Train epoch 547: [51200/94637 (54%)] Step: [2772998] | Lr: 0.000030 | Loss: 1.3728 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 58.36
24-04-06 09:22:15.662 - INFO: Train epoch 547: [54400/94637 (57%)] Step: [2773098] | Lr: 0.000030 | Loss: 1.1396 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 58.09
24-04-06 09:23:03.851 - INFO: Train epoch 547: [57600/94637 (61%)] Step: [2773198] | Lr: 0.000030 | Loss: 1.1970 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 67.93
24-04-06 09:23:52.068 - INFO: Train epoch 547: [60800/94637 (64%)] Step: [2773298] | Lr: 0.000030 | Loss: 1.1087 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 64.26
24-04-06 09:24:40.358 - INFO: Train epoch 547: [64000/94637 (68%)] Step: [2773398] | Lr: 0.000030 | Loss: 1.2983 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 55.14
24-04-06 09:25:29.019 - INFO: Train epoch 547: [67200/94637 (71%)] Step: [2773498] | Lr: 0.000030 | Loss: 1.5290 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 59.99
24-04-06 09:26:17.424 - INFO: Train epoch 547: [70400/94637 (74%)] Step: [2773598] | Lr: 0.000030 | Loss: 0.7456 | MSE loss: 0.0002 | Bpp loss: 0.47 | Aux loss: 62.29
24-04-06 09:27:05.358 - INFO: Train epoch 547: [73600/94637 (78%)] Step: [2773698] | Lr: 0.000030 | Loss: 0.9479 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 61.38
24-04-06 09:27:53.558 - INFO: Train epoch 547: [76800/94637 (81%)] Step: [2773798] | Lr: 0.000030 | Loss: 0.8208 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 58.58
24-04-06 09:28:41.745 - INFO: Train epoch 547: [80000/94637 (85%)] Step: [2773898] | Lr: 0.000030 | Loss: 1.1325 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 58.75
24-04-06 09:29:29.373 - INFO: Train epoch 547: [83200/94637 (88%)] Step: [2773998] | Lr: 0.000030 | Loss: 1.1566 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 57.85
24-04-06 09:30:17.149 - INFO: Train epoch 547: [86400/94637 (91%)] Step: [2774098] | Lr: 0.000030 | Loss: 1.6464 | MSE loss: 0.0004 | Bpp loss: 1.03 | Aux loss: 60.82
24-04-06 09:31:05.183 - INFO: Train epoch 547: [89600/94637 (95%)] Step: [2774198] | Lr: 0.000030 | Loss: 0.9319 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 58.57
24-04-06 09:31:53.137 - INFO: Train epoch 547: [92800/94637 (98%)] Step: [2774298] | Lr: 0.000030 | Loss: 1.0598 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 67.53
24-04-06 09:32:31.239 - INFO: Learning rate: 3e-05
24-04-06 09:32:32.553 - INFO: Train epoch 548: [    0/94637 (0%)] Step: [2774355] | Lr: 0.000030 | Loss: 1.0216 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 66.18
24-04-06 09:33:21.310 - INFO: Train epoch 548: [ 3200/94637 (3%)] Step: [2774455] | Lr: 0.000030 | Loss: 0.8425 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 66.15
24-04-06 09:34:10.419 - INFO: Train epoch 548: [ 6400/94637 (7%)] Step: [2774555] | Lr: 0.000030 | Loss: 0.8925 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 58.21
24-04-06 09:34:58.712 - INFO: Train epoch 548: [ 9600/94637 (10%)] Step: [2774655] | Lr: 0.000030 | Loss: 1.0250 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 64.03
24-04-06 09:35:47.357 - INFO: Train epoch 548: [12800/94637 (14%)] Step: [2774755] | Lr: 0.000030 | Loss: 1.0508 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 63.40
24-04-06 09:36:35.515 - INFO: Train epoch 548: [16000/94637 (17%)] Step: [2774855] | Lr: 0.000030 | Loss: 1.2463 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 58.10
24-04-06 09:37:23.863 - INFO: Train epoch 548: [19200/94637 (20%)] Step: [2774955] | Lr: 0.000030 | Loss: 1.3993 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 58.59
24-04-06 09:38:14.140 - INFO: Train epoch 548: [22400/94637 (24%)] Step: [2775055] | Lr: 0.000030 | Loss: 1.1370 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 61.77
24-04-06 09:39:02.437 - INFO: Train epoch 548: [25600/94637 (27%)] Step: [2775155] | Lr: 0.000030 | Loss: 1.3899 | MSE loss: 0.0004 | Bpp loss: 0.80 | Aux loss: 62.50
24-04-06 09:39:51.629 - INFO: Train epoch 548: [28800/94637 (30%)] Step: [2775255] | Lr: 0.000030 | Loss: 1.1559 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 63.03
24-04-06 09:40:39.541 - INFO: Train epoch 548: [32000/94637 (34%)] Step: [2775355] | Lr: 0.000030 | Loss: 1.1543 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 66.85
24-04-06 09:41:28.080 - INFO: Train epoch 548: [35200/94637 (37%)] Step: [2775455] | Lr: 0.000030 | Loss: 1.0114 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 62.04
24-04-06 09:42:16.519 - INFO: Train epoch 548: [38400/94637 (41%)] Step: [2775555] | Lr: 0.000030 | Loss: 0.8747 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 58.83
24-04-06 09:43:05.001 - INFO: Train epoch 548: [41600/94637 (44%)] Step: [2775655] | Lr: 0.000030 | Loss: 1.4332 | MSE loss: 0.0004 | Bpp loss: 0.72 | Aux loss: 62.46
24-04-06 09:43:53.570 - INFO: Train epoch 548: [44800/94637 (47%)] Step: [2775755] | Lr: 0.000030 | Loss: 1.0001 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 57.76
24-04-06 09:44:42.046 - INFO: Train epoch 548: [48000/94637 (51%)] Step: [2775855] | Lr: 0.000030 | Loss: 1.2818 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 58.73
24-04-06 09:45:30.314 - INFO: Train epoch 548: [51200/94637 (54%)] Step: [2775955] | Lr: 0.000030 | Loss: 1.1610 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 59.41
24-04-06 09:46:18.821 - INFO: Train epoch 548: [54400/94637 (57%)] Step: [2776055] | Lr: 0.000030 | Loss: 1.3805 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 61.92
24-04-06 09:47:07.338 - INFO: Train epoch 548: [57600/94637 (61%)] Step: [2776155] | Lr: 0.000030 | Loss: 1.0082 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 56.42
24-04-06 09:47:55.651 - INFO: Train epoch 548: [60800/94637 (64%)] Step: [2776255] | Lr: 0.000030 | Loss: 1.2163 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 61.99
24-04-06 09:48:44.616 - INFO: Train epoch 548: [64000/94637 (68%)] Step: [2776355] | Lr: 0.000030 | Loss: 0.8702 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 63.86
24-04-06 09:49:33.174 - INFO: Train epoch 548: [67200/94637 (71%)] Step: [2776455] | Lr: 0.000030 | Loss: 1.0274 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 56.16
24-04-06 09:50:22.025 - INFO: Train epoch 548: [70400/94637 (74%)] Step: [2776555] | Lr: 0.000030 | Loss: 1.4902 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 54.24
24-04-06 09:51:11.080 - INFO: Train epoch 548: [73600/94637 (78%)] Step: [2776655] | Lr: 0.000030 | Loss: 1.5375 | MSE loss: 0.0003 | Bpp loss: 0.98 | Aux loss: 63.95
24-04-06 09:51:59.908 - INFO: Train epoch 548: [76800/94637 (81%)] Step: [2776755] | Lr: 0.000030 | Loss: 1.1282 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 63.86
24-04-06 09:52:49.141 - INFO: Train epoch 548: [80000/94637 (85%)] Step: [2776855] | Lr: 0.000030 | Loss: 0.8666 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 60.56
24-04-06 09:53:37.585 - INFO: Train epoch 548: [83200/94637 (88%)] Step: [2776955] | Lr: 0.000030 | Loss: 1.0343 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 59.25
24-04-06 09:54:26.908 - INFO: Train epoch 548: [86400/94637 (91%)] Step: [2777055] | Lr: 0.000030 | Loss: 0.8707 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 60.64
24-04-06 09:55:16.018 - INFO: Train epoch 548: [89600/94637 (95%)] Step: [2777155] | Lr: 0.000030 | Loss: 1.1270 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 63.73
24-04-06 09:56:04.867 - INFO: Train epoch 548: [92800/94637 (98%)] Step: [2777255] | Lr: 0.000030 | Loss: 0.9878 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 61.51
24-04-06 09:56:43.900 - INFO: Learning rate: 3e-05
24-04-06 09:56:45.678 - INFO: Train epoch 549: [    0/94637 (0%)] Step: [2777312] | Lr: 0.000030 | Loss: 1.1698 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 58.89
24-04-06 09:57:33.808 - INFO: Train epoch 549: [ 3200/94637 (3%)] Step: [2777412] | Lr: 0.000030 | Loss: 1.2419 | MSE loss: 0.0004 | Bpp loss: 0.66 | Aux loss: 62.81
24-04-06 09:58:23.805 - INFO: Train epoch 549: [ 6400/94637 (7%)] Step: [2777512] | Lr: 0.000030 | Loss: 1.1157 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 58.68
24-04-06 09:59:12.674 - INFO: Train epoch 549: [ 9600/94637 (10%)] Step: [2777612] | Lr: 0.000030 | Loss: 0.9547 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 64.38
24-04-06 10:00:01.092 - INFO: Train epoch 549: [12800/94637 (14%)] Step: [2777712] | Lr: 0.000030 | Loss: 1.1903 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 59.76
24-04-06 10:00:49.916 - INFO: Train epoch 549: [16000/94637 (17%)] Step: [2777812] | Lr: 0.000030 | Loss: 1.2557 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 55.16
24-04-06 10:01:38.618 - INFO: Train epoch 549: [19200/94637 (20%)] Step: [2777912] | Lr: 0.000030 | Loss: 1.1569 | MSE loss: 0.0002 | Bpp loss: 0.78 | Aux loss: 60.76
24-04-06 10:02:27.880 - INFO: Train epoch 549: [22400/94637 (24%)] Step: [2778012] | Lr: 0.000030 | Loss: 0.9534 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 60.61
24-04-06 10:03:16.667 - INFO: Train epoch 549: [25600/94637 (27%)] Step: [2778112] | Lr: 0.000030 | Loss: 0.9496 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 62.62
24-04-06 10:04:05.943 - INFO: Train epoch 549: [28800/94637 (30%)] Step: [2778212] | Lr: 0.000030 | Loss: 0.9967 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 64.46
24-04-06 10:04:54.470 - INFO: Train epoch 549: [32000/94637 (34%)] Step: [2778312] | Lr: 0.000030 | Loss: 1.1467 | MSE loss: 0.0002 | Bpp loss: 0.76 | Aux loss: 60.85
24-04-06 10:05:43.281 - INFO: Train epoch 549: [35200/94637 (37%)] Step: [2778412] | Lr: 0.000030 | Loss: 1.4018 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 63.87
24-04-06 10:06:32.219 - INFO: Train epoch 549: [38400/94637 (41%)] Step: [2778512] | Lr: 0.000030 | Loss: 0.9685 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 66.48
24-04-06 10:07:21.154 - INFO: Train epoch 549: [41600/94637 (44%)] Step: [2778612] | Lr: 0.000030 | Loss: 1.3223 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 61.63
24-04-06 10:08:10.430 - INFO: Train epoch 549: [44800/94637 (47%)] Step: [2778712] | Lr: 0.000030 | Loss: 1.0858 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 57.93
24-04-06 10:08:59.388 - INFO: Train epoch 549: [48000/94637 (51%)] Step: [2778812] | Lr: 0.000030 | Loss: 1.5721 | MSE loss: 0.0003 | Bpp loss: 1.01 | Aux loss: 60.96
24-04-06 10:09:48.798 - INFO: Train epoch 549: [51200/94637 (54%)] Step: [2778912] | Lr: 0.000030 | Loss: 0.8244 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 60.14
24-04-06 10:10:37.685 - INFO: Train epoch 549: [54400/94637 (57%)] Step: [2779012] | Lr: 0.000030 | Loss: 1.0115 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 69.14
24-04-06 10:11:26.713 - INFO: Train epoch 549: [57600/94637 (61%)] Step: [2779112] | Lr: 0.000030 | Loss: 1.1309 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 61.48
24-04-06 10:12:16.092 - INFO: Train epoch 549: [60800/94637 (64%)] Step: [2779212] | Lr: 0.000030 | Loss: 1.4280 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 58.69
24-04-06 10:13:04.883 - INFO: Train epoch 549: [64000/94637 (68%)] Step: [2779312] | Lr: 0.000030 | Loss: 1.4020 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 60.83
24-04-06 10:13:53.974 - INFO: Train epoch 549: [67200/94637 (71%)] Step: [2779412] | Lr: 0.000030 | Loss: 1.3438 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 59.26
24-04-06 10:14:43.000 - INFO: Train epoch 549: [70400/94637 (74%)] Step: [2779512] | Lr: 0.000030 | Loss: 0.8289 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 64.24
24-04-06 10:15:31.922 - INFO: Train epoch 549: [73600/94637 (78%)] Step: [2779612] | Lr: 0.000030 | Loss: 0.8704 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 63.69
24-04-06 10:16:20.679 - INFO: Train epoch 549: [76800/94637 (81%)] Step: [2779712] | Lr: 0.000030 | Loss: 1.5035 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 62.38
24-04-06 10:17:10.008 - INFO: Train epoch 549: [80000/94637 (85%)] Step: [2779812] | Lr: 0.000030 | Loss: 1.0046 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 63.06
24-04-06 10:17:58.734 - INFO: Train epoch 549: [83200/94637 (88%)] Step: [2779912] | Lr: 0.000030 | Loss: 1.4803 | MSE loss: 0.0003 | Bpp loss: 0.96 | Aux loss: 67.55
24-04-06 10:18:49.453 - INFO: Train epoch 549: [86400/94637 (91%)] Step: [2780012] | Lr: 0.000030 | Loss: 1.1405 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 65.98
24-04-06 10:19:38.618 - INFO: Train epoch 549: [89600/94637 (95%)] Step: [2780112] | Lr: 0.000030 | Loss: 1.1111 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 59.93
24-04-06 10:20:27.323 - INFO: Train epoch 549: [92800/94637 (98%)] Step: [2780212] | Lr: 0.000030 | Loss: 0.9746 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 62.59
24-04-06 10:21:05.850 - INFO: Learning rate: 3e-05
24-04-06 10:21:06.906 - INFO: Train epoch 550: [    0/94637 (0%)] Step: [2780269] | Lr: 0.000030 | Loss: 1.3133 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 62.96
24-04-06 10:21:55.736 - INFO: Train epoch 550: [ 3200/94637 (3%)] Step: [2780369] | Lr: 0.000030 | Loss: 1.1170 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 59.88
24-04-06 10:22:44.250 - INFO: Train epoch 550: [ 6400/94637 (7%)] Step: [2780469] | Lr: 0.000030 | Loss: 1.1423 | MSE loss: 0.0002 | Bpp loss: 0.76 | Aux loss: 64.68
24-04-06 10:23:32.379 - INFO: Train epoch 550: [ 9600/94637 (10%)] Step: [2780569] | Lr: 0.000030 | Loss: 1.4922 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 64.89
24-04-06 10:24:20.709 - INFO: Train epoch 550: [12800/94637 (14%)] Step: [2780669] | Lr: 0.000030 | Loss: 1.1805 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 56.58
24-04-06 10:25:08.552 - INFO: Train epoch 550: [16000/94637 (17%)] Step: [2780769] | Lr: 0.000030 | Loss: 1.2195 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 60.60
24-04-06 10:25:56.596 - INFO: Train epoch 550: [19200/94637 (20%)] Step: [2780869] | Lr: 0.000030 | Loss: 1.3722 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 61.08
24-04-06 10:26:44.119 - INFO: Train epoch 550: [22400/94637 (24%)] Step: [2780969] | Lr: 0.000030 | Loss: 0.9811 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 56.90
24-04-06 10:27:32.165 - INFO: Train epoch 550: [25600/94637 (27%)] Step: [2781069] | Lr: 0.000030 | Loss: 1.3705 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 62.09
24-04-06 10:28:20.793 - INFO: Train epoch 550: [28800/94637 (30%)] Step: [2781169] | Lr: 0.000030 | Loss: 1.0268 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 62.78
24-04-06 10:29:09.142 - INFO: Train epoch 550: [32000/94637 (34%)] Step: [2781269] | Lr: 0.000030 | Loss: 1.1442 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 64.16
24-04-06 10:29:57.576 - INFO: Train epoch 550: [35200/94637 (37%)] Step: [2781369] | Lr: 0.000030 | Loss: 1.5872 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 56.42
24-04-06 10:30:45.983 - INFO: Train epoch 550: [38400/94637 (41%)] Step: [2781469] | Lr: 0.000030 | Loss: 1.4503 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 61.65
24-04-06 10:31:34.515 - INFO: Train epoch 550: [41600/94637 (44%)] Step: [2781569] | Lr: 0.000030 | Loss: 0.9578 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 65.64
24-04-06 10:32:23.250 - INFO: Train epoch 550: [44800/94637 (47%)] Step: [2781669] | Lr: 0.000030 | Loss: 1.1613 | MSE loss: 0.0002 | Bpp loss: 0.77 | Aux loss: 61.75
24-04-06 10:33:11.805 - INFO: Train epoch 550: [48000/94637 (51%)] Step: [2781769] | Lr: 0.000030 | Loss: 1.5932 | MSE loss: 0.0004 | Bpp loss: 0.93 | Aux loss: 65.64
24-04-06 10:34:00.531 - INFO: Train epoch 550: [51200/94637 (54%)] Step: [2781869] | Lr: 0.000030 | Loss: 1.4848 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 63.79
24-04-06 10:34:49.713 - INFO: Train epoch 550: [54400/94637 (57%)] Step: [2781969] | Lr: 0.000030 | Loss: 1.4007 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 64.99
24-04-06 10:35:38.708 - INFO: Train epoch 550: [57600/94637 (61%)] Step: [2782069] | Lr: 0.000030 | Loss: 1.3527 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 59.58
24-04-06 10:36:27.327 - INFO: Train epoch 550: [60800/94637 (64%)] Step: [2782169] | Lr: 0.000030 | Loss: 1.5021 | MSE loss: 0.0004 | Bpp loss: 0.93 | Aux loss: 65.17
24-04-06 10:37:16.137 - INFO: Train epoch 550: [64000/94637 (68%)] Step: [2782269] | Lr: 0.000030 | Loss: 1.0647 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 62.80
24-04-06 10:38:04.439 - INFO: Train epoch 550: [67200/94637 (71%)] Step: [2782369] | Lr: 0.000030 | Loss: 0.9130 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 62.15
24-04-06 10:38:52.867 - INFO: Train epoch 550: [70400/94637 (74%)] Step: [2782469] | Lr: 0.000030 | Loss: 1.2973 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 63.10
24-04-06 10:39:43.633 - INFO: Train epoch 550: [73600/94637 (78%)] Step: [2782569] | Lr: 0.000030 | Loss: 1.2247 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 63.16
24-04-06 10:40:32.668 - INFO: Train epoch 550: [76800/94637 (81%)] Step: [2782669] | Lr: 0.000030 | Loss: 1.3955 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 62.43
24-04-06 10:41:21.608 - INFO: Train epoch 550: [80000/94637 (85%)] Step: [2782769] | Lr: 0.000030 | Loss: 0.9142 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 62.53
24-04-06 10:42:10.280 - INFO: Train epoch 550: [83200/94637 (88%)] Step: [2782869] | Lr: 0.000030 | Loss: 1.3822 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 58.72
24-04-06 10:42:58.684 - INFO: Train epoch 550: [86400/94637 (91%)] Step: [2782969] | Lr: 0.000030 | Loss: 1.2982 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 63.20
24-04-06 10:43:47.189 - INFO: Train epoch 550: [89600/94637 (95%)] Step: [2783069] | Lr: 0.000030 | Loss: 1.1779 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 60.67
24-04-06 10:44:35.686 - INFO: Train epoch 550: [92800/94637 (98%)] Step: [2783169] | Lr: 0.000030 | Loss: 1.2037 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 63.90
24-04-06 10:45:13.934 - INFO: Learning rate: 3e-05
24-04-06 10:45:15.621 - INFO: Train epoch 551: [    0/94637 (0%)] Step: [2783226] | Lr: 0.000030 | Loss: 1.1907 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 62.24
24-04-06 10:46:03.566 - INFO: Train epoch 551: [ 3200/94637 (3%)] Step: [2783326] | Lr: 0.000030 | Loss: 1.3986 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 64.92
24-04-06 10:46:50.918 - INFO: Train epoch 551: [ 6400/94637 (7%)] Step: [2783426] | Lr: 0.000030 | Loss: 1.1423 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 62.52
24-04-06 10:47:38.628 - INFO: Train epoch 551: [ 9600/94637 (10%)] Step: [2783526] | Lr: 0.000030 | Loss: 0.8160 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 67.38
24-04-06 10:48:26.572 - INFO: Train epoch 551: [12800/94637 (14%)] Step: [2783626] | Lr: 0.000030 | Loss: 1.0285 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 65.13
24-04-06 10:49:14.018 - INFO: Train epoch 551: [16000/94637 (17%)] Step: [2783726] | Lr: 0.000030 | Loss: 1.0814 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 62.98
24-04-06 10:50:01.534 - INFO: Train epoch 551: [19200/94637 (20%)] Step: [2783826] | Lr: 0.000030 | Loss: 1.3245 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 63.17
24-04-06 10:50:48.938 - INFO: Train epoch 551: [22400/94637 (24%)] Step: [2783926] | Lr: 0.000030 | Loss: 1.2005 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 58.88
24-04-06 10:51:36.837 - INFO: Train epoch 551: [25600/94637 (27%)] Step: [2784026] | Lr: 0.000030 | Loss: 1.3113 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 59.76
24-04-06 10:52:24.250 - INFO: Train epoch 551: [28800/94637 (30%)] Step: [2784126] | Lr: 0.000030 | Loss: 1.1051 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 66.99
24-04-06 10:53:11.935 - INFO: Train epoch 551: [32000/94637 (34%)] Step: [2784226] | Lr: 0.000030 | Loss: 1.2262 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 63.44
24-04-06 10:53:59.257 - INFO: Train epoch 551: [35200/94637 (37%)] Step: [2784326] | Lr: 0.000030 | Loss: 1.0776 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 62.94
24-04-06 10:54:47.079 - INFO: Train epoch 551: [38400/94637 (41%)] Step: [2784426] | Lr: 0.000030 | Loss: 1.1559 | MSE loss: 0.0002 | Bpp loss: 0.77 | Aux loss: 60.88
24-04-06 10:55:34.873 - INFO: Train epoch 551: [41600/94637 (44%)] Step: [2784526] | Lr: 0.000030 | Loss: 1.1086 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 62.80
24-04-06 10:56:22.616 - INFO: Train epoch 551: [44800/94637 (47%)] Step: [2784626] | Lr: 0.000030 | Loss: 1.6301 | MSE loss: 0.0004 | Bpp loss: 1.03 | Aux loss: 67.78
24-04-06 10:57:11.714 - INFO: Train epoch 551: [48000/94637 (51%)] Step: [2784726] | Lr: 0.000030 | Loss: 0.7927 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 64.63
24-04-06 10:58:01.050 - INFO: Train epoch 551: [51200/94637 (54%)] Step: [2784826] | Lr: 0.000030 | Loss: 1.2553 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 60.37
24-04-06 10:58:50.177 - INFO: Train epoch 551: [54400/94637 (57%)] Step: [2784926] | Lr: 0.000030 | Loss: 1.7418 | MSE loss: 0.0005 | Bpp loss: 0.97 | Aux loss: 60.71
24-04-06 10:59:40.289 - INFO: Train epoch 551: [57600/94637 (61%)] Step: [2785026] | Lr: 0.000030 | Loss: 1.1657 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 59.32
24-04-06 11:00:29.540 - INFO: Train epoch 551: [60800/94637 (64%)] Step: [2785126] | Lr: 0.000030 | Loss: 1.4768 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 64.35
24-04-06 11:01:18.365 - INFO: Train epoch 551: [64000/94637 (68%)] Step: [2785226] | Lr: 0.000030 | Loss: 1.4873 | MSE loss: 0.0003 | Bpp loss: 0.97 | Aux loss: 61.88
24-04-06 11:02:06.922 - INFO: Train epoch 551: [67200/94637 (71%)] Step: [2785326] | Lr: 0.000030 | Loss: 1.2706 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 69.71
24-04-06 11:02:55.716 - INFO: Train epoch 551: [70400/94637 (74%)] Step: [2785426] | Lr: 0.000030 | Loss: 1.1754 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 62.90
24-04-06 11:03:44.592 - INFO: Train epoch 551: [73600/94637 (78%)] Step: [2785526] | Lr: 0.000030 | Loss: 1.3091 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 64.53
24-04-06 11:04:33.023 - INFO: Train epoch 551: [76800/94637 (81%)] Step: [2785626] | Lr: 0.000030 | Loss: 1.3252 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 62.61
24-04-06 11:05:21.562 - INFO: Train epoch 551: [80000/94637 (85%)] Step: [2785726] | Lr: 0.000030 | Loss: 1.1315 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 64.12
24-04-06 11:06:10.374 - INFO: Train epoch 551: [83200/94637 (88%)] Step: [2785826] | Lr: 0.000030 | Loss: 1.2236 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 60.82
24-04-06 11:06:59.332 - INFO: Train epoch 551: [86400/94637 (91%)] Step: [2785926] | Lr: 0.000030 | Loss: 1.1227 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 65.44
24-04-06 11:07:48.465 - INFO: Train epoch 551: [89600/94637 (95%)] Step: [2786026] | Lr: 0.000030 | Loss: 1.3238 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 61.75
24-04-06 11:08:37.612 - INFO: Train epoch 551: [92800/94637 (98%)] Step: [2786126] | Lr: 0.000030 | Loss: 1.8818 | MSE loss: 0.0004 | Bpp loss: 1.18 | Aux loss: 59.15
24-04-06 11:09:16.560 - INFO: Learning rate: 3e-05
24-04-06 11:09:17.616 - INFO: Train epoch 552: [    0/94637 (0%)] Step: [2786183] | Lr: 0.000030 | Loss: 1.0474 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 61.18
24-04-06 11:10:06.786 - INFO: Train epoch 552: [ 3200/94637 (3%)] Step: [2786283] | Lr: 0.000030 | Loss: 1.4570 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 59.23
24-04-06 11:10:55.837 - INFO: Train epoch 552: [ 6400/94637 (7%)] Step: [2786383] | Lr: 0.000030 | Loss: 1.2725 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 64.06
24-04-06 11:11:44.817 - INFO: Train epoch 552: [ 9600/94637 (10%)] Step: [2786483] | Lr: 0.000030 | Loss: 1.1770 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 55.49
24-04-06 11:12:33.768 - INFO: Train epoch 552: [12800/94637 (14%)] Step: [2786583] | Lr: 0.000030 | Loss: 1.4107 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 60.37
24-04-06 11:13:22.005 - INFO: Train epoch 552: [16000/94637 (17%)] Step: [2786683] | Lr: 0.000030 | Loss: 1.0183 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 61.96
24-04-06 11:14:10.120 - INFO: Train epoch 552: [19200/94637 (20%)] Step: [2786783] | Lr: 0.000030 | Loss: 1.1444 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 62.74
24-04-06 11:14:57.822 - INFO: Train epoch 552: [22400/94637 (24%)] Step: [2786883] | Lr: 0.000030 | Loss: 1.3459 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 61.68
24-04-06 11:15:45.904 - INFO: Train epoch 552: [25600/94637 (27%)] Step: [2786983] | Lr: 0.000030 | Loss: 1.2799 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 58.87
24-04-06 11:16:33.788 - INFO: Train epoch 552: [28800/94637 (30%)] Step: [2787083] | Lr: 0.000030 | Loss: 0.9587 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 61.65
24-04-06 11:17:21.994 - INFO: Train epoch 552: [32000/94637 (34%)] Step: [2787183] | Lr: 0.000030 | Loss: 1.5737 | MSE loss: 0.0004 | Bpp loss: 0.88 | Aux loss: 64.81
24-04-06 11:18:09.945 - INFO: Train epoch 552: [35200/94637 (37%)] Step: [2787283] | Lr: 0.000030 | Loss: 1.1475 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 63.73
24-04-06 11:18:58.261 - INFO: Train epoch 552: [38400/94637 (41%)] Step: [2787383] | Lr: 0.000030 | Loss: 0.9801 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 63.05
24-04-06 11:19:46.763 - INFO: Train epoch 552: [41600/94637 (44%)] Step: [2787483] | Lr: 0.000030 | Loss: 1.5408 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 59.55
24-04-06 11:20:36.911 - INFO: Train epoch 552: [44800/94637 (47%)] Step: [2787583] | Lr: 0.000030 | Loss: 1.5600 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 62.56
24-04-06 11:21:25.399 - INFO: Train epoch 552: [48000/94637 (51%)] Step: [2787683] | Lr: 0.000030 | Loss: 1.2724 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 62.92
24-04-06 11:22:14.143 - INFO: Train epoch 552: [51200/94637 (54%)] Step: [2787783] | Lr: 0.000030 | Loss: 1.2812 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 59.90
24-04-06 11:23:03.163 - INFO: Train epoch 552: [54400/94637 (57%)] Step: [2787883] | Lr: 0.000030 | Loss: 1.2461 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 64.41
24-04-06 11:23:51.473 - INFO: Train epoch 552: [57600/94637 (61%)] Step: [2787983] | Lr: 0.000030 | Loss: 1.2937 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 63.80
24-04-06 11:24:39.807 - INFO: Train epoch 552: [60800/94637 (64%)] Step: [2788083] | Lr: 0.000030 | Loss: 1.4584 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 64.57
24-04-06 11:25:28.574 - INFO: Train epoch 552: [64000/94637 (68%)] Step: [2788183] | Lr: 0.000030 | Loss: 1.2071 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 62.53
24-04-06 11:26:17.835 - INFO: Train epoch 552: [67200/94637 (71%)] Step: [2788283] | Lr: 0.000030 | Loss: 1.3762 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 64.19
24-04-06 11:27:07.275 - INFO: Train epoch 552: [70400/94637 (74%)] Step: [2788383] | Lr: 0.000030 | Loss: 1.4752 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 67.31
24-04-06 11:27:56.360 - INFO: Train epoch 552: [73600/94637 (78%)] Step: [2788483] | Lr: 0.000030 | Loss: 0.8314 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 60.35
24-04-06 11:28:44.860 - INFO: Train epoch 552: [76800/94637 (81%)] Step: [2788583] | Lr: 0.000030 | Loss: 1.3403 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 66.55
24-04-06 11:29:33.950 - INFO: Train epoch 552: [80000/94637 (85%)] Step: [2788683] | Lr: 0.000030 | Loss: 1.1532 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 62.25
24-04-06 11:30:22.864 - INFO: Train epoch 552: [83200/94637 (88%)] Step: [2788783] | Lr: 0.000030 | Loss: 1.3216 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 62.15
24-04-06 11:31:11.865 - INFO: Train epoch 552: [86400/94637 (91%)] Step: [2788883] | Lr: 0.000030 | Loss: 1.2328 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 62.32
24-04-06 11:32:01.101 - INFO: Train epoch 552: [89600/94637 (95%)] Step: [2788983] | Lr: 0.000030 | Loss: 1.4684 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 59.80
24-04-06 11:32:50.848 - INFO: Train epoch 552: [92800/94637 (98%)] Step: [2789083] | Lr: 0.000030 | Loss: 1.2866 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 64.04
24-04-06 11:33:30.233 - INFO: Learning rate: 3e-05
24-04-06 11:33:32.542 - INFO: Train epoch 553: [    0/94637 (0%)] Step: [2789140] | Lr: 0.000030 | Loss: 1.0420 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 61.55
24-04-06 11:34:21.342 - INFO: Train epoch 553: [ 3200/94637 (3%)] Step: [2789240] | Lr: 0.000030 | Loss: 1.1957 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 63.41
24-04-06 11:35:10.719 - INFO: Train epoch 553: [ 6400/94637 (7%)] Step: [2789340] | Lr: 0.000030 | Loss: 2.1534 | MSE loss: 0.0005 | Bpp loss: 1.27 | Aux loss: 59.47
24-04-06 11:35:59.743 - INFO: Train epoch 553: [ 9600/94637 (10%)] Step: [2789440] | Lr: 0.000030 | Loss: 1.0478 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 65.95
24-04-06 11:36:48.321 - INFO: Train epoch 553: [12800/94637 (14%)] Step: [2789540] | Lr: 0.000030 | Loss: 1.1718 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 65.94
24-04-06 11:37:35.942 - INFO: Train epoch 553: [16000/94637 (17%)] Step: [2789640] | Lr: 0.000030 | Loss: 1.0030 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 61.94
24-04-06 11:38:23.883 - INFO: Train epoch 553: [19200/94637 (20%)] Step: [2789740] | Lr: 0.000030 | Loss: 1.2331 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 62.47
24-04-06 11:39:11.659 - INFO: Train epoch 553: [22400/94637 (24%)] Step: [2789840] | Lr: 0.000030 | Loss: 1.0302 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 64.36
24-04-06 11:39:59.595 - INFO: Train epoch 553: [25600/94637 (27%)] Step: [2789940] | Lr: 0.000030 | Loss: 1.2384 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 64.45
24-04-06 11:40:49.605 - INFO: Train epoch 553: [28800/94637 (30%)] Step: [2790040] | Lr: 0.000030 | Loss: 1.3950 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 65.75
24-04-06 11:41:37.867 - INFO: Train epoch 553: [32000/94637 (34%)] Step: [2790140] | Lr: 0.000030 | Loss: 0.9495 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 71.00
24-04-06 11:42:26.587 - INFO: Train epoch 553: [35200/94637 (37%)] Step: [2790240] | Lr: 0.000030 | Loss: 0.8215 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 68.95
24-04-06 11:43:15.362 - INFO: Train epoch 553: [38400/94637 (41%)] Step: [2790340] | Lr: 0.000030 | Loss: 0.7590 | MSE loss: 0.0002 | Bpp loss: 0.48 | Aux loss: 60.39
24-04-06 11:44:04.277 - INFO: Train epoch 553: [41600/94637 (44%)] Step: [2790440] | Lr: 0.000030 | Loss: 0.9970 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 63.56
24-04-06 11:44:52.784 - INFO: Train epoch 553: [44800/94637 (47%)] Step: [2790540] | Lr: 0.000030 | Loss: 1.1400 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 62.66
24-04-06 11:45:41.500 - INFO: Train epoch 553: [48000/94637 (51%)] Step: [2790640] | Lr: 0.000030 | Loss: 1.1495 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 66.19
24-04-06 11:46:30.306 - INFO: Train epoch 553: [51200/94637 (54%)] Step: [2790740] | Lr: 0.000030 | Loss: 1.0598 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 63.73
24-04-06 11:47:18.740 - INFO: Train epoch 553: [54400/94637 (57%)] Step: [2790840] | Lr: 0.000030 | Loss: 0.8075 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 61.12
24-04-06 11:48:07.798 - INFO: Train epoch 553: [57600/94637 (61%)] Step: [2790940] | Lr: 0.000030 | Loss: 1.3532 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 62.29
24-04-06 11:48:56.252 - INFO: Train epoch 553: [60800/94637 (64%)] Step: [2791040] | Lr: 0.000030 | Loss: 1.1332 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 60.31
24-04-06 11:49:44.138 - INFO: Train epoch 553: [64000/94637 (68%)] Step: [2791140] | Lr: 0.000030 | Loss: 1.2366 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 63.73
24-04-06 11:50:31.981 - INFO: Train epoch 553: [67200/94637 (71%)] Step: [2791240] | Lr: 0.000030 | Loss: 1.3876 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 69.31
24-04-06 11:51:19.616 - INFO: Train epoch 553: [70400/94637 (74%)] Step: [2791340] | Lr: 0.000030 | Loss: 1.2195 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 65.35
24-04-06 11:52:07.624 - INFO: Train epoch 553: [73600/94637 (78%)] Step: [2791440] | Lr: 0.000030 | Loss: 1.3933 | MSE loss: 0.0004 | Bpp loss: 0.79 | Aux loss: 60.22
24-04-06 11:52:55.276 - INFO: Train epoch 553: [76800/94637 (81%)] Step: [2791540] | Lr: 0.000030 | Loss: 0.9485 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 63.28
24-04-06 11:53:43.191 - INFO: Train epoch 553: [80000/94637 (85%)] Step: [2791640] | Lr: 0.000030 | Loss: 0.9994 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 64.81
24-04-06 11:54:30.523 - INFO: Train epoch 553: [83200/94637 (88%)] Step: [2791740] | Lr: 0.000030 | Loss: 1.0625 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 66.46
24-04-06 11:55:17.834 - INFO: Train epoch 553: [86400/94637 (91%)] Step: [2791840] | Lr: 0.000030 | Loss: 1.2281 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 64.13
24-04-06 11:56:05.563 - INFO: Train epoch 553: [89600/94637 (95%)] Step: [2791940] | Lr: 0.000030 | Loss: 1.4468 | MSE loss: 0.0004 | Bpp loss: 0.86 | Aux loss: 63.25
24-04-06 11:56:53.524 - INFO: Train epoch 553: [92800/94637 (98%)] Step: [2792040] | Lr: 0.000030 | Loss: 1.2667 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 63.89
24-04-06 11:57:36.802 - INFO: Learning rate: 3e-05
24-04-06 11:57:37.989 - INFO: Train epoch 554: [    0/94637 (0%)] Step: [2792097] | Lr: 0.000030 | Loss: 0.8718 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 64.30
24-04-06 11:58:25.197 - INFO: Train epoch 554: [ 3200/94637 (3%)] Step: [2792197] | Lr: 0.000030 | Loss: 1.1954 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 66.56
24-04-06 11:59:13.370 - INFO: Train epoch 554: [ 6400/94637 (7%)] Step: [2792297] | Lr: 0.000030 | Loss: 0.8601 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 62.00
24-04-06 12:00:01.257 - INFO: Train epoch 554: [ 9600/94637 (10%)] Step: [2792397] | Lr: 0.000030 | Loss: 1.3580 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 63.93
24-04-06 12:00:49.279 - INFO: Train epoch 554: [12800/94637 (14%)] Step: [2792497] | Lr: 0.000030 | Loss: 1.0124 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 62.48
24-04-06 12:01:39.129 - INFO: Train epoch 554: [16000/94637 (17%)] Step: [2792597] | Lr: 0.000030 | Loss: 1.2180 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 66.25
24-04-06 12:02:26.836 - INFO: Train epoch 554: [19200/94637 (20%)] Step: [2792697] | Lr: 0.000030 | Loss: 1.3317 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 66.44
24-04-06 12:03:14.729 - INFO: Train epoch 554: [22400/94637 (24%)] Step: [2792797] | Lr: 0.000030 | Loss: 1.4701 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 65.04
24-04-06 12:04:02.274 - INFO: Train epoch 554: [25600/94637 (27%)] Step: [2792897] | Lr: 0.000030 | Loss: 1.2991 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 65.55
24-04-06 12:04:50.315 - INFO: Train epoch 554: [28800/94637 (30%)] Step: [2792997] | Lr: 0.000030 | Loss: 1.0458 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 61.69
24-04-06 12:05:38.253 - INFO: Train epoch 554: [32000/94637 (34%)] Step: [2793097] | Lr: 0.000030 | Loss: 1.0234 | MSE loss: 0.0003 | Bpp loss: 0.61 | Aux loss: 59.86
24-04-06 12:06:27.102 - INFO: Train epoch 554: [35200/94637 (37%)] Step: [2793197] | Lr: 0.000030 | Loss: 0.8445 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 67.44
24-04-06 12:07:15.280 - INFO: Train epoch 554: [38400/94637 (41%)] Step: [2793297] | Lr: 0.000030 | Loss: 1.1300 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 60.73
24-04-06 12:08:03.740 - INFO: Train epoch 554: [41600/94637 (44%)] Step: [2793397] | Lr: 0.000030 | Loss: 0.9386 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 64.51
24-04-06 12:08:51.876 - INFO: Train epoch 554: [44800/94637 (47%)] Step: [2793497] | Lr: 0.000030 | Loss: 1.0500 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 64.13
24-04-06 12:09:39.551 - INFO: Train epoch 554: [48000/94637 (51%)] Step: [2793597] | Lr: 0.000030 | Loss: 0.8608 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 63.70
24-04-06 12:10:28.234 - INFO: Train epoch 554: [51200/94637 (54%)] Step: [2793697] | Lr: 0.000030 | Loss: 0.9383 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 67.47
24-04-06 12:11:16.446 - INFO: Train epoch 554: [54400/94637 (57%)] Step: [2793797] | Lr: 0.000030 | Loss: 0.7565 | MSE loss: 0.0002 | Bpp loss: 0.46 | Aux loss: 65.03
24-04-06 12:12:04.201 - INFO: Train epoch 554: [57600/94637 (61%)] Step: [2793897] | Lr: 0.000030 | Loss: 1.4283 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 59.54
24-04-06 12:12:52.267 - INFO: Train epoch 554: [60800/94637 (64%)] Step: [2793997] | Lr: 0.000030 | Loss: 1.3369 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 65.00
24-04-06 12:13:39.915 - INFO: Train epoch 554: [64000/94637 (68%)] Step: [2794097] | Lr: 0.000030 | Loss: 1.2218 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 63.99
24-04-06 12:14:28.784 - INFO: Train epoch 554: [67200/94637 (71%)] Step: [2794197] | Lr: 0.000030 | Loss: 1.2784 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 61.91
24-04-06 12:15:17.767 - INFO: Train epoch 554: [70400/94637 (74%)] Step: [2794297] | Lr: 0.000030 | Loss: 1.4410 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 64.01
24-04-06 12:16:06.860 - INFO: Train epoch 554: [73600/94637 (78%)] Step: [2794397] | Lr: 0.000030 | Loss: 1.1243 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 60.05
24-04-06 12:16:55.779 - INFO: Train epoch 554: [76800/94637 (81%)] Step: [2794497] | Lr: 0.000030 | Loss: 1.5650 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 70.24
24-04-06 12:17:44.551 - INFO: Train epoch 554: [80000/94637 (85%)] Step: [2794597] | Lr: 0.000030 | Loss: 1.3667 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 64.71
24-04-06 12:18:33.193 - INFO: Train epoch 554: [83200/94637 (88%)] Step: [2794697] | Lr: 0.000030 | Loss: 1.0801 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 61.00
24-04-06 12:19:21.658 - INFO: Train epoch 554: [86400/94637 (91%)] Step: [2794797] | Lr: 0.000030 | Loss: 1.4354 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 63.18
24-04-06 12:20:09.675 - INFO: Train epoch 554: [89600/94637 (95%)] Step: [2794897] | Lr: 0.000030 | Loss: 0.9376 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 63.51
24-04-06 12:20:58.337 - INFO: Train epoch 554: [92800/94637 (98%)] Step: [2794997] | Lr: 0.000030 | Loss: 1.3282 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 60.99
24-04-06 12:21:39.333 - INFO: Learning rate: 3e-05
24-04-06 12:21:40.424 - INFO: Train epoch 555: [    0/94637 (0%)] Step: [2795054] | Lr: 0.000030 | Loss: 1.7558 | MSE loss: 0.0004 | Bpp loss: 1.14 | Aux loss: 65.47
24-04-06 12:22:29.426 - INFO: Train epoch 555: [ 3200/94637 (3%)] Step: [2795154] | Lr: 0.000030 | Loss: 1.1786 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 61.69
24-04-06 12:23:18.142 - INFO: Train epoch 555: [ 6400/94637 (7%)] Step: [2795254] | Lr: 0.000030 | Loss: 0.7903 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 64.38
24-04-06 12:24:07.072 - INFO: Train epoch 555: [ 9600/94637 (10%)] Step: [2795354] | Lr: 0.000030 | Loss: 1.4162 | MSE loss: 0.0004 | Bpp loss: 0.82 | Aux loss: 63.62
24-04-06 12:24:55.667 - INFO: Train epoch 555: [12800/94637 (14%)] Step: [2795454] | Lr: 0.000030 | Loss: 0.8960 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 63.35
24-04-06 12:25:44.514 - INFO: Train epoch 555: [16000/94637 (17%)] Step: [2795554] | Lr: 0.000030 | Loss: 1.1280 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 69.72
24-04-06 12:26:33.557 - INFO: Train epoch 555: [19200/94637 (20%)] Step: [2795654] | Lr: 0.000030 | Loss: 1.3932 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 65.96
24-04-06 12:27:22.967 - INFO: Train epoch 555: [22400/94637 (24%)] Step: [2795754] | Lr: 0.000030 | Loss: 1.3316 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 62.57
24-04-06 12:28:11.238 - INFO: Train epoch 555: [25600/94637 (27%)] Step: [2795854] | Lr: 0.000030 | Loss: 1.0754 | MSE loss: 0.0003 | Bpp loss: 0.62 | Aux loss: 63.56
24-04-06 12:29:00.480 - INFO: Train epoch 555: [28800/94637 (30%)] Step: [2795954] | Lr: 0.000030 | Loss: 1.2012 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 64.98
24-04-06 12:29:48.926 - INFO: Train epoch 555: [32000/94637 (34%)] Step: [2796054] | Lr: 0.000030 | Loss: 1.0985 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 69.51
24-04-06 12:30:37.791 - INFO: Train epoch 555: [35200/94637 (37%)] Step: [2796154] | Lr: 0.000030 | Loss: 1.4665 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 62.15
24-04-06 12:31:26.602 - INFO: Train epoch 555: [38400/94637 (41%)] Step: [2796254] | Lr: 0.000030 | Loss: 1.0954 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 66.61
24-04-06 12:32:14.718 - INFO: Train epoch 555: [41600/94637 (44%)] Step: [2796354] | Lr: 0.000030 | Loss: 1.1286 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 66.01
24-04-06 12:33:03.825 - INFO: Train epoch 555: [44800/94637 (47%)] Step: [2796454] | Lr: 0.000030 | Loss: 1.2270 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 69.33
24-04-06 12:33:52.397 - INFO: Train epoch 555: [48000/94637 (51%)] Step: [2796554] | Lr: 0.000030 | Loss: 1.0518 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 64.07
24-04-06 12:34:41.415 - INFO: Train epoch 555: [51200/94637 (54%)] Step: [2796654] | Lr: 0.000030 | Loss: 1.3626 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 64.82
24-04-06 12:35:30.316 - INFO: Train epoch 555: [54400/94637 (57%)] Step: [2796754] | Lr: 0.000030 | Loss: 1.3934 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 68.54
24-04-06 12:36:18.795 - INFO: Train epoch 555: [57600/94637 (61%)] Step: [2796854] | Lr: 0.000030 | Loss: 1.1093 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 65.46
24-04-06 12:37:07.772 - INFO: Train epoch 555: [60800/94637 (64%)] Step: [2796954] | Lr: 0.000030 | Loss: 1.1180 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 71.45
24-04-06 12:37:56.359 - INFO: Train epoch 555: [64000/94637 (68%)] Step: [2797054] | Lr: 0.000030 | Loss: 1.0441 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 64.68
24-04-06 12:38:45.897 - INFO: Train epoch 555: [67200/94637 (71%)] Step: [2797154] | Lr: 0.000030 | Loss: 1.2838 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 63.98
24-04-06 12:39:34.969 - INFO: Train epoch 555: [70400/94637 (74%)] Step: [2797254] | Lr: 0.000030 | Loss: 1.3617 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 63.94
24-04-06 12:40:24.137 - INFO: Train epoch 555: [73600/94637 (78%)] Step: [2797354] | Lr: 0.000030 | Loss: 1.0794 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 63.85
24-04-06 12:41:13.296 - INFO: Train epoch 555: [76800/94637 (81%)] Step: [2797454] | Lr: 0.000030 | Loss: 0.9036 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 66.22
24-04-06 12:42:04.347 - INFO: Train epoch 555: [80000/94637 (85%)] Step: [2797554] | Lr: 0.000030 | Loss: 1.1368 | MSE loss: 0.0002 | Bpp loss: 0.76 | Aux loss: 62.57
24-04-06 12:42:53.333 - INFO: Train epoch 555: [83200/94637 (88%)] Step: [2797654] | Lr: 0.000030 | Loss: 1.3497 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 61.60
24-04-06 12:43:42.051 - INFO: Train epoch 555: [86400/94637 (91%)] Step: [2797754] | Lr: 0.000030 | Loss: 1.1753 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 64.45
24-04-06 12:44:31.178 - INFO: Train epoch 555: [89600/94637 (95%)] Step: [2797854] | Lr: 0.000030 | Loss: 1.5274 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 64.20
24-04-06 12:45:20.473 - INFO: Train epoch 555: [92800/94637 (98%)] Step: [2797954] | Lr: 0.000030 | Loss: 1.3280 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 62.02
24-04-06 12:45:59.655 - INFO: Learning rate: 3e-05
24-04-06 12:46:01.710 - INFO: Train epoch 556: [    0/94637 (0%)] Step: [2798011] | Lr: 0.000030 | Loss: 1.4227 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 64.79
24-04-06 12:46:50.320 - INFO: Train epoch 556: [ 3200/94637 (3%)] Step: [2798111] | Lr: 0.000030 | Loss: 1.4995 | MSE loss: 0.0003 | Bpp loss: 0.97 | Aux loss: 64.69
24-04-06 12:47:39.101 - INFO: Train epoch 556: [ 6400/94637 (7%)] Step: [2798211] | Lr: 0.000030 | Loss: 1.7230 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 64.61
24-04-06 12:48:28.537 - INFO: Train epoch 556: [ 9600/94637 (10%)] Step: [2798311] | Lr: 0.000030 | Loss: 1.0389 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 66.35
24-04-06 12:49:18.197 - INFO: Train epoch 556: [12800/94637 (14%)] Step: [2798411] | Lr: 0.000030 | Loss: 1.4146 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 64.16
24-04-06 12:50:08.092 - INFO: Train epoch 556: [16000/94637 (17%)] Step: [2798511] | Lr: 0.000030 | Loss: 1.2870 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 62.08
24-04-06 12:50:57.337 - INFO: Train epoch 556: [19200/94637 (20%)] Step: [2798611] | Lr: 0.000030 | Loss: 0.7562 | MSE loss: 0.0002 | Bpp loss: 0.48 | Aux loss: 68.99
24-04-06 12:51:46.310 - INFO: Train epoch 556: [22400/94637 (24%)] Step: [2798711] | Lr: 0.000030 | Loss: 1.2309 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 64.12
24-04-06 12:52:35.483 - INFO: Train epoch 556: [25600/94637 (27%)] Step: [2798811] | Lr: 0.000030 | Loss: 1.0321 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 65.77
24-04-06 12:53:23.674 - INFO: Train epoch 556: [28800/94637 (30%)] Step: [2798911] | Lr: 0.000030 | Loss: 1.2708 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 65.25
24-04-06 12:54:12.120 - INFO: Train epoch 556: [32000/94637 (34%)] Step: [2799011] | Lr: 0.000030 | Loss: 1.2611 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 63.91
24-04-06 12:55:01.081 - INFO: Train epoch 556: [35200/94637 (37%)] Step: [2799111] | Lr: 0.000030 | Loss: 0.9551 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 60.91
24-04-06 12:55:49.650 - INFO: Train epoch 556: [38400/94637 (41%)] Step: [2799211] | Lr: 0.000030 | Loss: 1.0251 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 66.68
24-04-06 12:56:37.853 - INFO: Train epoch 556: [41600/94637 (44%)] Step: [2799311] | Lr: 0.000030 | Loss: 1.2825 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 66.86
24-04-06 12:57:25.469 - INFO: Train epoch 556: [44800/94637 (47%)] Step: [2799411] | Lr: 0.000030 | Loss: 1.1711 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 61.78
24-04-06 12:58:13.382 - INFO: Train epoch 556: [48000/94637 (51%)] Step: [2799511] | Lr: 0.000030 | Loss: 1.7302 | MSE loss: 0.0004 | Bpp loss: 1.07 | Aux loss: 64.65
24-04-06 12:59:01.431 - INFO: Train epoch 556: [51200/94637 (54%)] Step: [2799611] | Lr: 0.000030 | Loss: 1.1694 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 67.60
24-04-06 12:59:50.161 - INFO: Train epoch 556: [54400/94637 (57%)] Step: [2799711] | Lr: 0.000030 | Loss: 1.0903 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 69.28
24-04-06 13:00:38.757 - INFO: Train epoch 556: [57600/94637 (61%)] Step: [2799811] | Lr: 0.000030 | Loss: 0.9361 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 65.63
24-04-06 13:01:27.563 - INFO: Train epoch 556: [60800/94637 (64%)] Step: [2799911] | Lr: 0.000030 | Loss: 1.3524 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 62.88
24-04-06 13:02:18.033 - INFO: Train epoch 556: [64000/94637 (68%)] Step: [2800011] | Lr: 0.000030 | Loss: 1.0122 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 65.99
24-04-06 13:03:06.819 - INFO: Train epoch 556: [67200/94637 (71%)] Step: [2800111] | Lr: 0.000030 | Loss: 1.3037 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 69.14
24-04-06 13:03:55.456 - INFO: Train epoch 556: [70400/94637 (74%)] Step: [2800211] | Lr: 0.000030 | Loss: 1.0318 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 63.06
24-04-06 13:04:43.970 - INFO: Train epoch 556: [73600/94637 (78%)] Step: [2800311] | Lr: 0.000030 | Loss: 1.2063 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 66.53
24-04-06 13:05:32.994 - INFO: Train epoch 556: [76800/94637 (81%)] Step: [2800411] | Lr: 0.000030 | Loss: 1.3222 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 68.96
24-04-06 13:06:21.671 - INFO: Train epoch 556: [80000/94637 (85%)] Step: [2800511] | Lr: 0.000030 | Loss: 1.5846 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 63.39
24-04-06 13:07:10.022 - INFO: Train epoch 556: [83200/94637 (88%)] Step: [2800611] | Lr: 0.000030 | Loss: 1.1211 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 63.74
24-04-06 13:07:58.260 - INFO: Train epoch 556: [86400/94637 (91%)] Step: [2800711] | Lr: 0.000030 | Loss: 1.1895 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 63.78
24-04-06 13:08:46.979 - INFO: Train epoch 556: [89600/94637 (95%)] Step: [2800811] | Lr: 0.000030 | Loss: 0.9048 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 67.08
24-04-06 13:09:35.825 - INFO: Train epoch 556: [92800/94637 (98%)] Step: [2800911] | Lr: 0.000030 | Loss: 0.9740 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 68.85
24-04-06 13:10:14.869 - INFO: Learning rate: 3e-05
24-04-06 13:10:15.944 - INFO: Train epoch 557: [    0/94637 (0%)] Step: [2800968] | Lr: 0.000030 | Loss: 1.1764 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 59.92
24-04-06 13:11:04.255 - INFO: Train epoch 557: [ 3200/94637 (3%)] Step: [2801068] | Lr: 0.000030 | Loss: 1.4709 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 57.83
24-04-06 13:11:52.635 - INFO: Train epoch 557: [ 6400/94637 (7%)] Step: [2801168] | Lr: 0.000030 | Loss: 1.0005 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 64.97
24-04-06 13:12:41.263 - INFO: Train epoch 557: [ 9600/94637 (10%)] Step: [2801268] | Lr: 0.000030 | Loss: 1.1103 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 66.56
24-04-06 13:13:29.825 - INFO: Train epoch 557: [12800/94637 (14%)] Step: [2801368] | Lr: 0.000030 | Loss: 1.4280 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 62.44
24-04-06 13:14:18.196 - INFO: Train epoch 557: [16000/94637 (17%)] Step: [2801468] | Lr: 0.000030 | Loss: 1.5388 | MSE loss: 0.0004 | Bpp loss: 0.84 | Aux loss: 65.81
24-04-06 13:15:06.785 - INFO: Train epoch 557: [19200/94637 (20%)] Step: [2801568] | Lr: 0.000030 | Loss: 1.2865 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 62.72
24-04-06 13:15:55.371 - INFO: Train epoch 557: [22400/94637 (24%)] Step: [2801668] | Lr: 0.000030 | Loss: 1.1285 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 64.25
24-04-06 13:16:44.850 - INFO: Train epoch 557: [25600/94637 (27%)] Step: [2801768] | Lr: 0.000030 | Loss: 1.6515 | MSE loss: 0.0004 | Bpp loss: 1.03 | Aux loss: 62.10
24-04-06 13:17:33.796 - INFO: Train epoch 557: [28800/94637 (30%)] Step: [2801868] | Lr: 0.000030 | Loss: 1.2975 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 64.42
24-04-06 13:18:22.633 - INFO: Train epoch 557: [32000/94637 (34%)] Step: [2801968] | Lr: 0.000030 | Loss: 1.4740 | MSE loss: 0.0003 | Bpp loss: 0.96 | Aux loss: 62.28
24-04-06 13:19:11.548 - INFO: Train epoch 557: [35200/94637 (37%)] Step: [2802068] | Lr: 0.000030 | Loss: 1.3199 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 63.06
24-04-06 13:19:59.994 - INFO: Train epoch 557: [38400/94637 (41%)] Step: [2802168] | Lr: 0.000030 | Loss: 1.8222 | MSE loss: 0.0006 | Bpp loss: 0.80 | Aux loss: 64.51
24-04-06 13:20:48.797 - INFO: Train epoch 557: [41600/94637 (44%)] Step: [2802268] | Lr: 0.000030 | Loss: 1.6741 | MSE loss: 0.0004 | Bpp loss: 1.05 | Aux loss: 68.99
24-04-06 13:21:36.996 - INFO: Train epoch 557: [44800/94637 (47%)] Step: [2802368] | Lr: 0.000030 | Loss: 0.9925 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 65.90
24-04-06 13:22:26.262 - INFO: Train epoch 557: [48000/94637 (51%)] Step: [2802468] | Lr: 0.000030 | Loss: 1.4076 | MSE loss: 0.0004 | Bpp loss: 0.83 | Aux loss: 68.28
24-04-06 13:23:16.467 - INFO: Train epoch 557: [51200/94637 (54%)] Step: [2802568] | Lr: 0.000030 | Loss: 1.3413 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 66.34
24-04-06 13:24:05.109 - INFO: Train epoch 557: [54400/94637 (57%)] Step: [2802668] | Lr: 0.000030 | Loss: 1.3660 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 63.31
24-04-06 13:24:53.521 - INFO: Train epoch 557: [57600/94637 (61%)] Step: [2802768] | Lr: 0.000030 | Loss: 1.1266 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 64.21
24-04-06 13:25:41.737 - INFO: Train epoch 557: [60800/94637 (64%)] Step: [2802868] | Lr: 0.000030 | Loss: 1.0875 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 66.25
24-04-06 13:26:29.787 - INFO: Train epoch 557: [64000/94637 (68%)] Step: [2802968] | Lr: 0.000030 | Loss: 1.1859 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 65.05
24-04-06 13:27:17.342 - INFO: Train epoch 557: [67200/94637 (71%)] Step: [2803068] | Lr: 0.000030 | Loss: 1.1082 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 63.06
24-04-06 13:28:05.015 - INFO: Train epoch 557: [70400/94637 (74%)] Step: [2803168] | Lr: 0.000030 | Loss: 1.1177 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 62.67
24-04-06 13:28:52.689 - INFO: Train epoch 557: [73600/94637 (78%)] Step: [2803268] | Lr: 0.000030 | Loss: 1.2745 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 65.26
24-04-06 13:29:40.270 - INFO: Train epoch 557: [76800/94637 (81%)] Step: [2803368] | Lr: 0.000030 | Loss: 1.1693 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 62.45
24-04-06 13:30:27.998 - INFO: Train epoch 557: [80000/94637 (85%)] Step: [2803468] | Lr: 0.000030 | Loss: 1.0777 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 66.13
24-04-06 13:31:15.438 - INFO: Train epoch 557: [83200/94637 (88%)] Step: [2803568] | Lr: 0.000030 | Loss: 1.3030 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 64.84
24-04-06 13:32:03.580 - INFO: Train epoch 557: [86400/94637 (91%)] Step: [2803668] | Lr: 0.000030 | Loss: 1.1043 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 60.04
24-04-06 13:32:51.554 - INFO: Train epoch 557: [89600/94637 (95%)] Step: [2803768] | Lr: 0.000030 | Loss: 1.5208 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 65.25
24-04-06 13:33:40.417 - INFO: Train epoch 557: [92800/94637 (98%)] Step: [2803868] | Lr: 0.000030 | Loss: 1.2107 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 65.66
24-04-06 13:34:20.089 - INFO: Learning rate: 3e-05
24-04-06 13:34:21.217 - INFO: Train epoch 558: [    0/94637 (0%)] Step: [2803925] | Lr: 0.000030 | Loss: 1.2626 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 65.57
24-04-06 13:35:09.311 - INFO: Train epoch 558: [ 3200/94637 (3%)] Step: [2804025] | Lr: 0.000030 | Loss: 1.1239 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 66.30
24-04-06 13:35:56.885 - INFO: Train epoch 558: [ 6400/94637 (7%)] Step: [2804125] | Lr: 0.000030 | Loss: 1.1665 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 71.67
24-04-06 13:36:44.149 - INFO: Train epoch 558: [ 9600/94637 (10%)] Step: [2804225] | Lr: 0.000030 | Loss: 1.1289 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 61.50
24-04-06 13:37:31.826 - INFO: Train epoch 558: [12800/94637 (14%)] Step: [2804325] | Lr: 0.000030 | Loss: 1.4768 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 64.42
24-04-06 13:38:19.530 - INFO: Train epoch 558: [16000/94637 (17%)] Step: [2804425] | Lr: 0.000030 | Loss: 1.1082 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 66.21
24-04-06 13:39:07.853 - INFO: Train epoch 558: [19200/94637 (20%)] Step: [2804525] | Lr: 0.000030 | Loss: 1.0589 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 64.73
24-04-06 13:39:55.759 - INFO: Train epoch 558: [22400/94637 (24%)] Step: [2804625] | Lr: 0.000030 | Loss: 1.1946 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 62.86
24-04-06 13:40:43.413 - INFO: Train epoch 558: [25600/94637 (27%)] Step: [2804725] | Lr: 0.000030 | Loss: 1.4761 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 70.76
24-04-06 13:41:31.800 - INFO: Train epoch 558: [28800/94637 (30%)] Step: [2804825] | Lr: 0.000030 | Loss: 1.2007 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 64.27
24-04-06 13:42:19.406 - INFO: Train epoch 558: [32000/94637 (34%)] Step: [2804925] | Lr: 0.000030 | Loss: 0.9528 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 69.60
24-04-06 13:43:09.358 - INFO: Train epoch 558: [35200/94637 (37%)] Step: [2805025] | Lr: 0.000030 | Loss: 1.5258 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 63.11
24-04-06 13:43:58.015 - INFO: Train epoch 558: [38400/94637 (41%)] Step: [2805125] | Lr: 0.000030 | Loss: 1.2260 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 63.24
24-04-06 13:44:46.619 - INFO: Train epoch 558: [41600/94637 (44%)] Step: [2805225] | Lr: 0.000030 | Loss: 1.3359 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 68.20
24-04-06 13:45:36.063 - INFO: Train epoch 558: [44800/94637 (47%)] Step: [2805325] | Lr: 0.000030 | Loss: 1.2374 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 66.46
24-04-06 13:46:25.120 - INFO: Train epoch 558: [48000/94637 (51%)] Step: [2805425] | Lr: 0.000030 | Loss: 0.9294 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 61.96
24-04-06 13:47:13.461 - INFO: Train epoch 558: [51200/94637 (54%)] Step: [2805525] | Lr: 0.000030 | Loss: 0.9241 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 66.11
24-04-06 13:48:02.295 - INFO: Train epoch 558: [54400/94637 (57%)] Step: [2805625] | Lr: 0.000030 | Loss: 1.0699 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 57.83
24-04-06 13:48:50.558 - INFO: Train epoch 558: [57600/94637 (61%)] Step: [2805725] | Lr: 0.000030 | Loss: 1.0635 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 65.38
24-04-06 13:49:38.843 - INFO: Train epoch 558: [60800/94637 (64%)] Step: [2805825] | Lr: 0.000030 | Loss: 1.4880 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 63.67
24-04-06 13:50:27.185 - INFO: Train epoch 558: [64000/94637 (68%)] Step: [2805925] | Lr: 0.000030 | Loss: 1.1069 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 67.61
24-04-06 13:51:15.715 - INFO: Train epoch 558: [67200/94637 (71%)] Step: [2806025] | Lr: 0.000030 | Loss: 1.2300 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 65.33
24-04-06 13:52:05.293 - INFO: Train epoch 558: [70400/94637 (74%)] Step: [2806125] | Lr: 0.000030 | Loss: 1.0350 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 64.98
24-04-06 13:52:54.795 - INFO: Train epoch 558: [73600/94637 (78%)] Step: [2806225] | Lr: 0.000030 | Loss: 1.2763 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 62.70
24-04-06 13:53:43.618 - INFO: Train epoch 558: [76800/94637 (81%)] Step: [2806325] | Lr: 0.000030 | Loss: 0.9289 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 68.82
24-04-06 13:54:32.944 - INFO: Train epoch 558: [80000/94637 (85%)] Step: [2806425] | Lr: 0.000030 | Loss: 1.2613 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 67.11
24-04-06 13:55:22.303 - INFO: Train epoch 558: [83200/94637 (88%)] Step: [2806525] | Lr: 0.000030 | Loss: 1.3404 | MSE loss: 0.0004 | Bpp loss: 0.73 | Aux loss: 62.76
24-04-06 13:56:11.929 - INFO: Train epoch 558: [86400/94637 (91%)] Step: [2806625] | Lr: 0.000030 | Loss: 1.2752 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 67.43
24-04-06 13:57:01.611 - INFO: Train epoch 558: [89600/94637 (95%)] Step: [2806725] | Lr: 0.000030 | Loss: 1.0538 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 61.74
24-04-06 13:57:51.368 - INFO: Train epoch 558: [92800/94637 (98%)] Step: [2806825] | Lr: 0.000030 | Loss: 1.3487 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 62.35
24-04-06 13:58:30.453 - INFO: Learning rate: 3e-05
24-04-06 13:58:31.516 - INFO: Train epoch 559: [    0/94637 (0%)] Step: [2806882] | Lr: 0.000030 | Loss: 1.2520 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 64.04
24-04-06 13:59:20.713 - INFO: Train epoch 559: [ 3200/94637 (3%)] Step: [2806982] | Lr: 0.000030 | Loss: 0.9780 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 63.38
24-04-06 14:00:09.600 - INFO: Train epoch 559: [ 6400/94637 (7%)] Step: [2807082] | Lr: 0.000030 | Loss: 1.3088 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 65.12
24-04-06 14:00:58.920 - INFO: Train epoch 559: [ 9600/94637 (10%)] Step: [2807182] | Lr: 0.000030 | Loss: 1.1660 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 61.41
24-04-06 14:01:47.940 - INFO: Train epoch 559: [12800/94637 (14%)] Step: [2807282] | Lr: 0.000030 | Loss: 1.3850 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 64.49
24-04-06 14:02:37.523 - INFO: Train epoch 559: [16000/94637 (17%)] Step: [2807382] | Lr: 0.000030 | Loss: 1.2958 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 64.35
24-04-06 14:03:26.857 - INFO: Train epoch 559: [19200/94637 (20%)] Step: [2807482] | Lr: 0.000030 | Loss: 1.2494 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 63.16
24-04-06 14:04:17.465 - INFO: Train epoch 559: [22400/94637 (24%)] Step: [2807582] | Lr: 0.000030 | Loss: 1.5074 | MSE loss: 0.0003 | Bpp loss: 0.99 | Aux loss: 63.14
24-04-06 14:05:06.567 - INFO: Train epoch 559: [25600/94637 (27%)] Step: [2807682] | Lr: 0.000030 | Loss: 1.6596 | MSE loss: 0.0004 | Bpp loss: 1.06 | Aux loss: 61.80
24-04-06 14:05:55.916 - INFO: Train epoch 559: [28800/94637 (30%)] Step: [2807782] | Lr: 0.000030 | Loss: 1.4419 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 63.77
24-04-06 14:06:45.613 - INFO: Train epoch 559: [32000/94637 (34%)] Step: [2807882] | Lr: 0.000030 | Loss: 1.1758 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 67.80
24-04-06 14:07:34.696 - INFO: Train epoch 559: [35200/94637 (37%)] Step: [2807982] | Lr: 0.000030 | Loss: 1.5125 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 65.93
24-04-06 14:08:23.993 - INFO: Train epoch 559: [38400/94637 (41%)] Step: [2808082] | Lr: 0.000030 | Loss: 1.2453 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 66.73
24-04-06 14:09:13.279 - INFO: Train epoch 559: [41600/94637 (44%)] Step: [2808182] | Lr: 0.000030 | Loss: 1.7117 | MSE loss: 0.0004 | Bpp loss: 1.07 | Aux loss: 67.11
24-04-06 14:10:02.386 - INFO: Train epoch 559: [44800/94637 (47%)] Step: [2808282] | Lr: 0.000030 | Loss: 1.3170 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 67.51
24-04-06 14:10:52.818 - INFO: Train epoch 559: [48000/94637 (51%)] Step: [2808382] | Lr: 0.000030 | Loss: 1.1585 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 66.33
24-04-06 14:11:42.472 - INFO: Train epoch 559: [51200/94637 (54%)] Step: [2808482] | Lr: 0.000030 | Loss: 1.0426 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 65.21
24-04-06 14:12:31.348 - INFO: Train epoch 559: [54400/94637 (57%)] Step: [2808582] | Lr: 0.000030 | Loss: 1.6140 | MSE loss: 0.0004 | Bpp loss: 1.03 | Aux loss: 70.26
24-04-06 14:13:20.690 - INFO: Train epoch 559: [57600/94637 (61%)] Step: [2808682] | Lr: 0.000030 | Loss: 1.1521 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 65.10
24-04-06 14:14:09.119 - INFO: Train epoch 559: [60800/94637 (64%)] Step: [2808782] | Lr: 0.000030 | Loss: 1.1259 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 62.27
24-04-06 14:14:58.175 - INFO: Train epoch 559: [64000/94637 (68%)] Step: [2808882] | Lr: 0.000030 | Loss: 1.1761 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 65.87
24-04-06 14:15:46.825 - INFO: Train epoch 559: [67200/94637 (71%)] Step: [2808982] | Lr: 0.000030 | Loss: 0.8618 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 65.51
24-04-06 14:16:35.756 - INFO: Train epoch 559: [70400/94637 (74%)] Step: [2809082] | Lr: 0.000030 | Loss: 1.1345 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 64.46
24-04-06 14:17:24.283 - INFO: Train epoch 559: [73600/94637 (78%)] Step: [2809182] | Lr: 0.000030 | Loss: 1.1978 | MSE loss: 0.0002 | Bpp loss: 0.80 | Aux loss: 64.39
24-04-06 14:18:12.694 - INFO: Train epoch 559: [76800/94637 (81%)] Step: [2809282] | Lr: 0.000030 | Loss: 1.0772 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 65.74
24-04-06 14:19:01.773 - INFO: Train epoch 559: [80000/94637 (85%)] Step: [2809382] | Lr: 0.000030 | Loss: 1.1457 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 70.32
24-04-06 14:19:50.747 - INFO: Train epoch 559: [83200/94637 (88%)] Step: [2809482] | Lr: 0.000030 | Loss: 1.0214 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 61.27
24-04-06 14:20:39.743 - INFO: Train epoch 559: [86400/94637 (91%)] Step: [2809582] | Lr: 0.000030 | Loss: 0.8338 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 68.07
24-04-06 14:21:28.469 - INFO: Train epoch 559: [89600/94637 (95%)] Step: [2809682] | Lr: 0.000030 | Loss: 1.3644 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 69.32
24-04-06 14:22:17.394 - INFO: Train epoch 559: [92800/94637 (98%)] Step: [2809782] | Lr: 0.000030 | Loss: 0.9296 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 64.98
24-04-06 14:22:56.452 - INFO: Learning rate: 3e-05
24-04-06 14:22:57.543 - INFO: Train epoch 560: [    0/94637 (0%)] Step: [2809839] | Lr: 0.000030 | Loss: 1.3560 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 64.62
24-04-06 14:23:46.408 - INFO: Train epoch 560: [ 3200/94637 (3%)] Step: [2809939] | Lr: 0.000030 | Loss: 1.2929 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 65.08
24-04-06 14:24:36.720 - INFO: Train epoch 560: [ 6400/94637 (7%)] Step: [2810039] | Lr: 0.000030 | Loss: 1.1512 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 65.66
24-04-06 14:25:25.481 - INFO: Train epoch 560: [ 9600/94637 (10%)] Step: [2810139] | Lr: 0.000030 | Loss: 1.0784 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 60.63
24-04-06 14:26:14.084 - INFO: Train epoch 560: [12800/94637 (14%)] Step: [2810239] | Lr: 0.000030 | Loss: 0.8678 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 76.55
24-04-06 14:27:03.053 - INFO: Train epoch 560: [16000/94637 (17%)] Step: [2810339] | Lr: 0.000030 | Loss: 1.3947 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 65.60
24-04-06 14:27:50.797 - INFO: Train epoch 560: [19200/94637 (20%)] Step: [2810439] | Lr: 0.000030 | Loss: 0.9192 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 67.46
24-04-06 14:28:39.201 - INFO: Train epoch 560: [22400/94637 (24%)] Step: [2810539] | Lr: 0.000030 | Loss: 1.1477 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 67.48
24-04-06 14:29:27.507 - INFO: Train epoch 560: [25600/94637 (27%)] Step: [2810639] | Lr: 0.000030 | Loss: 1.1525 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 65.22
24-04-06 14:30:16.252 - INFO: Train epoch 560: [28800/94637 (30%)] Step: [2810739] | Lr: 0.000030 | Loss: 1.1375 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 62.03
24-04-06 14:31:04.631 - INFO: Train epoch 560: [32000/94637 (34%)] Step: [2810839] | Lr: 0.000030 | Loss: 1.0743 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 61.78
24-04-06 14:31:52.927 - INFO: Train epoch 560: [35200/94637 (37%)] Step: [2810939] | Lr: 0.000030 | Loss: 1.1730 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 69.44
24-04-06 14:32:41.442 - INFO: Train epoch 560: [38400/94637 (41%)] Step: [2811039] | Lr: 0.000030 | Loss: 1.1742 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 66.45
24-04-06 14:33:30.493 - INFO: Train epoch 560: [41600/94637 (44%)] Step: [2811139] | Lr: 0.000030 | Loss: 1.4767 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 61.76
24-04-06 14:34:19.028 - INFO: Train epoch 560: [44800/94637 (47%)] Step: [2811239] | Lr: 0.000030 | Loss: 0.9982 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 65.41
24-04-06 14:35:07.708 - INFO: Train epoch 560: [48000/94637 (51%)] Step: [2811339] | Lr: 0.000030 | Loss: 1.0144 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 63.44
24-04-06 14:35:56.524 - INFO: Train epoch 560: [51200/94637 (54%)] Step: [2811439] | Lr: 0.000030 | Loss: 1.1766 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 62.11
24-04-06 14:36:45.432 - INFO: Train epoch 560: [54400/94637 (57%)] Step: [2811539] | Lr: 0.000030 | Loss: 1.1712 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 62.59
24-04-06 14:37:34.112 - INFO: Train epoch 560: [57600/94637 (61%)] Step: [2811639] | Lr: 0.000030 | Loss: 0.9921 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 65.40
24-04-06 14:38:23.308 - INFO: Train epoch 560: [60800/94637 (64%)] Step: [2811739] | Lr: 0.000030 | Loss: 1.2080 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 67.14
24-04-06 14:39:11.656 - INFO: Train epoch 560: [64000/94637 (68%)] Step: [2811839] | Lr: 0.000030 | Loss: 1.2978 | MSE loss: 0.0004 | Bpp loss: 0.70 | Aux loss: 65.70
24-04-06 14:40:00.240 - INFO: Train epoch 560: [67200/94637 (71%)] Step: [2811939] | Lr: 0.000030 | Loss: 1.3657 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 67.40
24-04-06 14:40:48.580 - INFO: Train epoch 560: [70400/94637 (74%)] Step: [2812039] | Lr: 0.000030 | Loss: 1.0630 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 66.71
24-04-06 14:41:37.127 - INFO: Train epoch 560: [73600/94637 (78%)] Step: [2812139] | Lr: 0.000030 | Loss: 1.3766 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 66.26
24-04-06 14:42:25.272 - INFO: Train epoch 560: [76800/94637 (81%)] Step: [2812239] | Lr: 0.000030 | Loss: 1.1560 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 60.54
24-04-06 14:43:13.205 - INFO: Train epoch 560: [80000/94637 (85%)] Step: [2812339] | Lr: 0.000030 | Loss: 1.0835 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 62.98
24-04-06 14:44:01.473 - INFO: Train epoch 560: [83200/94637 (88%)] Step: [2812439] | Lr: 0.000030 | Loss: 1.3962 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 59.71
24-04-06 14:44:51.379 - INFO: Train epoch 560: [86400/94637 (91%)] Step: [2812539] | Lr: 0.000030 | Loss: 1.9850 | MSE loss: 0.0006 | Bpp loss: 1.08 | Aux loss: 64.11
24-04-06 14:45:40.160 - INFO: Train epoch 560: [89600/94637 (95%)] Step: [2812639] | Lr: 0.000030 | Loss: 1.2178 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 65.96
24-04-06 14:46:29.305 - INFO: Train epoch 560: [92800/94637 (98%)] Step: [2812739] | Lr: 0.000030 | Loss: 1.3405 | MSE loss: 0.0004 | Bpp loss: 0.77 | Aux loss: 65.64
24-04-06 14:47:08.018 - INFO: Learning rate: 3e-05
24-04-06 14:47:09.127 - INFO: Train epoch 561: [    0/94637 (0%)] Step: [2812796] | Lr: 0.000030 | Loss: 1.1371 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 66.95
24-04-06 14:47:57.376 - INFO: Train epoch 561: [ 3200/94637 (3%)] Step: [2812896] | Lr: 0.000030 | Loss: 0.9302 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 68.50
24-04-06 14:48:45.626 - INFO: Train epoch 561: [ 6400/94637 (7%)] Step: [2812996] | Lr: 0.000030 | Loss: 0.9674 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 63.77
24-04-06 14:49:33.903 - INFO: Train epoch 561: [ 9600/94637 (10%)] Step: [2813096] | Lr: 0.000030 | Loss: 1.6283 | MSE loss: 0.0004 | Bpp loss: 1.06 | Aux loss: 69.35
24-04-06 14:50:22.623 - INFO: Train epoch 561: [12800/94637 (14%)] Step: [2813196] | Lr: 0.000030 | Loss: 1.1973 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 61.06
24-04-06 14:51:11.704 - INFO: Train epoch 561: [16000/94637 (17%)] Step: [2813296] | Lr: 0.000030 | Loss: 1.3872 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 71.46
24-04-06 14:52:00.547 - INFO: Train epoch 561: [19200/94637 (20%)] Step: [2813396] | Lr: 0.000030 | Loss: 0.9075 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 62.05
24-04-06 14:52:49.037 - INFO: Train epoch 561: [22400/94637 (24%)] Step: [2813496] | Lr: 0.000030 | Loss: 1.3146 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 65.68
24-04-06 14:53:37.931 - INFO: Train epoch 561: [25600/94637 (27%)] Step: [2813596] | Lr: 0.000030 | Loss: 0.8930 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 68.65
24-04-06 14:54:26.128 - INFO: Train epoch 561: [28800/94637 (30%)] Step: [2813696] | Lr: 0.000030 | Loss: 1.1391 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 63.72
24-04-06 14:55:15.120 - INFO: Train epoch 561: [32000/94637 (34%)] Step: [2813796] | Lr: 0.000030 | Loss: 1.5315 | MSE loss: 0.0004 | Bpp loss: 0.93 | Aux loss: 67.52
24-04-06 14:56:04.563 - INFO: Train epoch 561: [35200/94637 (37%)] Step: [2813896] | Lr: 0.000030 | Loss: 1.4302 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 61.57
24-04-06 14:56:53.401 - INFO: Train epoch 561: [38400/94637 (41%)] Step: [2813996] | Lr: 0.000030 | Loss: 1.0967 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 62.37
24-04-06 14:57:42.157 - INFO: Train epoch 561: [41600/94637 (44%)] Step: [2814096] | Lr: 0.000030 | Loss: 1.4320 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 61.10
24-04-06 14:58:30.940 - INFO: Train epoch 561: [44800/94637 (47%)] Step: [2814196] | Lr: 0.000030 | Loss: 1.4304 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 63.75
24-04-06 14:59:20.086 - INFO: Train epoch 561: [48000/94637 (51%)] Step: [2814296] | Lr: 0.000030 | Loss: 0.9296 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 72.31
24-04-06 15:00:09.400 - INFO: Train epoch 561: [51200/94637 (54%)] Step: [2814396] | Lr: 0.000030 | Loss: 1.4609 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 69.17
24-04-06 15:00:58.473 - INFO: Train epoch 561: [54400/94637 (57%)] Step: [2814496] | Lr: 0.000030 | Loss: 0.9658 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 66.70
24-04-06 15:01:47.224 - INFO: Train epoch 561: [57600/94637 (61%)] Step: [2814596] | Lr: 0.000030 | Loss: 0.9509 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 64.28
24-04-06 15:02:36.118 - INFO: Train epoch 561: [60800/94637 (64%)] Step: [2814696] | Lr: 0.000030 | Loss: 1.0015 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 61.93
24-04-06 15:03:24.300 - INFO: Train epoch 561: [64000/94637 (68%)] Step: [2814796] | Lr: 0.000030 | Loss: 1.1178 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 67.45
24-04-06 15:04:12.700 - INFO: Train epoch 561: [67200/94637 (71%)] Step: [2814896] | Lr: 0.000030 | Loss: 1.3930 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 60.59
24-04-06 15:05:01.304 - INFO: Train epoch 561: [70400/94637 (74%)] Step: [2814996] | Lr: 0.000030 | Loss: 1.2232 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 66.54
24-04-06 15:05:52.029 - INFO: Train epoch 561: [73600/94637 (78%)] Step: [2815096] | Lr: 0.000030 | Loss: 1.0394 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 67.08
24-04-06 15:06:40.882 - INFO: Train epoch 561: [76800/94637 (81%)] Step: [2815196] | Lr: 0.000030 | Loss: 1.1944 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 62.42
24-04-06 15:07:29.379 - INFO: Train epoch 561: [80000/94637 (85%)] Step: [2815296] | Lr: 0.000030 | Loss: 0.8792 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 71.68
24-04-06 15:08:18.145 - INFO: Train epoch 561: [83200/94637 (88%)] Step: [2815396] | Lr: 0.000030 | Loss: 1.0951 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 61.96
24-04-06 15:09:06.782 - INFO: Train epoch 561: [86400/94637 (91%)] Step: [2815496] | Lr: 0.000030 | Loss: 0.8472 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 68.66
24-04-06 15:09:55.515 - INFO: Train epoch 561: [89600/94637 (95%)] Step: [2815596] | Lr: 0.000030 | Loss: 1.3284 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 62.92
24-04-06 15:10:43.763 - INFO: Train epoch 561: [92800/94637 (98%)] Step: [2815696] | Lr: 0.000030 | Loss: 0.9601 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 65.78
24-04-06 15:11:22.528 - INFO: Learning rate: 3e-05
24-04-06 15:11:23.795 - INFO: Train epoch 562: [    0/94637 (0%)] Step: [2815753] | Lr: 0.000030 | Loss: 1.2248 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 66.06
24-04-06 15:12:11.949 - INFO: Train epoch 562: [ 3200/94637 (3%)] Step: [2815853] | Lr: 0.000030 | Loss: 0.7860 | MSE loss: 0.0002 | Bpp loss: 0.47 | Aux loss: 64.38
24-04-06 15:13:00.678 - INFO: Train epoch 562: [ 6400/94637 (7%)] Step: [2815953] | Lr: 0.000030 | Loss: 1.0346 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 70.41
24-04-06 15:13:49.295 - INFO: Train epoch 562: [ 9600/94637 (10%)] Step: [2816053] | Lr: 0.000030 | Loss: 1.3547 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 70.01
24-04-06 15:14:37.589 - INFO: Train epoch 562: [12800/94637 (14%)] Step: [2816153] | Lr: 0.000030 | Loss: 1.1178 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 65.60
24-04-06 15:15:26.414 - INFO: Train epoch 562: [16000/94637 (17%)] Step: [2816253] | Lr: 0.000030 | Loss: 1.0859 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 62.79
24-04-06 15:16:14.627 - INFO: Train epoch 562: [19200/94637 (20%)] Step: [2816353] | Lr: 0.000030 | Loss: 1.1070 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 63.16
24-04-06 15:17:02.953 - INFO: Train epoch 562: [22400/94637 (24%)] Step: [2816453] | Lr: 0.000030 | Loss: 1.7681 | MSE loss: 0.0006 | Bpp loss: 0.86 | Aux loss: 65.56
24-04-06 15:17:51.218 - INFO: Train epoch 562: [25600/94637 (27%)] Step: [2816553] | Lr: 0.000030 | Loss: 1.0627 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 63.61
24-04-06 15:18:38.954 - INFO: Train epoch 562: [28800/94637 (30%)] Step: [2816653] | Lr: 0.000030 | Loss: 1.1597 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 62.94
24-04-06 15:19:26.888 - INFO: Train epoch 562: [32000/94637 (34%)] Step: [2816753] | Lr: 0.000030 | Loss: 1.4144 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 61.80
24-04-06 15:20:14.768 - INFO: Train epoch 562: [35200/94637 (37%)] Step: [2816853] | Lr: 0.000030 | Loss: 0.9403 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 65.51
24-04-06 15:21:03.079 - INFO: Train epoch 562: [38400/94637 (41%)] Step: [2816953] | Lr: 0.000030 | Loss: 1.2611 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 65.04
24-04-06 15:21:50.914 - INFO: Train epoch 562: [41600/94637 (44%)] Step: [2817053] | Lr: 0.000030 | Loss: 0.9774 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 67.56
24-04-06 15:22:39.074 - INFO: Train epoch 562: [44800/94637 (47%)] Step: [2817153] | Lr: 0.000030 | Loss: 1.1015 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 70.15
24-04-06 15:23:27.245 - INFO: Train epoch 562: [48000/94637 (51%)] Step: [2817253] | Lr: 0.000030 | Loss: 1.1129 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 67.01
24-04-06 15:24:15.023 - INFO: Train epoch 562: [51200/94637 (54%)] Step: [2817353] | Lr: 0.000030 | Loss: 1.1652 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 62.12
24-04-06 15:25:03.308 - INFO: Train epoch 562: [54400/94637 (57%)] Step: [2817453] | Lr: 0.000030 | Loss: 1.2718 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 65.72
24-04-06 15:25:53.214 - INFO: Train epoch 562: [57600/94637 (61%)] Step: [2817553] | Lr: 0.000030 | Loss: 1.1242 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 67.71
24-04-06 15:26:41.324 - INFO: Train epoch 562: [60800/94637 (64%)] Step: [2817653] | Lr: 0.000030 | Loss: 1.6081 | MSE loss: 0.0003 | Bpp loss: 1.04 | Aux loss: 61.35
24-04-06 15:27:30.045 - INFO: Train epoch 562: [64000/94637 (68%)] Step: [2817753] | Lr: 0.000030 | Loss: 0.8411 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 63.88
24-04-06 15:28:18.636 - INFO: Train epoch 562: [67200/94637 (71%)] Step: [2817853] | Lr: 0.000030 | Loss: 1.0543 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 69.93
24-04-06 15:29:06.839 - INFO: Train epoch 562: [70400/94637 (74%)] Step: [2817953] | Lr: 0.000030 | Loss: 1.4991 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 64.78
24-04-06 15:29:55.295 - INFO: Train epoch 562: [73600/94637 (78%)] Step: [2818053] | Lr: 0.000030 | Loss: 1.2862 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 66.76
24-04-06 15:30:43.770 - INFO: Train epoch 562: [76800/94637 (81%)] Step: [2818153] | Lr: 0.000030 | Loss: 0.8599 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 70.83
24-04-06 15:31:31.447 - INFO: Train epoch 562: [80000/94637 (85%)] Step: [2818253] | Lr: 0.000030 | Loss: 0.9448 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 67.93
24-04-06 15:32:19.043 - INFO: Train epoch 562: [83200/94637 (88%)] Step: [2818353] | Lr: 0.000030 | Loss: 1.3323 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 62.51
24-04-06 15:33:06.937 - INFO: Train epoch 562: [86400/94637 (91%)] Step: [2818453] | Lr: 0.000030 | Loss: 1.1527 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 61.96
24-04-06 15:33:54.608 - INFO: Train epoch 562: [89600/94637 (95%)] Step: [2818553] | Lr: 0.000030 | Loss: 1.4198 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 63.44
24-04-06 15:34:42.148 - INFO: Train epoch 562: [92800/94637 (98%)] Step: [2818653] | Lr: 0.000030 | Loss: 1.4828 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 69.06
24-04-06 15:35:20.254 - INFO: Learning rate: 3e-05
24-04-06 15:35:21.487 - INFO: Train epoch 563: [    0/94637 (0%)] Step: [2818710] | Lr: 0.000030 | Loss: 1.2142 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 65.11
24-04-06 15:36:09.412 - INFO: Train epoch 563: [ 3200/94637 (3%)] Step: [2818810] | Lr: 0.000030 | Loss: 1.2827 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 66.33
24-04-06 15:36:57.486 - INFO: Train epoch 563: [ 6400/94637 (7%)] Step: [2818910] | Lr: 0.000030 | Loss: 1.1561 | MSE loss: 0.0002 | Bpp loss: 0.76 | Aux loss: 68.26
24-04-06 15:37:45.444 - INFO: Train epoch 563: [ 9600/94637 (10%)] Step: [2819010] | Lr: 0.000030 | Loss: 1.1761 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 69.04
24-04-06 15:38:32.912 - INFO: Train epoch 563: [12800/94637 (14%)] Step: [2819110] | Lr: 0.000030 | Loss: 1.0348 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 70.02
24-04-06 15:39:20.969 - INFO: Train epoch 563: [16000/94637 (17%)] Step: [2819210] | Lr: 0.000030 | Loss: 1.3886 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 68.20
24-04-06 15:40:09.303 - INFO: Train epoch 563: [19200/94637 (20%)] Step: [2819310] | Lr: 0.000030 | Loss: 1.5144 | MSE loss: 0.0003 | Bpp loss: 0.97 | Aux loss: 66.96
24-04-06 15:40:57.586 - INFO: Train epoch 563: [22400/94637 (24%)] Step: [2819410] | Lr: 0.000030 | Loss: 0.9133 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 60.29
24-04-06 15:41:46.227 - INFO: Train epoch 563: [25600/94637 (27%)] Step: [2819510] | Lr: 0.000030 | Loss: 1.3131 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 68.93
24-04-06 15:42:34.848 - INFO: Train epoch 563: [28800/94637 (30%)] Step: [2819610] | Lr: 0.000030 | Loss: 1.1559 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 66.71
24-04-06 15:43:23.392 - INFO: Train epoch 563: [32000/94637 (34%)] Step: [2819710] | Lr: 0.000030 | Loss: 1.1376 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 64.05
24-04-06 15:44:11.763 - INFO: Train epoch 563: [35200/94637 (37%)] Step: [2819810] | Lr: 0.000030 | Loss: 1.1489 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 66.07
24-04-06 15:45:00.405 - INFO: Train epoch 563: [38400/94637 (41%)] Step: [2819910] | Lr: 0.000030 | Loss: 1.1016 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 64.09
24-04-06 15:45:50.757 - INFO: Train epoch 563: [41600/94637 (44%)] Step: [2820010] | Lr: 0.000030 | Loss: 1.0839 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 68.24
24-04-06 15:46:39.280 - INFO: Train epoch 563: [44800/94637 (47%)] Step: [2820110] | Lr: 0.000030 | Loss: 1.0535 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 69.58
24-04-06 15:47:28.397 - INFO: Train epoch 563: [48000/94637 (51%)] Step: [2820210] | Lr: 0.000030 | Loss: 1.0066 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 61.64
24-04-06 15:48:16.958 - INFO: Train epoch 563: [51200/94637 (54%)] Step: [2820310] | Lr: 0.000030 | Loss: 1.0559 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 68.21
24-04-06 15:49:05.603 - INFO: Train epoch 563: [54400/94637 (57%)] Step: [2820410] | Lr: 0.000030 | Loss: 1.5693 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 68.17
24-04-06 15:49:53.450 - INFO: Train epoch 563: [57600/94637 (61%)] Step: [2820510] | Lr: 0.000030 | Loss: 0.9482 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 68.15
24-04-06 15:50:41.732 - INFO: Train epoch 563: [60800/94637 (64%)] Step: [2820610] | Lr: 0.000030 | Loss: 1.2732 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 66.18
24-04-06 15:51:30.018 - INFO: Train epoch 563: [64000/94637 (68%)] Step: [2820710] | Lr: 0.000030 | Loss: 1.1527 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 69.53
24-04-06 15:52:18.590 - INFO: Train epoch 563: [67200/94637 (71%)] Step: [2820810] | Lr: 0.000030 | Loss: 1.4254 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 71.25
24-04-06 15:53:06.907 - INFO: Train epoch 563: [70400/94637 (74%)] Step: [2820910] | Lr: 0.000030 | Loss: 1.0024 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 63.39
24-04-06 15:53:54.472 - INFO: Train epoch 563: [73600/94637 (78%)] Step: [2821010] | Lr: 0.000030 | Loss: 0.9699 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 64.09
24-04-06 15:54:43.067 - INFO: Train epoch 563: [76800/94637 (81%)] Step: [2821110] | Lr: 0.000030 | Loss: 1.1692 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 70.50
24-04-06 15:55:31.243 - INFO: Train epoch 563: [80000/94637 (85%)] Step: [2821210] | Lr: 0.000030 | Loss: 1.3258 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 69.80
24-04-06 15:56:19.398 - INFO: Train epoch 563: [83200/94637 (88%)] Step: [2821310] | Lr: 0.000030 | Loss: 1.1963 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 67.42
24-04-06 15:57:07.473 - INFO: Train epoch 563: [86400/94637 (91%)] Step: [2821410] | Lr: 0.000030 | Loss: 0.8608 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 68.68
24-04-06 15:57:55.136 - INFO: Train epoch 563: [89600/94637 (95%)] Step: [2821510] | Lr: 0.000030 | Loss: 1.2776 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 67.61
24-04-06 15:58:42.400 - INFO: Train epoch 563: [92800/94637 (98%)] Step: [2821610] | Lr: 0.000030 | Loss: 0.9108 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 62.37
24-04-06 15:59:26.016 - INFO: Learning rate: 3e-05
24-04-06 15:59:27.882 - INFO: Train epoch 564: [    0/94637 (0%)] Step: [2821667] | Lr: 0.000030 | Loss: 1.2898 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 69.93
24-04-06 16:00:15.878 - INFO: Train epoch 564: [ 3200/94637 (3%)] Step: [2821767] | Lr: 0.000030 | Loss: 1.5911 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 66.93
24-04-06 16:01:04.636 - INFO: Train epoch 564: [ 6400/94637 (7%)] Step: [2821867] | Lr: 0.000030 | Loss: 1.3144 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 65.58
24-04-06 16:01:52.651 - INFO: Train epoch 564: [ 9600/94637 (10%)] Step: [2821967] | Lr: 0.000030 | Loss: 1.4279 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 64.43
24-04-06 16:02:40.685 - INFO: Train epoch 564: [12800/94637 (14%)] Step: [2822067] | Lr: 0.000030 | Loss: 1.0343 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 66.20
24-04-06 16:03:28.811 - INFO: Train epoch 564: [16000/94637 (17%)] Step: [2822167] | Lr: 0.000030 | Loss: 1.2945 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 69.68
24-04-06 16:04:17.332 - INFO: Train epoch 564: [19200/94637 (20%)] Step: [2822267] | Lr: 0.000030 | Loss: 1.5163 | MSE loss: 0.0003 | Bpp loss: 0.97 | Aux loss: 67.79
24-04-06 16:05:05.337 - INFO: Train epoch 564: [22400/94637 (24%)] Step: [2822367] | Lr: 0.000030 | Loss: 1.3874 | MSE loss: 0.0004 | Bpp loss: 0.77 | Aux loss: 60.29
24-04-06 16:05:53.412 - INFO: Train epoch 564: [25600/94637 (27%)] Step: [2822467] | Lr: 0.000030 | Loss: 1.2005 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 70.13
24-04-06 16:06:44.021 - INFO: Train epoch 564: [28800/94637 (30%)] Step: [2822567] | Lr: 0.000030 | Loss: 0.7136 | MSE loss: 0.0001 | Bpp loss: 0.47 | Aux loss: 62.99
24-04-06 16:07:32.247 - INFO: Train epoch 564: [32000/94637 (34%)] Step: [2822667] | Lr: 0.000030 | Loss: 1.1667 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 69.66
24-04-06 16:08:20.570 - INFO: Train epoch 564: [35200/94637 (37%)] Step: [2822767] | Lr: 0.000030 | Loss: 1.0047 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 67.56
24-04-06 16:09:08.781 - INFO: Train epoch 564: [38400/94637 (41%)] Step: [2822867] | Lr: 0.000030 | Loss: 1.5551 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 64.39
24-04-06 16:09:57.372 - INFO: Train epoch 564: [41600/94637 (44%)] Step: [2822967] | Lr: 0.000030 | Loss: 0.9879 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 67.93
24-04-06 16:10:45.562 - INFO: Train epoch 564: [44800/94637 (47%)] Step: [2823067] | Lr: 0.000030 | Loss: 1.1792 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 65.47
24-04-06 16:11:33.936 - INFO: Train epoch 564: [48000/94637 (51%)] Step: [2823167] | Lr: 0.000030 | Loss: 1.5435 | MSE loss: 0.0003 | Bpp loss: 0.98 | Aux loss: 65.73
24-04-06 16:12:22.243 - INFO: Train epoch 564: [51200/94637 (54%)] Step: [2823267] | Lr: 0.000030 | Loss: 0.8278 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 77.08
24-04-06 16:13:10.457 - INFO: Train epoch 564: [54400/94637 (57%)] Step: [2823367] | Lr: 0.000030 | Loss: 1.5514 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 65.71
24-04-06 16:13:59.151 - INFO: Train epoch 564: [57600/94637 (61%)] Step: [2823467] | Lr: 0.000030 | Loss: 1.3299 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 66.61
24-04-06 16:14:47.439 - INFO: Train epoch 564: [60800/94637 (64%)] Step: [2823567] | Lr: 0.000030 | Loss: 0.9300 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 65.64
24-04-06 16:15:35.807 - INFO: Train epoch 564: [64000/94637 (68%)] Step: [2823667] | Lr: 0.000030 | Loss: 1.1011 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 69.23
24-04-06 16:16:23.611 - INFO: Train epoch 564: [67200/94637 (71%)] Step: [2823767] | Lr: 0.000030 | Loss: 0.8652 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 62.17
24-04-06 16:17:11.898 - INFO: Train epoch 564: [70400/94637 (74%)] Step: [2823867] | Lr: 0.000030 | Loss: 1.4647 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 63.02
24-04-06 16:17:59.914 - INFO: Train epoch 564: [73600/94637 (78%)] Step: [2823967] | Lr: 0.000030 | Loss: 1.6234 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 67.40
24-04-06 16:18:48.187 - INFO: Train epoch 564: [76800/94637 (81%)] Step: [2824067] | Lr: 0.000030 | Loss: 0.8877 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 69.38
24-04-06 16:19:36.271 - INFO: Train epoch 564: [80000/94637 (85%)] Step: [2824167] | Lr: 0.000030 | Loss: 1.2126 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 68.17
24-04-06 16:20:24.494 - INFO: Train epoch 564: [83200/94637 (88%)] Step: [2824267] | Lr: 0.000030 | Loss: 0.9882 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 65.64
24-04-06 16:21:13.048 - INFO: Train epoch 564: [86400/94637 (91%)] Step: [2824367] | Lr: 0.000030 | Loss: 1.2191 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 68.18
24-04-06 16:22:01.637 - INFO: Train epoch 564: [89600/94637 (95%)] Step: [2824467] | Lr: 0.000030 | Loss: 0.7931 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 66.39
24-04-06 16:22:50.279 - INFO: Train epoch 564: [92800/94637 (98%)] Step: [2824567] | Lr: 0.000030 | Loss: 1.3781 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 65.88
24-04-06 16:23:28.984 - INFO: Learning rate: 3e-05
24-04-06 16:23:30.147 - INFO: Train epoch 565: [    0/94637 (0%)] Step: [2824624] | Lr: 0.000030 | Loss: 1.4865 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 65.57
24-04-06 16:24:18.645 - INFO: Train epoch 565: [ 3200/94637 (3%)] Step: [2824724] | Lr: 0.000030 | Loss: 1.3265 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 61.94
24-04-06 16:25:06.784 - INFO: Train epoch 565: [ 6400/94637 (7%)] Step: [2824824] | Lr: 0.000030 | Loss: 0.9929 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 71.02
24-04-06 16:25:55.050 - INFO: Train epoch 565: [ 9600/94637 (10%)] Step: [2824924] | Lr: 0.000030 | Loss: 1.4059 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 62.29
24-04-06 16:26:45.337 - INFO: Train epoch 565: [12800/94637 (14%)] Step: [2825024] | Lr: 0.000030 | Loss: 1.1300 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 63.92
24-04-06 16:27:33.832 - INFO: Train epoch 565: [16000/94637 (17%)] Step: [2825124] | Lr: 0.000030 | Loss: 1.5400 | MSE loss: 0.0004 | Bpp loss: 0.83 | Aux loss: 69.83
24-04-06 16:28:22.025 - INFO: Train epoch 565: [19200/94637 (20%)] Step: [2825224] | Lr: 0.000030 | Loss: 0.9893 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 69.42
24-04-06 16:29:10.138 - INFO: Train epoch 565: [22400/94637 (24%)] Step: [2825324] | Lr: 0.000030 | Loss: 1.3125 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 67.68
24-04-06 16:29:57.893 - INFO: Train epoch 565: [25600/94637 (27%)] Step: [2825424] | Lr: 0.000030 | Loss: 1.1961 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 64.84
24-04-06 16:30:45.662 - INFO: Train epoch 565: [28800/94637 (30%)] Step: [2825524] | Lr: 0.000030 | Loss: 1.1183 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 68.81
24-04-06 16:31:33.039 - INFO: Train epoch 565: [32000/94637 (34%)] Step: [2825624] | Lr: 0.000030 | Loss: 0.9021 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 67.34
24-04-06 16:32:21.101 - INFO: Train epoch 565: [35200/94637 (37%)] Step: [2825724] | Lr: 0.000030 | Loss: 1.1687 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 68.32
24-04-06 16:33:08.846 - INFO: Train epoch 565: [38400/94637 (41%)] Step: [2825824] | Lr: 0.000030 | Loss: 1.3990 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 62.86
24-04-06 16:33:56.795 - INFO: Train epoch 565: [41600/94637 (44%)] Step: [2825924] | Lr: 0.000030 | Loss: 1.0216 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 68.28
24-04-06 16:34:44.652 - INFO: Train epoch 565: [44800/94637 (47%)] Step: [2826024] | Lr: 0.000030 | Loss: 1.1708 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 62.25
24-04-06 16:35:31.525 - INFO: Train epoch 565: [48000/94637 (51%)] Step: [2826124] | Lr: 0.000030 | Loss: 1.0426 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 62.16
24-04-06 16:36:19.462 - INFO: Train epoch 565: [51200/94637 (54%)] Step: [2826224] | Lr: 0.000030 | Loss: 0.8077 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 64.07
24-04-06 16:37:07.245 - INFO: Train epoch 565: [54400/94637 (57%)] Step: [2826324] | Lr: 0.000030 | Loss: 1.3354 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 70.17
24-04-06 16:37:54.866 - INFO: Train epoch 565: [57600/94637 (61%)] Step: [2826424] | Lr: 0.000030 | Loss: 1.2280 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 68.79
24-04-06 16:38:42.550 - INFO: Train epoch 565: [60800/94637 (64%)] Step: [2826524] | Lr: 0.000030 | Loss: 1.5474 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 71.82
24-04-06 16:39:31.132 - INFO: Train epoch 565: [64000/94637 (68%)] Step: [2826624] | Lr: 0.000030 | Loss: 1.0164 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 63.35
24-04-06 16:40:19.478 - INFO: Train epoch 565: [67200/94637 (71%)] Step: [2826724] | Lr: 0.000030 | Loss: 1.0092 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 67.51
24-04-06 16:41:07.719 - INFO: Train epoch 565: [70400/94637 (74%)] Step: [2826824] | Lr: 0.000030 | Loss: 1.0283 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 72.43
24-04-06 16:41:56.083 - INFO: Train epoch 565: [73600/94637 (78%)] Step: [2826924] | Lr: 0.000030 | Loss: 1.2632 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 68.86
24-04-06 16:42:44.228 - INFO: Train epoch 565: [76800/94637 (81%)] Step: [2827024] | Lr: 0.000030 | Loss: 1.1220 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 63.66
24-04-06 16:43:32.809 - INFO: Train epoch 565: [80000/94637 (85%)] Step: [2827124] | Lr: 0.000030 | Loss: 1.1838 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 62.21
24-04-06 16:44:20.284 - INFO: Train epoch 565: [83200/94637 (88%)] Step: [2827224] | Lr: 0.000030 | Loss: 0.9578 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 67.90
24-04-06 16:45:08.610 - INFO: Train epoch 565: [86400/94637 (91%)] Step: [2827324] | Lr: 0.000030 | Loss: 0.9885 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 65.63
24-04-06 16:45:56.143 - INFO: Train epoch 565: [89600/94637 (95%)] Step: [2827424] | Lr: 0.000030 | Loss: 1.5300 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 63.20
24-04-06 16:46:45.688 - INFO: Train epoch 565: [92800/94637 (98%)] Step: [2827524] | Lr: 0.000030 | Loss: 1.0469 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 69.25
24-04-06 16:47:23.856 - INFO: Learning rate: 3e-05
24-04-06 16:47:25.819 - INFO: Train epoch 566: [    0/94637 (0%)] Step: [2827581] | Lr: 0.000030 | Loss: 1.2092 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 63.64
24-04-06 16:48:14.331 - INFO: Train epoch 566: [ 3200/94637 (3%)] Step: [2827681] | Lr: 0.000030 | Loss: 1.2212 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 68.16
24-04-06 16:49:02.498 - INFO: Train epoch 566: [ 6400/94637 (7%)] Step: [2827781] | Lr: 0.000030 | Loss: 1.6521 | MSE loss: 0.0004 | Bpp loss: 1.03 | Aux loss: 66.46
24-04-06 16:49:50.264 - INFO: Train epoch 566: [ 9600/94637 (10%)] Step: [2827881] | Lr: 0.000030 | Loss: 1.2787 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 68.54
24-04-06 16:50:37.876 - INFO: Train epoch 566: [12800/94637 (14%)] Step: [2827981] | Lr: 0.000030 | Loss: 0.9380 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 66.39
24-04-06 16:51:25.488 - INFO: Train epoch 566: [16000/94637 (17%)] Step: [2828081] | Lr: 0.000030 | Loss: 0.9843 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 62.48
24-04-06 16:52:13.142 - INFO: Train epoch 566: [19200/94637 (20%)] Step: [2828181] | Lr: 0.000030 | Loss: 1.1609 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 66.56
24-04-06 16:53:01.277 - INFO: Train epoch 566: [22400/94637 (24%)] Step: [2828281] | Lr: 0.000030 | Loss: 2.0013 | MSE loss: 0.0005 | Bpp loss: 1.15 | Aux loss: 71.10
24-04-06 16:53:49.676 - INFO: Train epoch 566: [25600/94637 (27%)] Step: [2828381] | Lr: 0.000030 | Loss: 1.3090 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 64.50
24-04-06 16:54:38.378 - INFO: Train epoch 566: [28800/94637 (30%)] Step: [2828481] | Lr: 0.000030 | Loss: 1.5000 | MSE loss: 0.0004 | Bpp loss: 0.93 | Aux loss: 66.00
24-04-06 16:55:26.085 - INFO: Train epoch 566: [32000/94637 (34%)] Step: [2828581] | Lr: 0.000030 | Loss: 0.9725 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 67.83
24-04-06 16:56:13.942 - INFO: Train epoch 566: [35200/94637 (37%)] Step: [2828681] | Lr: 0.000030 | Loss: 1.1203 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 69.93
24-04-06 16:57:01.779 - INFO: Train epoch 566: [38400/94637 (41%)] Step: [2828781] | Lr: 0.000030 | Loss: 1.4304 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 76.38
24-04-06 16:57:49.804 - INFO: Train epoch 566: [41600/94637 (44%)] Step: [2828881] | Lr: 0.000030 | Loss: 1.2119 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 70.93
24-04-06 16:58:37.337 - INFO: Train epoch 566: [44800/94637 (47%)] Step: [2828981] | Lr: 0.000030 | Loss: 1.2865 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 66.39
24-04-06 16:59:24.636 - INFO: Train epoch 566: [48000/94637 (51%)] Step: [2829081] | Lr: 0.000030 | Loss: 1.0403 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 68.35
24-04-06 17:00:12.046 - INFO: Train epoch 566: [51200/94637 (54%)] Step: [2829181] | Lr: 0.000030 | Loss: 1.1296 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 69.66
24-04-06 17:00:59.466 - INFO: Train epoch 566: [54400/94637 (57%)] Step: [2829281] | Lr: 0.000030 | Loss: 1.5828 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 62.81
24-04-06 17:01:47.400 - INFO: Train epoch 566: [57600/94637 (61%)] Step: [2829381] | Lr: 0.000030 | Loss: 1.1623 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 71.66
24-04-06 17:02:35.022 - INFO: Train epoch 566: [60800/94637 (64%)] Step: [2829481] | Lr: 0.000030 | Loss: 0.9357 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 69.85
24-04-06 17:03:23.237 - INFO: Train epoch 566: [64000/94637 (68%)] Step: [2829581] | Lr: 0.000030 | Loss: 1.2632 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 69.15
24-04-06 17:04:11.406 - INFO: Train epoch 566: [67200/94637 (71%)] Step: [2829681] | Lr: 0.000030 | Loss: 1.0119 | MSE loss: 0.0003 | Bpp loss: 0.61 | Aux loss: 66.65
24-04-06 17:05:00.284 - INFO: Train epoch 566: [70400/94637 (74%)] Step: [2829781] | Lr: 0.000030 | Loss: 0.9545 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 67.16
24-04-06 17:05:48.726 - INFO: Train epoch 566: [73600/94637 (78%)] Step: [2829881] | Lr: 0.000030 | Loss: 1.1341 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 74.43
24-04-06 17:06:36.642 - INFO: Train epoch 566: [76800/94637 (81%)] Step: [2829981] | Lr: 0.000030 | Loss: 1.4332 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 62.48
24-04-06 17:07:27.588 - INFO: Train epoch 566: [80000/94637 (85%)] Step: [2830081] | Lr: 0.000030 | Loss: 1.2009 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 70.32
24-04-06 17:08:15.597 - INFO: Train epoch 566: [83200/94637 (88%)] Step: [2830181] | Lr: 0.000030 | Loss: 1.2628 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 69.72
24-04-06 17:09:03.393 - INFO: Train epoch 566: [86400/94637 (91%)] Step: [2830281] | Lr: 0.000030 | Loss: 1.4868 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 64.40
24-04-06 17:09:50.985 - INFO: Train epoch 566: [89600/94637 (95%)] Step: [2830381] | Lr: 0.000030 | Loss: 1.4642 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 67.80
24-04-06 17:10:38.899 - INFO: Train epoch 566: [92800/94637 (98%)] Step: [2830481] | Lr: 0.000030 | Loss: 0.9710 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 67.75
24-04-06 17:11:17.134 - INFO: Learning rate: 3e-05
24-04-06 17:11:18.188 - INFO: Train epoch 567: [    0/94637 (0%)] Step: [2830538] | Lr: 0.000030 | Loss: 1.1822 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 64.74
24-04-06 17:12:05.962 - INFO: Train epoch 567: [ 3200/94637 (3%)] Step: [2830638] | Lr: 0.000030 | Loss: 1.1079 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 70.40
24-04-06 17:12:54.015 - INFO: Train epoch 567: [ 6400/94637 (7%)] Step: [2830738] | Lr: 0.000030 | Loss: 1.2510 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 64.11
24-04-06 17:13:41.782 - INFO: Train epoch 567: [ 9600/94637 (10%)] Step: [2830838] | Lr: 0.000030 | Loss: 0.9301 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 68.97
24-04-06 17:14:29.467 - INFO: Train epoch 567: [12800/94637 (14%)] Step: [2830938] | Lr: 0.000030 | Loss: 1.5526 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 66.79
24-04-06 17:15:16.837 - INFO: Train epoch 567: [16000/94637 (17%)] Step: [2831038] | Lr: 0.000030 | Loss: 1.0464 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 65.38
24-04-06 17:16:04.775 - INFO: Train epoch 567: [19200/94637 (20%)] Step: [2831138] | Lr: 0.000030 | Loss: 0.9584 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 68.05
24-04-06 17:16:52.438 - INFO: Train epoch 567: [22400/94637 (24%)] Step: [2831238] | Lr: 0.000030 | Loss: 1.2686 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 65.55
24-04-06 17:17:40.602 - INFO: Train epoch 567: [25600/94637 (27%)] Step: [2831338] | Lr: 0.000030 | Loss: 0.9091 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 64.87
24-04-06 17:18:28.043 - INFO: Train epoch 567: [28800/94637 (30%)] Step: [2831438] | Lr: 0.000030 | Loss: 1.3539 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 67.73
24-04-06 17:19:15.360 - INFO: Train epoch 567: [32000/94637 (34%)] Step: [2831538] | Lr: 0.000030 | Loss: 1.3242 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 67.16
24-04-06 17:20:03.306 - INFO: Train epoch 567: [35200/94637 (37%)] Step: [2831638] | Lr: 0.000030 | Loss: 1.0185 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 71.56
24-04-06 17:20:51.486 - INFO: Train epoch 567: [38400/94637 (41%)] Step: [2831738] | Lr: 0.000030 | Loss: 1.4111 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 67.16
24-04-06 17:21:39.269 - INFO: Train epoch 567: [41600/94637 (44%)] Step: [2831838] | Lr: 0.000030 | Loss: 1.0656 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 69.51
24-04-06 17:22:26.995 - INFO: Train epoch 567: [44800/94637 (47%)] Step: [2831938] | Lr: 0.000030 | Loss: 1.0508 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 69.28
24-04-06 17:23:15.017 - INFO: Train epoch 567: [48000/94637 (51%)] Step: [2832038] | Lr: 0.000030 | Loss: 1.7018 | MSE loss: 0.0004 | Bpp loss: 1.08 | Aux loss: 63.00
24-04-06 17:24:02.639 - INFO: Train epoch 567: [51200/94637 (54%)] Step: [2832138] | Lr: 0.000030 | Loss: 1.2105 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 71.34
24-04-06 17:24:50.919 - INFO: Train epoch 567: [54400/94637 (57%)] Step: [2832238] | Lr: 0.000030 | Loss: 1.2951 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 67.54
24-04-06 17:25:38.546 - INFO: Train epoch 567: [57600/94637 (61%)] Step: [2832338] | Lr: 0.000030 | Loss: 1.0240 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 72.81
24-04-06 17:26:26.515 - INFO: Train epoch 567: [60800/94637 (64%)] Step: [2832438] | Lr: 0.000030 | Loss: 1.4324 | MSE loss: 0.0004 | Bpp loss: 0.85 | Aux loss: 69.88
24-04-06 17:27:16.293 - INFO: Train epoch 567: [64000/94637 (68%)] Step: [2832538] | Lr: 0.000030 | Loss: 1.4386 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 66.61
24-04-06 17:28:04.064 - INFO: Train epoch 567: [67200/94637 (71%)] Step: [2832638] | Lr: 0.000030 | Loss: 1.5177 | MSE loss: 0.0003 | Bpp loss: 0.96 | Aux loss: 69.77
24-04-06 17:28:52.501 - INFO: Train epoch 567: [70400/94637 (74%)] Step: [2832738] | Lr: 0.000030 | Loss: 1.0310 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 67.91
24-04-06 17:29:41.058 - INFO: Train epoch 567: [73600/94637 (78%)] Step: [2832838] | Lr: 0.000030 | Loss: 0.7865 | MSE loss: 0.0002 | Bpp loss: 0.45 | Aux loss: 69.56
24-04-06 17:30:28.953 - INFO: Train epoch 567: [76800/94637 (81%)] Step: [2832938] | Lr: 0.000030 | Loss: 1.2402 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 70.31
24-04-06 17:31:17.753 - INFO: Train epoch 567: [80000/94637 (85%)] Step: [2833038] | Lr: 0.000030 | Loss: 1.0889 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 69.85
24-04-06 17:32:06.161 - INFO: Train epoch 567: [83200/94637 (88%)] Step: [2833138] | Lr: 0.000030 | Loss: 1.1907 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 65.74
24-04-06 17:32:54.722 - INFO: Train epoch 567: [86400/94637 (91%)] Step: [2833238] | Lr: 0.000030 | Loss: 1.3259 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 69.65
24-04-06 17:33:43.178 - INFO: Train epoch 567: [89600/94637 (95%)] Step: [2833338] | Lr: 0.000030 | Loss: 1.1198 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 68.19
24-04-06 17:34:31.464 - INFO: Train epoch 567: [92800/94637 (98%)] Step: [2833438] | Lr: 0.000030 | Loss: 1.1624 | MSE loss: 0.0002 | Bpp loss: 0.79 | Aux loss: 63.82
24-04-06 17:35:15.115 - INFO: Learning rate: 3e-05
24-04-06 17:35:16.170 - INFO: Train epoch 568: [    0/94637 (0%)] Step: [2833495] | Lr: 0.000030 | Loss: 1.1733 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 67.12
24-04-06 17:36:04.083 - INFO: Train epoch 568: [ 3200/94637 (3%)] Step: [2833595] | Lr: 0.000030 | Loss: 1.2305 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 66.24
24-04-06 17:36:51.880 - INFO: Train epoch 568: [ 6400/94637 (7%)] Step: [2833695] | Lr: 0.000030 | Loss: 1.0877 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 67.26
24-04-06 17:37:39.494 - INFO: Train epoch 568: [ 9600/94637 (10%)] Step: [2833795] | Lr: 0.000030 | Loss: 1.1725 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 67.48
24-04-06 17:38:27.665 - INFO: Train epoch 568: [12800/94637 (14%)] Step: [2833895] | Lr: 0.000030 | Loss: 1.1578 | MSE loss: 0.0002 | Bpp loss: 0.77 | Aux loss: 64.32
24-04-06 17:39:15.806 - INFO: Train epoch 568: [16000/94637 (17%)] Step: [2833995] | Lr: 0.000030 | Loss: 1.2462 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 72.75
24-04-06 17:40:03.807 - INFO: Train epoch 568: [19200/94637 (20%)] Step: [2834095] | Lr: 0.000030 | Loss: 1.1952 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 67.67
24-04-06 17:40:51.504 - INFO: Train epoch 568: [22400/94637 (24%)] Step: [2834195] | Lr: 0.000030 | Loss: 1.2778 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 72.18
24-04-06 17:41:39.493 - INFO: Train epoch 568: [25600/94637 (27%)] Step: [2834295] | Lr: 0.000030 | Loss: 1.1746 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 70.05
24-04-06 17:42:27.243 - INFO: Train epoch 568: [28800/94637 (30%)] Step: [2834395] | Lr: 0.000030 | Loss: 1.0163 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 69.18
24-04-06 17:43:15.663 - INFO: Train epoch 568: [32000/94637 (34%)] Step: [2834495] | Lr: 0.000030 | Loss: 0.8435 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 70.26
24-04-06 17:44:03.447 - INFO: Train epoch 568: [35200/94637 (37%)] Step: [2834595] | Lr: 0.000030 | Loss: 1.0953 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 67.77
24-04-06 17:44:51.489 - INFO: Train epoch 568: [38400/94637 (41%)] Step: [2834695] | Lr: 0.000030 | Loss: 1.2564 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 66.53
24-04-06 17:45:39.873 - INFO: Train epoch 568: [41600/94637 (44%)] Step: [2834795] | Lr: 0.000030 | Loss: 0.9358 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 65.63
24-04-06 17:46:28.051 - INFO: Train epoch 568: [44800/94637 (47%)] Step: [2834895] | Lr: 0.000030 | Loss: 0.8729 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 65.58
24-04-06 17:47:16.379 - INFO: Train epoch 568: [48000/94637 (51%)] Step: [2834995] | Lr: 0.000030 | Loss: 0.9704 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 70.40
24-04-06 17:48:06.238 - INFO: Train epoch 568: [51200/94637 (54%)] Step: [2835095] | Lr: 0.000030 | Loss: 1.1237 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 70.04
24-04-06 17:48:54.954 - INFO: Train epoch 568: [54400/94637 (57%)] Step: [2835195] | Lr: 0.000030 | Loss: 1.2641 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 69.39
24-04-06 17:49:42.931 - INFO: Train epoch 568: [57600/94637 (61%)] Step: [2835295] | Lr: 0.000030 | Loss: 1.4014 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 65.73
24-04-06 17:50:30.987 - INFO: Train epoch 568: [60800/94637 (64%)] Step: [2835395] | Lr: 0.000030 | Loss: 1.1074 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 66.19
24-04-06 17:51:19.181 - INFO: Train epoch 568: [64000/94637 (68%)] Step: [2835495] | Lr: 0.000030 | Loss: 1.6042 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 66.85
24-04-06 17:52:08.028 - INFO: Train epoch 568: [67200/94637 (71%)] Step: [2835595] | Lr: 0.000030 | Loss: 1.1777 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 69.60
24-04-06 17:52:56.729 - INFO: Train epoch 568: [70400/94637 (74%)] Step: [2835695] | Lr: 0.000030 | Loss: 1.0211 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 68.09
24-04-06 17:53:45.403 - INFO: Train epoch 568: [73600/94637 (78%)] Step: [2835795] | Lr: 0.000030 | Loss: 0.9987 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 70.09
24-04-06 17:54:33.864 - INFO: Train epoch 568: [76800/94637 (81%)] Step: [2835895] | Lr: 0.000030 | Loss: 0.9938 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 65.71
24-04-06 17:55:22.148 - INFO: Train epoch 568: [80000/94637 (85%)] Step: [2835995] | Lr: 0.000030 | Loss: 1.0274 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 70.06
24-04-06 17:56:10.730 - INFO: Train epoch 568: [83200/94637 (88%)] Step: [2836095] | Lr: 0.000030 | Loss: 1.2882 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 71.80
24-04-06 17:56:58.717 - INFO: Train epoch 568: [86400/94637 (91%)] Step: [2836195] | Lr: 0.000030 | Loss: 1.1404 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 67.95
24-04-06 17:57:47.814 - INFO: Train epoch 568: [89600/94637 (95%)] Step: [2836295] | Lr: 0.000030 | Loss: 0.8463 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 65.92
24-04-06 17:58:36.036 - INFO: Train epoch 568: [92800/94637 (98%)] Step: [2836395] | Lr: 0.000030 | Loss: 1.8314 | MSE loss: 0.0004 | Bpp loss: 1.15 | Aux loss: 72.92
24-04-06 17:59:14.492 - INFO: Learning rate: 3e-05
24-04-06 17:59:15.921 - INFO: Train epoch 569: [    0/94637 (0%)] Step: [2836452] | Lr: 0.000030 | Loss: 0.9558 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 68.52
24-04-06 18:00:03.781 - INFO: Train epoch 569: [ 3200/94637 (3%)] Step: [2836552] | Lr: 0.000030 | Loss: 0.9922 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 69.88
24-04-06 18:00:51.503 - INFO: Train epoch 569: [ 6400/94637 (7%)] Step: [2836652] | Lr: 0.000030 | Loss: 1.3849 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 67.10
24-04-06 18:01:39.025 - INFO: Train epoch 569: [ 9600/94637 (10%)] Step: [2836752] | Lr: 0.000030 | Loss: 1.0951 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 64.01
24-04-06 18:02:27.015 - INFO: Train epoch 569: [12800/94637 (14%)] Step: [2836852] | Lr: 0.000030 | Loss: 1.4735 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 69.20
24-04-06 18:03:15.003 - INFO: Train epoch 569: [16000/94637 (17%)] Step: [2836952] | Lr: 0.000030 | Loss: 1.3856 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 65.81
24-04-06 18:04:02.293 - INFO: Train epoch 569: [19200/94637 (20%)] Step: [2837052] | Lr: 0.000030 | Loss: 1.2201 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 64.43
24-04-06 18:04:49.526 - INFO: Train epoch 569: [22400/94637 (24%)] Step: [2837152] | Lr: 0.000030 | Loss: 1.1140 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 67.38
24-04-06 18:05:37.936 - INFO: Train epoch 569: [25600/94637 (27%)] Step: [2837252] | Lr: 0.000030 | Loss: 0.9906 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 60.65
24-04-06 18:06:26.098 - INFO: Train epoch 569: [28800/94637 (30%)] Step: [2837352] | Lr: 0.000030 | Loss: 1.3871 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 65.03
24-04-06 18:07:14.199 - INFO: Train epoch 569: [32000/94637 (34%)] Step: [2837452] | Lr: 0.000030 | Loss: 1.4177 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 68.01
24-04-06 18:08:04.925 - INFO: Train epoch 569: [35200/94637 (37%)] Step: [2837552] | Lr: 0.000030 | Loss: 1.3337 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 63.79
24-04-06 18:08:53.443 - INFO: Train epoch 569: [38400/94637 (41%)] Step: [2837652] | Lr: 0.000030 | Loss: 0.9731 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 69.70
24-04-06 18:09:41.722 - INFO: Train epoch 569: [41600/94637 (44%)] Step: [2837752] | Lr: 0.000030 | Loss: 1.0262 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 70.20
24-04-06 18:10:29.733 - INFO: Train epoch 569: [44800/94637 (47%)] Step: [2837852] | Lr: 0.000030 | Loss: 1.2292 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 65.75
24-04-06 18:11:17.470 - INFO: Train epoch 569: [48000/94637 (51%)] Step: [2837952] | Lr: 0.000030 | Loss: 1.3934 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 70.67
24-04-06 18:12:05.560 - INFO: Train epoch 569: [51200/94637 (54%)] Step: [2838052] | Lr: 0.000030 | Loss: 1.2541 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 69.71
24-04-06 18:12:54.155 - INFO: Train epoch 569: [54400/94637 (57%)] Step: [2838152] | Lr: 0.000030 | Loss: 1.3570 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 68.60
24-04-06 18:13:42.263 - INFO: Train epoch 569: [57600/94637 (61%)] Step: [2838252] | Lr: 0.000030 | Loss: 1.6072 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 69.77
24-04-06 18:14:30.134 - INFO: Train epoch 569: [60800/94637 (64%)] Step: [2838352] | Lr: 0.000030 | Loss: 0.7123 | MSE loss: 0.0002 | Bpp loss: 0.47 | Aux loss: 69.36
24-04-06 18:15:18.750 - INFO: Train epoch 569: [64000/94637 (68%)] Step: [2838452] | Lr: 0.000030 | Loss: 1.3263 | MSE loss: 0.0004 | Bpp loss: 0.75 | Aux loss: 65.67
24-04-06 18:16:07.796 - INFO: Train epoch 569: [67200/94637 (71%)] Step: [2838552] | Lr: 0.000030 | Loss: 1.5903 | MSE loss: 0.0003 | Bpp loss: 1.05 | Aux loss: 69.22
24-04-06 18:16:56.478 - INFO: Train epoch 569: [70400/94637 (74%)] Step: [2838652] | Lr: 0.000030 | Loss: 1.2549 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 68.43
24-04-06 18:17:44.979 - INFO: Train epoch 569: [73600/94637 (78%)] Step: [2838752] | Lr: 0.000030 | Loss: 1.1703 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 70.18
24-04-06 18:18:34.065 - INFO: Train epoch 569: [76800/94637 (81%)] Step: [2838852] | Lr: 0.000030 | Loss: 1.0839 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 69.47
24-04-06 18:19:23.245 - INFO: Train epoch 569: [80000/94637 (85%)] Step: [2838952] | Lr: 0.000030 | Loss: 1.0433 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 66.96
24-04-06 18:20:12.435 - INFO: Train epoch 569: [83200/94637 (88%)] Step: [2839052] | Lr: 0.000030 | Loss: 1.1912 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 71.63
24-04-06 18:21:00.653 - INFO: Train epoch 569: [86400/94637 (91%)] Step: [2839152] | Lr: 0.000030 | Loss: 1.4798 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 67.05
24-04-06 18:21:48.748 - INFO: Train epoch 569: [89600/94637 (95%)] Step: [2839252] | Lr: 0.000030 | Loss: 1.1545 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 72.28
24-04-06 18:22:37.432 - INFO: Train epoch 569: [92800/94637 (98%)] Step: [2839352] | Lr: 0.000030 | Loss: 1.0113 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 71.90
24-04-06 18:23:16.725 - INFO: Learning rate: 3e-05
24-04-06 18:23:17.837 - INFO: Train epoch 570: [    0/94637 (0%)] Step: [2839409] | Lr: 0.000030 | Loss: 1.4898 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 68.43
24-04-06 18:24:05.727 - INFO: Train epoch 570: [ 3200/94637 (3%)] Step: [2839509] | Lr: 0.000030 | Loss: 1.3646 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 64.70
24-04-06 18:24:54.049 - INFO: Train epoch 570: [ 6400/94637 (7%)] Step: [2839609] | Lr: 0.000030 | Loss: 1.2066 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 61.82
24-04-06 18:25:42.014 - INFO: Train epoch 570: [ 9600/94637 (10%)] Step: [2839709] | Lr: 0.000030 | Loss: 1.2978 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 71.07
24-04-06 18:26:30.175 - INFO: Train epoch 570: [12800/94637 (14%)] Step: [2839809] | Lr: 0.000030 | Loss: 1.2498 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 67.00
24-04-06 18:27:18.001 - INFO: Train epoch 570: [16000/94637 (17%)] Step: [2839909] | Lr: 0.000030 | Loss: 1.1320 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 67.23
24-04-06 18:28:07.908 - INFO: Train epoch 570: [19200/94637 (20%)] Step: [2840009] | Lr: 0.000030 | Loss: 1.0570 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 60.66
24-04-06 18:28:55.508 - INFO: Train epoch 570: [22400/94637 (24%)] Step: [2840109] | Lr: 0.000030 | Loss: 1.2221 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 66.31
24-04-06 18:29:43.262 - INFO: Train epoch 570: [25600/94637 (27%)] Step: [2840209] | Lr: 0.000030 | Loss: 1.3279 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 62.58
24-04-06 18:30:30.604 - INFO: Train epoch 570: [28800/94637 (30%)] Step: [2840309] | Lr: 0.000030 | Loss: 1.4826 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 66.97
24-04-06 18:31:18.272 - INFO: Train epoch 570: [32000/94637 (34%)] Step: [2840409] | Lr: 0.000030 | Loss: 0.8130 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 62.92
24-04-06 18:32:06.335 - INFO: Train epoch 570: [35200/94637 (37%)] Step: [2840509] | Lr: 0.000030 | Loss: 1.1524 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 69.30
24-04-06 18:32:54.020 - INFO: Train epoch 570: [38400/94637 (41%)] Step: [2840609] | Lr: 0.000030 | Loss: 1.0880 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 72.82
24-04-06 18:33:42.435 - INFO: Train epoch 570: [41600/94637 (44%)] Step: [2840709] | Lr: 0.000030 | Loss: 1.0483 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 67.77
24-04-06 18:34:30.335 - INFO: Train epoch 570: [44800/94637 (47%)] Step: [2840809] | Lr: 0.000030 | Loss: 1.3119 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 70.20
24-04-06 18:35:18.862 - INFO: Train epoch 570: [48000/94637 (51%)] Step: [2840909] | Lr: 0.000030 | Loss: 1.3136 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 71.25
24-04-06 18:36:07.129 - INFO: Train epoch 570: [51200/94637 (54%)] Step: [2841009] | Lr: 0.000030 | Loss: 1.1698 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 71.37
24-04-06 18:36:55.041 - INFO: Train epoch 570: [54400/94637 (57%)] Step: [2841109] | Lr: 0.000030 | Loss: 0.8780 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 65.69
24-04-06 18:37:43.491 - INFO: Train epoch 570: [57600/94637 (61%)] Step: [2841209] | Lr: 0.000030 | Loss: 1.2499 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 63.19
24-04-06 18:38:31.903 - INFO: Train epoch 570: [60800/94637 (64%)] Step: [2841309] | Lr: 0.000030 | Loss: 0.8625 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 68.62
24-04-06 18:39:20.207 - INFO: Train epoch 570: [64000/94637 (68%)] Step: [2841409] | Lr: 0.000030 | Loss: 0.8219 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 65.49
24-04-06 18:40:08.667 - INFO: Train epoch 570: [67200/94637 (71%)] Step: [2841509] | Lr: 0.000030 | Loss: 1.1409 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 71.20
24-04-06 18:40:56.911 - INFO: Train epoch 570: [70400/94637 (74%)] Step: [2841609] | Lr: 0.000030 | Loss: 1.2278 | MSE loss: 0.0002 | Bpp loss: 0.82 | Aux loss: 67.75
24-04-06 18:41:45.433 - INFO: Train epoch 570: [73600/94637 (78%)] Step: [2841709] | Lr: 0.000030 | Loss: 1.1761 | MSE loss: 0.0002 | Bpp loss: 0.78 | Aux loss: 69.29
24-04-06 18:42:33.827 - INFO: Train epoch 570: [76800/94637 (81%)] Step: [2841809] | Lr: 0.000030 | Loss: 1.3433 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 74.40
24-04-06 18:43:21.827 - INFO: Train epoch 570: [80000/94637 (85%)] Step: [2841909] | Lr: 0.000030 | Loss: 1.3494 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 66.06
24-04-06 18:44:09.890 - INFO: Train epoch 570: [83200/94637 (88%)] Step: [2842009] | Lr: 0.000030 | Loss: 1.3572 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 67.76
24-04-06 18:44:58.033 - INFO: Train epoch 570: [86400/94637 (91%)] Step: [2842109] | Lr: 0.000030 | Loss: 1.2186 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 72.28
24-04-06 18:45:45.953 - INFO: Train epoch 570: [89600/94637 (95%)] Step: [2842209] | Lr: 0.000030 | Loss: 1.0708 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 70.73
24-04-06 18:46:35.224 - INFO: Train epoch 570: [92800/94637 (98%)] Step: [2842309] | Lr: 0.000030 | Loss: 1.0879 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 66.30
24-04-06 18:47:13.688 - INFO: Learning rate: 3e-05
24-04-06 18:47:14.772 - INFO: Train epoch 571: [    0/94637 (0%)] Step: [2842366] | Lr: 0.000030 | Loss: 1.0811 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 67.38
24-04-06 18:48:02.846 - INFO: Train epoch 571: [ 3200/94637 (3%)] Step: [2842466] | Lr: 0.000030 | Loss: 1.1112 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 71.56
24-04-06 18:48:52.714 - INFO: Train epoch 571: [ 6400/94637 (7%)] Step: [2842566] | Lr: 0.000030 | Loss: 1.3543 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 73.21
24-04-06 18:49:41.250 - INFO: Train epoch 571: [ 9600/94637 (10%)] Step: [2842666] | Lr: 0.000030 | Loss: 0.8633 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 71.57
24-04-06 18:50:29.655 - INFO: Train epoch 571: [12800/94637 (14%)] Step: [2842766] | Lr: 0.000030 | Loss: 1.1399 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 71.35
24-04-06 18:51:18.320 - INFO: Train epoch 571: [16000/94637 (17%)] Step: [2842866] | Lr: 0.000030 | Loss: 1.3613 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 67.33
24-04-06 18:52:06.412 - INFO: Train epoch 571: [19200/94637 (20%)] Step: [2842966] | Lr: 0.000030 | Loss: 1.1573 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 66.87
24-04-06 18:52:55.207 - INFO: Train epoch 571: [22400/94637 (24%)] Step: [2843066] | Lr: 0.000030 | Loss: 1.2028 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 67.57
24-04-06 18:53:43.566 - INFO: Train epoch 571: [25600/94637 (27%)] Step: [2843166] | Lr: 0.000030 | Loss: 1.6614 | MSE loss: 0.0004 | Bpp loss: 1.06 | Aux loss: 64.52
24-04-06 18:54:31.861 - INFO: Train epoch 571: [28800/94637 (30%)] Step: [2843266] | Lr: 0.000030 | Loss: 1.2354 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 67.19
24-04-06 18:55:19.898 - INFO: Train epoch 571: [32000/94637 (34%)] Step: [2843366] | Lr: 0.000030 | Loss: 1.1290 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 69.19
24-04-06 18:56:08.213 - INFO: Train epoch 571: [35200/94637 (37%)] Step: [2843466] | Lr: 0.000030 | Loss: 0.9742 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 64.34
24-04-06 18:56:56.708 - INFO: Train epoch 571: [38400/94637 (41%)] Step: [2843566] | Lr: 0.000030 | Loss: 1.3253 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 70.99
24-04-06 18:57:45.207 - INFO: Train epoch 571: [41600/94637 (44%)] Step: [2843666] | Lr: 0.000030 | Loss: 1.4438 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 67.82
24-04-06 18:58:33.678 - INFO: Train epoch 571: [44800/94637 (47%)] Step: [2843766] | Lr: 0.000030 | Loss: 1.3295 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 63.92
24-04-06 18:59:21.473 - INFO: Train epoch 571: [48000/94637 (51%)] Step: [2843866] | Lr: 0.000030 | Loss: 1.0952 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 70.08
24-04-06 19:00:09.589 - INFO: Train epoch 571: [51200/94637 (54%)] Step: [2843966] | Lr: 0.000030 | Loss: 1.0879 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 71.42
24-04-06 19:00:57.323 - INFO: Train epoch 571: [54400/94637 (57%)] Step: [2844066] | Lr: 0.000030 | Loss: 1.3731 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 71.05
24-04-06 19:01:45.160 - INFO: Train epoch 571: [57600/94637 (61%)] Step: [2844166] | Lr: 0.000030 | Loss: 0.9685 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 68.94
24-04-06 19:02:33.038 - INFO: Train epoch 571: [60800/94637 (64%)] Step: [2844266] | Lr: 0.000030 | Loss: 1.3532 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 66.44
24-04-06 19:03:20.926 - INFO: Train epoch 571: [64000/94637 (68%)] Step: [2844366] | Lr: 0.000030 | Loss: 1.2221 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 65.11
24-04-06 19:04:08.487 - INFO: Train epoch 571: [67200/94637 (71%)] Step: [2844466] | Lr: 0.000030 | Loss: 1.3732 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 71.36
24-04-06 19:04:55.627 - INFO: Train epoch 571: [70400/94637 (74%)] Step: [2844566] | Lr: 0.000030 | Loss: 1.1239 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 70.86
24-04-06 19:05:42.905 - INFO: Train epoch 571: [73600/94637 (78%)] Step: [2844666] | Lr: 0.000030 | Loss: 1.0892 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 69.18
24-04-06 19:06:30.435 - INFO: Train epoch 571: [76800/94637 (81%)] Step: [2844766] | Lr: 0.000030 | Loss: 1.4668 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 66.81
24-04-06 19:07:18.239 - INFO: Train epoch 571: [80000/94637 (85%)] Step: [2844866] | Lr: 0.000030 | Loss: 1.0291 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 67.55
24-04-06 19:08:06.147 - INFO: Train epoch 571: [83200/94637 (88%)] Step: [2844966] | Lr: 0.000030 | Loss: 1.4328 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 69.31
24-04-06 19:08:56.260 - INFO: Train epoch 571: [86400/94637 (91%)] Step: [2845066] | Lr: 0.000030 | Loss: 1.0723 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 69.00
24-04-06 19:09:44.527 - INFO: Train epoch 571: [89600/94637 (95%)] Step: [2845166] | Lr: 0.000030 | Loss: 1.0723 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 68.53
24-04-06 19:10:33.118 - INFO: Train epoch 571: [92800/94637 (98%)] Step: [2845266] | Lr: 0.000030 | Loss: 1.3950 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 74.97
24-04-06 19:11:11.762 - INFO: Learning rate: 3e-05
24-04-06 19:11:12.866 - INFO: Train epoch 572: [    0/94637 (0%)] Step: [2845323] | Lr: 0.000030 | Loss: 1.0126 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 71.75
24-04-06 19:12:00.969 - INFO: Train epoch 572: [ 3200/94637 (3%)] Step: [2845423] | Lr: 0.000030 | Loss: 1.2352 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 68.15
24-04-06 19:12:49.520 - INFO: Train epoch 572: [ 6400/94637 (7%)] Step: [2845523] | Lr: 0.000030 | Loss: 1.2947 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 71.87
24-04-06 19:13:37.352 - INFO: Train epoch 572: [ 9600/94637 (10%)] Step: [2845623] | Lr: 0.000030 | Loss: 1.1449 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 63.70
24-04-06 19:14:25.743 - INFO: Train epoch 572: [12800/94637 (14%)] Step: [2845723] | Lr: 0.000030 | Loss: 1.0462 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 68.56
24-04-06 19:15:14.302 - INFO: Train epoch 572: [16000/94637 (17%)] Step: [2845823] | Lr: 0.000030 | Loss: 1.3918 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 67.67
24-04-06 19:16:02.027 - INFO: Train epoch 572: [19200/94637 (20%)] Step: [2845923] | Lr: 0.000030 | Loss: 1.4607 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 69.67
24-04-06 19:16:50.453 - INFO: Train epoch 572: [22400/94637 (24%)] Step: [2846023] | Lr: 0.000030 | Loss: 1.3002 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 65.73
24-04-06 19:17:38.595 - INFO: Train epoch 572: [25600/94637 (27%)] Step: [2846123] | Lr: 0.000030 | Loss: 1.4448 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 67.03
24-04-06 19:18:26.811 - INFO: Train epoch 572: [28800/94637 (30%)] Step: [2846223] | Lr: 0.000030 | Loss: 0.9618 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 71.21
24-04-06 19:19:14.997 - INFO: Train epoch 572: [32000/94637 (34%)] Step: [2846323] | Lr: 0.000030 | Loss: 1.2986 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 73.86
24-04-06 19:20:03.559 - INFO: Train epoch 572: [35200/94637 (37%)] Step: [2846423] | Lr: 0.000030 | Loss: 1.6405 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 68.88
24-04-06 19:20:52.753 - INFO: Train epoch 572: [38400/94637 (41%)] Step: [2846523] | Lr: 0.000030 | Loss: 1.2724 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 66.78
24-04-06 19:21:41.201 - INFO: Train epoch 572: [41600/94637 (44%)] Step: [2846623] | Lr: 0.000030 | Loss: 1.1587 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 68.73
24-04-06 19:22:29.225 - INFO: Train epoch 572: [44800/94637 (47%)] Step: [2846723] | Lr: 0.000030 | Loss: 1.2325 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 67.96
24-04-06 19:23:17.081 - INFO: Train epoch 572: [48000/94637 (51%)] Step: [2846823] | Lr: 0.000030 | Loss: 0.8413 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 67.48
24-04-06 19:24:05.023 - INFO: Train epoch 572: [51200/94637 (54%)] Step: [2846923] | Lr: 0.000030 | Loss: 0.9561 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 71.71
24-04-06 19:24:53.031 - INFO: Train epoch 572: [54400/94637 (57%)] Step: [2847023] | Lr: 0.000030 | Loss: 1.3223 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 65.11
24-04-06 19:25:41.277 - INFO: Train epoch 572: [57600/94637 (61%)] Step: [2847123] | Lr: 0.000030 | Loss: 1.2262 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 69.18
24-04-06 19:26:29.375 - INFO: Train epoch 572: [60800/94637 (64%)] Step: [2847223] | Lr: 0.000030 | Loss: 1.2117 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 70.88
24-04-06 19:27:18.070 - INFO: Train epoch 572: [64000/94637 (68%)] Step: [2847323] | Lr: 0.000030 | Loss: 1.1642 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 65.75
24-04-06 19:28:06.487 - INFO: Train epoch 572: [67200/94637 (71%)] Step: [2847423] | Lr: 0.000030 | Loss: 1.2960 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 71.04
24-04-06 19:28:56.522 - INFO: Train epoch 572: [70400/94637 (74%)] Step: [2847523] | Lr: 0.000030 | Loss: 1.3677 | MSE loss: 0.0004 | Bpp loss: 0.79 | Aux loss: 69.64
24-04-06 19:29:45.471 - INFO: Train epoch 572: [73600/94637 (78%)] Step: [2847623] | Lr: 0.000030 | Loss: 1.1439 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 67.56
24-04-06 19:30:33.878 - INFO: Train epoch 572: [76800/94637 (81%)] Step: [2847723] | Lr: 0.000030 | Loss: 1.1455 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 71.29
24-04-06 19:31:22.979 - INFO: Train epoch 572: [80000/94637 (85%)] Step: [2847823] | Lr: 0.000030 | Loss: 0.9972 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 73.08
24-04-06 19:32:11.895 - INFO: Train epoch 572: [83200/94637 (88%)] Step: [2847923] | Lr: 0.000030 | Loss: 1.3017 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 73.78
24-04-06 19:33:00.952 - INFO: Train epoch 572: [86400/94637 (91%)] Step: [2848023] | Lr: 0.000030 | Loss: 1.4095 | MSE loss: 0.0004 | Bpp loss: 0.83 | Aux loss: 71.34
24-04-06 19:33:50.149 - INFO: Train epoch 572: [89600/94637 (95%)] Step: [2848123] | Lr: 0.000030 | Loss: 1.3022 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 68.99
24-04-06 19:34:39.252 - INFO: Train epoch 572: [92800/94637 (98%)] Step: [2848223] | Lr: 0.000030 | Loss: 0.8055 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 65.63
24-04-06 19:35:18.036 - INFO: Learning rate: 3e-05
24-04-06 19:35:19.248 - INFO: Train epoch 573: [    0/94637 (0%)] Step: [2848280] | Lr: 0.000030 | Loss: 1.2498 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 68.64
24-04-06 19:36:08.052 - INFO: Train epoch 573: [ 3200/94637 (3%)] Step: [2848380] | Lr: 0.000030 | Loss: 1.0178 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 64.87
24-04-06 19:36:56.514 - INFO: Train epoch 573: [ 6400/94637 (7%)] Step: [2848480] | Lr: 0.000030 | Loss: 1.0531 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 75.69
24-04-06 19:37:45.629 - INFO: Train epoch 573: [ 9600/94637 (10%)] Step: [2848580] | Lr: 0.000030 | Loss: 1.5341 | MSE loss: 0.0003 | Bpp loss: 0.98 | Aux loss: 65.28
24-04-06 19:38:34.172 - INFO: Train epoch 573: [12800/94637 (14%)] Step: [2848680] | Lr: 0.000030 | Loss: 0.8907 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 72.11
24-04-06 19:39:23.145 - INFO: Train epoch 573: [16000/94637 (17%)] Step: [2848780] | Lr: 0.000030 | Loss: 1.0097 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 70.26
24-04-06 19:40:12.660 - INFO: Train epoch 573: [19200/94637 (20%)] Step: [2848880] | Lr: 0.000030 | Loss: 1.0599 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 66.78
24-04-06 19:41:02.013 - INFO: Train epoch 573: [22400/94637 (24%)] Step: [2848980] | Lr: 0.000030 | Loss: 1.6536 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 71.97
24-04-06 19:41:50.899 - INFO: Train epoch 573: [25600/94637 (27%)] Step: [2849080] | Lr: 0.000030 | Loss: 1.0921 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 67.34
24-04-06 19:42:39.860 - INFO: Train epoch 573: [28800/94637 (30%)] Step: [2849180] | Lr: 0.000030 | Loss: 1.1037 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 72.97
24-04-06 19:43:28.751 - INFO: Train epoch 573: [32000/94637 (34%)] Step: [2849280] | Lr: 0.000030 | Loss: 1.0466 | MSE loss: 0.0003 | Bpp loss: 0.62 | Aux loss: 67.22
24-04-06 19:44:18.194 - INFO: Train epoch 573: [35200/94637 (37%)] Step: [2849380] | Lr: 0.000030 | Loss: 1.4615 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 71.15
24-04-06 19:45:07.212 - INFO: Train epoch 573: [38400/94637 (41%)] Step: [2849480] | Lr: 0.000030 | Loss: 1.5623 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 62.32
24-04-06 19:45:56.125 - INFO: Train epoch 573: [41600/94637 (44%)] Step: [2849580] | Lr: 0.000030 | Loss: 1.1934 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 73.00
24-04-06 19:46:45.114 - INFO: Train epoch 573: [44800/94637 (47%)] Step: [2849680] | Lr: 0.000030 | Loss: 1.3442 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 72.76
24-04-06 19:47:34.848 - INFO: Train epoch 573: [48000/94637 (51%)] Step: [2849780] | Lr: 0.000030 | Loss: 1.0693 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 68.10
24-04-06 19:48:24.078 - INFO: Train epoch 573: [51200/94637 (54%)] Step: [2849880] | Lr: 0.000030 | Loss: 1.1256 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 68.61
24-04-06 19:49:13.374 - INFO: Train epoch 573: [54400/94637 (57%)] Step: [2849980] | Lr: 0.000030 | Loss: 1.5797 | MSE loss: 0.0004 | Bpp loss: 0.99 | Aux loss: 67.50
24-04-06 19:50:04.659 - INFO: Train epoch 573: [57600/94637 (61%)] Step: [2850080] | Lr: 0.000030 | Loss: 1.0208 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 70.54
24-04-06 19:50:53.912 - INFO: Train epoch 573: [60800/94637 (64%)] Step: [2850180] | Lr: 0.000030 | Loss: 1.0642 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 71.73
24-04-06 19:51:43.015 - INFO: Train epoch 573: [64000/94637 (68%)] Step: [2850280] | Lr: 0.000030 | Loss: 1.3986 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 64.02
24-04-06 19:52:31.659 - INFO: Train epoch 573: [67200/94637 (71%)] Step: [2850380] | Lr: 0.000030 | Loss: 1.0423 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 65.36
24-04-06 19:53:20.095 - INFO: Train epoch 573: [70400/94637 (74%)] Step: [2850480] | Lr: 0.000030 | Loss: 1.4742 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 74.79
24-04-06 19:54:08.253 - INFO: Train epoch 573: [73600/94637 (78%)] Step: [2850580] | Lr: 0.000030 | Loss: 0.9271 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 65.15
24-04-06 19:54:56.331 - INFO: Train epoch 573: [76800/94637 (81%)] Step: [2850680] | Lr: 0.000030 | Loss: 1.2685 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 72.31
24-04-06 19:55:44.508 - INFO: Train epoch 573: [80000/94637 (85%)] Step: [2850780] | Lr: 0.000030 | Loss: 1.6903 | MSE loss: 0.0004 | Bpp loss: 1.09 | Aux loss: 67.85
24-04-06 19:56:33.011 - INFO: Train epoch 573: [83200/94637 (88%)] Step: [2850880] | Lr: 0.000030 | Loss: 1.0827 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 66.79
24-04-06 19:57:21.096 - INFO: Train epoch 573: [86400/94637 (91%)] Step: [2850980] | Lr: 0.000030 | Loss: 1.2483 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 65.08
24-04-06 19:58:09.471 - INFO: Train epoch 573: [89600/94637 (95%)] Step: [2851080] | Lr: 0.000030 | Loss: 0.8058 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 72.36
24-04-06 19:58:57.856 - INFO: Train epoch 573: [92800/94637 (98%)] Step: [2851180] | Lr: 0.000030 | Loss: 1.4271 | MSE loss: 0.0004 | Bpp loss: 0.86 | Aux loss: 69.58
24-04-06 19:59:36.210 - INFO: Learning rate: 3e-05
24-04-06 19:59:37.320 - INFO: Train epoch 574: [    0/94637 (0%)] Step: [2851237] | Lr: 0.000030 | Loss: 0.9375 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 74.62
24-04-06 20:00:25.443 - INFO: Train epoch 574: [ 3200/94637 (3%)] Step: [2851337] | Lr: 0.000030 | Loss: 1.6667 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 73.14
24-04-06 20:01:13.279 - INFO: Train epoch 574: [ 6400/94637 (7%)] Step: [2851437] | Lr: 0.000030 | Loss: 0.8507 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 71.28
24-04-06 20:02:01.946 - INFO: Train epoch 574: [ 9600/94637 (10%)] Step: [2851537] | Lr: 0.000030 | Loss: 0.9375 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 70.12
24-04-06 20:02:50.416 - INFO: Train epoch 574: [12800/94637 (14%)] Step: [2851637] | Lr: 0.000030 | Loss: 1.4732 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 72.15
24-04-06 20:03:39.089 - INFO: Train epoch 574: [16000/94637 (17%)] Step: [2851737] | Lr: 0.000030 | Loss: 1.6553 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 66.31
24-04-06 20:04:27.436 - INFO: Train epoch 574: [19200/94637 (20%)] Step: [2851837] | Lr: 0.000030 | Loss: 0.9001 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 63.13
24-04-06 20:05:15.871 - INFO: Train epoch 574: [22400/94637 (24%)] Step: [2851937] | Lr: 0.000030 | Loss: 1.1433 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 71.73
24-04-06 20:06:03.982 - INFO: Train epoch 574: [25600/94637 (27%)] Step: [2852037] | Lr: 0.000030 | Loss: 1.3389 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 66.75
24-04-06 20:06:52.085 - INFO: Train epoch 574: [28800/94637 (30%)] Step: [2852137] | Lr: 0.000030 | Loss: 1.6188 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 73.70
24-04-06 20:07:40.238 - INFO: Train epoch 574: [32000/94637 (34%)] Step: [2852237] | Lr: 0.000030 | Loss: 0.9591 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 69.45
24-04-06 20:08:28.446 - INFO: Train epoch 574: [35200/94637 (37%)] Step: [2852337] | Lr: 0.000030 | Loss: 0.9809 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 72.55
24-04-06 20:09:17.058 - INFO: Train epoch 574: [38400/94637 (41%)] Step: [2852437] | Lr: 0.000030 | Loss: 1.0968 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 72.03
24-04-06 20:10:07.800 - INFO: Train epoch 574: [41600/94637 (44%)] Step: [2852537] | Lr: 0.000030 | Loss: 1.2117 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 64.54
24-04-06 20:10:57.194 - INFO: Train epoch 574: [44800/94637 (47%)] Step: [2852637] | Lr: 0.000030 | Loss: 1.1312 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 67.84
24-04-06 20:11:45.701 - INFO: Train epoch 574: [48000/94637 (51%)] Step: [2852737] | Lr: 0.000030 | Loss: 1.0662 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 73.76
24-04-06 20:12:34.418 - INFO: Train epoch 574: [51200/94637 (54%)] Step: [2852837] | Lr: 0.000030 | Loss: 1.8180 | MSE loss: 0.0005 | Bpp loss: 1.01 | Aux loss: 67.67
24-04-06 20:13:22.473 - INFO: Train epoch 574: [54400/94637 (57%)] Step: [2852937] | Lr: 0.000030 | Loss: 0.8358 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 70.69
24-04-06 20:14:10.647 - INFO: Train epoch 574: [57600/94637 (61%)] Step: [2853037] | Lr: 0.000030 | Loss: 1.2038 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 65.69
24-04-06 20:14:58.642 - INFO: Train epoch 574: [60800/94637 (64%)] Step: [2853137] | Lr: 0.000030 | Loss: 1.1846 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 76.61
24-04-06 20:15:47.039 - INFO: Train epoch 574: [64000/94637 (68%)] Step: [2853237] | Lr: 0.000030 | Loss: 1.1540 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 71.11
24-04-06 20:16:35.166 - INFO: Train epoch 574: [67200/94637 (71%)] Step: [2853337] | Lr: 0.000030 | Loss: 1.4522 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 66.34
24-04-06 20:17:23.332 - INFO: Train epoch 574: [70400/94637 (74%)] Step: [2853437] | Lr: 0.000030 | Loss: 1.3847 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 65.63
24-04-06 20:18:11.160 - INFO: Train epoch 574: [73600/94637 (78%)] Step: [2853537] | Lr: 0.000030 | Loss: 1.0688 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 69.39
24-04-06 20:18:59.571 - INFO: Train epoch 574: [76800/94637 (81%)] Step: [2853637] | Lr: 0.000030 | Loss: 0.9552 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 66.91
24-04-06 20:19:47.586 - INFO: Train epoch 574: [80000/94637 (85%)] Step: [2853737] | Lr: 0.000030 | Loss: 1.1893 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 75.80
24-04-06 20:20:36.074 - INFO: Train epoch 574: [83200/94637 (88%)] Step: [2853837] | Lr: 0.000030 | Loss: 1.2703 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 69.02
24-04-06 20:21:24.512 - INFO: Train epoch 574: [86400/94637 (91%)] Step: [2853937] | Lr: 0.000030 | Loss: 1.0608 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 67.72
24-04-06 20:22:12.992 - INFO: Train epoch 574: [89600/94637 (95%)] Step: [2854037] | Lr: 0.000030 | Loss: 1.5005 | MSE loss: 0.0004 | Bpp loss: 0.88 | Aux loss: 68.48
24-04-06 20:23:01.788 - INFO: Train epoch 574: [92800/94637 (98%)] Step: [2854137] | Lr: 0.000030 | Loss: 1.0481 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 76.35
24-04-06 20:23:40.608 - INFO: Learning rate: 3e-05
24-04-06 20:23:41.739 - INFO: Train epoch 575: [    0/94637 (0%)] Step: [2854194] | Lr: 0.000030 | Loss: 0.9397 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 72.61
24-04-06 20:24:29.970 - INFO: Train epoch 575: [ 3200/94637 (3%)] Step: [2854294] | Lr: 0.000030 | Loss: 1.0431 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 69.04
24-04-06 20:25:18.554 - INFO: Train epoch 575: [ 6400/94637 (7%)] Step: [2854394] | Lr: 0.000030 | Loss: 1.0630 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 66.17
24-04-06 20:26:06.433 - INFO: Train epoch 575: [ 9600/94637 (10%)] Step: [2854494] | Lr: 0.000030 | Loss: 1.2787 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 64.85
24-04-06 20:26:54.755 - INFO: Train epoch 575: [12800/94637 (14%)] Step: [2854594] | Lr: 0.000030 | Loss: 1.2786 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 67.65
24-04-06 20:27:42.569 - INFO: Train epoch 575: [16000/94637 (17%)] Step: [2854694] | Lr: 0.000030 | Loss: 0.9255 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 69.03
24-04-06 20:28:31.164 - INFO: Train epoch 575: [19200/94637 (20%)] Step: [2854794] | Lr: 0.000030 | Loss: 1.2823 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 67.35
24-04-06 20:29:19.887 - INFO: Train epoch 575: [22400/94637 (24%)] Step: [2854894] | Lr: 0.000030 | Loss: 1.3285 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 64.94
24-04-06 20:30:08.027 - INFO: Train epoch 575: [25600/94637 (27%)] Step: [2854994] | Lr: 0.000030 | Loss: 1.5035 | MSE loss: 0.0003 | Bpp loss: 0.96 | Aux loss: 65.74
24-04-06 20:30:59.100 - INFO: Train epoch 575: [28800/94637 (30%)] Step: [2855094] | Lr: 0.000030 | Loss: 1.2427 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 67.41
24-04-06 20:31:47.497 - INFO: Train epoch 575: [32000/94637 (34%)] Step: [2855194] | Lr: 0.000030 | Loss: 1.0687 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 73.22
24-04-06 20:32:36.174 - INFO: Train epoch 575: [35200/94637 (37%)] Step: [2855294] | Lr: 0.000030 | Loss: 1.1272 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 72.21
24-04-06 20:33:24.751 - INFO: Train epoch 575: [38400/94637 (41%)] Step: [2855394] | Lr: 0.000030 | Loss: 0.8734 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 69.61
24-04-06 20:34:12.547 - INFO: Train epoch 575: [41600/94637 (44%)] Step: [2855494] | Lr: 0.000030 | Loss: 0.9214 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 73.88
24-04-06 20:35:00.932 - INFO: Train epoch 575: [44800/94637 (47%)] Step: [2855594] | Lr: 0.000030 | Loss: 1.1590 | MSE loss: 0.0002 | Bpp loss: 0.76 | Aux loss: 68.26
24-04-06 20:35:49.096 - INFO: Train epoch 575: [48000/94637 (51%)] Step: [2855694] | Lr: 0.000030 | Loss: 1.2093 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 70.61
24-04-06 20:36:37.764 - INFO: Train epoch 575: [51200/94637 (54%)] Step: [2855794] | Lr: 0.000030 | Loss: 1.2869 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 69.09
24-04-06 20:37:26.730 - INFO: Train epoch 575: [54400/94637 (57%)] Step: [2855894] | Lr: 0.000030 | Loss: 1.2656 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 66.15
24-04-06 20:38:15.519 - INFO: Train epoch 575: [57600/94637 (61%)] Step: [2855994] | Lr: 0.000030 | Loss: 1.6217 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 72.02
24-04-06 20:39:04.294 - INFO: Train epoch 575: [60800/94637 (64%)] Step: [2856094] | Lr: 0.000030 | Loss: 1.4097 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 69.80
24-04-06 20:39:53.262 - INFO: Train epoch 575: [64000/94637 (68%)] Step: [2856194] | Lr: 0.000030 | Loss: 0.9983 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 69.54
24-04-06 20:40:41.989 - INFO: Train epoch 575: [67200/94637 (71%)] Step: [2856294] | Lr: 0.000030 | Loss: 1.0121 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 71.49
24-04-06 20:41:30.622 - INFO: Train epoch 575: [70400/94637 (74%)] Step: [2856394] | Lr: 0.000030 | Loss: 0.8453 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 71.46
24-04-06 20:42:19.118 - INFO: Train epoch 575: [73600/94637 (78%)] Step: [2856494] | Lr: 0.000030 | Loss: 1.5362 | MSE loss: 0.0003 | Bpp loss: 0.98 | Aux loss: 68.05
24-04-06 20:43:07.820 - INFO: Train epoch 575: [76800/94637 (81%)] Step: [2856594] | Lr: 0.000030 | Loss: 1.4754 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 67.17
24-04-06 20:43:56.491 - INFO: Train epoch 575: [80000/94637 (85%)] Step: [2856694] | Lr: 0.000030 | Loss: 1.1022 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 68.07
24-04-06 20:44:45.396 - INFO: Train epoch 575: [83200/94637 (88%)] Step: [2856794] | Lr: 0.000030 | Loss: 0.9269 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 68.81
24-04-06 20:45:34.743 - INFO: Train epoch 575: [86400/94637 (91%)] Step: [2856894] | Lr: 0.000030 | Loss: 1.0665 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 71.18
24-04-06 20:46:23.645 - INFO: Train epoch 575: [89600/94637 (95%)] Step: [2856994] | Lr: 0.000030 | Loss: 1.0649 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 69.86
24-04-06 20:47:12.160 - INFO: Train epoch 575: [92800/94637 (98%)] Step: [2857094] | Lr: 0.000030 | Loss: 1.1675 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 70.46
24-04-06 20:47:51.216 - INFO: Learning rate: 3e-05
24-04-06 20:47:53.418 - INFO: Train epoch 576: [    0/94637 (0%)] Step: [2857151] | Lr: 0.000030 | Loss: 0.8382 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 71.27
24-04-06 20:48:41.778 - INFO: Train epoch 576: [ 3200/94637 (3%)] Step: [2857251] | Lr: 0.000030 | Loss: 1.1228 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 70.95
24-04-06 20:49:29.502 - INFO: Train epoch 576: [ 6400/94637 (7%)] Step: [2857351] | Lr: 0.000030 | Loss: 1.4964 | MSE loss: 0.0003 | Bpp loss: 0.98 | Aux loss: 67.57
24-04-06 20:50:17.074 - INFO: Train epoch 576: [ 9600/94637 (10%)] Step: [2857451] | Lr: 0.000030 | Loss: 1.1208 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 68.10
24-04-06 20:51:06.782 - INFO: Train epoch 576: [12800/94637 (14%)] Step: [2857551] | Lr: 0.000030 | Loss: 1.1883 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 75.42
24-04-06 20:51:55.204 - INFO: Train epoch 576: [16000/94637 (17%)] Step: [2857651] | Lr: 0.000030 | Loss: 1.5653 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 72.57
24-04-06 20:52:43.450 - INFO: Train epoch 576: [19200/94637 (20%)] Step: [2857751] | Lr: 0.000030 | Loss: 1.2860 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 73.46
24-04-06 20:53:30.901 - INFO: Train epoch 576: [22400/94637 (24%)] Step: [2857851] | Lr: 0.000030 | Loss: 1.3896 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 71.18
24-04-06 20:54:19.081 - INFO: Train epoch 576: [25600/94637 (27%)] Step: [2857951] | Lr: 0.000030 | Loss: 0.8745 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 75.85
24-04-06 20:55:07.295 - INFO: Train epoch 576: [28800/94637 (30%)] Step: [2858051] | Lr: 0.000030 | Loss: 1.4591 | MSE loss: 0.0004 | Bpp loss: 0.86 | Aux loss: 68.14
24-04-06 20:55:55.249 - INFO: Train epoch 576: [32000/94637 (34%)] Step: [2858151] | Lr: 0.000030 | Loss: 1.3576 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 70.49
24-04-06 20:56:43.205 - INFO: Train epoch 576: [35200/94637 (37%)] Step: [2858251] | Lr: 0.000030 | Loss: 1.2106 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 66.17
24-04-06 20:57:31.786 - INFO: Train epoch 576: [38400/94637 (41%)] Step: [2858351] | Lr: 0.000030 | Loss: 0.9906 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 71.76
24-04-06 20:58:20.991 - INFO: Train epoch 576: [41600/94637 (44%)] Step: [2858451] | Lr: 0.000030 | Loss: 1.0504 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 75.81
24-04-06 20:59:09.221 - INFO: Train epoch 576: [44800/94637 (47%)] Step: [2858551] | Lr: 0.000030 | Loss: 1.0949 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 68.15
24-04-06 20:59:56.804 - INFO: Train epoch 576: [48000/94637 (51%)] Step: [2858651] | Lr: 0.000030 | Loss: 0.9698 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 66.45
24-04-06 21:00:44.555 - INFO: Train epoch 576: [51200/94637 (54%)] Step: [2858751] | Lr: 0.000030 | Loss: 1.2825 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 68.89
24-04-06 21:01:32.782 - INFO: Train epoch 576: [54400/94637 (57%)] Step: [2858851] | Lr: 0.000030 | Loss: 0.7378 | MSE loss: 0.0002 | Bpp loss: 0.48 | Aux loss: 70.11
24-04-06 21:02:21.019 - INFO: Train epoch 576: [57600/94637 (61%)] Step: [2858951] | Lr: 0.000030 | Loss: 1.6165 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 67.61
24-04-06 21:03:08.699 - INFO: Train epoch 576: [60800/94637 (64%)] Step: [2859051] | Lr: 0.000030 | Loss: 1.3746 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 66.48
24-04-06 21:03:56.697 - INFO: Train epoch 576: [64000/94637 (68%)] Step: [2859151] | Lr: 0.000030 | Loss: 0.9509 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 68.88
24-04-06 21:04:44.822 - INFO: Train epoch 576: [67200/94637 (71%)] Step: [2859251] | Lr: 0.000030 | Loss: 1.0353 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 69.42
24-04-06 21:05:32.757 - INFO: Train epoch 576: [70400/94637 (74%)] Step: [2859351] | Lr: 0.000030 | Loss: 1.4973 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 71.85
24-04-06 21:06:20.549 - INFO: Train epoch 576: [73600/94637 (78%)] Step: [2859451] | Lr: 0.000030 | Loss: 1.4985 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 65.52
24-04-06 21:07:08.864 - INFO: Train epoch 576: [76800/94637 (81%)] Step: [2859551] | Lr: 0.000030 | Loss: 1.0401 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 70.07
24-04-06 21:07:57.363 - INFO: Train epoch 576: [80000/94637 (85%)] Step: [2859651] | Lr: 0.000030 | Loss: 1.2628 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 67.71
24-04-06 21:08:45.622 - INFO: Train epoch 576: [83200/94637 (88%)] Step: [2859751] | Lr: 0.000030 | Loss: 1.0598 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 70.29
24-04-06 21:09:34.085 - INFO: Train epoch 576: [86400/94637 (91%)] Step: [2859851] | Lr: 0.000030 | Loss: 1.5586 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 68.78
24-04-06 21:10:22.754 - INFO: Train epoch 576: [89600/94637 (95%)] Step: [2859951] | Lr: 0.000030 | Loss: 1.1975 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 71.17
24-04-06 21:11:13.858 - INFO: Train epoch 576: [92800/94637 (98%)] Step: [2860051] | Lr: 0.000030 | Loss: 1.2645 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 71.77
24-04-06 21:11:52.244 - INFO: Learning rate: 3e-05
24-04-06 21:11:53.298 - INFO: Train epoch 577: [    0/94637 (0%)] Step: [2860108] | Lr: 0.000030 | Loss: 1.7702 | MSE loss: 0.0004 | Bpp loss: 1.16 | Aux loss: 63.49
24-04-06 21:12:41.864 - INFO: Train epoch 577: [ 3200/94637 (3%)] Step: [2860208] | Lr: 0.000030 | Loss: 1.0066 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 67.94
24-04-06 21:13:31.149 - INFO: Train epoch 577: [ 6400/94637 (7%)] Step: [2860308] | Lr: 0.000030 | Loss: 1.1315 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 67.80
24-04-06 21:14:18.782 - INFO: Train epoch 577: [ 9600/94637 (10%)] Step: [2860408] | Lr: 0.000030 | Loss: 1.1813 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 62.81
24-04-06 21:15:06.537 - INFO: Train epoch 577: [12800/94637 (14%)] Step: [2860508] | Lr: 0.000030 | Loss: 1.7820 | MSE loss: 0.0004 | Bpp loss: 1.09 | Aux loss: 77.37
24-04-06 21:15:54.172 - INFO: Train epoch 577: [16000/94637 (17%)] Step: [2860608] | Lr: 0.000030 | Loss: 1.3921 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 73.21
24-04-06 21:16:41.908 - INFO: Train epoch 577: [19200/94637 (20%)] Step: [2860708] | Lr: 0.000030 | Loss: 0.9913 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 68.47
24-04-06 21:17:30.046 - INFO: Train epoch 577: [22400/94637 (24%)] Step: [2860808] | Lr: 0.000030 | Loss: 1.3847 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 68.71
24-04-06 21:18:18.037 - INFO: Train epoch 577: [25600/94637 (27%)] Step: [2860908] | Lr: 0.000030 | Loss: 1.3499 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 67.76
24-04-06 21:19:05.802 - INFO: Train epoch 577: [28800/94637 (30%)] Step: [2861008] | Lr: 0.000030 | Loss: 1.0063 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 69.14
24-04-06 21:19:53.739 - INFO: Train epoch 577: [32000/94637 (34%)] Step: [2861108] | Lr: 0.000030 | Loss: 1.0051 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 68.52
24-04-06 21:20:42.463 - INFO: Train epoch 577: [35200/94637 (37%)] Step: [2861208] | Lr: 0.000030 | Loss: 1.4042 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 74.83
24-04-06 21:21:30.948 - INFO: Train epoch 577: [38400/94637 (41%)] Step: [2861308] | Lr: 0.000030 | Loss: 1.1598 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 69.31
24-04-06 21:22:19.384 - INFO: Train epoch 577: [41600/94637 (44%)] Step: [2861408] | Lr: 0.000030 | Loss: 0.9845 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 73.50
24-04-06 21:23:08.054 - INFO: Train epoch 577: [44800/94637 (47%)] Step: [2861508] | Lr: 0.000030 | Loss: 1.5333 | MSE loss: 0.0003 | Bpp loss: 0.98 | Aux loss: 72.16
24-04-06 21:23:56.218 - INFO: Train epoch 577: [48000/94637 (51%)] Step: [2861608] | Lr: 0.000030 | Loss: 1.2194 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 70.34
24-04-06 21:24:44.670 - INFO: Train epoch 577: [51200/94637 (54%)] Step: [2861708] | Lr: 0.000030 | Loss: 1.2270 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 69.93
24-04-06 21:25:33.337 - INFO: Train epoch 577: [54400/94637 (57%)] Step: [2861808] | Lr: 0.000030 | Loss: 1.0354 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 66.89
24-04-06 21:26:21.794 - INFO: Train epoch 577: [57600/94637 (61%)] Step: [2861908] | Lr: 0.000030 | Loss: 1.2039 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 66.19
24-04-06 21:27:10.439 - INFO: Train epoch 577: [60800/94637 (64%)] Step: [2862008] | Lr: 0.000030 | Loss: 1.5521 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 68.25
24-04-06 21:27:58.587 - INFO: Train epoch 577: [64000/94637 (68%)] Step: [2862108] | Lr: 0.000030 | Loss: 1.2172 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 72.02
24-04-06 21:28:46.815 - INFO: Train epoch 577: [67200/94637 (71%)] Step: [2862208] | Lr: 0.000030 | Loss: 0.9959 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 68.86
24-04-06 21:29:34.987 - INFO: Train epoch 577: [70400/94637 (74%)] Step: [2862308] | Lr: 0.000030 | Loss: 1.4366 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 68.39
24-04-06 21:30:23.573 - INFO: Train epoch 577: [73600/94637 (78%)] Step: [2862408] | Lr: 0.000030 | Loss: 0.7951 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 66.75
24-04-06 21:31:13.680 - INFO: Train epoch 577: [76800/94637 (81%)] Step: [2862508] | Lr: 0.000030 | Loss: 1.0956 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 70.45
24-04-06 21:32:02.710 - INFO: Train epoch 577: [80000/94637 (85%)] Step: [2862608] | Lr: 0.000030 | Loss: 1.2299 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 69.11
24-04-06 21:32:50.974 - INFO: Train epoch 577: [83200/94637 (88%)] Step: [2862708] | Lr: 0.000030 | Loss: 1.2426 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 68.00
24-04-06 21:33:39.786 - INFO: Train epoch 577: [86400/94637 (91%)] Step: [2862808] | Lr: 0.000030 | Loss: 1.2767 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 71.01
24-04-06 21:34:28.274 - INFO: Train epoch 577: [89600/94637 (95%)] Step: [2862908] | Lr: 0.000030 | Loss: 1.3483 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 66.03
24-04-06 21:35:17.081 - INFO: Train epoch 577: [92800/94637 (98%)] Step: [2863008] | Lr: 0.000030 | Loss: 1.4961 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 72.79
24-04-06 21:35:56.737 - INFO: Learning rate: 3e-05
24-04-06 21:35:58.008 - INFO: Train epoch 578: [    0/94637 (0%)] Step: [2863065] | Lr: 0.000030 | Loss: 1.0643 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 77.25
24-04-06 21:36:46.293 - INFO: Train epoch 578: [ 3200/94637 (3%)] Step: [2863165] | Lr: 0.000030 | Loss: 1.0203 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 68.45
24-04-06 21:37:35.172 - INFO: Train epoch 578: [ 6400/94637 (7%)] Step: [2863265] | Lr: 0.000030 | Loss: 1.3080 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 65.94
24-04-06 21:38:23.662 - INFO: Train epoch 578: [ 9600/94637 (10%)] Step: [2863365] | Lr: 0.000030 | Loss: 0.9213 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 71.07
24-04-06 21:39:12.446 - INFO: Train epoch 578: [12800/94637 (14%)] Step: [2863465] | Lr: 0.000030 | Loss: 1.0485 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 63.06
24-04-06 21:40:01.386 - INFO: Train epoch 578: [16000/94637 (17%)] Step: [2863565] | Lr: 0.000030 | Loss: 1.4102 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 70.15
24-04-06 21:40:50.078 - INFO: Train epoch 578: [19200/94637 (20%)] Step: [2863665] | Lr: 0.000030 | Loss: 1.2210 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 61.69
24-04-06 21:41:38.485 - INFO: Train epoch 578: [22400/94637 (24%)] Step: [2863765] | Lr: 0.000030 | Loss: 1.2146 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 66.76
24-04-06 21:42:27.173 - INFO: Train epoch 578: [25600/94637 (27%)] Step: [2863865] | Lr: 0.000030 | Loss: 1.4282 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 69.22
24-04-06 21:43:15.652 - INFO: Train epoch 578: [28800/94637 (30%)] Step: [2863965] | Lr: 0.000030 | Loss: 0.9248 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 69.84
24-04-06 21:44:03.772 - INFO: Train epoch 578: [32000/94637 (34%)] Step: [2864065] | Lr: 0.000030 | Loss: 1.1439 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 68.11
24-04-06 21:44:52.046 - INFO: Train epoch 578: [35200/94637 (37%)] Step: [2864165] | Lr: 0.000030 | Loss: 1.1195 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 68.57
24-04-06 21:45:40.214 - INFO: Train epoch 578: [38400/94637 (41%)] Step: [2864265] | Lr: 0.000030 | Loss: 1.0241 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 77.46
24-04-06 21:46:27.931 - INFO: Train epoch 578: [41600/94637 (44%)] Step: [2864365] | Lr: 0.000030 | Loss: 1.0839 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 75.63
24-04-06 21:47:16.077 - INFO: Train epoch 578: [44800/94637 (47%)] Step: [2864465] | Lr: 0.000030 | Loss: 1.1721 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 68.28
24-04-06 21:48:03.999 - INFO: Train epoch 578: [48000/94637 (51%)] Step: [2864565] | Lr: 0.000030 | Loss: 1.3102 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 73.77
24-04-06 21:48:52.666 - INFO: Train epoch 578: [51200/94637 (54%)] Step: [2864665] | Lr: 0.000030 | Loss: 1.1675 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 71.75
24-04-06 21:49:40.579 - INFO: Train epoch 578: [54400/94637 (57%)] Step: [2864765] | Lr: 0.000030 | Loss: 1.0596 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 76.64
24-04-06 21:50:29.246 - INFO: Train epoch 578: [57600/94637 (61%)] Step: [2864865] | Lr: 0.000030 | Loss: 1.4244 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 69.82
24-04-06 21:51:18.448 - INFO: Train epoch 578: [60800/94637 (64%)] Step: [2864965] | Lr: 0.000030 | Loss: 1.2874 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 69.52
24-04-06 21:52:10.102 - INFO: Train epoch 578: [64000/94637 (68%)] Step: [2865065] | Lr: 0.000030 | Loss: 1.2019 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 69.00
24-04-06 21:52:58.497 - INFO: Train epoch 578: [67200/94637 (71%)] Step: [2865165] | Lr: 0.000030 | Loss: 1.4733 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 66.43
24-04-06 21:53:47.380 - INFO: Train epoch 578: [70400/94637 (74%)] Step: [2865265] | Lr: 0.000030 | Loss: 0.9989 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 65.21
24-04-06 21:54:36.569 - INFO: Train epoch 578: [73600/94637 (78%)] Step: [2865365] | Lr: 0.000030 | Loss: 1.2505 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 70.62
24-04-06 21:55:25.275 - INFO: Train epoch 578: [76800/94637 (81%)] Step: [2865465] | Lr: 0.000030 | Loss: 1.0024 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 72.09
24-04-06 21:56:14.327 - INFO: Train epoch 578: [80000/94637 (85%)] Step: [2865565] | Lr: 0.000030 | Loss: 1.6296 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 69.82
24-04-06 21:57:02.524 - INFO: Train epoch 578: [83200/94637 (88%)] Step: [2865665] | Lr: 0.000030 | Loss: 1.1659 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 65.43
24-04-06 21:57:51.259 - INFO: Train epoch 578: [86400/94637 (91%)] Step: [2865765] | Lr: 0.000030 | Loss: 1.2749 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 69.63
24-04-06 21:58:39.652 - INFO: Train epoch 578: [89600/94637 (95%)] Step: [2865865] | Lr: 0.000030 | Loss: 1.7702 | MSE loss: 0.0004 | Bpp loss: 1.06 | Aux loss: 69.00
24-04-06 21:59:28.389 - INFO: Train epoch 578: [92800/94637 (98%)] Step: [2865965] | Lr: 0.000030 | Loss: 1.6095 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 68.56
24-04-06 22:00:07.671 - INFO: Learning rate: 3e-05
24-04-06 22:00:08.747 - INFO: Train epoch 579: [    0/94637 (0%)] Step: [2866022] | Lr: 0.000030 | Loss: 1.3374 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 72.22
24-04-06 22:00:58.843 - INFO: Train epoch 579: [ 3200/94637 (3%)] Step: [2866122] | Lr: 0.000030 | Loss: 0.9912 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 71.11
24-04-06 22:01:48.289 - INFO: Train epoch 579: [ 6400/94637 (7%)] Step: [2866222] | Lr: 0.000030 | Loss: 1.4021 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 70.04
24-04-06 22:02:37.710 - INFO: Train epoch 579: [ 9600/94637 (10%)] Step: [2866322] | Lr: 0.000030 | Loss: 1.5884 | MSE loss: 0.0003 | Bpp loss: 1.02 | Aux loss: 65.58
24-04-06 22:03:27.371 - INFO: Train epoch 579: [12800/94637 (14%)] Step: [2866422] | Lr: 0.000030 | Loss: 1.1515 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 71.00
24-04-06 22:04:16.811 - INFO: Train epoch 579: [16000/94637 (17%)] Step: [2866522] | Lr: 0.000030 | Loss: 1.3386 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 70.65
24-04-06 22:05:06.481 - INFO: Train epoch 579: [19200/94637 (20%)] Step: [2866622] | Lr: 0.000030 | Loss: 0.9146 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 74.97
24-04-06 22:05:55.678 - INFO: Train epoch 579: [22400/94637 (24%)] Step: [2866722] | Lr: 0.000030 | Loss: 1.5661 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 71.65
24-04-06 22:06:44.853 - INFO: Train epoch 579: [25600/94637 (27%)] Step: [2866822] | Lr: 0.000030 | Loss: 1.2600 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 68.19
24-04-06 22:07:34.128 - INFO: Train epoch 579: [28800/94637 (30%)] Step: [2866922] | Lr: 0.000030 | Loss: 1.3488 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 69.14
24-04-06 22:08:23.493 - INFO: Train epoch 579: [32000/94637 (34%)] Step: [2867022] | Lr: 0.000030 | Loss: 1.2967 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 65.13
24-04-06 22:09:12.731 - INFO: Train epoch 579: [35200/94637 (37%)] Step: [2867122] | Lr: 0.000030 | Loss: 1.6176 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 68.63
24-04-06 22:10:01.586 - INFO: Train epoch 579: [38400/94637 (41%)] Step: [2867222] | Lr: 0.000030 | Loss: 1.0478 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 70.84
24-04-06 22:10:50.333 - INFO: Train epoch 579: [41600/94637 (44%)] Step: [2867322] | Lr: 0.000030 | Loss: 1.0090 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 67.83
24-04-06 22:11:39.166 - INFO: Train epoch 579: [44800/94637 (47%)] Step: [2867422] | Lr: 0.000030 | Loss: 1.3760 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 77.54
24-04-06 22:12:30.036 - INFO: Train epoch 579: [48000/94637 (51%)] Step: [2867522] | Lr: 0.000030 | Loss: 1.5012 | MSE loss: 0.0004 | Bpp loss: 0.83 | Aux loss: 71.07
24-04-06 22:13:19.727 - INFO: Train epoch 579: [51200/94637 (54%)] Step: [2867622] | Lr: 0.000030 | Loss: 1.1422 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 72.26
24-04-06 22:14:08.756 - INFO: Train epoch 579: [54400/94637 (57%)] Step: [2867722] | Lr: 0.000030 | Loss: 1.6537 | MSE loss: 0.0004 | Bpp loss: 1.07 | Aux loss: 76.58
24-04-06 22:14:57.270 - INFO: Train epoch 579: [57600/94637 (61%)] Step: [2867822] | Lr: 0.000030 | Loss: 1.1271 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 68.48
24-04-06 22:15:46.017 - INFO: Train epoch 579: [60800/94637 (64%)] Step: [2867922] | Lr: 0.000030 | Loss: 1.1316 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 68.96
24-04-06 22:16:35.018 - INFO: Train epoch 579: [64000/94637 (68%)] Step: [2868022] | Lr: 0.000030 | Loss: 0.8741 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 74.71
24-04-06 22:17:24.239 - INFO: Train epoch 579: [67200/94637 (71%)] Step: [2868122] | Lr: 0.000030 | Loss: 1.4549 | MSE loss: 0.0004 | Bpp loss: 0.84 | Aux loss: 70.46
24-04-06 22:18:13.520 - INFO: Train epoch 579: [70400/94637 (74%)] Step: [2868222] | Lr: 0.000030 | Loss: 0.8957 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 71.80
24-04-06 22:19:02.316 - INFO: Train epoch 579: [73600/94637 (78%)] Step: [2868322] | Lr: 0.000030 | Loss: 1.1082 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 70.50
24-04-06 22:19:51.191 - INFO: Train epoch 579: [76800/94637 (81%)] Step: [2868422] | Lr: 0.000030 | Loss: 1.0228 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 70.40
24-04-06 22:20:40.259 - INFO: Train epoch 579: [80000/94637 (85%)] Step: [2868522] | Lr: 0.000030 | Loss: 1.3932 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 68.15
24-04-06 22:21:29.935 - INFO: Train epoch 579: [83200/94637 (88%)] Step: [2868622] | Lr: 0.000030 | Loss: 1.3781 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 69.24
24-04-06 22:22:19.399 - INFO: Train epoch 579: [86400/94637 (91%)] Step: [2868722] | Lr: 0.000030 | Loss: 1.1287 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 66.10
24-04-06 22:23:08.179 - INFO: Train epoch 579: [89600/94637 (95%)] Step: [2868822] | Lr: 0.000030 | Loss: 1.3158 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 69.53
24-04-06 22:23:57.271 - INFO: Train epoch 579: [92800/94637 (98%)] Step: [2868922] | Lr: 0.000030 | Loss: 1.1446 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 71.60
24-04-06 22:24:36.019 - INFO: Learning rate: 3e-05
24-04-06 22:24:37.704 - INFO: Train epoch 580: [    0/94637 (0%)] Step: [2868979] | Lr: 0.000030 | Loss: 1.3337 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 77.05
24-04-06 22:25:27.769 - INFO: Train epoch 580: [ 3200/94637 (3%)] Step: [2869079] | Lr: 0.000030 | Loss: 1.0643 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 70.50
24-04-06 22:26:17.447 - INFO: Train epoch 580: [ 6400/94637 (7%)] Step: [2869179] | Lr: 0.000030 | Loss: 1.2384 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 74.93
24-04-06 22:27:06.805 - INFO: Train epoch 580: [ 9600/94637 (10%)] Step: [2869279] | Lr: 0.000030 | Loss: 1.7031 | MSE loss: 0.0004 | Bpp loss: 1.07 | Aux loss: 70.83
24-04-06 22:27:55.651 - INFO: Train epoch 580: [12800/94637 (14%)] Step: [2869379] | Lr: 0.000030 | Loss: 1.0890 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 67.27
24-04-06 22:28:44.524 - INFO: Train epoch 580: [16000/94637 (17%)] Step: [2869479] | Lr: 0.000030 | Loss: 0.7254 | MSE loss: 0.0001 | Bpp loss: 0.49 | Aux loss: 71.28
24-04-06 22:29:33.978 - INFO: Train epoch 580: [19200/94637 (20%)] Step: [2869579] | Lr: 0.000030 | Loss: 1.0960 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 71.59
24-04-06 22:30:23.860 - INFO: Train epoch 580: [22400/94637 (24%)] Step: [2869679] | Lr: 0.000030 | Loss: 1.5524 | MSE loss: 0.0004 | Bpp loss: 0.93 | Aux loss: 76.36
24-04-06 22:31:13.658 - INFO: Train epoch 580: [25600/94637 (27%)] Step: [2869779] | Lr: 0.000030 | Loss: 1.5087 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 65.25
24-04-06 22:32:03.435 - INFO: Train epoch 580: [28800/94637 (30%)] Step: [2869879] | Lr: 0.000030 | Loss: 1.2160 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 76.00
24-04-06 22:32:52.738 - INFO: Train epoch 580: [32000/94637 (34%)] Step: [2869979] | Lr: 0.000030 | Loss: 1.2494 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 68.26
24-04-06 22:33:43.762 - INFO: Train epoch 580: [35200/94637 (37%)] Step: [2870079] | Lr: 0.000030 | Loss: 1.2696 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 71.78
24-04-06 22:34:33.315 - INFO: Train epoch 580: [38400/94637 (41%)] Step: [2870179] | Lr: 0.000030 | Loss: 1.3907 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 74.51
24-04-06 22:35:22.165 - INFO: Train epoch 580: [41600/94637 (44%)] Step: [2870279] | Lr: 0.000030 | Loss: 1.4091 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 78.13
24-04-06 22:36:11.897 - INFO: Train epoch 580: [44800/94637 (47%)] Step: [2870379] | Lr: 0.000030 | Loss: 1.2236 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 77.76
24-04-06 22:37:01.190 - INFO: Train epoch 580: [48000/94637 (51%)] Step: [2870479] | Lr: 0.000030 | Loss: 1.1921 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 74.36
24-04-06 22:37:50.896 - INFO: Train epoch 580: [51200/94637 (54%)] Step: [2870579] | Lr: 0.000030 | Loss: 1.8426 | MSE loss: 0.0005 | Bpp loss: 1.08 | Aux loss: 71.62
24-04-06 22:38:40.460 - INFO: Train epoch 580: [54400/94637 (57%)] Step: [2870679] | Lr: 0.000030 | Loss: 1.0589 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 72.32
24-04-06 22:39:30.047 - INFO: Train epoch 580: [57600/94637 (61%)] Step: [2870779] | Lr: 0.000030 | Loss: 1.2811 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 72.91
24-04-06 22:40:19.722 - INFO: Train epoch 580: [60800/94637 (64%)] Step: [2870879] | Lr: 0.000030 | Loss: 1.5801 | MSE loss: 0.0003 | Bpp loss: 1.01 | Aux loss: 70.39
24-04-06 22:41:08.897 - INFO: Train epoch 580: [64000/94637 (68%)] Step: [2870979] | Lr: 0.000030 | Loss: 1.2173 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 73.14
24-04-06 22:41:58.772 - INFO: Train epoch 580: [67200/94637 (71%)] Step: [2871079] | Lr: 0.000030 | Loss: 1.3073 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 66.96
24-04-06 22:42:47.699 - INFO: Train epoch 580: [70400/94637 (74%)] Step: [2871179] | Lr: 0.000030 | Loss: 1.3429 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 73.19
24-04-06 22:43:37.121 - INFO: Train epoch 580: [73600/94637 (78%)] Step: [2871279] | Lr: 0.000030 | Loss: 1.2798 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 76.60
24-04-06 22:44:25.707 - INFO: Train epoch 580: [76800/94637 (81%)] Step: [2871379] | Lr: 0.000030 | Loss: 1.0110 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 69.14
24-04-06 22:45:14.015 - INFO: Train epoch 580: [80000/94637 (85%)] Step: [2871479] | Lr: 0.000030 | Loss: 1.3736 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 75.09
24-04-06 22:46:02.256 - INFO: Train epoch 580: [83200/94637 (88%)] Step: [2871579] | Lr: 0.000030 | Loss: 1.3376 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 70.27
24-04-06 22:46:50.780 - INFO: Train epoch 580: [86400/94637 (91%)] Step: [2871679] | Lr: 0.000030 | Loss: 1.4929 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 69.35
24-04-06 22:47:40.058 - INFO: Train epoch 580: [89600/94637 (95%)] Step: [2871779] | Lr: 0.000030 | Loss: 1.0985 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 73.87
24-04-06 22:48:28.838 - INFO: Train epoch 580: [92800/94637 (98%)] Step: [2871879] | Lr: 0.000030 | Loss: 1.5648 | MSE loss: 0.0003 | Bpp loss: 1.02 | Aux loss: 69.34
24-04-06 22:49:08.671 - INFO: Learning rate: 3e-05
24-04-06 22:49:09.835 - INFO: Train epoch 581: [    0/94637 (0%)] Step: [2871936] | Lr: 0.000030 | Loss: 0.9179 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 69.63
24-04-06 22:49:58.916 - INFO: Train epoch 581: [ 3200/94637 (3%)] Step: [2872036] | Lr: 0.000030 | Loss: 1.3682 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 70.13
24-04-06 22:50:48.550 - INFO: Train epoch 581: [ 6400/94637 (7%)] Step: [2872136] | Lr: 0.000030 | Loss: 0.9577 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 65.64
24-04-06 22:51:37.976 - INFO: Train epoch 581: [ 9600/94637 (10%)] Step: [2872236] | Lr: 0.000030 | Loss: 1.1458 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 68.44
24-04-06 22:52:26.883 - INFO: Train epoch 581: [12800/94637 (14%)] Step: [2872336] | Lr: 0.000030 | Loss: 1.0432 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 74.91
24-04-06 22:53:16.877 - INFO: Train epoch 581: [16000/94637 (17%)] Step: [2872436] | Lr: 0.000030 | Loss: 1.3112 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 72.55
24-04-06 22:54:08.036 - INFO: Train epoch 581: [19200/94637 (20%)] Step: [2872536] | Lr: 0.000030 | Loss: 1.0396 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 74.67
24-04-06 22:54:57.436 - INFO: Train epoch 581: [22400/94637 (24%)] Step: [2872636] | Lr: 0.000030 | Loss: 1.2789 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 71.45
24-04-06 22:55:46.429 - INFO: Train epoch 581: [25600/94637 (27%)] Step: [2872736] | Lr: 0.000030 | Loss: 1.1635 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 72.75
24-04-06 22:56:36.281 - INFO: Train epoch 581: [28800/94637 (30%)] Step: [2872836] | Lr: 0.000030 | Loss: 1.0821 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 68.98
24-04-06 22:57:25.379 - INFO: Train epoch 581: [32000/94637 (34%)] Step: [2872936] | Lr: 0.000030 | Loss: 1.1929 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 69.33
24-04-06 22:58:13.955 - INFO: Train epoch 581: [35200/94637 (37%)] Step: [2873036] | Lr: 0.000030 | Loss: 1.2097 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 70.94
24-04-06 22:59:03.108 - INFO: Train epoch 581: [38400/94637 (41%)] Step: [2873136] | Lr: 0.000030 | Loss: 1.1167 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 73.21
24-04-06 22:59:51.864 - INFO: Train epoch 581: [41600/94637 (44%)] Step: [2873236] | Lr: 0.000030 | Loss: 0.8555 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 71.26
24-04-06 23:00:40.614 - INFO: Train epoch 581: [44800/94637 (47%)] Step: [2873336] | Lr: 0.000030 | Loss: 1.0699 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 70.94
24-04-06 23:01:29.101 - INFO: Train epoch 581: [48000/94637 (51%)] Step: [2873436] | Lr: 0.000030 | Loss: 1.3114 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 70.42
24-04-06 23:02:18.273 - INFO: Train epoch 581: [51200/94637 (54%)] Step: [2873536] | Lr: 0.000030 | Loss: 1.0936 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 68.58
24-04-06 23:03:07.559 - INFO: Train epoch 581: [54400/94637 (57%)] Step: [2873636] | Lr: 0.000030 | Loss: 1.2851 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 73.00
24-04-06 23:03:57.566 - INFO: Train epoch 581: [57600/94637 (61%)] Step: [2873736] | Lr: 0.000030 | Loss: 1.4747 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 70.04
24-04-06 23:04:46.792 - INFO: Train epoch 581: [60800/94637 (64%)] Step: [2873836] | Lr: 0.000030 | Loss: 1.7170 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 68.17
24-04-06 23:05:36.241 - INFO: Train epoch 581: [64000/94637 (68%)] Step: [2873936] | Lr: 0.000030 | Loss: 1.1456 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 72.18
24-04-06 23:06:25.758 - INFO: Train epoch 581: [67200/94637 (71%)] Step: [2874036] | Lr: 0.000030 | Loss: 1.3234 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 76.42
24-04-06 23:07:15.125 - INFO: Train epoch 581: [70400/94637 (74%)] Step: [2874136] | Lr: 0.000030 | Loss: 1.3677 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 76.27
24-04-06 23:08:04.342 - INFO: Train epoch 581: [73600/94637 (78%)] Step: [2874236] | Lr: 0.000030 | Loss: 1.2538 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 69.66
24-04-06 23:08:53.057 - INFO: Train epoch 581: [76800/94637 (81%)] Step: [2874336] | Lr: 0.000030 | Loss: 1.1613 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 71.52
24-04-06 23:09:42.058 - INFO: Train epoch 581: [80000/94637 (85%)] Step: [2874436] | Lr: 0.000030 | Loss: 0.7671 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 70.72
24-04-06 23:10:30.767 - INFO: Train epoch 581: [83200/94637 (88%)] Step: [2874536] | Lr: 0.000030 | Loss: 1.2799 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 71.16
24-04-06 23:11:18.786 - INFO: Train epoch 581: [86400/94637 (91%)] Step: [2874636] | Lr: 0.000030 | Loss: 1.0323 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 72.35
24-04-06 23:12:06.569 - INFO: Train epoch 581: [89600/94637 (95%)] Step: [2874736] | Lr: 0.000030 | Loss: 1.4326 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 75.24
24-04-06 23:12:54.431 - INFO: Train epoch 581: [92800/94637 (98%)] Step: [2874836] | Lr: 0.000030 | Loss: 1.1424 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 70.49
24-04-06 23:13:33.351 - INFO: Learning rate: 3e-05
24-04-06 23:13:35.290 - INFO: Train epoch 582: [    0/94637 (0%)] Step: [2874893] | Lr: 0.000030 | Loss: 1.3703 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 66.87
24-04-06 23:14:23.443 - INFO: Train epoch 582: [ 3200/94637 (3%)] Step: [2874993] | Lr: 0.000030 | Loss: 1.1634 | MSE loss: 0.0002 | Bpp loss: 0.76 | Aux loss: 66.06
24-04-06 23:15:13.453 - INFO: Train epoch 582: [ 6400/94637 (7%)] Step: [2875093] | Lr: 0.000030 | Loss: 1.2102 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 63.72
24-04-06 23:16:01.652 - INFO: Train epoch 582: [ 9600/94637 (10%)] Step: [2875193] | Lr: 0.000030 | Loss: 1.1636 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 70.69
24-04-06 23:16:50.048 - INFO: Train epoch 582: [12800/94637 (14%)] Step: [2875293] | Lr: 0.000030 | Loss: 0.9970 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 69.79
