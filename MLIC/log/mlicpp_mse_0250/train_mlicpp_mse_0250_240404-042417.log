24-04-04 04:25:38.031 - INFO: Namespace(experiment='mlicpp_mse_0250', dataset='/mnt/bn/jiangwei-lvc3/dataset/image', epochs=500, learning_rate=0.0001, num_workers=8, lmbda=0.025, metrics='mse', batch_size=8, test_batch_size=1, aux_learning_rate=0.001, patch_size=[512, 512], gpu_id=0, cuda=True, save=True, seed=1984.0, clip_max_norm=1.0, checkpoint='/mnt/bn/jiangwei-lvc3/work_space/MLICPlusPlus/playground/experiments/mlicpp_mse_0250/checkpoints', world_size=4, dist_url='env://', rank=0, gpu=0, distributed=True, dist_backend='nccl')
24-04-04 04:25:38.045 - INFO: {'N': 192, 'M': 320, 'enc_dims': [3, 192, 192, 192, 320], 'dec_dims': [320, 192, 192, 192, 16, 3], 'slice_num': 10, 'context_window': 5, 'slice_ch': [8, 8, 8, 8, 16, 16, 32, 32, 96, 96], 'max_support_slices': 5, 'quant': 'ste', 'lambda_list': [0.07, 0.08, 0.09], 'use_hyper_gain': False, 'interpolated_type': 'exponential', 'act': <class 'torch.nn.modules.activation.GELU'>, 'L': 10, 'target_bpp': [0.0761, 0.1854, 0.2752, 0.3652, 0.4282, 0.5238, 0.5653, 0.6334, 0.745], 'bpp_threshold': [0.02, 0.02, 0.02, 0.02, 0.03, 0.02, 0.02, 0.02, 0.02], 'min_lmbda': 0.001, 'init_lmbda': [0.001, 0.0018, 0.0035, 0.0035, 0.0067, 0.0067, 0.013, 0.013, 0.025, 0.0483], 'lower_bound': 1e-09, 'ki': 0.1, 'kp': 0.1}
24-04-04 04:25:38.047 - INFO: DistributedDataParallel(
  (module): MLICPlusPlus(
    (entropy_bottleneck): EntropyBottleneck(
      (likelihood_lower_bound): LowerBound()
    )
    (g_a): AnalysisTransform(
      (analysis_transform): Sequential(
        (0): ResidualBlockWithStride(
          (conv1): Conv2d(3, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (gdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (skip): Conv2d(3, 192, kernel_size=(1, 1), stride=(2, 2))
        )
        (1): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (2): ResidualBlockWithStride(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (gdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (skip): Conv2d(192, 192, kernel_size=(1, 1), stride=(2, 2))
        )
        (3): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (4): ResidualBlockWithStride(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (gdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (skip): Conv2d(192, 192, kernel_size=(1, 1), stride=(2, 2))
        )
        (5): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (6): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      )
    )
    (g_s): SynthesisTransform(
      (synthesis_transform): Sequential(
        (0): ResidualBlock(
          (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (1): ResidualBlockUpsample(
          (subpel_conv): Sequential(
            (0): Conv2d(320, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
          (act): GELU(approximate='none')
          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (igdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (upsample): Sequential(
            (0): Conv2d(320, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
        )
        (2): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (3): ResidualBlockUpsample(
          (subpel_conv): Sequential(
            (0): Conv2d(192, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
          (act): GELU(approximate='none')
          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (igdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (upsample): Sequential(
            (0): Conv2d(192, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
        )
        (4): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (5): ResidualBlockUpsample(
          (subpel_conv): Sequential(
            (0): Conv2d(192, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
          (act): GELU(approximate='none')
          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (igdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (upsample): Sequential(
            (0): Conv2d(192, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
        )
        (6): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (7): Sequential(
          (0): Conv2d(192, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): PixelShuffle(upscale_factor=2)
        )
      )
    )
    (h_a): HyperAnalysis(
      (reduction): Sequential(
        (0): Conv2d(320, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): GELU(approximate='none')
        (2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): GELU(approximate='none')
        (4): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (5): GELU(approximate='none')
        (6): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): GELU(approximate='none')
        (8): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      )
    )
    (h_s): HyperSynthesis(
      (increase): Sequential(
        (0): Conv2d(192, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): GELU(approximate='none')
        (2): Sequential(
          (0): Conv2d(320, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): PixelShuffle(upscale_factor=2)
        )
        (3): GELU(approximate='none')
        (4): Conv2d(320, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): GELU(approximate='none')
        (6): Sequential(
          (0): Conv2d(480, 1920, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): PixelShuffle(upscale_factor=2)
        )
        (7): GELU(approximate='none')
        (8): Conv2d(480, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (gaussian_conditional): GaussianConditional(
      (likelihood_lower_bound): LowerBound()
      (lower_bound_scale): LowerBound()
    )
    (local_context): ModuleList(
      (0-9): 10 x LocalContext(
        (qkv_proj): Linear(in_features=32, out_features=96, bias=True)
        (unfold): Unfold(kernel_size=5, dilation=1, padding=2, stride=1)
        (softmax): Softmax(dim=-1)
        (proj): Linear(in_features=64, out_features=64, bias=True)
        (mlp): MLP(
          (fc1): Linear(in_features=64, out_features=128, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=128, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (fusion): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
      )
    )
    (channel_context): ModuleList(
      (0): None
      (1): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(32, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (2): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (3): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (4): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (5): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(160, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (6): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (7): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(224, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (8): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (9): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(288, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (global_inter_context): ModuleList(
      (0): None
      (1): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (queries): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (values): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (reprojection): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
        )
        (queries): Sequential(
          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
        )
        (values): Sequential(
          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
        )
        (reprojection): Conv2d(64, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (3): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
        )
        (queries): Sequential(
          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
        )
        (values): Sequential(
          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
        )
        (reprojection): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (4): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
        )
        (queries): Sequential(
          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
        )
        (values): Sequential(
          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
        )
        (reprojection): Conv2d(128, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (5): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)
        )
        (queries): Sequential(
          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)
        )
        (values): Sequential(
          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)
        )
        (reprojection): Conv2d(160, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (6): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
        )
        (queries): Sequential(
          (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
        )
        (values): Sequential(
          (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
        )
        (reprojection): Conv2d(192, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (7): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(224, 224, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=224)
        )
        (queries): Sequential(
          (0): Conv2d(224, 224, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=224)
        )
        (values): Sequential(
          (0): Conv2d(224, 224, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=224)
        )
        (reprojection): Conv2d(224, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (8): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
        )
        (queries): Sequential(
          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
        )
        (values): Sequential(
          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
        )
        (reprojection): Conv2d(256, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (9): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)
        )
        (queries): Sequential(
          (0): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)
        )
        (values): Sequential(
          (0): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)
        )
        (reprojection): Conv2d(288, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (global_intra_context): ModuleList(
      (0): None
      (1-9): 9 x LinearGlobalIntraContext(
        (keys): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (queries): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (values): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (reprojection): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
    (entropy_parameters_anchor): ModuleList(
      (0): EntropyParameters(
        (fusion): Sequential(
          (0): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
          (5): GELU(approximate='none')
          (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (1-9): 9 x EntropyParameters(
        (fusion): Sequential(
          (0): Conv2d(832, 320, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
          (5): GELU(approximate='none')
          (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
    (entropy_parameters_nonanchor): ModuleList(
      (0): EntropyParameters(
        (fusion): Sequential(
          (0): Conv2d(704, 320, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
          (5): GELU(approximate='none')
          (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (1-9): 9 x EntropyParameters(
        (fusion): Sequential(
          (0): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
          (5): GELU(approximate='none')
          (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
    (lrp_anchor): ModuleList(
      (0): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(352, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (1): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(384, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (2): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(416, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (3): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(448, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (4): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(480, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (5): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(512, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (6): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(544, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (7): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(576, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (8): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(608, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (9): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(640, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (lrp_nonanchor): ModuleList(
      (0): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(352, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (1): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(384, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (2): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(416, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (3): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(448, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (4): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(480, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (5): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(512, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (6): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(544, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (7): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(576, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (8): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(608, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (9): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(640, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
  )
)
24-04-04 04:25:38.074 - INFO: Learning rate: 0.0001
24-04-04 04:51:07.769 - INFO: Learning rate: 0.0001
24-04-04 05:16:32.017 - INFO: Learning rate: 0.0001
24-04-04 05:42:00.626 - INFO: Learning rate: 0.0001
24-04-04 06:07:24.008 - INFO: Learning rate: 0.0001
24-04-04 06:32:51.212 - INFO: Learning rate: 0.0001
24-04-04 06:58:17.744 - INFO: Learning rate: 0.0001
24-04-04 07:24:15.206 - INFO: Learning rate: 0.0001
24-04-04 07:49:36.582 - INFO: Learning rate: 0.0001
24-04-04 08:14:58.579 - INFO: Learning rate: 0.0001
24-04-04 08:40:23.276 - INFO: Learning rate: 0.0001
24-04-04 09:05:43.068 - INFO: Learning rate: 0.0001
24-04-04 09:30:51.891 - INFO: Learning rate: 0.0001
24-04-04 09:56:11.758 - INFO: Learning rate: 0.0001
24-04-04 10:21:41.839 - INFO: Learning rate: 0.0001
24-04-04 10:47:10.464 - INFO: Learning rate: 0.0001
24-04-04 11:12:35.502 - INFO: Learning rate: 0.0001
24-04-04 11:37:53.617 - INFO: Learning rate: 0.0001
24-04-04 12:03:08.876 - INFO: Learning rate: 0.0001
24-04-04 12:28:30.132 - INFO: Learning rate: 0.0001
24-04-04 12:53:51.260 - INFO: Learning rate: 0.0001
24-04-04 13:19:16.390 - INFO: Learning rate: 0.0001
24-04-04 13:44:44.615 - INFO: Learning rate: 0.0001
24-04-04 14:10:09.240 - INFO: Learning rate: 0.0001
24-04-04 14:35:36.089 - INFO: Learning rate: 0.0001
24-04-04 15:01:02.222 - INFO: Learning rate: 0.0001
24-04-04 15:26:22.149 - INFO: Learning rate: 0.0001
24-04-04 15:51:45.125 - INFO: Learning rate: 0.0001
24-04-04 16:17:14.020 - INFO: Learning rate: 0.0001
24-04-04 16:42:36.420 - INFO: Learning rate: 0.0001
24-04-04 17:08:00.939 - INFO: Learning rate: 0.0001
24-04-04 17:33:29.022 - INFO: Learning rate: 0.0001
24-04-04 17:58:48.019 - INFO: Learning rate: 0.0001
24-04-04 18:24:18.176 - INFO: Learning rate: 0.0001
24-04-04 18:49:52.655 - INFO: Learning rate: 0.0001
24-04-04 19:15:28.709 - INFO: Learning rate: 0.0001
24-04-04 19:40:43.019 - INFO: Learning rate: 0.0001
24-04-04 20:06:09.445 - INFO: Learning rate: 0.0001
24-04-04 20:31:27.614 - INFO: Learning rate: 0.0001
24-04-04 20:56:54.386 - INFO: Learning rate: 0.0001
24-04-04 21:22:27.186 - INFO: Learning rate: 0.0001
24-04-04 21:47:50.762 - INFO: Learning rate: 0.0001
24-04-04 22:13:17.046 - INFO: Learning rate: 0.0001
24-04-04 22:38:53.382 - INFO: Learning rate: 0.0001
24-04-04 23:04:23.762 - INFO: Learning rate: 0.0001
24-04-04 23:29:49.046 - INFO: Learning rate: 0.0001
-04 04:37:55.809 - INFO: Train epoch 441: [44800/94637 (47%)] Step: [2531401] | Lr: 0.000100 | Loss: 1.0771 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 44.43
24-04-04 04:38:46.445 - INFO: Train epoch 441: [48000/94637 (51%)] Step: [2531501] | Lr: 0.000100 | Loss: 1.1016 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 45.22
24-04-04 04:39:37.290 - INFO: Train epoch 441: [51200/94637 (54%)] Step: [2531601] | Lr: 0.000100 | Loss: 1.4622 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 44.96
24-04-04 04:40:27.839 - INFO: Train epoch 441: [54400/94637 (57%)] Step: [2531701] | Lr: 0.000100 | Loss: 1.4024 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 41.62
24-04-04 04:41:18.401 - INFO: Train epoch 441: [57600/94637 (61%)] Step: [2531801] | Lr: 0.000100 | Loss: 1.5389 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 42.70
24-04-04 04:42:09.375 - INFO: Train epoch 441: [60800/94637 (64%)] Step: [2531901] | Lr: 0.000100 | Loss: 1.1031 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 44.59
24-04-04 04:43:00.282 - INFO: Train epoch 441: [64000/94637 (68%)] Step: [2532001] | Lr: 0.000100 | Loss: 1.0599 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 48.70
24-04-04 04:43:52.442 - INFO: Train epoch 441: [67200/94637 (71%)] Step: [2532101] | Lr: 0.000100 | Loss: 1.3279 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 42.13
24-04-04 04:44:42.810 - INFO: Train epoch 441: [70400/94637 (74%)] Step: [2532201] | Lr: 0.000100 | Loss: 1.3880 | MSE loss: 0.0004 | Bpp loss: 0.81 | Aux loss: 43.64
24-04-04 04:45:33.580 - INFO: Train epoch 441: [73600/94637 (78%)] Step: [2532301] | Lr: 0.000100 | Loss: 1.5077 | MSE loss: 0.0004 | Bpp loss: 0.83 | Aux loss: 44.96
24-04-04 04:46:24.138 - INFO: Train epoch 441: [76800/94637 (81%)] Step: [2532401] | Lr: 0.000100 | Loss: 1.4607 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 41.36
24-04-04 04:47:16.903 - INFO: Train epoch 441: [80000/94637 (85%)] Step: [2532501] | Lr: 0.000100 | Loss: 1.1109 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 46.41
24-04-04 04:48:07.938 - INFO: Train epoch 441: [83200/94637 (88%)] Step: [2532601] | Lr: 0.000100 | Loss: 1.5011 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 47.16
24-04-04 04:48:57.990 - INFO: Train epoch 441: [86400/94637 (91%)] Step: [2532701] | Lr: 0.000100 | Loss: 1.5456 | MSE loss: 0.0004 | Bpp loss: 0.85 | Aux loss: 41.27
24-04-04 04:49:48.195 - INFO: Train epoch 441: [89600/94637 (95%)] Step: [2532801] | Lr: 0.000100 | Loss: 1.2444 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 43.86
24-04-04 04:50:38.996 - INFO: Train epoch 441: [92800/94637 (98%)] Step: [2532901] | Lr: 0.000100 | Loss: 0.9815 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 44.43
24-04-04 04:51:26.998 - INFO: Learning rate: 0.0001
24-04-04 04:51:28.983 - INFO: Train epoch 442: [    0/94637 (0%)] Step: [2532958] | Lr: 0.000100 | Loss: 0.9084 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 42.16
24-04-04 04:52:19.799 - INFO: Train epoch 442: [ 3200/94637 (3%)] Step: [2533058] | Lr: 0.000100 | Loss: 0.9511 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 43.85
24-04-04 04:53:10.246 - INFO: Train epoch 442: [ 6400/94637 (7%)] Step: [2533158] | Lr: 0.000100 | Loss: 1.3042 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 41.58
24-04-04 04:54:01.834 - INFO: Train epoch 442: [ 9600/94637 (10%)] Step: [2533258] | Lr: 0.000100 | Loss: 1.6703 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 45.70
24-04-04 04:54:52.432 - INFO: Train epoch 442: [12800/94637 (14%)] Step: [2533358] | Lr: 0.000100 | Loss: 1.3588 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 42.29
24-04-04 04:55:43.446 - INFO: Train epoch 442: [16000/94637 (17%)] Step: [2533458] | Lr: 0.000100 | Loss: 1.3102 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 44.84
24-04-04 04:56:34.524 - INFO: Train epoch 442: [19200/94637 (20%)] Step: [2533558] | Lr: 0.000100 | Loss: 1.8681 | MSE loss: 0.0005 | Bpp loss: 1.13 | Aux loss: 41.08
24-04-04 04:57:25.609 - INFO: Train epoch 442: [22400/94637 (24%)] Step: [2533658] | Lr: 0.000100 | Loss: 0.9591 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 45.39
24-04-04 04:58:16.472 - INFO: Train epoch 442: [25600/94637 (27%)] Step: [2533758] | Lr: 0.000100 | Loss: 1.2203 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 41.13
24-04-04 04:59:07.926 - INFO: Train epoch 442: [28800/94637 (30%)] Step: [2533858] | Lr: 0.000100 | Loss: 1.2278 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 45.38
24-04-04 04:59:58.699 - INFO: Train epoch 442: [32000/94637 (34%)] Step: [2533958] | Lr: 0.000100 | Loss: 1.6970 | MSE loss: 0.0004 | Bpp loss: 1.07 | Aux loss: 40.48
24-04-04 05:00:50.055 - INFO: Train epoch 442: [35200/94637 (37%)] Step: [2534058] | Lr: 0.000100 | Loss: 1.1508 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 37.60
24-04-04 05:01:40.771 - INFO: Train epoch 442: [38400/94637 (41%)] Step: [2534158] | Lr: 0.000100 | Loss: 1.0707 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 37.85
24-04-04 05:02:31.743 - INFO: Train epoch 442: [41600/94637 (44%)] Step: [2534258] | Lr: 0.000100 | Loss: 1.3766 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 38.35
24-04-04 05:03:23.512 - INFO: Train epoch 442: [44800/94637 (47%)] Step: [2534358] | Lr: 0.000100 | Loss: 1.2644 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 37.90
24-04-04 05:04:14.653 - INFO: Train epoch 442: [48000/94637 (51%)] Step: [2534458] | Lr: 0.000100 | Loss: 1.0076 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 35.95
24-04-04 05:05:05.522 - INFO: Train epoch 442: [51200/94637 (54%)] Step: [2534558] | Lr: 0.000100 | Loss: 1.7422 | MSE loss: 0.0004 | Bpp loss: 1.03 | Aux loss: 37.80
24-04-04 05:05:56.678 - INFO: Train epoch 442: [54400/94637 (57%)] Step: [2534658] | Lr: 0.000100 | Loss: 1.3461 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 38.62
24-04-04 05:06:47.271 - INFO: Train epoch 442: [57600/94637 (61%)] Step: [2534758] | Lr: 0.000100 | Loss: 1.3043 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 41.15
24-04-04 05:07:38.011 - INFO: Train epoch 442: [60800/94637 (64%)] Step: [2534858] | Lr: 0.000100 | Loss: 0.9494 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 40.43
24-04-04 05:08:28.671 - INFO: Train epoch 442: [64000/94637 (68%)] Step: [2534958] | Lr: 0.000100 | Loss: 1.3253 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 36.78
24-04-04 05:09:21.537 - INFO: Train epoch 442: [67200/94637 (71%)] Step: [2535058] | Lr: 0.000100 | Loss: 0.9901 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 43.11
24-04-04 05:10:11.480 - INFO: Train epoch 442: [70400/94637 (74%)] Step: [2535158] | Lr: 0.000100 | Loss: 1.4148 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 39.04
24-04-04 05:11:02.172 - INFO: Train epoch 442: [73600/94637 (78%)] Step: [2535258] | Lr: 0.000100 | Loss: 1.1079 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 40.05
24-04-04 05:11:52.516 - INFO: Train epoch 442: [76800/94637 (81%)] Step: [2535358] | Lr: 0.000100 | Loss: 1.2738 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 39.74
24-04-04 05:12:42.690 - INFO: Train epoch 442: [80000/94637 (85%)] Step: [2535458] | Lr: 0.000100 | Loss: 1.0409 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 38.29
24-04-04 05:13:32.855 - INFO: Train epoch 442: [83200/94637 (88%)] Step: [2535558] | Lr: 0.000100 | Loss: 1.0845 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 39.45
24-04-04 05:14:22.886 - INFO: Train epoch 442: [86400/94637 (91%)] Step: [2535658] | Lr: 0.000100 | Loss: 1.2131 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 39.55
24-04-04 05:15:13.168 - INFO: Train epoch 442: [89600/94637 (95%)] Step: [2535758] | Lr: 0.000100 | Loss: 1.7104 | MSE loss: 0.0004 | Bpp loss: 0.99 | Aux loss: 43.74
24-04-04 05:16:03.577 - INFO: Train epoch 442: [92800/94637 (98%)] Step: [2535858] | Lr: 0.000100 | Loss: 1.5340 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 40.55
24-04-04 05:16:43.812 - INFO: Learning rate: 0.0001
24-04-04 05:16:45.426 - INFO: Train epoch 443: [    0/94637 (0%)] Step: [2535915] | Lr: 0.000100 | Loss: 1.0656 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 39.54
24-04-04 05:17:35.819 - INFO: Train epoch 443: [ 3200/94637 (3%)] Step: [2536015] | Lr: 0.000100 | Loss: 1.0518 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 42.71
24-04-04 05:18:27.333 - INFO: Train epoch 443: [ 6400/94637 (7%)] Step: [2536115] | Lr: 0.000100 | Loss: 0.9805 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 38.83
24-04-04 05:19:18.545 - INFO: Train epoch 443: [ 9600/94637 (10%)] Step: [2536215] | Lr: 0.000100 | Loss: 1.0965 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 39.61
24-04-04 05:20:09.626 - INFO: Train epoch 443: [12800/94637 (14%)] Step: [2536315] | Lr: 0.000100 | Loss: 1.2598 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 40.47
24-04-04 05:21:01.099 - INFO: Train epoch 443: [16000/94637 (17%)] Step: [2536415] | Lr: 0.000100 | Loss: 1.4453 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 41.82
24-04-04 05:21:52.407 - INFO: Train epoch 443: [19200/94637 (20%)] Step: [2536515] | Lr: 0.000100 | Loss: 1.3721 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 41.80
24-04-04 05:22:44.366 - INFO: Train epoch 443: [22400/94637 (24%)] Step: [2536615] | Lr: 0.000100 | Loss: 1.4776 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 40.83
24-04-04 05:23:35.632 - INFO: Train epoch 443: [25600/94637 (27%)] Step: [2536715] | Lr: 0.000100 | Loss: 1.0910 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 42.93
24-04-04 05:24:27.454 - INFO: Train epoch 443: [28800/94637 (30%)] Step: [2536815] | Lr: 0.000100 | Loss: 1.3855 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 41.06
24-04-04 05:25:19.269 - INFO: Train epoch 443: [32000/94637 (34%)] Step: [2536915] | Lr: 0.000100 | Loss: 1.0749 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 39.20
24-04-04 05:26:10.411 - INFO: Train epoch 443: [35200/94637 (37%)] Step: [2537015] | Lr: 0.000100 | Loss: 0.9727 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 42.10
24-04-04 05:27:02.206 - INFO: Train epoch 443: [38400/94637 (41%)] Step: [2537115] | Lr: 0.000100 | Loss: 1.1355 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 38.04
24-04-04 05:27:53.445 - INFO: Train epoch 443: [41600/94637 (44%)] Step: [2537215] | Lr: 0.000100 | Loss: 1.4323 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 42.10
24-04-04 05:28:44.570 - INFO: Train epoch 443: [44800/94637 (47%)] Step: [2537315] | Lr: 0.000100 | Loss: 1.2063 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 40.13
24-04-04 05:29:35.997 - INFO: Train epoch 443: [48000/94637 (51%)] Step: [2537415] | Lr: 0.000100 | Loss: 1.1447 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 39.71
24-04-04 05:30:30.469 - INFO: Train epoch 443: [51200/94637 (54%)] Step: [2537515] | Lr: 0.000100 | Loss: 1.5990 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 39.15
24-04-04 05:31:21.933 - INFO: Train epoch 443: [54400/94637 (57%)] Step: [2537615] | Lr: 0.000100 | Loss: 1.5505 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 40.26
24-04-04 05:32:13.277 - INFO: Train epoch 443: [57600/94637 (61%)] Step: [2537715] | Lr: 0.000100 | Loss: 0.9349 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 41.89
24-04-04 05:33:04.488 - INFO: Train epoch 443: [60800/94637 (64%)] Step: [2537815] | Lr: 0.000100 | Loss: 1.0116 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 39.51
24-04-04 05:33:54.970 - INFO: Train epoch 443: [64000/94637 (68%)] Step: [2537915] | Lr: 0.000100 | Loss: 1.3375 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 40.30
24-04-04 05:34:46.292 - INFO: Train epoch 443: [67200/94637 (71%)] Step: [2538015] | Lr: 0.000100 | Loss: 1.1041 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 45.03
24-04-04 05:35:36.373 - INFO: Train epoch 443: [70400/94637 (74%)] Step: [2538115] | Lr: 0.000100 | Loss: 1.0283 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 38.40
24-04-04 05:36:26.848 - INFO: Train epoch 443: [73600/94637 (78%)] Step: [2538215] | Lr: 0.000100 | Loss: 1.0833 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 43.37
24-04-04 05:37:17.084 - INFO: Train epoch 443: [76800/94637 (81%)] Step: [2538315] | Lr: 0.000100 | Loss: 0.9266 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 43.50
24-04-04 05:38:07.679 - INFO: Train epoch 443: [80000/94637 (85%)] Step: [2538415] | Lr: 0.000100 | Loss: 0.9512 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 40.26
24-04-04 05:38:58.751 - INFO: Train epoch 443: [83200/94637 (88%)] Step: [2538515] | Lr: 0.000100 | Loss: 1.1461 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 43.42
24-04-04 05:39:50.135 - INFO: Train epoch 443: [86400/94637 (91%)] Step: [2538615] | Lr: 0.000100 | Loss: 1.3047 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 43.07
24-04-04 05:40:41.472 - INFO: Train epoch 443: [89600/94637 (95%)] Step: [2538715] | Lr: 0.000100 | Loss: 1.0727 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 38.63
24-04-04 05:41:31.839 - INFO: Train epoch 443: [92800/94637 (98%)] Step: [2538815] | Lr: 0.000100 | Loss: 1.4675 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 38.27
24-04-04 05:42:11.886 - INFO: Learning rate: 0.0001
24-04-04 05:42:13.630 - INFO: Train epoch 444: [    0/94637 (0%)] Step: [2538872] | Lr: 0.000100 | Loss: 1.4502 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 40.58
24-04-04 05:43:04.366 - INFO: Train epoch 444: [ 3200/94637 (3%)] Step: [2538972] | Lr: 0.000100 | Loss: 1.4951 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 39.31
24-04-04 05:43:55.174 - INFO: Train epoch 444: [ 6400/94637 (7%)] Step: [2539072] | Lr: 0.000100 | Loss: 1.0977 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 42.97
24-04-04 05:44:45.466 - INFO: Train epoch 444: [ 9600/94637 (10%)] Step: [2539172] | Lr: 0.000100 | Loss: 2.0317 | MSE loss: 0.0005 | Bpp loss: 1.21 | Aux loss: 39.48
24-04-04 05:45:35.970 - INFO: Train epoch 444: [12800/94637 (14%)] Step: [2539272] | Lr: 0.000100 | Loss: 1.1411 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 49.09
24-04-04 05:46:27.219 - INFO: Train epoch 444: [16000/94637 (17%)] Step: [2539372] | Lr: 0.000100 | Loss: 0.7490 | MSE loss: 0.0001 | Bpp loss: 0.51 | Aux loss: 40.00
24-04-04 05:47:17.434 - INFO: Train epoch 444: [19200/94637 (20%)] Step: [2539472] | Lr: 0.000100 | Loss: 1.0495 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 40.94
24-04-04 05:48:08.276 - INFO: Train epoch 444: [22400/94637 (24%)] Step: [2539572] | Lr: 0.000100 | Loss: 1.0640 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 40.77
24-04-04 05:48:59.336 - INFO: Train epoch 444: [25600/94637 (27%)] Step: [2539672] | Lr: 0.000100 | Loss: 1.1219 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 41.12
24-04-04 05:49:50.702 - INFO: Train epoch 444: [28800/94637 (30%)] Step: [2539772] | Lr: 0.000100 | Loss: 1.3566 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 41.44
24-04-04 05:50:42.148 - INFO: Train epoch 444: [32000/94637 (34%)] Step: [2539872] | Lr: 0.000100 | Loss: 0.8580 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 39.34
24-04-04 05:51:33.043 - INFO: Train epoch 444: [35200/94637 (37%)] Step: [2539972] | Lr: 0.000100 | Loss: 1.0752 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 37.72
24-04-04 05:52:26.519 - INFO: Train epoch 444: [38400/94637 (41%)] Step: [2540072] | Lr: 0.000100 | Loss: 0.8603 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 42.43
24-04-04 05:53:16.919 - INFO: Train epoch 444: [41600/94637 (44%)] Step: [2540172] | Lr: 0.000100 | Loss: 1.0235 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 40.79
24-04-04 05:54:08.378 - INFO: Train epoch 444: [44800/94637 (47%)] Step: [2540272] | Lr: 0.000100 | Loss: 1.3523 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 43.26
24-04-04 05:54:59.676 - INFO: Train epoch 444: [48000/94637 (51%)] Step: [2540372] | Lr: 0.000100 | Loss: 1.2760 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 42.90
24-04-04 05:55:50.372 - INFO: Train epoch 444: [51200/94637 (54%)] Step: [2540472] | Lr: 0.000100 | Loss: 1.3942 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 37.94
24-04-04 05:56:41.796 - INFO: Train epoch 444: [54400/94637 (57%)] Step: [2540572] | Lr: 0.000100 | Loss: 0.9876 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 44.68
24-04-04 05:57:32.431 - INFO: Train epoch 444: [57600/94637 (61%)] Step: [2540672] | Lr: 0.000100 | Loss: 1.0563 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 40.02
24-04-04 05:58:24.375 - INFO: Train epoch 444: [60800/94637 (64%)] Step: [2540772] | Lr: 0.000100 | Loss: 1.1282 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 43.43
24-04-04 05:59:15.215 - INFO: Train epoch 444: [64000/94637 (68%)] Step: [2540872] | Lr: 0.000100 | Loss: 1.2296 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 41.41
24-04-04 06:00:06.772 - INFO: Train epoch 444: [67200/94637 (71%)] Step: [2540972] | Lr: 0.000100 | Loss: 1.2558 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 42.36
24-04-04 06:00:58.010 - INFO: Train epoch 444: [70400/94637 (74%)] Step: [2541072] | Lr: 0.000100 | Loss: 0.8702 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 40.98
24-04-04 06:01:49.681 - INFO: Train epoch 444: [73600/94637 (78%)] Step: [2541172] | Lr: 0.000100 | Loss: 1.1297 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 43.05
24-04-04 06:02:40.585 - INFO: Train epoch 444: [76800/94637 (81%)] Step: [2541272] | Lr: 0.000100 | Loss: 1.3985 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 39.42
24-04-04 06:03:31.799 - INFO: Train epoch 444: [80000/94637 (85%)] Step: [2541372] | Lr: 0.000100 | Loss: 1.4133 | MSE loss: 0.0004 | Bpp loss: 0.81 | Aux loss: 42.24
24-04-04 06:04:23.188 - INFO: Train epoch 444: [83200/94637 (88%)] Step: [2541472] | Lr: 0.000100 | Loss: 1.8150 | MSE loss: 0.0005 | Bpp loss: 0.93 | Aux loss: 39.16
24-04-04 06:05:14.273 - INFO: Train epoch 444: [86400/94637 (91%)] Step: [2541572] | Lr: 0.000100 | Loss: 1.2307 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 37.65
24-04-04 06:06:05.422 - INFO: Train epoch 444: [89600/94637 (95%)] Step: [2541672] | Lr: 0.000100 | Loss: 1.1575 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 40.98
24-04-04 06:06:55.597 - INFO: Train epoch 444: [92800/94637 (98%)] Step: [2541772] | Lr: 0.000100 | Loss: 1.0251 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 39.95
24-04-04 06:07:41.331 - INFO: Learning rate: 0.0001
24-04-04 06:07:42.495 - INFO: Train epoch 445: [    0/94637 (0%)] Step: [2541829] | Lr: 0.000100 | Loss: 1.1061 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 41.74
24-04-04 06:08:32.725 - INFO: Train epoch 445: [ 3200/94637 (3%)] Step: [2541929] | Lr: 0.000100 | Loss: 1.4055 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 40.52
24-04-04 06:09:23.743 - INFO: Train epoch 445: [ 6400/94637 (7%)] Step: [2542029] | Lr: 0.000100 | Loss: 1.1769 | MSE loss: 0.0002 | Bpp loss: 0.78 | Aux loss: 40.92
24-04-04 06:10:14.573 - INFO: Train epoch 445: [ 9600/94637 (10%)] Step: [2542129] | Lr: 0.000100 | Loss: 1.3117 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 43.32
24-04-04 06:11:05.802 - INFO: Train epoch 445: [12800/94637 (14%)] Step: [2542229] | Lr: 0.000100 | Loss: 1.0807 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 40.80
24-04-04 06:11:56.895 - INFO: Train epoch 445: [16000/94637 (17%)] Step: [2542329] | Lr: 0.000100 | Loss: 0.9364 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 44.36
24-04-04 06:12:47.825 - INFO: Train epoch 445: [19200/94637 (20%)] Step: [2542429] | Lr: 0.000100 | Loss: 1.1782 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 42.51
24-04-04 06:13:41.107 - INFO: Train epoch 445: [22400/94637 (24%)] Step: [2542529] | Lr: 0.000100 | Loss: 1.1470 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 40.72
24-04-04 06:14:32.052 - INFO: Train epoch 445: [25600/94637 (27%)] Step: [2542629] | Lr: 0.000100 | Loss: 0.9625 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 42.29
24-04-04 06:15:22.938 - INFO: Train epoch 445: [28800/94637 (30%)] Step: [2542729] | Lr: 0.000100 | Loss: 1.1837 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 41.38
24-04-04 06:16:14.270 - INFO: Train epoch 445: [32000/94637 (34%)] Step: [2542829] | Lr: 0.000100 | Loss: 1.4168 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 40.49
24-04-04 06:17:05.498 - INFO: Train epoch 445: [35200/94637 (37%)] Step: [2542929] | Lr: 0.000100 | Loss: 1.1497 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 41.51
24-04-04 06:17:56.724 - INFO: Train epoch 445: [38400/94637 (41%)] Step: [2543029] | Lr: 0.000100 | Loss: 1.0506 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 40.86
24-04-04 06:18:47.526 - INFO: Train epoch 445: [41600/94637 (44%)] Step: [2543129] | Lr: 0.000100 | Loss: 0.7155 | MSE loss: 0.0002 | Bpp loss: 0.46 | Aux loss: 42.32
24-04-04 06:19:38.932 - INFO: Train epoch 445: [44800/94637 (47%)] Step: [2543229] | Lr: 0.000100 | Loss: 1.3708 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 44.99
24-04-04 06:20:30.106 - INFO: Train epoch 445: [48000/94637 (51%)] Step: [2543329] | Lr: 0.000100 | Loss: 1.2930 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 40.18
24-04-04 06:21:20.976 - INFO: Train epoch 445: [51200/94637 (54%)] Step: [2543429] | Lr: 0.000100 | Loss: 1.2409 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 39.95
24-04-04 06:22:12.164 - INFO: Train epoch 445: [54400/94637 (57%)] Step: [2543529] | Lr: 0.000100 | Loss: 1.0856 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 41.23
24-04-04 06:23:02.644 - INFO: Train epoch 445: [57600/94637 (61%)] Step: [2543629] | Lr: 0.000100 | Loss: 0.9017 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 40.17
24-04-04 06:23:53.760 - INFO: Train epoch 445: [60800/94637 (64%)] Step: [2543729] | Lr: 0.000100 | Loss: 1.2167 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 40.81
24-04-04 06:24:45.038 - INFO: Train epoch 445: [64000/94637 (68%)] Step: [2543829] | Lr: 0.000100 | Loss: 1.5031 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 45.36
24-04-04 06:25:35.510 - INFO: Train epoch 445: [67200/94637 (71%)] Step: [2543929] | Lr: 0.000100 | Loss: 1.5205 | MSE loss: 0.0004 | Bpp loss: 0.88 | Aux loss: 42.85
24-04-04 06:26:25.761 - INFO: Train epoch 445: [70400/94637 (74%)] Step: [2544029] | Lr: 0.000100 | Loss: 1.2262 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 45.76
24-04-04 06:27:15.540 - INFO: Train epoch 445: [73600/94637 (78%)] Step: [2544129] | Lr: 0.000100 | Loss: 1.0912 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 43.00
24-04-04 06:28:06.278 - INFO: Train epoch 445: [76800/94637 (81%)] Step: [2544229] | Lr: 0.000100 | Loss: 1.2599 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 40.65
24-04-04 06:28:57.533 - INFO: Train epoch 445: [80000/94637 (85%)] Step: [2544329] | Lr: 0.000100 | Loss: 1.0374 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 40.03
24-04-04 06:29:49.100 - INFO: Train epoch 445: [83200/94637 (88%)] Step: [2544429] | Lr: 0.000100 | Loss: 1.2920 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 41.95
24-04-04 06:30:40.906 - INFO: Train epoch 445: [86400/94637 (91%)] Step: [2544529] | Lr: 0.000100 | Loss: 1.1936 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 40.64
24-04-04 06:31:32.216 - INFO: Train epoch 445: [89600/94637 (95%)] Step: [2544629] | Lr: 0.000100 | Loss: 1.2744 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 46.55
24-04-04 06:32:22.632 - INFO: Train epoch 445: [92800/94637 (98%)] Step: [2544729] | Lr: 0.000100 | Loss: 1.3090 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 43.97
24-04-04 06:33:02.715 - INFO: Learning rate: 0.0001
24-04-04 06:33:04.954 - INFO: Train epoch 446: [    0/94637 (0%)] Step: [2544786] | Lr: 0.000100 | Loss: 1.1770 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 42.03
24-04-04 06:33:54.933 - INFO: Train epoch 446: [ 3200/94637 (3%)] Step: [2544886] | Lr: 0.000100 | Loss: 0.9795 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 49.70
24-04-04 06:34:45.540 - INFO: Train epoch 446: [ 6400/94637 (7%)] Step: [2544986] | Lr: 0.000100 | Loss: 1.4180 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 41.22
24-04-04 06:35:38.195 - INFO: Train epoch 446: [ 9600/94637 (10%)] Step: [2545086] | Lr: 0.000100 | Loss: 1.3118 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 41.91
24-04-04 06:36:29.503 - INFO: Train epoch 446: [12800/94637 (14%)] Step: [2545186] | Lr: 0.000100 | Loss: 1.4178 | MSE loss: 0.0004 | Bpp loss: 0.83 | Aux loss: 42.65
24-04-04 06:37:21.971 - INFO: Train epoch 446: [16000/94637 (17%)] Step: [2545286] | Lr: 0.000100 | Loss: 1.0256 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 40.50
24-04-04 06:38:13.792 - INFO: Train epoch 446: [19200/94637 (20%)] Step: [2545386] | Lr: 0.000100 | Loss: 0.9995 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 43.87
24-04-04 06:39:04.953 - INFO: Train epoch 446: [22400/94637 (24%)] Step: [2545486] | Lr: 0.000100 | Loss: 1.2174 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 44.82
24-04-04 06:39:55.643 - INFO: Train epoch 446: [25600/94637 (27%)] Step: [2545586] | Lr: 0.000100 | Loss: 1.3852 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 42.47
24-04-04 06:40:45.142 - INFO: Train epoch 446: [28800/94637 (30%)] Step: [2545686] | Lr: 0.000100 | Loss: 1.5805 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 41.21
24-04-04 06:41:35.369 - INFO: Train epoch 446: [32000/94637 (34%)] Step: [2545786] | Lr: 0.000100 | Loss: 1.3633 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 44.14
24-04-04 06:42:25.472 - INFO: Train epoch 446: [35200/94637 (37%)] Step: [2545886] | Lr: 0.000100 | Loss: 1.2775 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 38.64
24-04-04 06:43:16.437 - INFO: Train epoch 446: [38400/94637 (41%)] Step: [2545986] | Lr: 0.000100 | Loss: 0.9357 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 41.00
24-04-04 06:44:08.185 - INFO: Train epoch 446: [41600/94637 (44%)] Step: [2546086] | Lr: 0.000100 | Loss: 1.1062 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 43.72
24-04-04 06:44:59.916 - INFO: Train epoch 446: [44800/94637 (47%)] Step: [2546186] | Lr: 0.000100 | Loss: 1.5389 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 45.91
24-04-04 06:45:51.401 - INFO: Train epoch 446: [48000/94637 (51%)] Step: [2546286] | Lr: 0.000100 | Loss: 1.2260 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 44.08
24-04-04 06:46:42.314 - INFO: Train epoch 446: [51200/94637 (54%)] Step: [2546386] | Lr: 0.000100 | Loss: 2.0910 | MSE loss: 0.0005 | Bpp loss: 1.21 | Aux loss: 42.98
24-04-04 06:47:33.369 - INFO: Train epoch 446: [54400/94637 (57%)] Step: [2546486] | Lr: 0.000100 | Loss: 0.8841 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 43.55
24-04-04 06:48:24.910 - INFO: Train epoch 446: [57600/94637 (61%)] Step: [2546586] | Lr: 0.000100 | Loss: 1.6410 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 40.07
24-04-04 06:49:16.133 - INFO: Train epoch 446: [60800/94637 (64%)] Step: [2546686] | Lr: 0.000100 | Loss: 1.3447 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 43.36
24-04-04 06:50:07.412 - INFO: Train epoch 446: [64000/94637 (68%)] Step: [2546786] | Lr: 0.000100 | Loss: 1.4510 | MSE loss: 0.0004 | Bpp loss: 0.88 | Aux loss: 43.20
24-04-04 06:50:58.268 - INFO: Train epoch 446: [67200/94637 (71%)] Step: [2546886] | Lr: 0.000100 | Loss: 1.2461 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 39.87
24-04-04 06:51:49.098 - INFO: Train epoch 446: [70400/94637 (74%)] Step: [2546986] | Lr: 0.000100 | Loss: 1.3843 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 41.47
24-04-04 06:52:39.758 - INFO: Train epoch 446: [73600/94637 (78%)] Step: [2547086] | Lr: 0.000100 | Loss: 1.4408 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 39.28
24-04-04 06:53:30.903 - INFO: Train epoch 446: [76800/94637 (81%)] Step: [2547186] | Lr: 0.000100 | Loss: 1.0997 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 40.50
24-04-04 06:54:22.286 - INFO: Train epoch 446: [80000/94637 (85%)] Step: [2547286] | Lr: 0.000100 | Loss: 1.3794 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 42.69
24-04-04 06:55:13.733 - INFO: Train epoch 446: [83200/94637 (88%)] Step: [2547386] | Lr: 0.000100 | Loss: 0.8864 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 41.74
24-04-04 06:56:05.393 - INFO: Train epoch 446: [86400/94637 (91%)] Step: [2547486] | Lr: 0.000100 | Loss: 0.7007 | MSE loss: 0.0002 | Bpp loss: 0.46 | Aux loss: 41.72
24-04-04 06:56:58.451 - INFO: Train epoch 446: [89600/94637 (95%)] Step: [2547586] | Lr: 0.000100 | Loss: 1.1416 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 41.91
24-04-04 06:57:49.073 - INFO: Train epoch 446: [92800/94637 (98%)] Step: [2547686] | Lr: 0.000100 | Loss: 1.2401 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 43.18
24-04-04 06:58:35.007 - INFO: Learning rate: 0.0001
24-04-04 06:58:36.164 - INFO: Train epoch 447: [    0/94637 (0%)] Step: [2547743] | Lr: 0.000100 | Loss: 1.3906 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 38.58
24-04-04 06:59:26.699 - INFO: Train epoch 447: [ 3200/94637 (3%)] Step: [2547843] | Lr: 0.000100 | Loss: 0.7769 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 39.47
24-04-04 07:00:17.785 - INFO: Train epoch 447: [ 6400/94637 (7%)] Step: [2547943] | Lr: 0.000100 | Loss: 1.2370 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 44.28
24-04-04 07:01:08.828 - INFO: Train epoch 447: [ 9600/94637 (10%)] Step: [2548043] | Lr: 0.000100 | Loss: 0.9525 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 43.42
24-04-04 07:01:59.456 - INFO: Train epoch 447: [12800/94637 (14%)] Step: [2548143] | Lr: 0.000100 | Loss: 0.9315 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 38.08
24-04-04 07:03:14.708 - INFO: Train epoch 447: [16000/94637 (17%)] Step: [2548243] | Lr: 0.000100 | Loss: 1.3065 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 42.27
24-04-04 07:04:06.245 - INFO: Train epoch 447: [19200/94637 (20%)] Step: [2548343] | Lr: 0.000100 | Loss: 1.1882 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 39.43
24-04-04 07:04:58.719 - INFO: Train epoch 447: [22400/94637 (24%)] Step: [2548443] | Lr: 0.000100 | Loss: 1.0804 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 41.96
24-04-04 07:05:50.169 - INFO: Train epoch 447: [25600/94637 (27%)] Step: [2548543] | Lr: 0.000100 | Loss: 1.1756 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 39.22
24-04-04 07:06:42.546 - INFO: Train epoch 447: [28800/94637 (30%)] Step: [2548643] | Lr: 0.000100 | Loss: 1.5292 | MSE loss: 0.0003 | Bpp loss: 0.98 | Aux loss: 40.31
24-04-04 07:07:33.885 - INFO: Train epoch 447: [32000/94637 (34%)] Step: [2548743] | Lr: 0.000100 | Loss: 1.3336 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 43.32
24-04-04 07:08:24.894 - INFO: Train epoch 447: [35200/94637 (37%)] Step: [2548843] | Lr: 0.000100 | Loss: 1.4994 | MSE loss: 0.0004 | Bpp loss: 0.93 | Aux loss: 42.80
24-04-04 07:09:16.216 - INFO: Train epoch 447: [38400/94637 (41%)] Step: [2548943] | Lr: 0.000100 | Loss: 1.0819 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 44.12
24-04-04 07:10:07.646 - INFO: Train epoch 447: [41600/94637 (44%)] Step: [2549043] | Lr: 0.000100 | Loss: 1.8683 | MSE loss: 0.0004 | Bpp loss: 1.19 | Aux loss: 40.22
24-04-04 07:10:58.979 - INFO: Train epoch 447: [44800/94637 (47%)] Step: [2549143] | Lr: 0.000100 | Loss: 1.1492 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 40.86
24-04-04 07:11:50.814 - INFO: Train epoch 447: [48000/94637 (51%)] Step: [2549243] | Lr: 0.000100 | Loss: 1.1943 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 44.88
24-04-04 07:12:42.504 - INFO: Train epoch 447: [51200/94637 (54%)] Step: [2549343] | Lr: 0.000100 | Loss: 0.8522 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 43.34
24-04-04 07:13:33.176 - INFO: Train epoch 447: [54400/94637 (57%)] Step: [2549443] | Lr: 0.000100 | Loss: 1.1354 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 39.51
24-04-04 07:14:23.912 - INFO: Train epoch 447: [57600/94637 (61%)] Step: [2549543] | Lr: 0.000100 | Loss: 0.8873 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 51.80
24-04-04 07:15:14.756 - INFO: Train epoch 447: [60800/94637 (64%)] Step: [2549643] | Lr: 0.000100 | Loss: 1.5778 | MSE loss: 0.0005 | Bpp loss: 0.83 | Aux loss: 36.61
24-04-04 07:16:04.907 - INFO: Train epoch 447: [64000/94637 (68%)] Step: [2549743] | Lr: 0.000100 | Loss: 1.5697 | MSE loss: 0.0004 | Bpp loss: 0.88 | Aux loss: 37.32
24-04-04 07:16:55.716 - INFO: Train epoch 447: [67200/94637 (71%)] Step: [2549843] | Lr: 0.000100 | Loss: 1.0925 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 37.37
24-04-04 07:17:46.110 - INFO: Train epoch 447: [70400/94637 (74%)] Step: [2549943] | Lr: 0.000100 | Loss: 1.2320 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 37.41
24-04-04 07:18:39.214 - INFO: Train epoch 447: [73600/94637 (78%)] Step: [2550043] | Lr: 0.000100 | Loss: 1.5368 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 36.43
24-04-04 07:19:31.137 - INFO: Train epoch 447: [76800/94637 (81%)] Step: [2550143] | Lr: 0.000100 | Loss: 1.1201 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 39.25
24-04-04 07:20:22.678 - INFO: Train epoch 447: [80000/94637 (85%)] Step: [2550243] | Lr: 0.000100 | Loss: 1.1751 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 38.65
24-04-04 07:21:14.306 - INFO: Train epoch 447: [83200/94637 (88%)] Step: [2550343] | Lr: 0.000100 | Loss: 1.2781 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 36.65
24-04-04 07:22:05.630 - INFO: Train epoch 447: [86400/94637 (91%)] Step: [2550443] | Lr: 0.000100 | Loss: 1.3164 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 37.50
24-04-04 07:22:56.131 - INFO: Train epoch 447: [89600/94637 (95%)] Step: [2550543] | Lr: 0.000100 | Loss: 1.5304 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 41.35
24-04-04 07:23:46.554 - INFO: Train epoch 447: [92800/94637 (98%)] Step: [2550643] | Lr: 0.000100 | Loss: 1.0042 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 37.63
24-04-04 07:24:26.673 - INFO: Learning rate: 0.0001
24-04-04 07:24:28.373 - INFO: Train epoch 448: [    0/94637 (0%)] Step: [2550700] | Lr: 0.000100 | Loss: 0.8578 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 40.60
24-04-04 07:25:19.080 - INFO: Train epoch 448: [ 3200/94637 (3%)] Step: [2550800] | Lr: 0.000100 | Loss: 1.6699 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 42.03
24-04-04 07:26:10.847 - INFO: Train epoch 448: [ 6400/94637 (7%)] Step: [2550900] | Lr: 0.000100 | Loss: 1.1207 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 39.88
24-04-04 07:27:00.858 - INFO: Train epoch 448: [ 9600/94637 (10%)] Step: [2551000] | Lr: 0.000100 | Loss: 1.0648 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 39.83
24-04-04 07:27:52.372 - INFO: Train epoch 448: [12800/94637 (14%)] Step: [2551100] | Lr: 0.000100 | Loss: 1.3461 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 40.78
24-04-04 07:28:43.456 - INFO: Train epoch 448: [16000/94637 (17%)] Step: [2551200] | Lr: 0.000100 | Loss: 1.5310 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 41.43
24-04-04 07:29:33.356 - INFO: Train epoch 448: [19200/94637 (20%)] Step: [2551300] | Lr: 0.000100 | Loss: 1.3066 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 39.05
24-04-04 07:30:23.931 - INFO: Train epoch 448: [22400/94637 (24%)] Step: [2551400] | Lr: 0.000100 | Loss: 0.7658 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 40.01
24-04-04 07:31:13.961 - INFO: Train epoch 448: [25600/94637 (27%)] Step: [2551500] | Lr: 0.000100 | Loss: 0.8241 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 41.17
24-04-04 07:32:05.446 - INFO: Train epoch 448: [28800/94637 (30%)] Step: [2551600] | Lr: 0.000100 | Loss: 1.0382 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 39.38
24-04-04 07:32:57.193 - INFO: Train epoch 448: [32000/94637 (34%)] Step: [2551700] | Lr: 0.000100 | Loss: 0.8378 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 36.56
24-04-04 07:33:48.435 - INFO: Train epoch 448: [35200/94637 (37%)] Step: [2551800] | Lr: 0.000100 | Loss: 1.3020 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 35.40
24-04-04 07:34:39.502 - INFO: Train epoch 448: [38400/94637 (41%)] Step: [2551900] | Lr: 0.000100 | Loss: 1.2426 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 37.80
24-04-04 07:35:30.292 - INFO: Train epoch 448: [41600/94637 (44%)] Step: [2552000] | Lr: 0.000100 | Loss: 1.6762 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 37.47
24-04-04 07:36:21.110 - INFO: Train epoch 448: [44800/94637 (47%)] Step: [2552100] | Lr: 0.000100 | Loss: 1.0449 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 41.05
24-04-04 07:37:12.443 - INFO: Train epoch 448: [48000/94637 (51%)] Step: [2552200] | Lr: 0.000100 | Loss: 1.0420 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 41.32
24-04-04 07:38:03.707 - INFO: Train epoch 448: [51200/94637 (54%)] Step: [2552300] | Lr: 0.000100 | Loss: 1.1606 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 40.99
24-04-04 07:38:54.630 - INFO: Train epoch 448: [54400/94637 (57%)] Step: [2552400] | Lr: 0.000100 | Loss: 0.8280 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 41.42
24-04-04 07:39:45.589 - INFO: Train epoch 448: [57600/94637 (61%)] Step: [2552500] | Lr: 0.000100 | Loss: 1.3441 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 40.15
24-04-04 07:40:38.526 - INFO: Train epoch 448: [60800/94637 (64%)] Step: [2552600] | Lr: 0.000100 | Loss: 1.4761 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 38.08
24-04-04 07:41:30.227 - INFO: Train epoch 448: [64000/94637 (68%)] Step: [2552700] | Lr: 0.000100 | Loss: 1.4126 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 38.39
24-04-04 07:42:20.365 - INFO: Train epoch 448: [67200/94637 (71%)] Step: [2552800] | Lr: 0.000100 | Loss: 0.8796 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 41.78
24-04-04 07:43:11.097 - INFO: Train epoch 448: [70400/94637 (74%)] Step: [2552900] | Lr: 0.000100 | Loss: 1.2814 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 39.75
24-04-04 07:44:02.473 - INFO: Train epoch 448: [73600/94637 (78%)] Step: [2553000] | Lr: 0.000100 | Loss: 1.1480 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 40.89
24-04-04 07:44:52.944 - INFO: Train epoch 448: [76800/94637 (81%)] Step: [2553100] | Lr: 0.000100 | Loss: 1.0336 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 38.37
24-04-04 07:45:43.421 - INFO: Train epoch 448: [80000/94637 (85%)] Step: [2553200] | Lr: 0.000100 | Loss: 1.2042 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 39.55
24-04-04 07:46:34.625 - INFO: Train epoch 448: [83200/94637 (88%)] Step: [2553300] | Lr: 0.000100 | Loss: 1.1634 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 40.02
24-04-04 07:47:25.863 - INFO: Train epoch 448: [86400/94637 (91%)] Step: [2553400] | Lr: 0.000100 | Loss: 0.6942 | MSE loss: 0.0001 | Bpp loss: 0.45 | Aux loss: 39.47
24-04-04 07:48:17.070 - INFO: Train epoch 448: [89600/94637 (95%)] Step: [2553500] | Lr: 0.000100 | Loss: 1.0964 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 41.37
24-04-04 07:49:08.104 - INFO: Train epoch 448: [92800/94637 (98%)] Step: [2553600] | Lr: 0.000100 | Loss: 1.1018 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 40.23
24-04-04 07:49:48.728 - INFO: Learning rate: 0.0001
24-04-04 07:49:49.857 - INFO: Train epoch 449: [    0/94637 (0%)] Step: [2553657] | Lr: 0.000100 | Loss: 1.1891 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 41.25
24-04-04 07:50:40.819 - INFO: Train epoch 449: [ 3200/94637 (3%)] Step: [2553757] | Lr: 0.000100 | Loss: 1.8680 | MSE loss: 0.0005 | Bpp loss: 1.09 | Aux loss: 41.35
24-04-04 07:51:31.541 - INFO: Train epoch 449: [ 6400/94637 (7%)] Step: [2553857] | Lr: 0.000100 | Loss: 1.2009 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 43.31
24-04-04 07:52:22.790 - INFO: Train epoch 449: [ 9600/94637 (10%)] Step: [2553957] | Lr: 0.000100 | Loss: 1.4482 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 40.86
24-04-04 07:53:13.656 - INFO: Train epoch 449: [12800/94637 (14%)] Step: [2554057] | Lr: 0.000100 | Loss: 1.3272 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 39.46
24-04-04 07:54:04.374 - INFO: Train epoch 449: [16000/94637 (17%)] Step: [2554157] | Lr: 0.000100 | Loss: 0.9135 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 40.68
24-04-04 07:54:55.175 - INFO: Train epoch 449: [19200/94637 (20%)] Step: [2554257] | Lr: 0.000100 | Loss: 1.0070 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 40.71
24-04-04 07:55:45.265 - INFO: Train epoch 449: [22400/94637 (24%)] Step: [2554357] | Lr: 0.000100 | Loss: 1.2369 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 40.09
24-04-04 07:56:36.103 - INFO: Train epoch 449: [25600/94637 (27%)] Step: [2554457] | Lr: 0.000100 | Loss: 0.7197 | MSE loss: 0.0002 | Bpp loss: 0.47 | Aux loss: 41.96
24-04-04 07:57:27.038 - INFO: Train epoch 449: [28800/94637 (30%)] Step: [2554557] | Lr: 0.000100 | Loss: 1.6530 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 38.69
24-04-04 07:58:18.407 - INFO: Train epoch 449: [32000/94637 (34%)] Step: [2554657] | Lr: 0.000100 | Loss: 1.3661 | MSE loss: 0.0004 | Bpp loss: 0.76 | Aux loss: 40.51
24-04-04 07:59:09.306 - INFO: Train epoch 449: [35200/94637 (37%)] Step: [2554757] | Lr: 0.000100 | Loss: 0.9494 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 42.22
24-04-04 08:00:00.533 - INFO: Train epoch 449: [38400/94637 (41%)] Step: [2554857] | Lr: 0.000100 | Loss: 1.1240 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 40.53
24-04-04 08:00:50.844 - INFO: Train epoch 449: [41600/94637 (44%)] Step: [2554957] | Lr: 0.000100 | Loss: 1.2427 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 38.35
24-04-04 08:01:43.386 - INFO: Train epoch 449: [44800/94637 (47%)] Step: [2555057] | Lr: 0.000100 | Loss: 1.2420 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 39.92
24-04-04 08:02:34.454 - INFO: Train epoch 449: [48000/94637 (51%)] Step: [2555157] | Lr: 0.000100 | Loss: 1.4496 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 39.15
24-04-04 08:03:25.319 - INFO: Train epoch 449: [51200/94637 (54%)] Step: [2555257] | Lr: 0.000100 | Loss: 0.9523 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 41.72
24-04-04 08:04:16.620 - INFO: Train epoch 449: [54400/94637 (57%)] Step: [2555357] | Lr: 0.000100 | Loss: 1.0235 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 42.15
24-04-04 08:05:07.449 - INFO: Train epoch 449: [57600/94637 (61%)] Step: [2555457] | Lr: 0.000100 | Loss: 1.2551 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 41.08
24-04-04 08:05:58.247 - INFO: Train epoch 449: [60800/94637 (64%)] Step: [2555557] | Lr: 0.000100 | Loss: 1.1041 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 40.11
24-04-04 08:06:48.577 - INFO: Train epoch 449: [64000/94637 (68%)] Step: [2555657] | Lr: 0.000100 | Loss: 1.3839 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 43.18
24-04-04 08:07:39.860 - INFO: Train epoch 449: [67200/94637 (71%)] Step: [2555757] | Lr: 0.000100 | Loss: 1.1256 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 42.18
24-04-04 08:08:30.772 - INFO: Train epoch 449: [70400/94637 (74%)] Step: [2555857] | Lr: 0.000100 | Loss: 1.0887 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 42.42
24-04-04 08:09:22.209 - INFO: Train epoch 449: [73600/94637 (78%)] Step: [2555957] | Lr: 0.000100 | Loss: 1.2448 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 43.13
24-04-04 08:10:12.735 - INFO: Train epoch 449: [76800/94637 (81%)] Step: [2556057] | Lr: 0.000100 | Loss: 1.4881 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 42.65
24-04-04 08:11:03.744 - INFO: Train epoch 449: [80000/94637 (85%)] Step: [2556157] | Lr: 0.000100 | Loss: 1.9280 | MSE loss: 0.0005 | Bpp loss: 1.17 | Aux loss: 37.22
24-04-04 08:11:55.324 - INFO: Train epoch 449: [83200/94637 (88%)] Step: [2556257] | Lr: 0.000100 | Loss: 1.3172 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 41.58
24-04-04 08:12:46.576 - INFO: Train epoch 449: [86400/94637 (91%)] Step: [2556357] | Lr: 0.000100 | Loss: 1.2678 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 40.36
24-04-04 08:13:37.148 - INFO: Train epoch 449: [89600/94637 (95%)] Step: [2556457] | Lr: 0.000100 | Loss: 1.1129 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 39.90
24-04-04 08:14:29.146 - INFO: Train epoch 449: [92800/94637 (98%)] Step: [2556557] | Lr: 0.000100 | Loss: 1.2383 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 40.84
24-04-04 08:15:10.240 - INFO: Learning rate: 0.0001
24-04-04 08:15:11.371 - INFO: Train epoch 450: [    0/94637 (0%)] Step: [2556614] | Lr: 0.000100 | Loss: 1.3552 | MSE loss: 0.0004 | Bpp loss: 0.76 | Aux loss: 44.83
24-04-04 08:16:01.919 - INFO: Train epoch 450: [ 3200/94637 (3%)] Step: [2556714] | Lr: 0.000100 | Loss: 1.4160 | MSE loss: 0.0004 | Bpp loss: 0.84 | Aux loss: 41.13
24-04-04 08:16:52.643 - INFO: Train epoch 450: [ 6400/94637 (7%)] Step: [2556814] | Lr: 0.000100 | Loss: 1.1267 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 43.05
24-04-04 08:17:43.581 - INFO: Train epoch 450: [ 9600/94637 (10%)] Step: [2556914] | Lr: 0.000100 | Loss: 1.8505 | MSE loss: 0.0004 | Bpp loss: 1.14 | Aux loss: 42.06
24-04-04 08:18:33.940 - INFO: Train epoch 450: [12800/94637 (14%)] Step: [2557014] | Lr: 0.000100 | Loss: 1.1965 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 41.54
24-04-04 08:19:24.579 - INFO: Train epoch 450: [16000/94637 (17%)] Step: [2557114] | Lr: 0.000100 | Loss: 1.4534 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 40.70
24-04-04 08:20:15.508 - INFO: Train epoch 450: [19200/94637 (20%)] Step: [2557214] | Lr: 0.000100 | Loss: 1.4108 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 42.75
24-04-04 08:21:06.734 - INFO: Train epoch 450: [22400/94637 (24%)] Step: [2557314] | Lr: 0.000100 | Loss: 1.2122 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 39.77
24-04-04 08:21:57.427 - INFO: Train epoch 450: [25600/94637 (27%)] Step: [2557414] | Lr: 0.000100 | Loss: 1.1316 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 46.49
24-04-04 08:22:50.353 - INFO: Train epoch 450: [28800/94637 (30%)] Step: [2557514] | Lr: 0.000100 | Loss: 0.9812 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 39.81
24-04-04 08:23:40.935 - INFO: Train epoch 450: [32000/94637 (34%)] Step: [2557614] | Lr: 0.000100 | Loss: 1.3370 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 40.92
24-04-04 08:24:32.176 - INFO: Train epoch 450: [35200/94637 (37%)] Step: [2557714] | Lr: 0.000100 | Loss: 1.0805 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 42.91
24-04-04 08:25:24.184 - INFO: Train epoch 450: [38400/94637 (41%)] Step: [2557814] | Lr: 0.000100 | Loss: 1.3896 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 45.08
24-04-04 08:26:15.526 - INFO: Train epoch 450: [41600/94637 (44%)] Step: [2557914] | Lr: 0.000100 | Loss: 1.1217 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 42.05
24-04-04 08:27:06.071 - INFO: Train epoch 450: [44800/94637 (47%)] Step: [2558014] | Lr: 0.000100 | Loss: 0.8661 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 39.64
24-04-04 08:27:57.058 - INFO: Train epoch 450: [48000/94637 (51%)] Step: [2558114] | Lr: 0.000100 | Loss: 1.3779 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 42.55
24-04-04 08:28:48.461 - INFO: Train epoch 450: [51200/94637 (54%)] Step: [2558214] | Lr: 0.000100 | Loss: 1.1970 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 39.81
24-04-04 08:29:39.857 - INFO: Train epoch 450: [54400/94637 (57%)] Step: [2558314] | Lr: 0.000100 | Loss: 1.1596 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 38.73
24-04-04 08:30:31.616 - INFO: Train epoch 450: [57600/94637 (61%)] Step: [2558414] | Lr: 0.000100 | Loss: 1.1660 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 37.60
24-04-04 08:31:23.031 - INFO: Train epoch 450: [60800/94637 (64%)] Step: [2558514] | Lr: 0.000100 | Loss: 1.3760 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 43.10
24-04-04 08:32:14.369 - INFO: Train epoch 450: [64000/94637 (68%)] Step: [2558614] | Lr: 0.000100 | Loss: 1.2702 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 43.04
24-04-04 08:33:05.875 - INFO: Train epoch 450: [67200/94637 (71%)] Step: [2558714] | Lr: 0.000100 | Loss: 1.6127 | MSE loss: 0.0005 | Bpp loss: 0.87 | Aux loss: 41.68
24-04-04 08:33:57.096 - INFO: Train epoch 450: [70400/94637 (74%)] Step: [2558814] | Lr: 0.000100 | Loss: 1.2047 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 42.18
24-04-04 08:34:47.578 - INFO: Train epoch 450: [73600/94637 (78%)] Step: [2558914] | Lr: 0.000100 | Loss: 1.3969 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 41.20
24-04-04 08:35:38.721 - INFO: Train epoch 450: [76800/94637 (81%)] Step: [2559014] | Lr: 0.000100 | Loss: 1.6154 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 39.92
24-04-04 08:36:29.933 - INFO: Train epoch 450: [80000/94637 (85%)] Step: [2559114] | Lr: 0.000100 | Loss: 1.2861 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 38.63
24-04-04 08:37:20.897 - INFO: Train epoch 450: [83200/94637 (88%)] Step: [2559214] | Lr: 0.000100 | Loss: 1.5221 | MSE loss: 0.0003 | Bpp loss: 0.99 | Aux loss: 41.29
24-04-04 08:38:12.737 - INFO: Train epoch 450: [86400/94637 (91%)] Step: [2559314] | Lr: 0.000100 | Loss: 0.9919 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 38.18
24-04-04 08:39:03.509 - INFO: Train epoch 450: [89600/94637 (95%)] Step: [2559414] | Lr: 0.000100 | Loss: 1.1400 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 40.79
24-04-04 08:39:54.432 - INFO: Train epoch 450: [92800/94637 (98%)] Step: [2559514] | Lr: 0.000100 | Loss: 1.1162 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 43.71
24-04-04 08:40:35.149 - INFO: Learning rate: 0.0001
24-04-04 08:40:37.060 - INFO: Train epoch 451: [    0/94637 (0%)] Step: [2559571] | Lr: 0.000100 | Loss: 1.3605 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 40.94
24-04-04 08:41:27.572 - INFO: Train epoch 451: [ 3200/94637 (3%)] Step: [2559671] | Lr: 0.000100 | Loss: 0.9264 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 43.38
24-04-04 08:42:18.265 - INFO: Train epoch 451: [ 6400/94637 (7%)] Step: [2559771] | Lr: 0.000100 | Loss: 1.2080 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 39.54
24-04-04 08:43:07.991 - INFO: Train epoch 451: [ 9600/94637 (10%)] Step: [2559871] | Lr: 0.000100 | Loss: 1.6077 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 44.02
24-04-04 08:43:58.530 - INFO: Train epoch 451: [12800/94637 (14%)] Step: [2559971] | Lr: 0.000100 | Loss: 0.9186 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 40.23
24-04-04 08:44:50.246 - INFO: Train epoch 451: [16000/94637 (17%)] Step: [2560071] | Lr: 0.000100 | Loss: 1.5984 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 40.78
24-04-04 08:45:41.297 - INFO: Train epoch 451: [19200/94637 (20%)] Step: [2560171] | Lr: 0.000100 | Loss: 1.3057 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 43.12
24-04-04 08:46:32.632 - INFO: Train epoch 451: [22400/94637 (24%)] Step: [2560271] | Lr: 0.000100 | Loss: 1.4343 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 44.24
24-04-04 08:47:23.385 - INFO: Train epoch 451: [25600/94637 (27%)] Step: [2560371] | Lr: 0.000100 | Loss: 1.7482 | MSE loss: 0.0005 | Bpp loss: 0.96 | Aux loss: 45.55
24-04-04 08:48:14.676 - INFO: Train epoch 451: [28800/94637 (30%)] Step: [2560471] | Lr: 0.000100 | Loss: 1.2240 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 40.11
24-04-04 08:49:05.316 - INFO: Train epoch 451: [32000/94637 (34%)] Step: [2560571] | Lr: 0.000100 | Loss: 1.0815 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 40.37
24-04-04 08:49:55.902 - INFO: Train epoch 451: [35200/94637 (37%)] Step: [2560671] | Lr: 0.000100 | Loss: 0.8052 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 44.65
24-04-04 08:50:46.746 - INFO: Train epoch 451: [38400/94637 (41%)] Step: [2560771] | Lr: 0.000100 | Loss: 1.4622 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 41.31
24-04-04 08:51:37.145 - INFO: Train epoch 451: [41600/94637 (44%)] Step: [2560871] | Lr: 0.000100 | Loss: 1.3872 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 39.57
24-04-04 08:52:28.076 - INFO: Train epoch 451: [44800/94637 (47%)] Step: [2560971] | Lr: 0.000100 | Loss: 1.5638 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 44.33
24-04-04 08:53:19.251 - INFO: Train epoch 451: [48000/94637 (51%)] Step: [2561071] | Lr: 0.000100 | Loss: 0.8769 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 46.60
24-04-04 08:54:09.804 - INFO: Train epoch 451: [51200/94637 (54%)] Step: [2561171] | Lr: 0.000100 | Loss: 1.4662 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 43.80
24-04-04 08:55:00.663 - INFO: Train epoch 451: [54400/94637 (57%)] Step: [2561271] | Lr: 0.000100 | Loss: 1.2797 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 43.59
24-04-04 08:55:52.220 - INFO: Train epoch 451: [57600/94637 (61%)] Step: [2561371] | Lr: 0.000100 | Loss: 0.9935 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 42.95
24-04-04 08:56:43.228 - INFO: Train epoch 451: [60800/94637 (64%)] Step: [2561471] | Lr: 0.000100 | Loss: 1.6272 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 42.55
24-04-04 08:57:33.743 - INFO: Train epoch 451: [64000/94637 (68%)] Step: [2561571] | Lr: 0.000100 | Loss: 1.3165 | MSE loss: 0.0004 | Bpp loss: 0.75 | Aux loss: 42.27
24-04-04 08:58:23.986 - INFO: Train epoch 451: [67200/94637 (71%)] Step: [2561671] | Lr: 0.000100 | Loss: 1.2509 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 39.94
24-04-04 08:59:14.834 - INFO: Train epoch 451: [70400/94637 (74%)] Step: [2561771] | Lr: 0.000100 | Loss: 1.0625 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 43.90
24-04-04 09:00:05.654 - INFO: Train epoch 451: [73600/94637 (78%)] Step: [2561871] | Lr: 0.000100 | Loss: 0.8812 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 40.75
24-04-04 09:00:56.204 - INFO: Train epoch 451: [76800/94637 (81%)] Step: [2561971] | Lr: 0.000100 | Loss: 1.1560 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 43.02
24-04-04 09:01:47.312 - INFO: Train epoch 451: [80000/94637 (85%)] Step: [2562071] | Lr: 0.000100 | Loss: 1.6246 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 42.36
24-04-04 09:02:38.528 - INFO: Train epoch 451: [83200/94637 (88%)] Step: [2562171] | Lr: 0.000100 | Loss: 1.5002 | MSE loss: 0.0003 | Bpp loss: 0.98 | Aux loss: 40.10
24-04-04 09:03:28.999 - INFO: Train epoch 451: [86400/94637 (91%)] Step: [2562271] | Lr: 0.000100 | Loss: 0.9724 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 45.23
24-04-04 09:04:20.679 - INFO: Train epoch 451: [89600/94637 (95%)] Step: [2562371] | Lr: 0.000100 | Loss: 1.3236 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 44.97
24-04-04 09:05:12.067 - INFO: Train epoch 451: [92800/94637 (98%)] Step: [2562471] | Lr: 0.000100 | Loss: 1.3725 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 43.56
24-04-04 09:05:54.887 - INFO: Learning rate: 0.0001
24-04-04 09:05:56.428 - INFO: Train epoch 452: [    0/94637 (0%)] Step: [2562528] | Lr: 0.000100 | Loss: 1.2497 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 45.38
24-04-04 09:06:47.262 - INFO: Train epoch 452: [ 3200/94637 (3%)] Step: [2562628] | Lr: 0.000100 | Loss: 1.4164 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 42.10
24-04-04 09:07:37.612 - INFO: Train epoch 452: [ 6400/94637 (7%)] Step: [2562728] | Lr: 0.000100 | Loss: 1.8633 | MSE loss: 0.0005 | Bpp loss: 1.12 | Aux loss: 46.49
24-04-04 09:08:28.793 - INFO: Train epoch 452: [ 9600/94637 (10%)] Step: [2562828] | Lr: 0.000100 | Loss: 1.2119 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 40.94
24-04-04 09:09:18.998 - INFO: Train epoch 452: [12800/94637 (14%)] Step: [2562928] | Lr: 0.000100 | Loss: 0.8736 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 40.03
24-04-04 09:10:09.892 - INFO: Train epoch 452: [16000/94637 (17%)] Step: [2563028] | Lr: 0.000100 | Loss: 1.0904 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 43.21
24-04-04 09:11:00.194 - INFO: Train epoch 452: [19200/94637 (20%)] Step: [2563128] | Lr: 0.000100 | Loss: 1.3377 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 42.92
24-04-04 09:11:50.936 - INFO: Train epoch 452: [22400/94637 (24%)] Step: [2563228] | Lr: 0.000100 | Loss: 1.1312 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 41.19
24-04-04 09:12:41.215 - INFO: Train epoch 452: [25600/94637 (27%)] Step: [2563328] | Lr: 0.000100 | Loss: 1.1646 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 43.02
24-04-04 09:13:31.685 - INFO: Train epoch 452: [28800/94637 (30%)] Step: [2563428] | Lr: 0.000100 | Loss: 1.1094 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 43.66
24-04-04 09:14:21.951 - INFO: Train epoch 452: [32000/94637 (34%)] Step: [2563528] | Lr: 0.000100 | Loss: 1.2602 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 46.42
24-04-04 09:15:12.764 - INFO: Train epoch 452: [35200/94637 (37%)] Step: [2563628] | Lr: 0.000100 | Loss: 0.9604 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 42.01
24-04-04 09:16:03.987 - INFO: Train epoch 452: [38400/94637 (41%)] Step: [2563728] | Lr: 0.000100 | Loss: 1.1684 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 43.63
24-04-04 09:16:55.097 - INFO: Train epoch 452: [41600/94637 (44%)] Step: [2563828] | Lr: 0.000100 | Loss: 1.2699 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 40.57
24-04-04 09:17:46.126 - INFO: Train epoch 452: [44800/94637 (47%)] Step: [2563928] | Lr: 0.000100 | Loss: 1.2594 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 39.97
24-04-04 09:18:36.428 - INFO: Train epoch 452: [48000/94637 (51%)] Step: [2564028] | Lr: 0.000100 | Loss: 0.9843 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 44.75
24-04-04 09:19:27.122 - INFO: Train epoch 452: [51200/94637 (54%)] Step: [2564128] | Lr: 0.000100 | Loss: 1.1946 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 40.00
24-04-04 09:20:17.771 - INFO: Train epoch 452: [54400/94637 (57%)] Step: [2564228] | Lr: 0.000100 | Loss: 1.1857 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 43.30
24-04-04 09:21:08.463 - INFO: Train epoch 452: [57600/94637 (61%)] Step: [2564328] | Lr: 0.000100 | Loss: 1.0905 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 41.20
24-04-04 09:21:59.358 - INFO: Train epoch 452: [60800/94637 (64%)] Step: [2564428] | Lr: 0.000100 | Loss: 1.0132 | MSE loss: 0.0003 | Bpp loss: 0.59 | Aux loss: 45.16
24-04-04 09:22:50.253 - INFO: Train epoch 452: [64000/94637 (68%)] Step: [2564528] | Lr: 0.000100 | Loss: 1.1159 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 41.91
24-04-04 09:23:40.588 - INFO: Train epoch 452: [67200/94637 (71%)] Step: [2564628] | Lr: 0.000100 | Loss: 1.1780 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 40.15
24-04-04 09:24:30.908 - INFO: Train epoch 452: [70400/94637 (74%)] Step: [2564728] | Lr: 0.000100 | Loss: 1.1760 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 38.81
24-04-04 09:25:20.800 - INFO: Train epoch 452: [73600/94637 (78%)] Step: [2564828] | Lr: 0.000100 | Loss: 1.2699 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 44.39
24-04-04 09:26:11.448 - INFO: Train epoch 452: [76800/94637 (81%)] Step: [2564928] | Lr: 0.000100 | Loss: 1.3355 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 44.14
24-04-04 09:27:03.692 - INFO: Train epoch 452: [80000/94637 (85%)] Step: [2565028] | Lr: 0.000100 | Loss: 1.1424 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 40.47
24-04-04 09:27:54.097 - INFO: Train epoch 452: [83200/94637 (88%)] Step: [2565128] | Lr: 0.000100 | Loss: 1.0794 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 44.77
24-04-04 09:28:43.335 - INFO: Train epoch 452: [86400/94637 (91%)] Step: [2565228] | Lr: 0.000100 | Loss: 1.2369 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 41.71
24-04-04 09:29:33.227 - INFO: Train epoch 452: [89600/94637 (95%)] Step: [2565328] | Lr: 0.000100 | Loss: 1.4248 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 41.98
24-04-04 09:30:23.215 - INFO: Train epoch 452: [92800/94637 (98%)] Step: [2565428] | Lr: 0.000100 | Loss: 1.6045 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 43.42
24-04-04 09:31:03.523 - INFO: Learning rate: 0.0001
24-04-04 09:31:04.656 - INFO: Train epoch 453: [    0/94637 (0%)] Step: [2565485] | Lr: 0.000100 | Loss: 1.0265 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 41.86
24-04-04 09:31:55.148 - INFO: Train epoch 453: [ 3200/94637 (3%)] Step: [2565585] | Lr: 0.000100 | Loss: 1.2354 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 44.33
24-04-04 09:32:45.550 - INFO: Train epoch 453: [ 6400/94637 (7%)] Step: [2565685] | Lr: 0.000100 | Loss: 1.1992 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 40.55
24-04-04 09:33:36.411 - INFO: Train epoch 453: [ 9600/94637 (10%)] Step: [2565785] | Lr: 0.000100 | Loss: 1.3394 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 45.44
24-04-04 09:34:26.541 - INFO: Train epoch 453: [12800/94637 (14%)] Step: [2565885] | Lr: 0.000100 | Loss: 1.0833 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 40.36
24-04-04 09:35:17.059 - INFO: Train epoch 453: [16000/94637 (17%)] Step: [2565985] | Lr: 0.000100 | Loss: 1.4650 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 43.11
24-04-04 09:36:07.789 - INFO: Train epoch 453: [19200/94637 (20%)] Step: [2566085] | Lr: 0.000100 | Loss: 1.4099 | MSE loss: 0.0004 | Bpp loss: 0.76 | Aux loss: 45.45
24-04-04 09:36:58.998 - INFO: Train epoch 453: [22400/94637 (24%)] Step: [2566185] | Lr: 0.000100 | Loss: 0.9505 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 41.30
24-04-04 09:37:49.779 - INFO: Train epoch 453: [25600/94637 (27%)] Step: [2566285] | Lr: 0.000100 | Loss: 0.8785 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 43.59
24-04-04 09:38:41.100 - INFO: Train epoch 453: [28800/94637 (30%)] Step: [2566385] | Lr: 0.000100 | Loss: 1.2172 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 38.71
24-04-04 09:39:31.658 - INFO: Train epoch 453: [32000/94637 (34%)] Step: [2566485] | Lr: 0.000100 | Loss: 1.0575 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 38.21
24-04-04 09:40:22.849 - INFO: Train epoch 453: [35200/94637 (37%)] Step: [2566585] | Lr: 0.000100 | Loss: 1.1045 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 40.98
24-04-04 09:41:13.965 - INFO: Train epoch 453: [38400/94637 (41%)] Step: [2566685] | Lr: 0.000100 | Loss: 1.1927 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 41.51
24-04-04 09:42:04.556 - INFO: Train epoch 453: [41600/94637 (44%)] Step: [2566785] | Lr: 0.000100 | Loss: 1.1891 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 40.28
24-04-04 09:42:55.491 - INFO: Train epoch 453: [44800/94637 (47%)] Step: [2566885] | Lr: 0.000100 | Loss: 1.3265 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 40.46
24-04-04 09:43:46.677 - INFO: Train epoch 453: [48000/94637 (51%)] Step: [2566985] | Lr: 0.000100 | Loss: 1.0536 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 40.83
24-04-04 09:44:38.404 - INFO: Train epoch 453: [51200/94637 (54%)] Step: [2567085] | Lr: 0.000100 | Loss: 1.2785 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 42.74
24-04-04 09:45:28.532 - INFO: Train epoch 453: [54400/94637 (57%)] Step: [2567185] | Lr: 0.000100 | Loss: 1.5213 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 41.91
24-04-04 09:46:19.695 - INFO: Train epoch 453: [57600/94637 (61%)] Step: [2567285] | Lr: 0.000100 | Loss: 1.5284 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 38.88
24-04-04 09:47:10.771 - INFO: Train epoch 453: [60800/94637 (64%)] Step: [2567385] | Lr: 0.000100 | Loss: 0.9493 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 41.33
24-04-04 09:48:01.534 - INFO: Train epoch 453: [64000/94637 (68%)] Step: [2567485] | Lr: 0.000100 | Loss: 1.2044 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 41.61
24-04-04 09:48:55.494 - INFO: Train epoch 453: [67200/94637 (71%)] Step: [2567585] | Lr: 0.000100 | Loss: 1.0864 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 41.90
24-04-04 09:49:46.395 - INFO: Train epoch 453: [70400/94637 (74%)] Step: [2567685] | Lr: 0.000100 | Loss: 1.1407 | MSE loss: 0.0002 | Bpp loss: 0.76 | Aux loss: 40.50
24-04-04 09:50:37.439 - INFO: Train epoch 453: [73600/94637 (78%)] Step: [2567785] | Lr: 0.000100 | Loss: 1.2131 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 43.05
24-04-04 09:51:28.538 - INFO: Train epoch 453: [76800/94637 (81%)] Step: [2567885] | Lr: 0.000100 | Loss: 0.8971 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 43.33
24-04-04 09:52:19.692 - INFO: Train epoch 453: [80000/94637 (85%)] Step: [2567985] | Lr: 0.000100 | Loss: 1.5061 | MSE loss: 0.0004 | Bpp loss: 0.86 | Aux loss: 43.78
24-04-04 09:53:10.684 - INFO: Train epoch 453: [83200/94637 (88%)] Step: [2568085] | Lr: 0.000100 | Loss: 1.8820 | MSE loss: 0.0005 | Bpp loss: 1.09 | Aux loss: 41.76
24-04-04 09:54:01.097 - INFO: Train epoch 453: [86400/94637 (91%)] Step: [2568185] | Lr: 0.000100 | Loss: 1.3573 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 42.16
24-04-04 09:54:52.312 - INFO: Train epoch 453: [89600/94637 (95%)] Step: [2568285] | Lr: 0.000100 | Loss: 1.0934 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 45.40
24-04-04 09:55:43.228 - INFO: Train epoch 453: [92800/94637 (98%)] Step: [2568385] | Lr: 0.000100 | Loss: 0.9739 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 40.12
24-04-04 09:56:28.643 - INFO: Learning rate: 0.0001
24-04-04 09:56:29.805 - INFO: Train epoch 454: [    0/94637 (0%)] Step: [2568442] | Lr: 0.000100 | Loss: 1.3708 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 37.48
24-04-04 09:57:20.093 - INFO: Train epoch 454: [ 3200/94637 (3%)] Step: [2568542] | Lr: 0.000100 | Loss: 1.1374 | MSE loss: 0.0002 | Bpp loss: 0.76 | Aux loss: 43.78
24-04-04 09:58:10.550 - INFO: Train epoch 454: [ 6400/94637 (7%)] Step: [2568642] | Lr: 0.000100 | Loss: 0.9558 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 37.78
24-04-04 09:59:01.690 - INFO: Train epoch 454: [ 9600/94637 (10%)] Step: [2568742] | Lr: 0.000100 | Loss: 1.0143 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 41.30
24-04-04 09:59:53.209 - INFO: Train epoch 454: [12800/94637 (14%)] Step: [2568842] | Lr: 0.000100 | Loss: 1.1125 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 38.30
24-04-04 10:00:43.939 - INFO: Train epoch 454: [16000/94637 (17%)] Step: [2568942] | Lr: 0.000100 | Loss: 1.2257 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 41.67
24-04-04 10:01:35.178 - INFO: Train epoch 454: [19200/94637 (20%)] Step: [2569042] | Lr: 0.000100 | Loss: 1.2560 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 41.73
24-04-04 10:02:27.084 - INFO: Train epoch 454: [22400/94637 (24%)] Step: [2569142] | Lr: 0.000100 | Loss: 1.3245 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 40.80
24-04-04 10:03:18.353 - INFO: Train epoch 454: [25600/94637 (27%)] Step: [2569242] | Lr: 0.000100 | Loss: 0.7338 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 41.82
24-04-04 10:04:09.176 - INFO: Train epoch 454: [28800/94637 (30%)] Step: [2569342] | Lr: 0.000100 | Loss: 1.2356 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 43.28
24-04-04 10:05:01.309 - INFO: Train epoch 454: [32000/94637 (34%)] Step: [2569442] | Lr: 0.000100 | Loss: 1.3847 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 41.01
24-04-04 10:05:52.831 - INFO: Train epoch 454: [35200/94637 (37%)] Step: [2569542] | Lr: 0.000100 | Loss: 1.4505 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 39.35
24-04-04 10:06:43.641 - INFO: Train epoch 454: [38400/94637 (41%)] Step: [2569642] | Lr: 0.000100 | Loss: 1.0871 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 39.72
24-04-04 10:07:34.772 - INFO: Train epoch 454: [41600/94637 (44%)] Step: [2569742] | Lr: 0.000100 | Loss: 1.6714 | MSE loss: 0.0005 | Bpp loss: 0.93 | Aux loss: 40.02
24-04-04 10:08:26.148 - INFO: Train epoch 454: [44800/94637 (47%)] Step: [2569842] | Lr: 0.000100 | Loss: 1.5252 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 38.86
24-04-04 10:09:16.841 - INFO: Train epoch 454: [48000/94637 (51%)] Step: [2569942] | Lr: 0.000100 | Loss: 1.1447 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 39.70
24-04-04 10:10:09.618 - INFO: Train epoch 454: [51200/94637 (54%)] Step: [2570042] | Lr: 0.000100 | Loss: 1.4134 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 37.82
24-04-04 10:11:01.037 - INFO: Train epoch 454: [54400/94637 (57%)] Step: [2570142] | Lr: 0.000100 | Loss: 1.5456 | MSE loss: 0.0003 | Bpp loss: 1.02 | Aux loss: 47.60
24-04-04 10:11:52.360 - INFO: Train epoch 454: [57600/94637 (61%)] Step: [2570242] | Lr: 0.000100 | Loss: 1.4326 | MSE loss: 0.0004 | Bpp loss: 0.85 | Aux loss: 42.37
24-04-04 10:12:43.513 - INFO: Train epoch 454: [60800/94637 (64%)] Step: [2570342] | Lr: 0.000100 | Loss: 1.3724 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 41.55
24-04-04 10:13:34.194 - INFO: Train epoch 454: [64000/94637 (68%)] Step: [2570442] | Lr: 0.000100 | Loss: 2.1472 | MSE loss: 0.0006 | Bpp loss: 1.25 | Aux loss: 42.45
24-04-04 10:14:24.743 - INFO: Train epoch 454: [67200/94637 (71%)] Step: [2570542] | Lr: 0.000100 | Loss: 1.7367 | MSE loss: 0.0004 | Bpp loss: 1.03 | Aux loss: 41.58
24-04-04 10:15:15.477 - INFO: Train epoch 454: [70400/94637 (74%)] Step: [2570642] | Lr: 0.000100 | Loss: 1.2226 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 45.33
24-04-04 10:16:06.543 - INFO: Train epoch 454: [73600/94637 (78%)] Step: [2570742] | Lr: 0.000100 | Loss: 1.2922 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 39.00
24-04-04 10:16:57.364 - INFO: Train epoch 454: [76800/94637 (81%)] Step: [2570842] | Lr: 0.000100 | Loss: 1.4190 | MSE loss: 0.0004 | Bpp loss: 0.81 | Aux loss: 44.02
24-04-04 10:17:48.763 - INFO: Train epoch 454: [80000/94637 (85%)] Step: [2570942] | Lr: 0.000100 | Loss: 1.7670 | MSE loss: 0.0006 | Bpp loss: 0.86 | Aux loss: 40.95
24-04-04 10:18:40.226 - INFO: Train epoch 454: [83200/94637 (88%)] Step: [2571042] | Lr: 0.000100 | Loss: 1.1588 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 39.93
24-04-04 10:19:31.443 - INFO: Train epoch 454: [86400/94637 (91%)] Step: [2571142] | Lr: 0.000100 | Loss: 1.0109 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 39.99
24-04-04 10:20:22.768 - INFO: Train epoch 454: [89600/94637 (95%)] Step: [2571242] | Lr: 0.000100 | Loss: 0.9859 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 44.98
24-04-04 10:21:13.352 - INFO: Train epoch 454: [92800/94637 (98%)] Step: [2571342] | Lr: 0.000100 | Loss: 1.1158 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 44.62
24-04-04 10:21:53.765 - INFO: Learning rate: 0.0001
24-04-04 10:21:54.875 - INFO: Train epoch 455: [    0/94637 (0%)] Step: [2571399] | Lr: 0.000100 | Loss: 1.0067 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 41.77
24-04-04 10:22:46.093 - INFO: Train epoch 455: [ 3200/94637 (3%)] Step: [2571499] | Lr: 0.000100 | Loss: 1.1576 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 36.47
24-04-04 10:23:37.133 - INFO: Train epoch 455: [ 6400/94637 (7%)] Step: [2571599] | Lr: 0.000100 | Loss: 0.9954 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 40.87
24-04-04 10:24:28.730 - INFO: Train epoch 455: [ 9600/94637 (10%)] Step: [2571699] | Lr: 0.000100 | Loss: 0.9120 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 38.87
24-04-04 10:25:19.909 - INFO: Train epoch 455: [12800/94637 (14%)] Step: [2571799] | Lr: 0.000100 | Loss: 1.0886 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 41.96
24-04-04 10:26:10.834 - INFO: Train epoch 455: [16000/94637 (17%)] Step: [2571899] | Lr: 0.000100 | Loss: 1.1870 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 40.02
24-04-04 10:27:02.329 - INFO: Train epoch 455: [19200/94637 (20%)] Step: [2571999] | Lr: 0.000100 | Loss: 1.0495 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 41.61
24-04-04 10:27:53.861 - INFO: Train epoch 455: [22400/94637 (24%)] Step: [2572099] | Lr: 0.000100 | Loss: 1.1095 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 40.36
24-04-04 10:28:45.309 - INFO: Train epoch 455: [25600/94637 (27%)] Step: [2572199] | Lr: 0.000100 | Loss: 1.5003 | MSE loss: 0.0003 | Bpp loss: 0.96 | Aux loss: 41.29
24-04-04 10:29:36.529 - INFO: Train epoch 455: [28800/94637 (30%)] Step: [2572299] | Lr: 0.000100 | Loss: 1.0489 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 42.73
24-04-04 10:30:27.347 - INFO: Train epoch 455: [32000/94637 (34%)] Step: [2572399] | Lr: 0.000100 | Loss: 1.6028 | MSE loss: 0.0005 | Bpp loss: 0.81 | Aux loss: 41.13
24-04-04 10:31:17.923 - INFO: Train epoch 455: [35200/94637 (37%)] Step: [2572499] | Lr: 0.000100 | Loss: 1.0754 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 41.48
24-04-04 10:32:10.833 - INFO: Train epoch 455: [38400/94637 (41%)] Step: [2572599] | Lr: 0.000100 | Loss: 0.9404 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 40.40
24-04-04 10:33:01.201 - INFO: Train epoch 455: [41600/94637 (44%)] Step: [2572699] | Lr: 0.000100 | Loss: 1.2771 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 40.31
24-04-04 10:33:52.236 - INFO: Train epoch 455: [44800/94637 (47%)] Step: [2572799] | Lr: 0.000100 | Loss: 1.0985 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 52.55
24-04-04 10:34:42.976 - INFO: Train epoch 455: [48000/94637 (51%)] Step: [2572899] | Lr: 0.000100 | Loss: 1.3400 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 40.15
24-04-04 10:35:34.145 - INFO: Train epoch 455: [51200/94637 (54%)] Step: [2572999] | Lr: 0.000100 | Loss: 1.6379 | MSE loss: 0.0004 | Bpp loss: 1.03 | Aux loss: 40.06
24-04-04 10:36:25.489 - INFO: Train epoch 455: [54400/94637 (57%)] Step: [2573099] | Lr: 0.000100 | Loss: 1.0549 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 41.17
24-04-04 10:37:17.209 - INFO: Train epoch 455: [57600/94637 (61%)] Step: [2573199] | Lr: 0.000100 | Loss: 1.2476 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 35.17
24-04-04 10:38:09.010 - INFO: Train epoch 455: [60800/94637 (64%)] Step: [2573299] | Lr: 0.000100 | Loss: 0.8506 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 40.69
24-04-04 10:39:00.822 - INFO: Train epoch 455: [64000/94637 (68%)] Step: [2573399] | Lr: 0.000100 | Loss: 0.9667 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 37.95
24-04-04 10:39:51.287 - INFO: Train epoch 455: [67200/94637 (71%)] Step: [2573499] | Lr: 0.000100 | Loss: 1.1218 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 43.02
24-04-04 10:40:42.228 - INFO: Train epoch 455: [70400/94637 (74%)] Step: [2573599] | Lr: 0.000100 | Loss: 1.4144 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 40.08
24-04-04 10:41:33.740 - INFO: Train epoch 455: [73600/94637 (78%)] Step: [2573699] | Lr: 0.000100 | Loss: 1.4411 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 38.69
24-04-04 10:42:24.862 - INFO: Train epoch 455: [76800/94637 (81%)] Step: [2573799] | Lr: 0.000100 | Loss: 0.7700 | MSE loss: 0.0002 | Bpp loss: 0.48 | Aux loss: 43.13
24-04-04 10:43:16.283 - INFO: Train epoch 455: [80000/94637 (85%)] Step: [2573899] | Lr: 0.000100 | Loss: 1.5060 | MSE loss: 0.0003 | Bpp loss: 0.96 | Aux loss: 39.87
24-04-04 10:44:07.507 - INFO: Train epoch 455: [83200/94637 (88%)] Step: [2573999] | Lr: 0.000100 | Loss: 0.7624 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 41.09
24-04-04 10:44:59.001 - INFO: Train epoch 455: [86400/94637 (91%)] Step: [2574099] | Lr: 0.000100 | Loss: 1.7319 | MSE loss: 0.0005 | Bpp loss: 0.92 | Aux loss: 41.75
24-04-04 10:45:50.362 - INFO: Train epoch 455: [89600/94637 (95%)] Step: [2574199] | Lr: 0.000100 | Loss: 1.4468 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 38.78
24-04-04 10:46:41.612 - INFO: Train epoch 455: [92800/94637 (98%)] Step: [2574299] | Lr: 0.000100 | Loss: 1.3395 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 40.25
24-04-04 10:47:21.960 - INFO: Learning rate: 0.0001
24-04-04 10:47:23.130 - INFO: Train epoch 456: [    0/94637 (0%)] Step: [2574356] | Lr: 0.000100 | Loss: 1.3357 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 38.37
24-04-04 10:48:13.392 - INFO: Train epoch 456: [ 3200/94637 (3%)] Step: [2574456] | Lr: 0.000100 | Loss: 1.7521 | MSE loss: 0.0004 | Bpp loss: 1.08 | Aux loss: 42.19
24-04-04 10:49:05.395 - INFO: Train epoch 456: [ 6400/94637 (7%)] Step: [2574556] | Lr: 0.000100 | Loss: 1.2087 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 42.14
24-04-04 10:49:57.086 - INFO: Train epoch 456: [ 9600/94637 (10%)] Step: [2574656] | Lr: 0.000100 | Loss: 1.1815 | MSE loss: 0.0002 | Bpp loss: 0.78 | Aux loss: 42.27
24-04-04 10:50:47.709 - INFO: Train epoch 456: [12800/94637 (14%)] Step: [2574756] | Lr: 0.000100 | Loss: 1.2092 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 40.76
24-04-04 10:51:38.647 - INFO: Train epoch 456: [16000/94637 (17%)] Step: [2574856] | Lr: 0.000100 | Loss: 1.1705 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 47.07
24-04-04 10:52:30.227 - INFO: Train epoch 456: [19200/94637 (20%)] Step: [2574956] | Lr: 0.000100 | Loss: 1.3795 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 41.72
24-04-04 10:53:23.206 - INFO: Train epoch 456: [22400/94637 (24%)] Step: [2575056] | Lr: 0.000100 | Loss: 0.9998 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 39.47
24-04-04 10:54:14.491 - INFO: Train epoch 456: [25600/94637 (27%)] Step: [2575156] | Lr: 0.000100 | Loss: 0.7975 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 36.91
24-04-04 10:55:05.960 - INFO: Train epoch 456: [28800/94637 (30%)] Step: [2575256] | Lr: 0.000100 | Loss: 1.4448 | MSE loss: 0.0004 | Bpp loss: 0.80 | Aux loss: 35.32
24-04-04 10:55:57.344 - INFO: Train epoch 456: [32000/94637 (34%)] Step: [2575356] | Lr: 0.000100 | Loss: 1.4785 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 38.63
24-04-04 10:56:48.594 - INFO: Train epoch 456: [35200/94637 (37%)] Step: [2575456] | Lr: 0.000100 | Loss: 1.1387 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 42.91
24-04-04 10:57:39.581 - INFO: Train epoch 456: [38400/94637 (41%)] Step: [2575556] | Lr: 0.000100 | Loss: 1.4723 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 42.37
24-04-04 10:58:30.556 - INFO: Train epoch 456: [41600/94637 (44%)] Step: [2575656] | Lr: 0.000100 | Loss: 0.8975 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 36.03
24-04-04 10:59:21.645 - INFO: Train epoch 456: [44800/94637 (47%)] Step: [2575756] | Lr: 0.000100 | Loss: 1.1161 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 37.48
24-04-04 11:00:12.509 - INFO: Train epoch 456: [48000/94637 (51%)] Step: [2575856] | Lr: 0.000100 | Loss: 1.2053 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 38.42
24-04-04 11:01:03.675 - INFO: Train epoch 456: [51200/94637 (54%)] Step: [2575956] | Lr: 0.000100 | Loss: 0.9583 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 40.20
24-04-04 11:01:54.672 - INFO: Train epoch 456: [54400/94637 (57%)] Step: [2576056] | Lr: 0.000100 | Loss: 1.1289 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 41.43
24-04-04 11:02:45.676 - INFO: Train epoch 456: [57600/94637 (61%)] Step: [2576156] | Lr: 0.000100 | Loss: 1.5521 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 40.17
24-04-04 11:03:37.382 - INFO: Train epoch 456: [60800/94637 (64%)] Step: [2576256] | Lr: 0.000100 | Loss: 0.9930 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 42.24
24-04-04 11:04:28.351 - INFO: Train epoch 456: [64000/94637 (68%)] Step: [2576356] | Lr: 0.000100 | Loss: 1.1812 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 39.49
24-04-04 11:05:19.970 - INFO: Train epoch 456: [67200/94637 (71%)] Step: [2576456] | Lr: 0.000100 | Loss: 1.8037 | MSE loss: 0.0004 | Bpp loss: 1.08 | Aux loss: 41.08
24-04-04 11:06:11.627 - INFO: Train epoch 456: [70400/94637 (74%)] Step: [2576556] | Lr: 0.000100 | Loss: 0.8773 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 42.84
24-04-04 11:07:02.463 - INFO: Train epoch 456: [73600/94637 (78%)] Step: [2576656] | Lr: 0.000100 | Loss: 1.1571 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 40.73
24-04-04 11:07:53.392 - INFO: Train epoch 456: [76800/94637 (81%)] Step: [2576756] | Lr: 0.000100 | Loss: 1.3007 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 39.40
24-04-04 11:08:44.681 - INFO: Train epoch 456: [80000/94637 (85%)] Step: [2576856] | Lr: 0.000100 | Loss: 1.0895 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 42.24
24-04-04 11:09:35.889 - INFO: Train epoch 456: [83200/94637 (88%)] Step: [2576956] | Lr: 0.000100 | Loss: 1.0340 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 41.07
24-04-04 11:10:26.401 - INFO: Train epoch 456: [86400/94637 (91%)] Step: [2577056] | Lr: 0.000100 | Loss: 1.3376 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 42.59
24-04-04 11:11:16.936 - INFO: Train epoch 456: [89600/94637 (95%)] Step: [2577156] | Lr: 0.000100 | Loss: 0.9472 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 40.31
24-04-04 11:12:06.939 - INFO: Train epoch 456: [92800/94637 (98%)] Step: [2577256] | Lr: 0.000100 | Loss: 1.0166 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 40.23
24-04-04 11:12:47.533 - INFO: Learning rate: 0.0001
24-04-04 11:12:49.003 - INFO: Train epoch 457: [    0/94637 (0%)] Step: [2577313] | Lr: 0.000100 | Loss: 1.2831 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 41.52
24-04-04 11:13:39.179 - INFO: Train epoch 457: [ 3200/94637 (3%)] Step: [2577413] | Lr: 0.000100 | Loss: 1.4970 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 46.13
24-04-04 11:14:31.663 - INFO: Train epoch 457: [ 6400/94637 (7%)] Step: [2577513] | Lr: 0.000100 | Loss: 1.2842 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 41.61
24-04-04 11:15:20.918 - INFO: Train epoch 457: [ 9600/94637 (10%)] Step: [2577613] | Lr: 0.000100 | Loss: 1.1554 | MSE loss: 0.0002 | Bpp loss: 0.76 | Aux loss: 39.90
24-04-04 11:16:11.211 - INFO: Train epoch 457: [12800/94637 (14%)] Step: [2577713] | Lr: 0.000100 | Loss: 1.3349 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 40.02
24-04-04 11:17:00.895 - INFO: Train epoch 457: [16000/94637 (17%)] Step: [2577813] | Lr: 0.000100 | Loss: 1.6423 | MSE loss: 0.0004 | Bpp loss: 0.99 | Aux loss: 39.69
24-04-04 11:17:51.283 - INFO: Train epoch 457: [19200/94637 (20%)] Step: [2577913] | Lr: 0.000100 | Loss: 0.9806 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 39.61
24-04-04 11:18:41.972 - INFO: Train epoch 457: [22400/94637 (24%)] Step: [2578013] | Lr: 0.000100 | Loss: 1.2851 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 40.51
24-04-04 11:19:32.567 - INFO: Train epoch 457: [25600/94637 (27%)] Step: [2578113] | Lr: 0.000100 | Loss: 1.2585 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 38.69
24-04-04 11:20:23.973 - INFO: Train epoch 457: [28800/94637 (30%)] Step: [2578213] | Lr: 0.000100 | Loss: 1.0866 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 39.16
24-04-04 11:21:14.639 - INFO: Train epoch 457: [32000/94637 (34%)] Step: [2578313] | Lr: 0.000100 | Loss: 0.9100 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 38.69
24-04-04 11:22:05.485 - INFO: Train epoch 457: [35200/94637 (37%)] Step: [2578413] | Lr: 0.000100 | Loss: 1.0605 | MSE loss: 0.0003 | Bpp loss: 0.61 | Aux loss: 41.02
24-04-04 11:22:55.551 - INFO: Train epoch 457: [38400/94637 (41%)] Step: [2578513] | Lr: 0.000100 | Loss: 1.3417 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 41.54
24-04-04 11:23:47.065 - INFO: Train epoch 457: [41600/94637 (44%)] Step: [2578613] | Lr: 0.000100 | Loss: 1.2123 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 39.42
24-04-04 11:24:38.423 - INFO: Train epoch 457: [44800/94637 (47%)] Step: [2578713] | Lr: 0.000100 | Loss: 1.1579 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 36.71
24-04-04 11:25:29.169 - INFO: Train epoch 457: [48000/94637 (51%)] Step: [2578813] | Lr: 0.000100 | Loss: 295.9188 | MSE loss: 0.1815 | Bpp loss: 0.88 | Aux loss: 41.24
24-04-04 11:26:20.119 - INFO: Train epoch 457: [51200/94637 (54%)] Step: [2578913] | Lr: 0.000100 | Loss: 1.1348 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 40.35
24-04-04 11:27:10.850 - INFO: Train epoch 457: [54400/94637 (57%)] Step: [2579013] | Lr: 0.000100 | Loss: 1.7456 | MSE loss: 0.0005 | Bpp loss: 1.00 | Aux loss: 38.65
24-04-04 11:28:01.673 - INFO: Train epoch 457: [57600/94637 (61%)] Step: [2579113] | Lr: 0.000100 | Loss: 1.0909 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 39.00
24-04-04 11:28:52.048 - INFO: Train epoch 457: [60800/94637 (64%)] Step: [2579213] | Lr: 0.000100 | Loss: 1.0448 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 40.58
24-04-04 11:29:42.783 - INFO: Train epoch 457: [64000/94637 (68%)] Step: [2579313] | Lr: 0.000100 | Loss: 1.4064 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 37.82
24-04-04 11:30:33.460 - INFO: Train epoch 457: [67200/94637 (71%)] Step: [2579413] | Lr: 0.000100 | Loss: 1.1114 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 39.94
24-04-04 11:31:24.401 - INFO: Train epoch 457: [70400/94637 (74%)] Step: [2579513] | Lr: 0.000100 | Loss: 1.1577 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 35.60
24-04-04 11:32:15.931 - INFO: Train epoch 457: [73600/94637 (78%)] Step: [2579613] | Lr: 0.000100 | Loss: 1.6770 | MSE loss: 0.0005 | Bpp loss: 0.91 | Aux loss: 41.41
24-04-04 11:33:06.777 - INFO: Train epoch 457: [76800/94637 (81%)] Step: [2579713] | Lr: 0.000100 | Loss: 1.2295 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 40.44
24-04-04 11:33:57.659 - INFO: Train epoch 457: [80000/94637 (85%)] Step: [2579813] | Lr: 0.000100 | Loss: 1.2953 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 38.91
24-04-04 11:34:48.561 - INFO: Train epoch 457: [83200/94637 (88%)] Step: [2579913] | Lr: 0.000100 | Loss: 1.2913 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 37.82
24-04-04 11:35:41.927 - INFO: Train epoch 457: [86400/94637 (91%)] Step: [2580013] | Lr: 0.000100 | Loss: 1.2537 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 40.04
24-04-04 11:36:32.935 - INFO: Train epoch 457: [89600/94637 (95%)] Step: [2580113] | Lr: 0.000100 | Loss: 1.5060 | MSE loss: 0.0003 | Bpp loss: 0.96 | Aux loss: 38.65
24-04-04 11:37:24.209 - INFO: Train epoch 457: [92800/94637 (98%)] Step: [2580213] | Lr: 0.000100 | Loss: 1.1148 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 39.69
24-04-04 11:38:05.045 - INFO: Learning rate: 0.0001
24-04-04 11:38:06.182 - INFO: Train epoch 458: [    0/94637 (0%)] Step: [2580270] | Lr: 0.000100 | Loss: 0.9030 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 38.26
24-04-04 11:38:56.963 - INFO: Train epoch 458: [ 3200/94637 (3%)] Step: [2580370] | Lr: 0.000100 | Loss: 1.2208 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 38.27
24-04-04 11:39:47.578 - INFO: Train epoch 458: [ 6400/94637 (7%)] Step: [2580470] | Lr: 0.000100 | Loss: 1.3664 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 40.18
24-04-04 11:40:38.292 - INFO: Train epoch 458: [ 9600/94637 (10%)] Step: [2580570] | Lr: 0.000100 | Loss: 1.7117 | MSE loss: 0.0004 | Bpp loss: 1.06 | Aux loss: 41.13
24-04-04 11:41:29.350 - INFO: Train epoch 458: [12800/94637 (14%)] Step: [2580670] | Lr: 0.000100 | Loss: 1.2576 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 39.32
24-04-04 11:42:19.812 - INFO: Train epoch 458: [16000/94637 (17%)] Step: [2580770] | Lr: 0.000100 | Loss: 1.0968 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 39.61
24-04-04 11:43:10.362 - INFO: Train epoch 458: [19200/94637 (20%)] Step: [2580870] | Lr: 0.000100 | Loss: 1.3155 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 44.70
24-04-04 11:44:00.540 - INFO: Train epoch 458: [22400/94637 (24%)] Step: [2580970] | Lr: 0.000100 | Loss: 1.3493 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 38.34
24-04-04 11:44:51.189 - INFO: Train epoch 458: [25600/94637 (27%)] Step: [2581070] | Lr: 0.000100 | Loss: 1.3734 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 38.05
24-04-04 11:45:41.544 - INFO: Train epoch 458: [28800/94637 (30%)] Step: [2581170] | Lr: 0.000100 | Loss: 1.3437 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 35.29
24-04-04 11:46:32.106 - INFO: Train epoch 458: [32000/94637 (34%)] Step: [2581270] | Lr: 0.000100 | Loss: 1.5346 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 34.30
24-04-04 11:47:22.457 - INFO: Train epoch 458: [35200/94637 (37%)] Step: [2581370] | Lr: 0.000100 | Loss: 1.0978 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 37.11
24-04-04 11:48:12.949 - INFO: Train epoch 458: [38400/94637 (41%)] Step: [2581470] | Lr: 0.000100 | Loss: 1.2657 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 35.16
24-04-04 11:49:03.784 - INFO: Train epoch 458: [41600/94637 (44%)] Step: [2581570] | Lr: 0.000100 | Loss: 0.8164 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 41.04
24-04-04 11:49:54.443 - INFO: Train epoch 458: [44800/94637 (47%)] Step: [2581670] | Lr: 0.000100 | Loss: 1.2169 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 41.22
24-04-04 11:50:45.900 - INFO: Train epoch 458: [48000/94637 (51%)] Step: [2581770] | Lr: 0.000100 | Loss: 1.1418 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 34.40
24-04-04 11:51:37.077 - INFO: Train epoch 458: [51200/94637 (54%)] Step: [2581870] | Lr: 0.000100 | Loss: 1.4630 | MSE loss: 0.0004 | Bpp loss: 0.86 | Aux loss: 38.41
24-04-04 11:52:28.243 - INFO: Train epoch 458: [54400/94637 (57%)] Step: [2581970] | Lr: 0.000100 | Loss: 1.2601 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 36.79
24-04-04 11:53:19.104 - INFO: Train epoch 458: [57600/94637 (61%)] Step: [2582070] | Lr: 0.000100 | Loss: 1.3035 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 36.59
24-04-04 11:54:09.756 - INFO: Train epoch 458: [60800/94637 (64%)] Step: [2582170] | Lr: 0.000100 | Loss: 0.7800 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 39.77
24-04-04 11:55:00.919 - INFO: Train epoch 458: [64000/94637 (68%)] Step: [2582270] | Lr: 0.000100 | Loss: 1.2015 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 36.70
24-04-04 11:55:51.343 - INFO: Train epoch 458: [67200/94637 (71%)] Step: [2582370] | Lr: 0.000100 | Loss: 1.1862 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 39.24
24-04-04 11:56:42.019 - INFO: Train epoch 458: [70400/94637 (74%)] Step: [2582470] | Lr: 0.000100 | Loss: 1.5437 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 39.76
24-04-04 11:57:34.739 - INFO: Train epoch 458: [73600/94637 (78%)] Step: [2582570] | Lr: 0.000100 | Loss: 1.0685 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 38.64
24-04-04 11:58:25.056 - INFO: Train epoch 458: [76800/94637 (81%)] Step: [2582670] | Lr: 0.000100 | Loss: 1.1606 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 34.90
24-04-04 11:59:16.085 - INFO: Train epoch 458: [80000/94637 (85%)] Step: [2582770] | Lr: 0.000100 | Loss: 1.3847 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 37.67
24-04-04 12:00:06.112 - INFO: Train epoch 458: [83200/94637 (88%)] Step: [2582870] | Lr: 0.000100 | Loss: 1.3365 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 45.08
24-04-04 12:00:56.897 - INFO: Train epoch 458: [86400/94637 (91%)] Step: [2582970] | Lr: 0.000100 | Loss: 0.8794 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 41.06
24-04-04 12:01:48.838 - INFO: Train epoch 458: [89600/94637 (95%)] Step: [2583070] | Lr: 0.000100 | Loss: 1.0846 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 37.44
24-04-04 12:02:39.916 - INFO: Train epoch 458: [92800/94637 (98%)] Step: [2583170] | Lr: 0.000100 | Loss: 1.1330 | MSE loss: 0.0002 | Bpp loss: 0.76 | Aux loss: 34.59
24-04-04 12:03:20.402 - INFO: Learning rate: 0.0001
24-04-04 12:03:21.947 - INFO: Train epoch 459: [    0/94637 (0%)] Step: [2583227] | Lr: 0.000100 | Loss: 0.9945 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 36.77
24-04-04 12:04:12.661 - INFO: Train epoch 459: [ 3200/94637 (3%)] Step: [2583327] | Lr: 0.000100 | Loss: 0.8951 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 37.24
24-04-04 12:05:04.253 - INFO: Train epoch 459: [ 6400/94637 (7%)] Step: [2583427] | Lr: 0.000100 | Loss: 0.9350 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 38.60
24-04-04 12:05:55.404 - INFO: Train epoch 459: [ 9600/94637 (10%)] Step: [2583527] | Lr: 0.000100 | Loss: 1.0358 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 40.82
24-04-04 12:06:46.376 - INFO: Train epoch 459: [12800/94637 (14%)] Step: [2583627] | Lr: 0.000100 | Loss: 1.2604 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 38.27
24-04-04 12:07:36.898 - INFO: Train epoch 459: [16000/94637 (17%)] Step: [2583727] | Lr: 0.000100 | Loss: 1.0727 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 38.39
24-04-04 12:08:28.035 - INFO: Train epoch 459: [19200/94637 (20%)] Step: [2583827] | Lr: 0.000100 | Loss: 1.0820 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 34.86
24-04-04 12:09:19.190 - INFO: Train epoch 459: [22400/94637 (24%)] Step: [2583927] | Lr: 0.000100 | Loss: 1.8482 | MSE loss: 0.0004 | Bpp loss: 1.15 | Aux loss: 38.76
24-04-04 12:10:10.602 - INFO: Train epoch 459: [25600/94637 (27%)] Step: [2584027] | Lr: 0.000100 | Loss: 1.0931 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 34.31
24-04-04 12:11:01.645 - INFO: Train epoch 459: [28800/94637 (30%)] Step: [2584127] | Lr: 0.000100 | Loss: 1.1241 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 33.31
24-04-04 12:11:52.077 - INFO: Train epoch 459: [32000/94637 (34%)] Step: [2584227] | Lr: 0.000100 | Loss: 1.4600 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 40.62
24-04-04 12:12:42.503 - INFO: Train epoch 459: [35200/94637 (37%)] Step: [2584327] | Lr: 0.000100 | Loss: 0.8569 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 36.65
24-04-04 12:13:33.323 - INFO: Train epoch 459: [38400/94637 (41%)] Step: [2584427] | Lr: 0.000100 | Loss: 1.2587 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 37.62
24-04-04 12:14:24.319 - INFO: Train epoch 459: [41600/94637 (44%)] Step: [2584527] | Lr: 0.000100 | Loss: 1.2895 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 34.60
24-04-04 12:15:15.050 - INFO: Train epoch 459: [44800/94637 (47%)] Step: [2584627] | Lr: 0.000100 | Loss: 1.2443 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 36.21
24-04-04 12:16:05.725 - INFO: Train epoch 459: [48000/94637 (51%)] Step: [2584727] | Lr: 0.000100 | Loss: 1.2771 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 36.44
24-04-04 12:16:55.546 - INFO: Train epoch 459: [51200/94637 (54%)] Step: [2584827] | Lr: 0.000100 | Loss: 0.9205 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 35.55
24-04-04 12:17:46.244 - INFO: Train epoch 459: [54400/94637 (57%)] Step: [2584927] | Lr: 0.000100 | Loss: 1.1943 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 37.95
24-04-04 12:18:39.551 - INFO: Train epoch 459: [57600/94637 (61%)] Step: [2585027] | Lr: 0.000100 | Loss: 1.2011 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 35.00
24-04-04 12:19:31.290 - INFO: Train epoch 459: [60800/94637 (64%)] Step: [2585127] | Lr: 0.000100 | Loss: 1.1739 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 37.59
24-04-04 12:20:21.994 - INFO: Train epoch 459: [64000/94637 (68%)] Step: [2585227] | Lr: 0.000100 | Loss: 0.9228 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 37.45
24-04-04 12:21:12.790 - INFO: Train epoch 459: [67200/94637 (71%)] Step: [2585327] | Lr: 0.000100 | Loss: 0.9352 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 37.96
24-04-04 12:22:02.875 - INFO: Train epoch 459: [70400/94637 (74%)] Step: [2585427] | Lr: 0.000100 | Loss: 1.2206 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 37.50
24-04-04 12:22:53.588 - INFO: Train epoch 459: [73600/94637 (78%)] Step: [2585527] | Lr: 0.000100 | Loss: 1.0985 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 35.20
24-04-04 12:23:44.642 - INFO: Train epoch 459: [76800/94637 (81%)] Step: [2585627] | Lr: 0.000100 | Loss: 1.0114 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 36.40
24-04-04 12:24:36.470 - INFO: Train epoch 459: [80000/94637 (85%)] Step: [2585727] | Lr: 0.000100 | Loss: 1.2562 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 39.56
24-04-04 12:25:28.001 - INFO: Train epoch 459: [83200/94637 (88%)] Step: [2585827] | Lr: 0.000100 | Loss: 1.2335 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 36.65
24-04-04 12:26:19.080 - INFO: Train epoch 459: [86400/94637 (91%)] Step: [2585927] | Lr: 0.000100 | Loss: 1.0073 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 38.24
24-04-04 12:27:10.117 - INFO: Train epoch 459: [89600/94637 (95%)] Step: [2586027] | Lr: 0.000100 | Loss: 1.2379 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 36.78
24-04-04 12:28:01.112 - INFO: Train epoch 459: [92800/94637 (98%)] Step: [2586127] | Lr: 0.000100 | Loss: 1.2176 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 33.58
24-04-04 12:28:41.925 - INFO: Learning rate: 0.0001
24-04-04 12:28:43.199 - INFO: Train epoch 460: [    0/94637 (0%)] Step: [2586184] | Lr: 0.000100 | Loss: 1.4223 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 30.83
24-04-04 12:29:34.147 - INFO: Train epoch 460: [ 3200/94637 (3%)] Step: [2586284] | Lr: 0.000100 | Loss: 0.8412 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 37.26
24-04-04 12:30:24.630 - INFO: Train epoch 460: [ 6400/94637 (7%)] Step: [2586384] | Lr: 0.000100 | Loss: 0.7869 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 33.84
24-04-04 12:31:16.038 - INFO: Train epoch 460: [ 9600/94637 (10%)] Step: [2586484] | Lr: 0.000100 | Loss: 1.3086 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 34.73
24-04-04 12:32:06.225 - INFO: Train epoch 460: [12800/94637 (14%)] Step: [2586584] | Lr: 0.000100 | Loss: 1.3642 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 31.36
24-04-04 12:32:56.898 - INFO: Train epoch 460: [16000/94637 (17%)] Step: [2586684] | Lr: 0.000100 | Loss: 1.2918 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 34.37
24-04-04 12:33:46.925 - INFO: Train epoch 460: [19200/94637 (20%)] Step: [2586784] | Lr: 0.000100 | Loss: 0.9747 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 31.88
24-04-04 12:34:38.126 - INFO: Train epoch 460: [22400/94637 (24%)] Step: [2586884] | Lr: 0.000100 | Loss: 1.3602 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 33.32
24-04-04 12:35:29.212 - INFO: Train epoch 460: [25600/94637 (27%)] Step: [2586984] | Lr: 0.000100 | Loss: 0.9745 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 34.24
24-04-04 12:36:20.336 - INFO: Train epoch 460: [28800/94637 (30%)] Step: [2587084] | Lr: 0.000100 | Loss: 1.5127 | MSE loss: 0.0004 | Bpp loss: 0.93 | Aux loss: 33.56
24-04-04 12:37:10.953 - INFO: Train epoch 460: [32000/94637 (34%)] Step: [2587184] | Lr: 0.000100 | Loss: 1.1435 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 35.20
24-04-04 12:38:01.330 - INFO: Train epoch 460: [35200/94637 (37%)] Step: [2587284] | Lr: 0.000100 | Loss: 1.1838 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 35.08
24-04-04 12:38:52.592 - INFO: Train epoch 460: [38400/94637 (41%)] Step: [2587384] | Lr: 0.000100 | Loss: 1.1865 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 36.23
24-04-04 12:39:42.831 - INFO: Train epoch 460: [41600/94637 (44%)] Step: [2587484] | Lr: 0.000100 | Loss: 1.2194 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 34.00
24-04-04 12:40:35.470 - INFO: Train epoch 460: [44800/94637 (47%)] Step: [2587584] | Lr: 0.000100 | Loss: 1.4171 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 36.24
24-04-04 12:41:25.924 - INFO: Train epoch 460: [48000/94637 (51%)] Step: [2587684] | Lr: 0.000100 | Loss: 1.4074 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 33.36
24-04-04 12:42:16.766 - INFO: Train epoch 460: [51200/94637 (54%)] Step: [2587784] | Lr: 0.000100 | Loss: 1.2722 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 39.09
24-04-04 12:43:07.265 - INFO: Train epoch 460: [54400/94637 (57%)] Step: [2587884] | Lr: 0.000100 | Loss: 1.0848 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 35.51
24-04-04 12:43:58.185 - INFO: Train epoch 460: [57600/94637 (61%)] Step: [2587984] | Lr: 0.000100 | Loss: 0.9587 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 36.28
24-04-04 12:44:49.688 - INFO: Train epoch 460: [60800/94637 (64%)] Step: [2588084] | Lr: 0.000100 | Loss: 1.2372 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 36.75
24-04-04 12:45:41.499 - INFO: Train epoch 460: [64000/94637 (68%)] Step: [2588184] | Lr: 0.000100 | Loss: 0.9097 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 35.85
24-04-04 12:46:32.524 - INFO: Train epoch 460: [67200/94637 (71%)] Step: [2588284] | Lr: 0.000100 | Loss: 1.0807 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 37.60
24-04-04 12:47:23.922 - INFO: Train epoch 460: [70400/94637 (74%)] Step: [2588384] | Lr: 0.000100 | Loss: 1.0799 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 37.70
24-04-04 12:48:15.565 - INFO: Train epoch 460: [73600/94637 (78%)] Step: [2588484] | Lr: 0.000100 | Loss: 1.0245 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 37.48
24-04-04 12:49:07.477 - INFO: Train epoch 460: [76800/94637 (81%)] Step: [2588584] | Lr: 0.000100 | Loss: 1.2573 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 36.02
24-04-04 12:49:57.909 - INFO: Train epoch 460: [80000/94637 (85%)] Step: [2588684] | Lr: 0.000100 | Loss: 1.2109 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 38.64
24-04-04 12:50:48.810 - INFO: Train epoch 460: [83200/94637 (88%)] Step: [2588784] | Lr: 0.000100 | Loss: 0.8376 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 36.73
24-04-04 12:51:39.547 - INFO: Train epoch 460: [86400/94637 (91%)] Step: [2588884] | Lr: 0.000100 | Loss: 1.1671 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 37.54
24-04-04 12:52:31.147 - INFO: Train epoch 460: [89600/94637 (95%)] Step: [2588984] | Lr: 0.000100 | Loss: 1.0540 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 39.28
24-04-04 12:53:22.532 - INFO: Train epoch 460: [92800/94637 (98%)] Step: [2589084] | Lr: 0.000100 | Loss: 1.3531 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 34.26
24-04-04 12:54:03.040 - INFO: Learning rate: 0.0001
24-04-04 12:54:04.199 - INFO: Train epoch 461: [    0/94637 (0%)] Step: [2589141] | Lr: 0.000100 | Loss: 1.0154 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 37.70
24-04-04 12:54:55.143 - INFO: Train epoch 461: [ 3200/94637 (3%)] Step: [2589241] | Lr: 0.000100 | Loss: 0.9878 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 35.88
24-04-04 12:55:45.688 - INFO: Train epoch 461: [ 6400/94637 (7%)] Step: [2589341] | Lr: 0.000100 | Loss: 1.0918 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 40.44
24-04-04 12:56:36.347 - INFO: Train epoch 461: [ 9600/94637 (10%)] Step: [2589441] | Lr: 0.000100 | Loss: 0.9960 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 36.50
24-04-04 12:57:26.710 - INFO: Train epoch 461: [12800/94637 (14%)] Step: [2589541] | Lr: 0.000100 | Loss: 1.1639 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 39.98
24-04-04 12:58:17.889 - INFO: Train epoch 461: [16000/94637 (17%)] Step: [2589641] | Lr: 0.000100 | Loss: 0.8974 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 40.10
24-04-04 12:59:08.986 - INFO: Train epoch 461: [19200/94637 (20%)] Step: [2589741] | Lr: 0.000100 | Loss: 1.0029 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 34.91
24-04-04 13:00:00.196 - INFO: Train epoch 461: [22400/94637 (24%)] Step: [2589841] | Lr: 0.000100 | Loss: 1.4920 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 37.61
24-04-04 13:00:51.146 - INFO: Train epoch 461: [25600/94637 (27%)] Step: [2589941] | Lr: 0.000100 | Loss: 1.5257 | MSE loss: 0.0003 | Bpp loss: 0.96 | Aux loss: 39.01
24-04-04 13:01:44.139 - INFO: Train epoch 461: [28800/94637 (30%)] Step: [2590041] | Lr: 0.000100 | Loss: 1.2216 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 40.50
24-04-04 13:02:35.508 - INFO: Train epoch 461: [32000/94637 (34%)] Step: [2590141] | Lr: 0.000100 | Loss: 1.6314 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 41.46
24-04-04 13:03:27.036 - INFO: Train epoch 461: [35200/94637 (37%)] Step: [2590241] | Lr: 0.000100 | Loss: 1.2655 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 41.82
24-04-04 13:04:18.429 - INFO: Train epoch 461: [38400/94637 (41%)] Step: [2590341] | Lr: 0.000100 | Loss: 1.1126 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 34.97
24-04-04 13:05:10.116 - INFO: Train epoch 461: [41600/94637 (44%)] Step: [2590441] | Lr: 0.000100 | Loss: 1.1835 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 40.01
24-04-04 13:06:01.537 - INFO: Train epoch 461: [44800/94637 (47%)] Step: [2590541] | Lr: 0.000100 | Loss: 1.4862 | MSE loss: 0.0004 | Bpp loss: 0.86 | Aux loss: 41.12
24-04-04 13:06:53.118 - INFO: Train epoch 461: [48000/94637 (51%)] Step: [2590641] | Lr: 0.000100 | Loss: 1.2532 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 38.20
24-04-04 13:07:44.296 - INFO: Train epoch 461: [51200/94637 (54%)] Step: [2590741] | Lr: 0.000100 | Loss: 0.9548 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 37.08
24-04-04 13:08:35.724 - INFO: Train epoch 461: [54400/94637 (57%)] Step: [2590841] | Lr: 0.000100 | Loss: 1.2319 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 38.52
24-04-04 13:09:25.980 - INFO: Train epoch 461: [57600/94637 (61%)] Step: [2590941] | Lr: 0.000100 | Loss: 1.4400 | MSE loss: 0.0004 | Bpp loss: 0.83 | Aux loss: 38.16
24-04-04 13:10:16.691 - INFO: Train epoch 461: [60800/94637 (64%)] Step: [2591041] | Lr: 0.000100 | Loss: 1.4471 | MSE loss: 0.0004 | Bpp loss: 0.84 | Aux loss: 42.88
24-04-04 13:11:07.827 - INFO: Train epoch 461: [64000/94637 (68%)] Step: [2591141] | Lr: 0.000100 | Loss: 1.1120 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 36.61
24-04-04 13:11:59.068 - INFO: Train epoch 461: [67200/94637 (71%)] Step: [2591241] | Lr: 0.000100 | Loss: 1.3936 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 39.99
24-04-04 13:12:50.422 - INFO: Train epoch 461: [70400/94637 (74%)] Step: [2591341] | Lr: 0.000100 | Loss: 1.0114 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 37.21
24-04-04 13:13:41.186 - INFO: Train epoch 461: [73600/94637 (78%)] Step: [2591441] | Lr: 0.000100 | Loss: 1.1223 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 37.95
24-04-04 13:14:32.602 - INFO: Train epoch 461: [76800/94637 (81%)] Step: [2591541] | Lr: 0.000100 | Loss: 1.0868 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 38.21
24-04-04 13:15:24.047 - INFO: Train epoch 461: [80000/94637 (85%)] Step: [2591641] | Lr: 0.000100 | Loss: 1.7120 | MSE loss: 0.0004 | Bpp loss: 1.08 | Aux loss: 39.97
24-04-04 13:16:15.610 - INFO: Train epoch 461: [83200/94637 (88%)] Step: [2591741] | Lr: 0.000100 | Loss: 1.3025 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 37.35
24-04-04 13:17:06.464 - INFO: Train epoch 461: [86400/94637 (91%)] Step: [2591841] | Lr: 0.000100 | Loss: 1.3258 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 38.80
24-04-04 13:17:57.235 - INFO: Train epoch 461: [89600/94637 (95%)] Step: [2591941] | Lr: 0.000100 | Loss: 0.9411 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 39.10
24-04-04 13:18:47.824 - INFO: Train epoch 461: [92800/94637 (98%)] Step: [2592041] | Lr: 0.000100 | Loss: 1.1091 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 40.06
24-04-04 13:19:28.191 - INFO: Learning rate: 0.0001
24-04-04 13:19:29.436 - INFO: Train epoch 462: [    0/94637 (0%)] Step: [2592098] | Lr: 0.000100 | Loss: 1.2489 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 38.13
24-04-04 13:20:19.691 - INFO: Train epoch 462: [ 3200/94637 (3%)] Step: [2592198] | Lr: 0.000100 | Loss: 1.0821 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 38.74
24-04-04 13:21:09.855 - INFO: Train epoch 462: [ 6400/94637 (7%)] Step: [2592298] | Lr: 0.000100 | Loss: 1.2460 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 40.04
24-04-04 13:22:00.180 - INFO: Train epoch 462: [ 9600/94637 (10%)] Step: [2592398] | Lr: 0.000100 | Loss: 1.1499 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 40.23
24-04-04 13:22:51.132 - INFO: Train epoch 462: [12800/94637 (14%)] Step: [2592498] | Lr: 0.000100 | Loss: 1.0472 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 40.55
24-04-04 13:23:44.116 - INFO: Train epoch 462: [16000/94637 (17%)] Step: [2592598] | Lr: 0.000100 | Loss: 0.8485 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 37.66
24-04-04 13:24:35.012 - INFO: Train epoch 462: [19200/94637 (20%)] Step: [2592698] | Lr: 0.000100 | Loss: 1.4136 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 40.68
24-04-04 13:25:25.985 - INFO: Train epoch 462: [22400/94637 (24%)] Step: [2592798] | Lr: 0.000100 | Loss: 0.8085 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 38.66
24-04-04 13:26:16.890 - INFO: Train epoch 462: [25600/94637 (27%)] Step: [2592898] | Lr: 0.000100 | Loss: 1.2002 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 38.70
24-04-04 13:27:08.093 - INFO: Train epoch 462: [28800/94637 (30%)] Step: [2592998] | Lr: 0.000100 | Loss: 1.3893 | MSE loss: 0.0004 | Bpp loss: 0.81 | Aux loss: 39.31
24-04-04 13:27:59.285 - INFO: Train epoch 462: [32000/94637 (34%)] Step: [2593098] | Lr: 0.000100 | Loss: 1.1650 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 36.81
24-04-04 13:28:50.309 - INFO: Train epoch 462: [35200/94637 (37%)] Step: [2593198] | Lr: 0.000100 | Loss: 1.1532 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 39.45
24-04-04 13:29:41.436 - INFO: Train epoch 462: [38400/94637 (41%)] Step: [2593298] | Lr: 0.000100 | Loss: 1.6718 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 41.99
24-04-04 13:30:31.503 - INFO: Train epoch 462: [41600/94637 (44%)] Step: [2593398] | Lr: 0.000100 | Loss: 1.3505 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 38.72
24-04-04 13:31:22.817 - INFO: Train epoch 462: [44800/94637 (47%)] Step: [2593498] | Lr: 0.000100 | Loss: 1.6345 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 39.07
24-04-04 13:32:12.892 - INFO: Train epoch 462: [48000/94637 (51%)] Step: [2593598] | Lr: 0.000100 | Loss: 1.1866 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 39.46
24-04-04 13:33:04.520 - INFO: Train epoch 462: [51200/94637 (54%)] Step: [2593698] | Lr: 0.000100 | Loss: 1.6509 | MSE loss: 0.0004 | Bpp loss: 1.03 | Aux loss: 40.87
24-04-04 13:33:56.542 - INFO: Train epoch 462: [54400/94637 (57%)] Step: [2593798] | Lr: 0.000100 | Loss: 0.9715 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 38.90
24-04-04 13:34:48.904 - INFO: Train epoch 462: [57600/94637 (61%)] Step: [2593898] | Lr: 0.000100 | Loss: 1.0139 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 37.49
24-04-04 13:35:40.921 - INFO: Train epoch 462: [60800/94637 (64%)] Step: [2593998] | Lr: 0.000100 | Loss: 1.4740 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 37.26
24-04-04 13:36:32.126 - INFO: Train epoch 462: [64000/94637 (68%)] Step: [2594098] | Lr: 0.000100 | Loss: 1.1342 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 39.15
24-04-04 13:37:23.007 - INFO: Train epoch 462: [67200/94637 (71%)] Step: [2594198] | Lr: 0.000100 | Loss: 1.0662 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 38.34
24-04-04 13:38:13.674 - INFO: Train epoch 462: [70400/94637 (74%)] Step: [2594298] | Lr: 0.000100 | Loss: 1.6064 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 40.24
24-04-04 13:39:04.557 - INFO: Train epoch 462: [73600/94637 (78%)] Step: [2594398] | Lr: 0.000100 | Loss: 1.7036 | MSE loss: 0.0005 | Bpp loss: 0.87 | Aux loss: 39.26
24-04-04 13:39:55.618 - INFO: Train epoch 462: [76800/94637 (81%)] Step: [2594498] | Lr: 0.000100 | Loss: 1.5760 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 37.55
24-04-04 13:40:46.858 - INFO: Train epoch 462: [80000/94637 (85%)] Step: [2594598] | Lr: 0.000100 | Loss: 1.1839 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 38.52
24-04-04 13:41:37.970 - INFO: Train epoch 462: [83200/94637 (88%)] Step: [2594698] | Lr: 0.000100 | Loss: 1.2917 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 36.73
24-04-04 13:42:30.207 - INFO: Train epoch 462: [86400/94637 (91%)] Step: [2594798] | Lr: 0.000100 | Loss: 1.0742 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 40.27
24-04-04 13:43:21.959 - INFO: Train epoch 462: [89600/94637 (95%)] Step: [2594898] | Lr: 0.000100 | Loss: 1.5609 | MSE loss: 0.0004 | Bpp loss: 0.99 | Aux loss: 39.95
24-04-04 13:44:13.266 - INFO: Train epoch 462: [92800/94637 (98%)] Step: [2594998] | Lr: 0.000100 | Loss: 1.4301 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 42.81
24-04-04 13:44:56.165 - INFO: Learning rate: 0.0001
24-04-04 13:44:57.961 - INFO: Train epoch 463: [    0/94637 (0%)] Step: [2595055] | Lr: 0.000100 | Loss: 0.8570 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 40.44
24-04-04 13:45:48.744 - INFO: Train epoch 463: [ 3200/94637 (3%)] Step: [2595155] | Lr: 0.000100 | Loss: 1.5580 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 36.33
24-04-04 13:46:39.515 - INFO: Train epoch 463: [ 6400/94637 (7%)] Step: [2595255] | Lr: 0.000100 | Loss: 1.0044 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 36.65
24-04-04 13:47:30.162 - INFO: Train epoch 463: [ 9600/94637 (10%)] Step: [2595355] | Lr: 0.000100 | Loss: 1.1217 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 36.67
24-04-04 13:48:21.709 - INFO: Train epoch 463: [12800/94637 (14%)] Step: [2595455] | Lr: 0.000100 | Loss: 1.0592 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 38.85
24-04-04 13:49:12.866 - INFO: Train epoch 463: [16000/94637 (17%)] Step: [2595555] | Lr: 0.000100 | Loss: 1.7270 | MSE loss: 0.0005 | Bpp loss: 0.97 | Aux loss: 42.85
24-04-04 13:50:04.335 - INFO: Train epoch 463: [19200/94637 (20%)] Step: [2595655] | Lr: 0.000100 | Loss: 0.9946 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 41.26
24-04-04 13:50:55.275 - INFO: Train epoch 463: [22400/94637 (24%)] Step: [2595755] | Lr: 0.000100 | Loss: 1.0165 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 35.69
24-04-04 13:51:46.404 - INFO: Train epoch 463: [25600/94637 (27%)] Step: [2595855] | Lr: 0.000100 | Loss: 1.6622 | MSE loss: 0.0005 | Bpp loss: 0.89 | Aux loss: 41.05
24-04-04 13:52:37.066 - INFO: Train epoch 463: [28800/94637 (30%)] Step: [2595955] | Lr: 0.000100 | Loss: 0.7580 | MSE loss: 0.0002 | Bpp loss: 0.48 | Aux loss: 37.17
24-04-04 13:53:27.761 - INFO: Train epoch 463: [32000/94637 (34%)] Step: [2596055] | Lr: 0.000100 | Loss: 1.0089 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 36.54
24-04-04 13:54:18.455 - INFO: Train epoch 463: [35200/94637 (37%)] Step: [2596155] | Lr: 0.000100 | Loss: 1.4658 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 40.77
24-04-04 13:55:09.767 - INFO: Train epoch 463: [38400/94637 (41%)] Step: [2596255] | Lr: 0.000100 | Loss: 1.2987 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 37.87
24-04-04 13:56:00.797 - INFO: Train epoch 463: [41600/94637 (44%)] Step: [2596355] | Lr: 0.000100 | Loss: 1.2750 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 41.53
24-04-04 13:56:51.116 - INFO: Train epoch 463: [44800/94637 (47%)] Step: [2596455] | Lr: 0.000100 | Loss: 0.8432 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 36.67
24-04-04 13:57:42.157 - INFO: Train epoch 463: [48000/94637 (51%)] Step: [2596555] | Lr: 0.000100 | Loss: 0.8954 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 42.16
24-04-04 13:58:33.667 - INFO: Train epoch 463: [51200/94637 (54%)] Step: [2596655] | Lr: 0.000100 | Loss: 1.1782 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 40.45
24-04-04 13:59:25.024 - INFO: Train epoch 463: [54400/94637 (57%)] Step: [2596755] | Lr: 0.000100 | Loss: 0.9826 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 38.74
24-04-04 14:00:16.005 - INFO: Train epoch 463: [57600/94637 (61%)] Step: [2596855] | Lr: 0.000100 | Loss: 1.0169 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 38.87
24-04-04 14:01:07.423 - INFO: Train epoch 463: [60800/94637 (64%)] Step: [2596955] | Lr: 0.000100 | Loss: 1.2168 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 42.72
24-04-04 14:01:59.190 - INFO: Train epoch 463: [64000/94637 (68%)] Step: [2597055] | Lr: 0.000100 | Loss: 1.2415 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 36.60
24-04-04 14:02:50.146 - INFO: Train epoch 463: [67200/94637 (71%)] Step: [2597155] | Lr: 0.000100 | Loss: 1.0245 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 43.59
24-04-04 14:03:40.766 - INFO: Train epoch 463: [70400/94637 (74%)] Step: [2597255] | Lr: 0.000100 | Loss: 1.1972 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 40.68
24-04-04 14:04:31.651 - INFO: Train epoch 463: [73600/94637 (78%)] Step: [2597355] | Lr: 0.000100 | Loss: 1.0453 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 37.57
24-04-04 14:05:22.534 - INFO: Train epoch 463: [76800/94637 (81%)] Step: [2597455] | Lr: 0.000100 | Loss: 1.2717 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 41.90
24-04-04 14:06:15.685 - INFO: Train epoch 463: [80000/94637 (85%)] Step: [2597555] | Lr: 0.000100 | Loss: 1.2542 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 40.47
24-04-04 14:07:06.741 - INFO: Train epoch 463: [83200/94637 (88%)] Step: [2597655] | Lr: 0.000100 | Loss: 1.2965 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 39.25
24-04-04 14:07:57.520 - INFO: Train epoch 463: [86400/94637 (91%)] Step: [2597755] | Lr: 0.000100 | Loss: 1.0949 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 41.02
24-04-04 14:08:48.603 - INFO: Train epoch 463: [89600/94637 (95%)] Step: [2597855] | Lr: 0.000100 | Loss: 1.3601 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 42.18
24-04-04 14:09:40.213 - INFO: Train epoch 463: [92800/94637 (98%)] Step: [2597955] | Lr: 0.000100 | Loss: 1.3952 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 40.19
24-04-04 14:10:20.994 - INFO: Learning rate: 0.0001
24-04-04 14:10:22.230 - INFO: Train epoch 464: [    0/94637 (0%)] Step: [2598012] | Lr: 0.000100 | Loss: 1.1631 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 40.20
24-04-04 14:11:12.870 - INFO: Train epoch 464: [ 3200/94637 (3%)] Step: [2598112] | Lr: 0.000100 | Loss: 0.9077 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 37.63
24-04-04 14:12:03.608 - INFO: Train epoch 464: [ 6400/94637 (7%)] Step: [2598212] | Lr: 0.000100 | Loss: 1.4715 | MSE loss: 0.0004 | Bpp loss: 0.84 | Aux loss: 38.41
24-04-04 14:12:54.802 - INFO: Train epoch 464: [ 9600/94637 (10%)] Step: [2598312] | Lr: 0.000100 | Loss: 0.9515 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 38.91
24-04-04 14:13:46.860 - INFO: Train epoch 464: [12800/94637 (14%)] Step: [2598412] | Lr: 0.000100 | Loss: 1.0886 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 40.82
24-04-04 14:14:37.145 - INFO: Train epoch 464: [16000/94637 (17%)] Step: [2598512] | Lr: 0.000100 | Loss: 0.7888 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 40.39
24-04-04 14:15:27.960 - INFO: Train epoch 464: [19200/94637 (20%)] Step: [2598612] | Lr: 0.000100 | Loss: 0.9585 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 39.67
24-04-04 14:16:19.001 - INFO: Train epoch 464: [22400/94637 (24%)] Step: [2598712] | Lr: 0.000100 | Loss: 1.3017 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 40.26
24-04-04 14:17:10.323 - INFO: Train epoch 464: [25600/94637 (27%)] Step: [2598812] | Lr: 0.000100 | Loss: 1.2847 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 43.77
24-04-04 14:18:01.720 - INFO: Train epoch 464: [28800/94637 (30%)] Step: [2598912] | Lr: 0.000100 | Loss: 0.8964 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 41.54
24-04-04 14:18:52.614 - INFO: Train epoch 464: [32000/94637 (34%)] Step: [2599012] | Lr: 0.000100 | Loss: 1.2379 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 40.86
24-04-04 14:19:44.264 - INFO: Train epoch 464: [35200/94637 (37%)] Step: [2599112] | Lr: 0.000100 | Loss: 1.2224 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 41.63
24-04-04 14:20:35.433 - INFO: Train epoch 464: [38400/94637 (41%)] Step: [2599212] | Lr: 0.000100 | Loss: 1.3734 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 38.83
24-04-04 14:21:26.022 - INFO: Train epoch 464: [41600/94637 (44%)] Step: [2599312] | Lr: 0.000100 | Loss: 1.1391 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 40.68
24-04-04 14:22:17.761 - INFO: Train epoch 464: [44800/94637 (47%)] Step: [2599412] | Lr: 0.000100 | Loss: 1.1618 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 37.29
24-04-04 14:23:08.550 - INFO: Train epoch 464: [48000/94637 (51%)] Step: [2599512] | Lr: 0.000100 | Loss: 1.0641 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 39.95
24-04-04 14:23:58.835 - INFO: Train epoch 464: [51200/94637 (54%)] Step: [2599612] | Lr: 0.000100 | Loss: 1.2144 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 38.12
24-04-04 14:24:49.247 - INFO: Train epoch 464: [54400/94637 (57%)] Step: [2599712] | Lr: 0.000100 | Loss: 1.7242 | MSE loss: 0.0004 | Bpp loss: 1.08 | Aux loss: 36.50
24-04-04 14:25:40.474 - INFO: Train epoch 464: [57600/94637 (61%)] Step: [2599812] | Lr: 0.000100 | Loss: 1.4613 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 38.38
24-04-04 14:26:31.759 - INFO: Train epoch 464: [60800/94637 (64%)] Step: [2599912] | Lr: 0.000100 | Loss: 1.2846 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 38.17
24-04-04 14:27:25.429 - INFO: Train epoch 464: [64000/94637 (68%)] Step: [2600012] | Lr: 0.000100 | Loss: 1.7027 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 38.59
24-04-04 14:28:16.264 - INFO: Train epoch 464: [67200/94637 (71%)] Step: [2600112] | Lr: 0.000100 | Loss: 1.1200 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 40.02
24-04-04 14:29:07.183 - INFO: Train epoch 464: [70400/94637 (74%)] Step: [2600212] | Lr: 0.000100 | Loss: 1.7981 | MSE loss: 0.0004 | Bpp loss: 1.07 | Aux loss: 37.94
24-04-04 14:29:58.184 - INFO: Train epoch 464: [73600/94637 (78%)] Step: [2600312] | Lr: 0.000100 | Loss: 1.5135 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 45.66
24-04-04 14:30:49.895 - INFO: Train epoch 464: [76800/94637 (81%)] Step: [2600412] | Lr: 0.000100 | Loss: 1.0805 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 42.03
24-04-04 14:31:41.198 - INFO: Train epoch 464: [80000/94637 (85%)] Step: [2600512] | Lr: 0.000100 | Loss: 1.3905 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 38.81
24-04-04 14:32:33.001 - INFO: Train epoch 464: [83200/94637 (88%)] Step: [2600612] | Lr: 0.000100 | Loss: 1.0352 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 37.59
24-04-04 14:33:24.561 - INFO: Train epoch 464: [86400/94637 (91%)] Step: [2600712] | Lr: 0.000100 | Loss: 1.2794 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 37.13
24-04-04 14:34:15.535 - INFO: Train epoch 464: [89600/94637 (95%)] Step: [2600812] | Lr: 0.000100 | Loss: 1.1631 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 38.63
24-04-04 14:35:07.327 - INFO: Train epoch 464: [92800/94637 (98%)] Step: [2600912] | Lr: 0.000100 | Loss: 0.9013 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 43.14
24-04-04 14:35:48.040 - INFO: Learning rate: 0.0001
24-04-04 14:35:49.786 - INFO: Train epoch 465: [    0/94637 (0%)] Step: [2600969] | Lr: 0.000100 | Loss: 1.2388 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 39.53
24-04-04 14:36:39.303 - INFO: Train epoch 465: [ 3200/94637 (3%)] Step: [2601069] | Lr: 0.000100 | Loss: 1.4672 | MSE loss: 0.0004 | Bpp loss: 0.86 | Aux loss: 41.76
24-04-04 14:37:30.650 - INFO: Train epoch 465: [ 6400/94637 (7%)] Step: [2601169] | Lr: 0.000100 | Loss: 0.8400 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 42.06
24-04-04 14:38:21.829 - INFO: Train epoch 465: [ 9600/94637 (10%)] Step: [2601269] | Lr: 0.000100 | Loss: 1.1422 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 40.22
24-04-04 14:39:12.962 - INFO: Train epoch 465: [12800/94637 (14%)] Step: [2601369] | Lr: 0.000100 | Loss: 1.1051 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 40.81
24-04-04 14:40:04.381 - INFO: Train epoch 465: [16000/94637 (17%)] Step: [2601469] | Lr: 0.000100 | Loss: 1.1770 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 37.03
24-04-04 14:40:55.983 - INFO: Train epoch 465: [19200/94637 (20%)] Step: [2601569] | Lr: 0.000100 | Loss: 0.9433 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 40.51
24-04-04 14:41:47.231 - INFO: Train epoch 465: [22400/94637 (24%)] Step: [2601669] | Lr: 0.000100 | Loss: 1.3025 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 41.35
24-04-04 14:42:38.394 - INFO: Train epoch 465: [25600/94637 (27%)] Step: [2601769] | Lr: 0.000100 | Loss: 0.8281 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 37.27
24-04-04 14:43:29.577 - INFO: Train epoch 465: [28800/94637 (30%)] Step: [2601869] | Lr: 0.000100 | Loss: 1.5804 | MSE loss: 0.0003 | Bpp loss: 1.01 | Aux loss: 35.71
24-04-04 14:44:19.878 - INFO: Train epoch 465: [32000/94637 (34%)] Step: [2601969] | Lr: 0.000100 | Loss: 1.6822 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 41.20
24-04-04 14:45:10.535 - INFO: Train epoch 465: [35200/94637 (37%)] Step: [2602069] | Lr: 0.000100 | Loss: 1.2715 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 40.86
24-04-04 14:46:01.911 - INFO: Train epoch 465: [38400/94637 (41%)] Step: [2602169] | Lr: 0.000100 | Loss: 1.3150 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 39.07
24-04-04 14:46:53.164 - INFO: Train epoch 465: [41600/94637 (44%)] Step: [2602269] | Lr: 0.000100 | Loss: 1.6901 | MSE loss: 0.0004 | Bpp loss: 1.07 | Aux loss: 40.36
24-04-04 14:47:44.086 - INFO: Train epoch 465: [44800/94637 (47%)] Step: [2602369] | Lr: 0.000100 | Loss: 1.2402 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 40.67
24-04-04 14:48:35.504 - INFO: Train epoch 465: [48000/94637 (51%)] Step: [2602469] | Lr: 0.000100 | Loss: 1.0737 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 42.70
24-04-04 14:49:29.000 - INFO: Train epoch 465: [51200/94637 (54%)] Step: [2602569] | Lr: 0.000100 | Loss: 1.0766 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 35.44
24-04-04 14:50:21.402 - INFO: Train epoch 465: [54400/94637 (57%)] Step: [2602669] | Lr: 0.000100 | Loss: 1.2958 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 42.21
24-04-04 14:51:13.172 - INFO: Train epoch 465: [57600/94637 (61%)] Step: [2602769] | Lr: 0.000100 | Loss: 1.1525 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 39.97
24-04-04 14:52:04.282 - INFO: Train epoch 465: [60800/94637 (64%)] Step: [2602869] | Lr: 0.000100 | Loss: 0.7688 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 39.97
24-04-04 14:52:54.763 - INFO: Train epoch 465: [64000/94637 (68%)] Step: [2602969] | Lr: 0.000100 | Loss: 1.0393 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 39.50
24-04-04 14:53:44.972 - INFO: Train epoch 465: [67200/94637 (71%)] Step: [2603069] | Lr: 0.000100 | Loss: 1.0925 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 44.13
24-04-04 14:54:35.590 - INFO: Train epoch 465: [70400/94637 (74%)] Step: [2603169] | Lr: 0.000100 | Loss: 0.9095 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 41.18
24-04-04 14:55:26.072 - INFO: Train epoch 465: [73600/94637 (78%)] Step: [2603269] | Lr: 0.000100 | Loss: 1.4785 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 41.87
24-04-04 14:56:16.927 - INFO: Train epoch 465: [76800/94637 (81%)] Step: [2603369] | Lr: 0.000100 | Loss: 0.9864 | MSE loss: 0.0003 | Bpp loss: 0.57 | Aux loss: 40.19
24-04-04 14:57:07.773 - INFO: Train epoch 465: [80000/94637 (85%)] Step: [2603469] | Lr: 0.000100 | Loss: 0.9930 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 44.30
24-04-04 14:57:58.896 - INFO: Train epoch 465: [83200/94637 (88%)] Step: [2603569] | Lr: 0.000100 | Loss: 0.8662 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 43.84
24-04-04 14:58:49.495 - INFO: Train epoch 465: [86400/94637 (91%)] Step: [2603669] | Lr: 0.000100 | Loss: 0.9712 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 39.63
24-04-04 14:59:41.208 - INFO: Train epoch 465: [89600/94637 (95%)] Step: [2603769] | Lr: 0.000100 | Loss: 1.5811 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 38.12
24-04-04 15:00:32.906 - INFO: Train epoch 465: [92800/94637 (98%)] Step: [2603869] | Lr: 0.000100 | Loss: 1.2353 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 40.41
24-04-04 15:01:13.894 - INFO: Learning rate: 0.0001
24-04-04 15:01:15.044 - INFO: Train epoch 466: [    0/94637 (0%)] Step: [2603926] | Lr: 0.000100 | Loss: 1.0161 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 43.86
24-04-04 15:02:06.480 - INFO: Train epoch 466: [ 3200/94637 (3%)] Step: [2604026] | Lr: 0.000100 | Loss: 1.1590 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 35.60
24-04-04 15:02:58.078 - INFO: Train epoch 466: [ 6400/94637 (7%)] Step: [2604126] | Lr: 0.000100 | Loss: 0.9867 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 38.35
24-04-04 15:03:49.538 - INFO: Train epoch 466: [ 9600/94637 (10%)] Step: [2604226] | Lr: 0.000100 | Loss: 1.3822 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 40.48
24-04-04 15:04:39.773 - INFO: Train epoch 466: [12800/94637 (14%)] Step: [2604326] | Lr: 0.000100 | Loss: 1.2428 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 40.56
24-04-04 15:05:31.421 - INFO: Train epoch 466: [16000/94637 (17%)] Step: [2604426] | Lr: 0.000100 | Loss: 1.4852 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 43.10
24-04-04 15:06:22.595 - INFO: Train epoch 466: [19200/94637 (20%)] Step: [2604526] | Lr: 0.000100 | Loss: 1.0636 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 38.48
24-04-04 15:07:13.747 - INFO: Train epoch 466: [22400/94637 (24%)] Step: [2604626] | Lr: 0.000100 | Loss: 1.4434 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 39.90
24-04-04 15:08:04.769 - INFO: Train epoch 466: [25600/94637 (27%)] Step: [2604726] | Lr: 0.000100 | Loss: 1.0553 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 40.72
24-04-04 15:08:56.023 - INFO: Train epoch 466: [28800/94637 (30%)] Step: [2604826] | Lr: 0.000100 | Loss: 1.4352 | MSE loss: 0.0004 | Bpp loss: 0.86 | Aux loss: 40.63
24-04-04 15:09:47.115 - INFO: Train epoch 466: [32000/94637 (34%)] Step: [2604926] | Lr: 0.000100 | Loss: 1.6145 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 40.83
24-04-04 15:10:40.078 - INFO: Train epoch 466: [35200/94637 (37%)] Step: [2605026] | Lr: 0.000100 | Loss: 0.9969 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 39.99
24-04-04 15:11:30.094 - INFO: Train epoch 466: [38400/94637 (41%)] Step: [2605126] | Lr: 0.000100 | Loss: 1.3974 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 37.28
24-04-04 15:12:21.510 - INFO: Train epoch 466: [41600/94637 (44%)] Step: [2605226] | Lr: 0.000100 | Loss: 1.2965 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 41.78
24-04-04 15:13:12.433 - INFO: Train epoch 466: [44800/94637 (47%)] Step: [2605326] | Lr: 0.000100 | Loss: 1.3581 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 37.58
24-04-04 15:14:03.273 - INFO: Train epoch 466: [48000/94637 (51%)] Step: [2605426] | Lr: 0.000100 | Loss: 0.9025 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 40.96
24-04-04 15:14:53.822 - INFO: Train epoch 466: [51200/94637 (54%)] Step: [2605526] | Lr: 0.000100 | Loss: 1.4988 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 40.31
24-04-04 15:15:44.223 - INFO: Train epoch 466: [54400/94637 (57%)] Step: [2605626] | Lr: 0.000100 | Loss: 0.9806 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 38.86
24-04-04 15:16:34.685 - INFO: Train epoch 466: [57600/94637 (61%)] Step: [2605726] | Lr: 0.000100 | Loss: 0.9847 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 37.94
24-04-04 15:17:25.269 - INFO: Train epoch 466: [60800/94637 (64%)] Step: [2605826] | Lr: 0.000100 | Loss: 1.0406 | MSE loss: 0.0003 | Bpp loss: 0.62 | Aux loss: 37.51
24-04-04 15:18:15.681 - INFO: Train epoch 466: [64000/94637 (68%)] Step: [2605926] | Lr: 0.000100 | Loss: 1.1512 | MSE loss: 0.0002 | Bpp loss: 0.76 | Aux loss: 38.19
24-04-04 15:19:06.277 - INFO: Train epoch 466: [67200/94637 (71%)] Step: [2606026] | Lr: 0.000100 | Loss: 0.9587 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 40.08
24-04-04 15:19:57.426 - INFO: Train epoch 466: [70400/94637 (74%)] Step: [2606126] | Lr: 0.000100 | Loss: 1.2714 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 39.77
24-04-04 15:20:48.294 - INFO: Train epoch 466: [73600/94637 (78%)] Step: [2606226] | Lr: 0.000100 | Loss: 1.2500 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 40.36
24-04-04 15:21:38.698 - INFO: Train epoch 466: [76800/94637 (81%)] Step: [2606326] | Lr: 0.000100 | Loss: 1.5401 | MSE loss: 0.0003 | Bpp loss: 1.01 | Aux loss: 39.66
24-04-04 15:22:29.856 - INFO: Train epoch 466: [80000/94637 (85%)] Step: [2606426] | Lr: 0.000100 | Loss: 1.0567 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 41.51
24-04-04 15:23:20.592 - INFO: Train epoch 466: [83200/94637 (88%)] Step: [2606526] | Lr: 0.000100 | Loss: 1.0878 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 38.68
24-04-04 15:24:11.753 - INFO: Train epoch 466: [86400/94637 (91%)] Step: [2606626] | Lr: 0.000100 | Loss: 1.2401 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 38.18
24-04-04 15:25:02.538 - INFO: Train epoch 466: [89600/94637 (95%)] Step: [2606726] | Lr: 0.000100 | Loss: 1.1333 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 39.47
24-04-04 15:25:53.214 - INFO: Train epoch 466: [92800/94637 (98%)] Step: [2606826] | Lr: 0.000100 | Loss: 1.2377 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 39.64
24-04-04 15:26:33.929 - INFO: Learning rate: 0.0001
24-04-04 15:26:35.373 - INFO: Train epoch 467: [    0/94637 (0%)] Step: [2606883] | Lr: 0.000100 | Loss: 1.3637 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 43.44
24-04-04 15:27:25.906 - INFO: Train epoch 467: [ 3200/94637 (3%)] Step: [2606983] | Lr: 0.000100 | Loss: 1.2743 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 41.91
24-04-04 15:28:16.703 - INFO: Train epoch 467: [ 6400/94637 (7%)] Step: [2607083] | Lr: 0.000100 | Loss: 2.0141 | MSE loss: 0.0005 | Bpp loss: 1.21 | Aux loss: 38.94
24-04-04 15:29:08.022 - INFO: Train epoch 467: [ 9600/94637 (10%)] Step: [2607183] | Lr: 0.000100 | Loss: 1.3264 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 40.07
24-04-04 15:29:59.531 - INFO: Train epoch 467: [12800/94637 (14%)] Step: [2607283] | Lr: 0.000100 | Loss: 0.8904 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 40.59
24-04-04 15:30:50.693 - INFO: Train epoch 467: [16000/94637 (17%)] Step: [2607383] | Lr: 0.000100 | Loss: 1.0493 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 42.60
24-04-04 15:31:42.538 - INFO: Train epoch 467: [19200/94637 (20%)] Step: [2607483] | Lr: 0.000100 | Loss: 1.4642 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 40.33
24-04-04 15:32:36.613 - INFO: Train epoch 467: [22400/94637 (24%)] Step: [2607583] | Lr: 0.000100 | Loss: 1.0969 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 40.02
24-04-04 15:33:27.056 - INFO: Train epoch 467: [25600/94637 (27%)] Step: [2607683] | Lr: 0.000100 | Loss: 1.4817 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 45.57
24-04-04 15:34:17.584 - INFO: Train epoch 467: [28800/94637 (30%)] Step: [2607783] | Lr: 0.000100 | Loss: 1.4856 | MSE loss: 0.0003 | Bpp loss: 0.97 | Aux loss: 39.51
24-04-04 15:35:08.008 - INFO: Train epoch 467: [32000/94637 (34%)] Step: [2607883] | Lr: 0.000100 | Loss: 1.0291 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 38.14
24-04-04 15:35:58.624 - INFO: Train epoch 467: [35200/94637 (37%)] Step: [2607983] | Lr: 0.000100 | Loss: 1.2390 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 44.20
24-04-04 15:36:50.243 - INFO: Train epoch 467: [38400/94637 (41%)] Step: [2608083] | Lr: 0.000100 | Loss: 1.5710 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 41.11
24-04-04 15:37:41.811 - INFO: Train epoch 467: [41600/94637 (44%)] Step: [2608183] | Lr: 0.000100 | Loss: 1.0965 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 41.84
24-04-04 15:38:32.240 - INFO: Train epoch 467: [44800/94637 (47%)] Step: [2608283] | Lr: 0.000100 | Loss: 0.9125 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 42.06
24-04-04 15:39:22.753 - INFO: Train epoch 467: [48000/94637 (51%)] Step: [2608383] | Lr: 0.000100 | Loss: 1.2252 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 41.27
24-04-04 15:40:13.936 - INFO: Train epoch 467: [51200/94637 (54%)] Step: [2608483] | Lr: 0.000100 | Loss: 1.2305 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 44.00
24-04-04 15:41:04.336 - INFO: Train epoch 467: [54400/94637 (57%)] Step: [2608583] | Lr: 0.000100 | Loss: 1.0164 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 41.64
24-04-04 15:41:54.918 - INFO: Train epoch 467: [57600/94637 (61%)] Step: [2608683] | Lr: 0.000100 | Loss: 1.3544 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 41.63
24-04-04 15:42:45.927 - INFO: Train epoch 467: [60800/94637 (64%)] Step: [2608783] | Lr: 0.000100 | Loss: 1.4831 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 40.35
24-04-04 15:43:37.275 - INFO: Train epoch 467: [64000/94637 (68%)] Step: [2608883] | Lr: 0.000100 | Loss: 0.8887 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 40.85
24-04-04 15:44:28.712 - INFO: Train epoch 467: [67200/94637 (71%)] Step: [2608983] | Lr: 0.000100 | Loss: 1.1110 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 42.61
24-04-04 15:45:19.422 - INFO: Train epoch 467: [70400/94637 (74%)] Step: [2609083] | Lr: 0.000100 | Loss: 1.3191 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 40.23
24-04-04 15:46:10.265 - INFO: Train epoch 467: [73600/94637 (78%)] Step: [2609183] | Lr: 0.000100 | Loss: 1.4516 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 41.49
24-04-04 15:47:01.165 - INFO: Train epoch 467: [76800/94637 (81%)] Step: [2609283] | Lr: 0.000100 | Loss: 1.4146 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 41.56
24-04-04 15:47:51.907 - INFO: Train epoch 467: [80000/94637 (85%)] Step: [2609383] | Lr: 0.000100 | Loss: 0.9345 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 37.18
24-04-04 15:48:42.769 - INFO: Train epoch 467: [83200/94637 (88%)] Step: [2609483] | Lr: 0.000100 | Loss: 1.8472 | MSE loss: 0.0005 | Bpp loss: 1.05 | Aux loss: 37.87
24-04-04 15:49:34.295 - INFO: Train epoch 467: [86400/94637 (91%)] Step: [2609583] | Lr: 0.000100 | Loss: 1.3514 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 39.42
24-04-04 15:50:25.498 - INFO: Train epoch 467: [89600/94637 (95%)] Step: [2609683] | Lr: 0.000100 | Loss: 1.2109 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 42.44
24-04-04 15:51:16.136 - INFO: Train epoch 467: [92800/94637 (98%)] Step: [2609783] | Lr: 0.000100 | Loss: 0.6584 | MSE loss: 0.0001 | Bpp loss: 0.42 | Aux loss: 41.89
24-04-04 15:51:56.766 - INFO: Learning rate: 0.0001
24-04-04 15:51:57.925 - INFO: Train epoch 468: [    0/94637 (0%)] Step: [2609840] | Lr: 0.000100 | Loss: 1.1456 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 39.90
24-04-04 15:52:49.651 - INFO: Train epoch 468: [ 3200/94637 (3%)] Step: [2609940] | Lr: 0.000100 | Loss: 1.0139 | MSE loss: 0.0003 | Bpp loss: 0.61 | Aux loss: 41.43
24-04-04 15:53:42.657 - INFO: Train epoch 468: [ 6400/94637 (7%)] Step: [2610040] | Lr: 0.000100 | Loss: 0.8605 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 42.38
24-04-04 15:54:32.819 - INFO: Train epoch 468: [ 9600/94637 (10%)] Step: [2610140] | Lr: 0.000100 | Loss: 1.5754 | MSE loss: 0.0004 | Bpp loss: 0.99 | Aux loss: 41.24
24-04-04 15:55:23.330 - INFO: Train epoch 468: [12800/94637 (14%)] Step: [2610240] | Lr: 0.000100 | Loss: 1.4212 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 43.94
24-04-04 15:56:14.068 - INFO: Train epoch 468: [16000/94637 (17%)] Step: [2610340] | Lr: 0.000100 | Loss: 1.0890 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 43.54
24-04-04 15:57:05.142 - INFO: Train epoch 468: [19200/94637 (20%)] Step: [2610440] | Lr: 0.000100 | Loss: 0.9333 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 41.56
24-04-04 15:57:56.092 - INFO: Train epoch 468: [22400/94637 (24%)] Step: [2610540] | Lr: 0.000100 | Loss: 1.0450 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 42.10
24-04-04 15:58:47.266 - INFO: Train epoch 468: [25600/94637 (27%)] Step: [2610640] | Lr: 0.000100 | Loss: 1.3113 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 45.83
24-04-04 15:59:37.957 - INFO: Train epoch 468: [28800/94637 (30%)] Step: [2610740] | Lr: 0.000100 | Loss: 1.1710 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 40.09
24-04-04 16:00:28.921 - INFO: Train epoch 468: [32000/94637 (34%)] Step: [2610840] | Lr: 0.000100 | Loss: 1.0682 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 41.21
24-04-04 16:01:19.908 - INFO: Train epoch 468: [35200/94637 (37%)] Step: [2610940] | Lr: 0.000100 | Loss: 1.1584 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 41.46
24-04-04 16:02:10.763 - INFO: Train epoch 468: [38400/94637 (41%)] Step: [2611040] | Lr: 0.000100 | Loss: 1.1665 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 43.93
24-04-04 16:03:02.400 - INFO: Train epoch 468: [41600/94637 (44%)] Step: [2611140] | Lr: 0.000100 | Loss: 1.2789 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 43.26
24-04-04 16:03:54.252 - INFO: Train epoch 468: [44800/94637 (47%)] Step: [2611240] | Lr: 0.000100 | Loss: 1.0676 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 41.64
24-04-04 16:04:46.213 - INFO: Train epoch 468: [48000/94637 (51%)] Step: [2611340] | Lr: 0.000100 | Loss: 1.0684 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 40.89
24-04-04 16:05:38.393 - INFO: Train epoch 468: [51200/94637 (54%)] Step: [2611440] | Lr: 0.000100 | Loss: 1.0166 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 42.12
24-04-04 16:06:30.198 - INFO: Train epoch 468: [54400/94637 (57%)] Step: [2611540] | Lr: 0.000100 | Loss: 1.2156 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 42.16
24-04-04 16:07:21.898 - INFO: Train epoch 468: [57600/94637 (61%)] Step: [2611640] | Lr: 0.000100 | Loss: 1.3668 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 43.60
24-04-04 16:08:13.454 - INFO: Train epoch 468: [60800/94637 (64%)] Step: [2611740] | Lr: 0.000100 | Loss: 1.1491 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 44.47
24-04-04 16:09:04.813 - INFO: Train epoch 468: [64000/94637 (68%)] Step: [2611840] | Lr: 0.000100 | Loss: 1.0584 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 41.21
24-04-04 16:09:56.473 - INFO: Train epoch 468: [67200/94637 (71%)] Step: [2611940] | Lr: 0.000100 | Loss: 0.9652 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 40.46
24-04-04 16:10:48.332 - INFO: Train epoch 468: [70400/94637 (74%)] Step: [2612040] | Lr: 0.000100 | Loss: 1.4342 | MSE loss: 0.0004 | Bpp loss: 0.83 | Aux loss: 43.86
24-04-04 16:11:39.669 - INFO: Train epoch 468: [73600/94637 (78%)] Step: [2612140] | Lr: 0.000100 | Loss: 1.0067 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 40.18
24-04-04 16:12:30.190 - INFO: Train epoch 468: [76800/94637 (81%)] Step: [2612240] | Lr: 0.000100 | Loss: 1.0842 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 43.39
24-04-04 16:13:20.484 - INFO: Train epoch 468: [80000/94637 (85%)] Step: [2612340] | Lr: 0.000100 | Loss: 0.9074 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 45.95
24-04-04 16:14:10.667 - INFO: Train epoch 468: [83200/94637 (88%)] Step: [2612440] | Lr: 0.000100 | Loss: 1.7400 | MSE loss: 0.0005 | Bpp loss: 1.01 | Aux loss: 39.34
24-04-04 16:15:03.049 - INFO: Train epoch 468: [86400/94637 (91%)] Step: [2612540] | Lr: 0.000100 | Loss: 0.9584 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 43.93
24-04-04 16:15:54.493 - INFO: Train epoch 468: [89600/94637 (95%)] Step: [2612640] | Lr: 0.000100 | Loss: 1.4943 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 40.10
24-04-04 16:16:45.289 - INFO: Train epoch 468: [92800/94637 (98%)] Step: [2612740] | Lr: 0.000100 | Loss: 0.7822 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 42.14
24-04-04 16:17:25.637 - INFO: Learning rate: 0.0001
24-04-04 16:17:26.777 - INFO: Train epoch 469: [    0/94637 (0%)] Step: [2612797] | Lr: 0.000100 | Loss: 1.4405 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 42.03
24-04-04 16:18:18.210 - INFO: Train epoch 469: [ 3200/94637 (3%)] Step: [2612897] | Lr: 0.000100 | Loss: 1.3011 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 45.42
24-04-04 16:19:09.411 - INFO: Train epoch 469: [ 6400/94637 (7%)] Step: [2612997] | Lr: 0.000100 | Loss: 1.4956 | MSE loss: 0.0004 | Bpp loss: 0.88 | Aux loss: 41.39
24-04-04 16:20:00.587 - INFO: Train epoch 469: [ 9600/94637 (10%)] Step: [2613097] | Lr: 0.000100 | Loss: 0.9523 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 43.36
24-04-04 16:20:50.459 - INFO: Train epoch 469: [12800/94637 (14%)] Step: [2613197] | Lr: 0.000100 | Loss: 1.3800 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 46.59
24-04-04 16:21:41.266 - INFO: Train epoch 469: [16000/94637 (17%)] Step: [2613297] | Lr: 0.000100 | Loss: 0.8325 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 41.85
24-04-04 16:22:31.800 - INFO: Train epoch 469: [19200/94637 (20%)] Step: [2613397] | Lr: 0.000100 | Loss: 0.9396 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 46.90
24-04-04 16:23:22.608 - INFO: Train epoch 469: [22400/94637 (24%)] Step: [2613497] | Lr: 0.000100 | Loss: 1.1053 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 44.51
24-04-04 16:24:13.103 - INFO: Train epoch 469: [25600/94637 (27%)] Step: [2613597] | Lr: 0.000100 | Loss: 1.1471 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 50.78
24-04-04 16:25:03.334 - INFO: Train epoch 469: [28800/94637 (30%)] Step: [2613697] | Lr: 0.000100 | Loss: 1.4169 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 40.72
24-04-04 16:25:53.466 - INFO: Train epoch 469: [32000/94637 (34%)] Step: [2613797] | Lr: 0.000100 | Loss: 0.9292 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 43.03
24-04-04 16:26:44.182 - INFO: Train epoch 469: [35200/94637 (37%)] Step: [2613897] | Lr: 0.000100 | Loss: 0.9138 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 41.40
24-04-04 16:27:34.489 - INFO: Train epoch 469: [38400/94637 (41%)] Step: [2613997] | Lr: 0.000100 | Loss: 1.5255 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 45.42
24-04-04 16:28:24.834 - INFO: Train epoch 469: [41600/94637 (44%)] Step: [2614097] | Lr: 0.000100 | Loss: 1.5220 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 43.42
24-04-04 16:29:16.563 - INFO: Train epoch 469: [44800/94637 (47%)] Step: [2614197] | Lr: 0.000100 | Loss: 1.9335 | MSE loss: 0.0005 | Bpp loss: 1.12 | Aux loss: 39.32
24-04-04 16:30:07.959 - INFO: Train epoch 469: [48000/94637 (51%)] Step: [2614297] | Lr: 0.000100 | Loss: 1.0825 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 41.62
24-04-04 16:30:58.879 - INFO: Train epoch 469: [51200/94637 (54%)] Step: [2614397] | Lr: 0.000100 | Loss: 1.4600 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 41.68
24-04-04 16:31:50.633 - INFO: Train epoch 469: [54400/94637 (57%)] Step: [2614497] | Lr: 0.000100 | Loss: 1.4564 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 41.76
24-04-04 16:32:41.823 - INFO: Train epoch 469: [57600/94637 (61%)] Step: [2614597] | Lr: 0.000100 | Loss: 1.2250 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 44.89
24-04-04 16:33:32.839 - INFO: Train epoch 469: [60800/94637 (64%)] Step: [2614697] | Lr: 0.000100 | Loss: 0.8782 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 42.34
24-04-04 16:34:24.455 - INFO: Train epoch 469: [64000/94637 (68%)] Step: [2614797] | Lr: 0.000100 | Loss: 1.4925 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 39.35
24-04-04 16:35:15.742 - INFO: Train epoch 469: [67200/94637 (71%)] Step: [2614897] | Lr: 0.000100 | Loss: 1.1324 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 42.10
24-04-04 16:36:06.770 - INFO: Train epoch 469: [70400/94637 (74%)] Step: [2614997] | Lr: 0.000100 | Loss: 1.0493 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 39.31
24-04-04 16:36:59.937 - INFO: Train epoch 469: [73600/94637 (78%)] Step: [2615097] | Lr: 0.000100 | Loss: 1.0419 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 44.06
24-04-04 16:37:51.614 - INFO: Train epoch 469: [76800/94637 (81%)] Step: [2615197] | Lr: 0.000100 | Loss: 1.5402 | MSE loss: 0.0003 | Bpp loss: 1.00 | Aux loss: 42.92
24-04-04 16:38:43.335 - INFO: Train epoch 469: [80000/94637 (85%)] Step: [2615297] | Lr: 0.000100 | Loss: 0.7536 | MSE loss: 0.0002 | Bpp loss: 0.48 | Aux loss: 40.20
24-04-04 16:39:35.269 - INFO: Train epoch 469: [83200/94637 (88%)] Step: [2615397] | Lr: 0.000100 | Loss: 1.1921 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 41.73
24-04-04 16:40:26.239 - INFO: Train epoch 469: [86400/94637 (91%)] Step: [2615497] | Lr: 0.000100 | Loss: 1.1229 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 41.84
24-04-04 16:41:17.277 - INFO: Train epoch 469: [89600/94637 (95%)] Step: [2615597] | Lr: 0.000100 | Loss: 1.0323 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 41.65
24-04-04 16:42:07.934 - INFO: Train epoch 469: [92800/94637 (98%)] Step: [2615697] | Lr: 0.000100 | Loss: 1.2812 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 39.16
24-04-04 16:42:48.540 - INFO: Learning rate: 0.0001
24-04-04 16:42:49.808 - INFO: Train epoch 470: [    0/94637 (0%)] Step: [2615754] | Lr: 0.000100 | Loss: 1.1274 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 43.14
24-04-04 16:43:41.009 - INFO: Train epoch 470: [ 3200/94637 (3%)] Step: [2615854] | Lr: 0.000100 | Loss: 1.1086 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 46.67
24-04-04 16:44:31.978 - INFO: Train epoch 470: [ 6400/94637 (7%)] Step: [2615954] | Lr: 0.000100 | Loss: 1.3651 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 41.12
24-04-04 16:45:22.886 - INFO: Train epoch 470: [ 9600/94637 (10%)] Step: [2616054] | Lr: 0.000100 | Loss: 1.3793 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 41.35
24-04-04 16:46:13.070 - INFO: Train epoch 470: [12800/94637 (14%)] Step: [2616154] | Lr: 0.000100 | Loss: 1.0821 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 44.84
24-04-04 16:47:03.185 - INFO: Train epoch 470: [16000/94637 (17%)] Step: [2616254] | Lr: 0.000100 | Loss: 1.0567 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 44.68
24-04-04 16:47:55.426 - INFO: Train epoch 470: [19200/94637 (20%)] Step: [2616354] | Lr: 0.000100 | Loss: 1.4358 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 41.86
24-04-04 16:48:45.806 - INFO: Train epoch 470: [22400/94637 (24%)] Step: [2616454] | Lr: 0.000100 | Loss: 1.4593 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 42.96
24-04-04 16:49:36.452 - INFO: Train epoch 470: [25600/94637 (27%)] Step: [2616554] | Lr: 0.000100 | Loss: 1.0995 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 38.82
24-04-04 16:50:28.155 - INFO: Train epoch 470: [28800/94637 (30%)] Step: [2616654] | Lr: 0.000100 | Loss: 1.0328 | MSE loss: 0.0003 | Bpp loss: 0.62 | Aux loss: 41.34
24-04-04 16:51:19.395 - INFO: Train epoch 470: [32000/94637 (34%)] Step: [2616754] | Lr: 0.000100 | Loss: 0.9831 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 43.75
24-04-04 16:52:10.677 - INFO: Train epoch 470: [35200/94637 (37%)] Step: [2616854] | Lr: 0.000100 | Loss: 1.2311 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 39.02
24-04-04 16:53:01.700 - INFO: Train epoch 470: [38400/94637 (41%)] Step: [2616954] | Lr: 0.000100 | Loss: 1.0380 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 41.53
24-04-04 16:53:53.356 - INFO: Train epoch 470: [41600/94637 (44%)] Step: [2617054] | Lr: 0.000100 | Loss: 1.2178 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 45.38
24-04-04 16:54:44.696 - INFO: Train epoch 470: [44800/94637 (47%)] Step: [2617154] | Lr: 0.000100 | Loss: 0.9223 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 38.69
24-04-04 16:55:35.924 - INFO: Train epoch 470: [48000/94637 (51%)] Step: [2617254] | Lr: 0.000100 | Loss: 0.9877 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 43.89
24-04-04 16:56:27.300 - INFO: Train epoch 470: [51200/94637 (54%)] Step: [2617354] | Lr: 0.000100 | Loss: 1.1945 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 41.29
24-04-04 16:57:18.157 - INFO: Train epoch 470: [54400/94637 (57%)] Step: [2617454] | Lr: 0.000100 | Loss: 0.9475 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 39.23
24-04-04 16:58:11.271 - INFO: Train epoch 470: [57600/94637 (61%)] Step: [2617554] | Lr: 0.000100 | Loss: 1.7226 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 43.64
24-04-04 16:59:02.597 - INFO: Train epoch 470: [60800/94637 (64%)] Step: [2617654] | Lr: 0.000100 | Loss: 1.2291 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 41.86
24-04-04 16:59:53.167 - INFO: Train epoch 470: [64000/94637 (68%)] Step: [2617754] | Lr: 0.000100 | Loss: 1.7294 | MSE loss: 0.0004 | Bpp loss: 1.09 | Aux loss: 39.99
24-04-04 17:00:43.734 - INFO: Train epoch 470: [67200/94637 (71%)] Step: [2617854] | Lr: 0.000100 | Loss: 1.3777 | MSE loss: 0.0004 | Bpp loss: 0.78 | Aux loss: 44.55
24-04-04 17:01:34.305 - INFO: Train epoch 470: [70400/94637 (74%)] Step: [2617954] | Lr: 0.000100 | Loss: 1.4791 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 41.70
24-04-04 17:02:25.588 - INFO: Train epoch 470: [73600/94637 (78%)] Step: [2618054] | Lr: 0.000100 | Loss: 1.6566 | MSE loss: 0.0004 | Bpp loss: 1.07 | Aux loss: 45.12
24-04-04 17:03:16.277 - INFO: Train epoch 470: [76800/94637 (81%)] Step: [2618154] | Lr: 0.000100 | Loss: 1.1810 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 42.39
24-04-04 17:04:07.342 - INFO: Train epoch 470: [80000/94637 (85%)] Step: [2618254] | Lr: 0.000100 | Loss: 0.6617 | MSE loss: 0.0001 | Bpp loss: 0.44 | Aux loss: 42.31
24-04-04 17:04:58.482 - INFO: Train epoch 470: [83200/94637 (88%)] Step: [2618354] | Lr: 0.000100 | Loss: 1.2040 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 40.69
24-04-04 17:05:49.525 - INFO: Train epoch 470: [86400/94637 (91%)] Step: [2618454] | Lr: 0.000100 | Loss: 1.0549 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 39.36
24-04-04 17:06:40.485 - INFO: Train epoch 470: [89600/94637 (95%)] Step: [2618554] | Lr: 0.000100 | Loss: 1.5490 | MSE loss: 0.0003 | Bpp loss: 1.03 | Aux loss: 45.70
24-04-04 17:07:32.028 - INFO: Train epoch 470: [92800/94637 (98%)] Step: [2618654] | Lr: 0.000100 | Loss: 1.1946 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 42.44
24-04-04 17:08:12.570 - INFO: Learning rate: 0.0001
24-04-04 17:08:13.850 - INFO: Train epoch 471: [    0/94637 (0%)] Step: [2618711] | Lr: 0.000100 | Loss: 1.2479 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 40.55
24-04-04 17:09:04.733 - INFO: Train epoch 471: [ 3200/94637 (3%)] Step: [2618811] | Lr: 0.000100 | Loss: 1.1344 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 41.48
24-04-04 17:09:55.871 - INFO: Train epoch 471: [ 6400/94637 (7%)] Step: [2618911] | Lr: 0.000100 | Loss: 1.0047 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 40.50
24-04-04 17:10:47.431 - INFO: Train epoch 471: [ 9600/94637 (10%)] Step: [2619011] | Lr: 0.000100 | Loss: 1.3135 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 45.19
24-04-04 17:11:38.940 - INFO: Train epoch 471: [12800/94637 (14%)] Step: [2619111] | Lr: 0.000100 | Loss: 0.9727 | MSE loss: 0.0003 | Bpp loss: 0.53 | Aux loss: 45.07
24-04-04 17:12:30.706 - INFO: Train epoch 471: [16000/94637 (17%)] Step: [2619211] | Lr: 0.000100 | Loss: 1.0930 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 44.18
24-04-04 17:13:22.159 - INFO: Train epoch 471: [19200/94637 (20%)] Step: [2619311] | Lr: 0.000100 | Loss: 1.1763 | MSE loss: 0.0002 | Bpp loss: 0.79 | Aux loss: 46.58
24-04-04 17:14:12.535 - INFO: Train epoch 471: [22400/94637 (24%)] Step: [2619411] | Lr: 0.000100 | Loss: 1.3637 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 38.58
24-04-04 17:15:02.664 - INFO: Train epoch 471: [25600/94637 (27%)] Step: [2619511] | Lr: 0.000100 | Loss: 1.2854 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 41.16
24-04-04 17:15:52.883 - INFO: Train epoch 471: [28800/94637 (30%)] Step: [2619611] | Lr: 0.000100 | Loss: 1.0187 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 43.44
24-04-04 17:16:43.435 - INFO: Train epoch 471: [32000/94637 (34%)] Step: [2619711] | Lr: 0.000100 | Loss: 1.2493 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 42.35
24-04-04 17:17:34.368 - INFO: Train epoch 471: [35200/94637 (37%)] Step: [2619811] | Lr: 0.000100 | Loss: 1.0962 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 43.84
24-04-04 17:18:25.195 - INFO: Train epoch 471: [38400/94637 (41%)] Step: [2619911] | Lr: 0.000100 | Loss: 1.1203 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 40.16
24-04-04 17:19:18.034 - INFO: Train epoch 471: [41600/94637 (44%)] Step: [2620011] | Lr: 0.000100 | Loss: 1.4640 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 41.49
24-04-04 17:20:09.799 - INFO: Train epoch 471: [44800/94637 (47%)] Step: [2620111] | Lr: 0.000100 | Loss: 1.0613 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 44.65
24-04-04 17:21:01.285 - INFO: Train epoch 471: [48000/94637 (51%)] Step: [2620211] | Lr: 0.000100 | Loss: 1.3531 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 39.97
24-04-04 17:21:52.599 - INFO: Train epoch 471: [51200/94637 (54%)] Step: [2620311] | Lr: 0.000100 | Loss: 1.0748 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 42.93
24-04-04 17:22:43.447 - INFO: Train epoch 471: [54400/94637 (57%)] Step: [2620411] | Lr: 0.000100 | Loss: 1.2961 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 42.54
24-04-04 17:23:35.433 - INFO: Train epoch 471: [57600/94637 (61%)] Step: [2620511] | Lr: 0.000100 | Loss: 1.1767 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 39.90
24-04-04 17:24:26.927 - INFO: Train epoch 471: [60800/94637 (64%)] Step: [2620611] | Lr: 0.000100 | Loss: 1.2428 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 38.58
24-04-04 17:25:17.707 - INFO: Train epoch 471: [64000/94637 (68%)] Step: [2620711] | Lr: 0.000100 | Loss: 1.0150 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 42.46
24-04-04 17:26:08.531 - INFO: Train epoch 471: [67200/94637 (71%)] Step: [2620811] | Lr: 0.000100 | Loss: 1.3313 | MSE loss: 0.0004 | Bpp loss: 0.76 | Aux loss: 43.52
24-04-04 17:26:59.037 - INFO: Train epoch 471: [70400/94637 (74%)] Step: [2620911] | Lr: 0.000100 | Loss: 1.5261 | MSE loss: 0.0003 | Bpp loss: 0.97 | Aux loss: 39.13
24-04-04 17:27:50.688 - INFO: Train epoch 471: [73600/94637 (78%)] Step: [2621011] | Lr: 0.000100 | Loss: 1.3756 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 43.54
24-04-04 17:28:41.891 - INFO: Train epoch 471: [76800/94637 (81%)] Step: [2621111] | Lr: 0.000100 | Loss: 1.1361 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 43.11
24-04-04 17:29:33.313 - INFO: Train epoch 471: [80000/94637 (85%)] Step: [2621211] | Lr: 0.000100 | Loss: 1.4142 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 43.22
24-04-04 17:30:25.262 - INFO: Train epoch 471: [83200/94637 (88%)] Step: [2621311] | Lr: 0.000100 | Loss: 0.8622 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 42.75
24-04-04 17:31:16.648 - INFO: Train epoch 471: [86400/94637 (91%)] Step: [2621411] | Lr: 0.000100 | Loss: 1.2641 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 39.09
24-04-04 17:32:08.196 - INFO: Train epoch 471: [89600/94637 (95%)] Step: [2621511] | Lr: 0.000100 | Loss: 0.8407 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 43.09
24-04-04 17:33:00.036 - INFO: Train epoch 471: [92800/94637 (98%)] Step: [2621611] | Lr: 0.000100 | Loss: 1.2653 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 40.09
24-04-04 17:33:40.963 - INFO: Learning rate: 0.0001
24-04-04 17:33:42.228 - INFO: Train epoch 472: [    0/94637 (0%)] Step: [2621668] | Lr: 0.000100 | Loss: 1.2886 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 40.06
24-04-04 17:34:32.838 - INFO: Train epoch 472: [ 3200/94637 (3%)] Step: [2621768] | Lr: 0.000100 | Loss: 1.7714 | MSE loss: 0.0004 | Bpp loss: 1.12 | Aux loss: 38.09
24-04-04 17:35:24.106 - INFO: Train epoch 472: [ 6400/94637 (7%)] Step: [2621868] | Lr: 0.000100 | Loss: 1.0109 | MSE loss: 0.0003 | Bpp loss: 0.60 | Aux loss: 42.39
24-04-04 17:36:14.861 - INFO: Train epoch 472: [ 9600/94637 (10%)] Step: [2621968] | Lr: 0.000100 | Loss: 1.3748 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 38.76
24-04-04 17:37:04.817 - INFO: Train epoch 472: [12800/94637 (14%)] Step: [2622068] | Lr: 0.000100 | Loss: 0.9671 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 42.54
24-04-04 17:37:56.227 - INFO: Train epoch 472: [16000/94637 (17%)] Step: [2622168] | Lr: 0.000100 | Loss: 1.2948 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 45.89
24-04-04 17:38:47.303 - INFO: Train epoch 472: [19200/94637 (20%)] Step: [2622268] | Lr: 0.000100 | Loss: 1.0897 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 39.76
24-04-04 17:39:38.801 - INFO: Train epoch 472: [22400/94637 (24%)] Step: [2622368] | Lr: 0.000100 | Loss: 1.2348 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 41.68
24-04-04 17:40:29.761 - INFO: Train epoch 472: [25600/94637 (27%)] Step: [2622468] | Lr: 0.000100 | Loss: 0.9823 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 42.32
24-04-04 17:41:22.786 - INFO: Train epoch 472: [28800/94637 (30%)] Step: [2622568] | Lr: 0.000100 | Loss: 1.1461 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 42.81
24-04-04 17:42:13.171 - INFO: Train epoch 472: [32000/94637 (34%)] Step: [2622668] | Lr: 0.000100 | Loss: 0.9039 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 40.63
24-04-04 17:43:03.816 - INFO: Train epoch 472: [35200/94637 (37%)] Step: [2622768] | Lr: 0.000100 | Loss: 0.9611 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 44.74
24-04-04 17:43:54.407 - INFO: Train epoch 472: [38400/94637 (41%)] Step: [2622868] | Lr: 0.000100 | Loss: 1.0764 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 41.16
24-04-04 17:44:44.637 - INFO: Train epoch 472: [41600/94637 (44%)] Step: [2622968] | Lr: 0.000100 | Loss: 1.2356 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 42.68
24-04-04 17:45:34.261 - INFO: Train epoch 472: [44800/94637 (47%)] Step: [2623068] | Lr: 0.000100 | Loss: 1.4303 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 44.35
24-04-04 17:46:25.005 - INFO: Train epoch 472: [48000/94637 (51%)] Step: [2623168] | Lr: 0.000100 | Loss: 1.2213 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 41.46
24-04-04 17:47:16.294 - INFO: Train epoch 472: [51200/94637 (54%)] Step: [2623268] | Lr: 0.000100 | Loss: 1.6299 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 40.86
24-04-04 17:48:07.276 - INFO: Train epoch 472: [54400/94637 (57%)] Step: [2623368] | Lr: 0.000100 | Loss: 1.1878 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 44.42
24-04-04 17:48:58.066 - INFO: Train epoch 472: [57600/94637 (61%)] Step: [2623468] | Lr: 0.000100 | Loss: 0.9685 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 46.07
24-04-04 17:49:49.607 - INFO: Train epoch 472: [60800/94637 (64%)] Step: [2623568] | Lr: 0.000100 | Loss: 0.9525 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 44.81
24-04-04 17:50:40.964 - INFO: Train epoch 472: [64000/94637 (68%)] Step: [2623668] | Lr: 0.000100 | Loss: 1.3521 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 43.65
24-04-04 17:51:32.089 - INFO: Train epoch 472: [67200/94637 (71%)] Step: [2623768] | Lr: 0.000100 | Loss: 1.0823 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 43.38
24-04-04 17:52:23.291 - INFO: Train epoch 472: [70400/94637 (74%)] Step: [2623868] | Lr: 0.000100 | Loss: 1.2066 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 40.10
24-04-04 17:53:13.981 - INFO: Train epoch 472: [73600/94637 (78%)] Step: [2623968] | Lr: 0.000100 | Loss: 0.9908 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 43.83
24-04-04 17:54:04.975 - INFO: Train epoch 472: [76800/94637 (81%)] Step: [2624068] | Lr: 0.000100 | Loss: 1.1257 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 43.97
24-04-04 17:54:55.747 - INFO: Train epoch 472: [80000/94637 (85%)] Step: [2624168] | Lr: 0.000100 | Loss: 1.4505 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 43.58
24-04-04 17:55:46.173 - INFO: Train epoch 472: [83200/94637 (88%)] Step: [2624268] | Lr: 0.000100 | Loss: 1.1186 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 47.38
24-04-04 17:56:36.787 - INFO: Train epoch 472: [86400/94637 (91%)] Step: [2624368] | Lr: 0.000100 | Loss: 1.1082 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 42.93
24-04-04 17:57:28.260 - INFO: Train epoch 472: [89600/94637 (95%)] Step: [2624468] | Lr: 0.000100 | Loss: 1.7202 | MSE loss: 0.0004 | Bpp loss: 1.03 | Aux loss: 44.60
24-04-04 17:58:18.976 - INFO: Train epoch 472: [92800/94637 (98%)] Step: [2624568] | Lr: 0.000100 | Loss: 1.7162 | MSE loss: 0.0004 | Bpp loss: 1.06 | Aux loss: 44.10
24-04-04 17:58:59.587 - INFO: Learning rate: 0.0001
24-04-04 17:59:01.273 - INFO: Train epoch 473: [    0/94637 (0%)] Step: [2624625] | Lr: 0.000100 | Loss: 1.1087 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 43.34
24-04-04 17:59:50.990 - INFO: Train epoch 473: [ 3200/94637 (3%)] Step: [2624725] | Lr: 0.000100 | Loss: 1.2726 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 43.52
24-04-04 18:00:41.964 - INFO: Train epoch 473: [ 6400/94637 (7%)] Step: [2624825] | Lr: 0.000100 | Loss: 1.1550 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 43.24
24-04-04 18:01:33.142 - INFO: Train epoch 473: [ 9600/94637 (10%)] Step: [2624925] | Lr: 0.000100 | Loss: 1.0552 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 44.10
24-04-04 18:02:25.878 - INFO: Train epoch 473: [12800/94637 (14%)] Step: [2625025] | Lr: 0.000100 | Loss: 1.0709 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 42.71
24-04-04 18:03:17.345 - INFO: Train epoch 473: [16000/94637 (17%)] Step: [2625125] | Lr: 0.000100 | Loss: 1.2026 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 45.03
24-04-04 18:04:08.937 - INFO: Train epoch 473: [19200/94637 (20%)] Step: [2625225] | Lr: 0.000100 | Loss: 1.4734 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 43.88
24-04-04 18:05:01.098 - INFO: Train epoch 473: [22400/94637 (24%)] Step: [2625325] | Lr: 0.000100 | Loss: 1.4196 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 41.67
24-04-04 18:05:52.549 - INFO: Train epoch 473: [25600/94637 (27%)] Step: [2625425] | Lr: 0.000100 | Loss: 0.9747 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 43.36
24-04-04 18:06:43.716 - INFO: Train epoch 473: [28800/94637 (30%)] Step: [2625525] | Lr: 0.000100 | Loss: 1.1619 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 43.15
24-04-04 18:07:35.095 - INFO: Train epoch 473: [32000/94637 (34%)] Step: [2625625] | Lr: 0.000100 | Loss: 1.2815 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 51.35
24-04-04 18:08:25.959 - INFO: Train epoch 473: [35200/94637 (37%)] Step: [2625725] | Lr: 0.000100 | Loss: 1.1133 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 44.60
24-04-04 18:09:17.567 - INFO: Train epoch 473: [38400/94637 (41%)] Step: [2625825] | Lr: 0.000100 | Loss: 1.4089 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 43.44
24-04-04 18:10:08.961 - INFO: Train epoch 473: [41600/94637 (44%)] Step: [2625925] | Lr: 0.000100 | Loss: 1.5891 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 38.93
24-04-04 18:11:00.404 - INFO: Train epoch 473: [44800/94637 (47%)] Step: [2626025] | Lr: 0.000100 | Loss: 1.4260 | MSE loss: 0.0004 | Bpp loss: 0.79 | Aux loss: 39.02
24-04-04 18:11:51.984 - INFO: Train epoch 473: [48000/94637 (51%)] Step: [2626125] | Lr: 0.000100 | Loss: 1.4885 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 39.99
24-04-04 18:12:42.765 - INFO: Train epoch 473: [51200/94637 (54%)] Step: [2626225] | Lr: 0.000100 | Loss: 1.4579 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 40.30
24-04-04 18:13:33.670 - INFO: Train epoch 473: [54400/94637 (57%)] Step: [2626325] | Lr: 0.000100 | Loss: 1.0210 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 40.19
24-04-04 18:14:24.235 - INFO: Train epoch 473: [57600/94637 (61%)] Step: [2626425] | Lr: 0.000100 | Loss: 1.3909 | MSE loss: 0.0004 | Bpp loss: 0.78 | Aux loss: 43.87
24-04-04 18:15:15.672 - INFO: Train epoch 473: [60800/94637 (64%)] Step: [2626525] | Lr: 0.000100 | Loss: 1.6445 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 40.53
24-04-04 18:16:06.755 - INFO: Train epoch 473: [64000/94637 (68%)] Step: [2626625] | Lr: 0.000100 | Loss: 1.1813 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 39.62
24-04-04 18:16:58.077 - INFO: Train epoch 473: [67200/94637 (71%)] Step: [2626725] | Lr: 0.000100 | Loss: 1.2434 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 43.23
24-04-04 18:17:49.338 - INFO: Train epoch 473: [70400/94637 (74%)] Step: [2626825] | Lr: 0.000100 | Loss: 1.3125 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 40.47
24-04-04 18:18:40.391 - INFO: Train epoch 473: [73600/94637 (78%)] Step: [2626925] | Lr: 0.000100 | Loss: 1.3320 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 37.28
24-04-04 18:19:31.690 - INFO: Train epoch 473: [76800/94637 (81%)] Step: [2627025] | Lr: 0.000100 | Loss: 1.0637 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 40.34
24-04-04 18:20:22.738 - INFO: Train epoch 473: [80000/94637 (85%)] Step: [2627125] | Lr: 0.000100 | Loss: 1.6438 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 42.07
24-04-04 18:21:14.212 - INFO: Train epoch 473: [83200/94637 (88%)] Step: [2627225] | Lr: 0.000100 | Loss: 1.0327 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 44.62
24-04-04 18:22:04.927 - INFO: Train epoch 473: [86400/94637 (91%)] Step: [2627325] | Lr: 0.000100 | Loss: 1.0494 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 46.32
24-04-04 18:22:56.704 - INFO: Train epoch 473: [89600/94637 (95%)] Step: [2627425] | Lr: 0.000100 | Loss: 0.8225 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 40.41
24-04-04 18:23:49.585 - INFO: Train epoch 473: [92800/94637 (98%)] Step: [2627525] | Lr: 0.000100 | Loss: 1.1220 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 41.83
24-04-04 18:24:30.035 - INFO: Learning rate: 0.0001
24-04-04 18:24:31.251 - INFO: Train epoch 474: [    0/94637 (0%)] Step: [2627582] | Lr: 0.000100 | Loss: 1.1859 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 41.70
24-04-04 18:25:22.421 - INFO: Train epoch 474: [ 3200/94637 (3%)] Step: [2627682] | Lr: 0.000100 | Loss: 1.0356 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 43.08
24-04-04 18:26:12.925 - INFO: Train epoch 474: [ 6400/94637 (7%)] Step: [2627782] | Lr: 0.000100 | Loss: 1.0221 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 41.23
24-04-04 18:27:03.569 - INFO: Train epoch 474: [ 9600/94637 (10%)] Step: [2627882] | Lr: 0.000100 | Loss: 1.4848 | MSE loss: 0.0004 | Bpp loss: 0.84 | Aux loss: 41.79
24-04-04 18:27:54.697 - INFO: Train epoch 474: [12800/94637 (14%)] Step: [2627982] | Lr: 0.000100 | Loss: 1.5326 | MSE loss: 0.0003 | Bpp loss: 0.98 | Aux loss: 41.79
24-04-04 18:28:46.041 - INFO: Train epoch 474: [16000/94637 (17%)] Step: [2628082] | Lr: 0.000100 | Loss: 1.1084 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 41.67
24-04-04 18:29:37.987 - INFO: Train epoch 474: [19200/94637 (20%)] Step: [2628182] | Lr: 0.000100 | Loss: 0.8368 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 41.65
24-04-04 18:30:29.142 - INFO: Train epoch 474: [22400/94637 (24%)] Step: [2628282] | Lr: 0.000100 | Loss: 0.9951 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 38.50
24-04-04 18:31:19.869 - INFO: Train epoch 474: [25600/94637 (27%)] Step: [2628382] | Lr: 0.000100 | Loss: 1.0988 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 41.58
24-04-04 18:32:10.454 - INFO: Train epoch 474: [28800/94637 (30%)] Step: [2628482] | Lr: 0.000100 | Loss: 1.1396 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 42.65
24-04-04 18:33:02.403 - INFO: Train epoch 474: [32000/94637 (34%)] Step: [2628582] | Lr: 0.000100 | Loss: 0.8322 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 40.75
24-04-04 18:33:53.939 - INFO: Train epoch 474: [35200/94637 (37%)] Step: [2628682] | Lr: 0.000100 | Loss: 1.7637 | MSE loss: 0.0004 | Bpp loss: 1.09 | Aux loss: 42.79
24-04-04 18:34:45.077 - INFO: Train epoch 474: [38400/94637 (41%)] Step: [2628782] | Lr: 0.000100 | Loss: 1.0200 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 40.87
24-04-04 18:35:37.058 - INFO: Train epoch 474: [41600/94637 (44%)] Step: [2628882] | Lr: 0.000100 | Loss: 1.2332 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 39.46
24-04-04 18:36:28.781 - INFO: Train epoch 474: [44800/94637 (47%)] Step: [2628982] | Lr: 0.000100 | Loss: 0.6363 | MSE loss: 0.0001 | Bpp loss: 0.44 | Aux loss: 42.54
24-04-04 18:37:20.314 - INFO: Train epoch 474: [48000/94637 (51%)] Step: [2629082] | Lr: 0.000100 | Loss: 1.5004 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 41.85
24-04-04 18:38:11.181 - INFO: Train epoch 474: [51200/94637 (54%)] Step: [2629182] | Lr: 0.000100 | Loss: 0.9332 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 42.13
24-04-04 18:39:02.061 - INFO: Train epoch 474: [54400/94637 (57%)] Step: [2629282] | Lr: 0.000100 | Loss: 1.2980 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 42.57
24-04-04 18:39:53.249 - INFO: Train epoch 474: [57600/94637 (61%)] Step: [2629382] | Lr: 0.000100 | Loss: 1.3575 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 43.82
24-04-04 18:40:44.778 - INFO: Train epoch 474: [60800/94637 (64%)] Step: [2629482] | Lr: 0.000100 | Loss: 0.9137 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 42.94
24-04-04 18:41:37.087 - INFO: Train epoch 474: [64000/94637 (68%)] Step: [2629582] | Lr: 0.000100 | Loss: 1.5489 | MSE loss: 0.0003 | Bpp loss: 0.99 | Aux loss: 38.62
24-04-04 18:42:27.974 - INFO: Train epoch 474: [67200/94637 (71%)] Step: [2629682] | Lr: 0.000100 | Loss: 0.7672 | MSE loss: 0.0002 | Bpp loss: 0.48 | Aux loss: 41.02
24-04-04 18:43:23.588 - INFO: Train epoch 474: [70400/94637 (74%)] Step: [2629782] | Lr: 0.000100 | Loss: 1.3780 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 41.93
24-04-04 18:44:14.487 - INFO: Train epoch 474: [73600/94637 (78%)] Step: [2629882] | Lr: 0.000100 | Loss: 0.9816 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 43.06
24-04-04 18:45:05.273 - INFO: Train epoch 474: [76800/94637 (81%)] Step: [2629982] | Lr: 0.000100 | Loss: 1.4353 | MSE loss: 0.0004 | Bpp loss: 0.78 | Aux loss: 43.72
24-04-04 18:45:58.034 - INFO: Train epoch 474: [80000/94637 (85%)] Step: [2630082] | Lr: 0.000100 | Loss: 1.3074 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 40.31
24-04-04 18:46:49.605 - INFO: Train epoch 474: [83200/94637 (88%)] Step: [2630182] | Lr: 0.000100 | Loss: 1.0109 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 41.89
24-04-04 18:47:40.576 - INFO: Train epoch 474: [86400/94637 (91%)] Step: [2630282] | Lr: 0.000100 | Loss: 1.0925 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 43.37
24-04-04 18:48:31.490 - INFO: Train epoch 474: [89600/94637 (95%)] Step: [2630382] | Lr: 0.000100 | Loss: 1.2090 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 44.17
24-04-04 18:49:23.814 - INFO: Train epoch 474: [92800/94637 (98%)] Step: [2630482] | Lr: 0.000100 | Loss: 1.0598 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 39.94
24-04-04 18:50:04.469 - INFO: Learning rate: 0.0001
24-04-04 18:50:05.607 - INFO: Train epoch 475: [    0/94637 (0%)] Step: [2630539] | Lr: 0.000100 | Loss: 1.1721 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 42.93
24-04-04 18:50:57.291 - INFO: Train epoch 475: [ 3200/94637 (3%)] Step: [2630639] | Lr: 0.000100 | Loss: 1.1108 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 41.85
24-04-04 18:51:48.895 - INFO: Train epoch 475: [ 6400/94637 (7%)] Step: [2630739] | Lr: 0.000100 | Loss: 1.3138 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 44.70
24-04-04 18:52:40.559 - INFO: Train epoch 475: [ 9600/94637 (10%)] Step: [2630839] | Lr: 0.000100 | Loss: 0.8787 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 43.84
24-04-04 18:53:32.036 - INFO: Train epoch 475: [12800/94637 (14%)] Step: [2630939] | Lr: 0.000100 | Loss: 0.8089 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 42.15
24-04-04 18:54:23.884 - INFO: Train epoch 475: [16000/94637 (17%)] Step: [2631039] | Lr: 0.000100 | Loss: 0.9389 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 40.03
24-04-04 18:55:15.471 - INFO: Train epoch 475: [19200/94637 (20%)] Step: [2631139] | Lr: 0.000100 | Loss: 1.0522 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 44.17
24-04-04 18:56:07.152 - INFO: Train epoch 475: [22400/94637 (24%)] Step: [2631239] | Lr: 0.000100 | Loss: 1.4391 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 43.61
24-04-04 18:56:58.412 - INFO: Train epoch 475: [25600/94637 (27%)] Step: [2631339] | Lr: 0.000100 | Loss: 0.8844 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 44.15
24-04-04 18:57:49.140 - INFO: Train epoch 475: [28800/94637 (30%)] Step: [2631439] | Lr: 0.000100 | Loss: 1.1667 | MSE loss: 0.0002 | Bpp loss: 0.76 | Aux loss: 43.40
24-04-04 18:58:39.861 - INFO: Train epoch 475: [32000/94637 (34%)] Step: [2631539] | Lr: 0.000100 | Loss: 0.8912 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 40.67
24-04-04 18:59:30.915 - INFO: Train epoch 475: [35200/94637 (37%)] Step: [2631639] | Lr: 0.000100 | Loss: 1.4264 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 44.74
24-04-04 19:00:22.345 - INFO: Train epoch 475: [38400/94637 (41%)] Step: [2631739] | Lr: 0.000100 | Loss: 1.3197 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 41.29
24-04-04 19:01:13.627 - INFO: Train epoch 475: [41600/94637 (44%)] Step: [2631839] | Lr: 0.000100 | Loss: 1.1827 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 43.10
24-04-04 19:02:04.591 - INFO: Train epoch 475: [44800/94637 (47%)] Step: [2631939] | Lr: 0.000100 | Loss: 1.1550 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 42.63
24-04-04 19:02:56.110 - INFO: Train epoch 475: [48000/94637 (51%)] Step: [2632039] | Lr: 0.000100 | Loss: 1.0734 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 42.01
24-04-04 19:03:47.546 - INFO: Train epoch 475: [51200/94637 (54%)] Step: [2632139] | Lr: 0.000100 | Loss: 1.8243 | MSE loss: 0.0004 | Bpp loss: 1.15 | Aux loss: 41.59
24-04-04 19:04:39.339 - INFO: Train epoch 475: [54400/94637 (57%)] Step: [2632239] | Lr: 0.000100 | Loss: 1.1421 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 42.13
24-04-04 19:05:30.880 - INFO: Train epoch 475: [57600/94637 (61%)] Step: [2632339] | Lr: 0.000100 | Loss: 1.0658 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 44.47
24-04-04 19:06:22.544 - INFO: Train epoch 475: [60800/94637 (64%)] Step: [2632439] | Lr: 0.000100 | Loss: 1.1054 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 41.41
24-04-04 19:07:16.610 - INFO: Train epoch 475: [64000/94637 (68%)] Step: [2632539] | Lr: 0.000100 | Loss: 1.3809 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 43.54
24-04-04 19:08:08.502 - INFO: Train epoch 475: [67200/94637 (71%)] Step: [2632639] | Lr: 0.000100 | Loss: 1.1083 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 43.34
24-04-04 19:08:59.868 - INFO: Train epoch 475: [70400/94637 (74%)] Step: [2632739] | Lr: 0.000100 | Loss: 1.0896 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 45.83
24-04-04 19:09:51.211 - INFO: Train epoch 475: [73600/94637 (78%)] Step: [2632839] | Lr: 0.000100 | Loss: 1.7259 | MSE loss: 0.0005 | Bpp loss: 0.98 | Aux loss: 40.35
24-04-04 19:10:42.476 - INFO: Train epoch 475: [76800/94637 (81%)] Step: [2632939] | Lr: 0.000100 | Loss: 0.9172 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 42.53
24-04-04 19:11:34.067 - INFO: Train epoch 475: [80000/94637 (85%)] Step: [2633039] | Lr: 0.000100 | Loss: 1.4251 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 42.41
24-04-04 19:12:25.784 - INFO: Train epoch 475: [83200/94637 (88%)] Step: [2633139] | Lr: 0.000100 | Loss: 1.4173 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 43.81
24-04-04 19:13:17.664 - INFO: Train epoch 475: [86400/94637 (91%)] Step: [2633239] | Lr: 0.000100 | Loss: 1.3254 | MSE loss: 0.0004 | Bpp loss: 0.75 | Aux loss: 40.65
24-04-04 19:14:09.094 - INFO: Train epoch 475: [89600/94637 (95%)] Step: [2633339] | Lr: 0.000100 | Loss: 1.2663 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 42.34
24-04-04 19:15:00.141 - INFO: Train epoch 475: [92800/94637 (98%)] Step: [2633439] | Lr: 0.000100 | Loss: 0.9122 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 43.89
24-04-04 19:15:40.352 - INFO: Learning rate: 0.0001
24-04-04 19:15:41.631 - INFO: Train epoch 476: [    0/94637 (0%)] Step: [2633496] | Lr: 0.000100 | Loss: 1.6462 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 43.90
24-04-04 19:16:32.403 - INFO: Train epoch 476: [ 3200/94637 (3%)] Step: [2633596] | Lr: 0.000100 | Loss: 1.2824 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 45.85
24-04-04 19:17:22.460 - INFO: Train epoch 476: [ 6400/94637 (7%)] Step: [2633696] | Lr: 0.000100 | Loss: 1.5954 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 40.48
24-04-04 19:18:12.883 - INFO: Train epoch 476: [ 9600/94637 (10%)] Step: [2633796] | Lr: 0.000100 | Loss: 1.1907 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 42.45
24-04-04 19:19:03.324 - INFO: Train epoch 476: [12800/94637 (14%)] Step: [2633896] | Lr: 0.000100 | Loss: 1.4647 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 42.97
24-04-04 19:19:53.844 - INFO: Train epoch 476: [16000/94637 (17%)] Step: [2633996] | Lr: 0.000100 | Loss: 1.0970 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 40.63
24-04-04 19:20:44.680 - INFO: Train epoch 476: [19200/94637 (20%)] Step: [2634096] | Lr: 0.000100 | Loss: 0.9431 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 39.55
24-04-04 19:21:35.221 - INFO: Train epoch 476: [22400/94637 (24%)] Step: [2634196] | Lr: 0.000100 | Loss: 0.9521 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 40.32
24-04-04 19:22:25.879 - INFO: Train epoch 476: [25600/94637 (27%)] Step: [2634296] | Lr: 0.000100 | Loss: 1.0581 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 38.49
24-04-04 19:23:16.957 - INFO: Train epoch 476: [28800/94637 (30%)] Step: [2634396] | Lr: 0.000100 | Loss: 1.4217 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 45.35
24-04-04 19:24:07.952 - INFO: Train epoch 476: [32000/94637 (34%)] Step: [2634496] | Lr: 0.000100 | Loss: 1.3265 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 40.73
24-04-04 19:24:59.052 - INFO: Train epoch 476: [35200/94637 (37%)] Step: [2634596] | Lr: 0.000100 | Loss: 1.3908 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 41.06
24-04-04 19:25:50.163 - INFO: Train epoch 476: [38400/94637 (41%)] Step: [2634696] | Lr: 0.000100 | Loss: 1.1664 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 44.04
24-04-04 19:26:41.735 - INFO: Train epoch 476: [41600/94637 (44%)] Step: [2634796] | Lr: 0.000100 | Loss: 1.2186 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 39.83
24-04-04 19:27:32.897 - INFO: Train epoch 476: [44800/94637 (47%)] Step: [2634896] | Lr: 0.000100 | Loss: 1.0287 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 43.67
24-04-04 19:28:23.639 - INFO: Train epoch 476: [48000/94637 (51%)] Step: [2634996] | Lr: 0.000100 | Loss: 1.0128 | MSE loss: 0.0003 | Bpp loss: 0.58 | Aux loss: 42.27
24-04-04 19:29:15.924 - INFO: Train epoch 476: [51200/94637 (54%)] Step: [2635096] | Lr: 0.000100 | Loss: 1.3087 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 43.27
24-04-04 19:30:06.630 - INFO: Train epoch 476: [54400/94637 (57%)] Step: [2635196] | Lr: 0.000100 | Loss: 1.2570 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 43.22
24-04-04 19:30:57.958 - INFO: Train epoch 476: [57600/94637 (61%)] Step: [2635296] | Lr: 0.000100 | Loss: 1.5470 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 46.20
24-04-04 19:31:48.126 - INFO: Train epoch 476: [60800/94637 (64%)] Step: [2635396] | Lr: 0.000100 | Loss: 1.4623 | MSE loss: 0.0004 | Bpp loss: 0.85 | Aux loss: 43.19
24-04-04 19:32:38.850 - INFO: Train epoch 476: [64000/94637 (68%)] Step: [2635496] | Lr: 0.000100 | Loss: 1.0622 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 42.35
24-04-04 19:33:29.565 - INFO: Train epoch 476: [67200/94637 (71%)] Step: [2635596] | Lr: 0.000100 | Loss: 0.9736 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 37.68
24-04-04 19:34:20.135 - INFO: Train epoch 476: [70400/94637 (74%)] Step: [2635696] | Lr: 0.000100 | Loss: 1.2014 | MSE loss: 0.0002 | Bpp loss: 0.80 | Aux loss: 41.73
24-04-04 19:35:10.220 - INFO: Train epoch 476: [73600/94637 (78%)] Step: [2635796] | Lr: 0.000100 | Loss: 1.2879 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 43.16
24-04-04 19:36:00.508 - INFO: Train epoch 476: [76800/94637 (81%)] Step: [2635896] | Lr: 0.000100 | Loss: 1.2111 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 43.21
24-04-04 19:36:50.736 - INFO: Train epoch 476: [80000/94637 (85%)] Step: [2635996] | Lr: 0.000100 | Loss: 1.4348 | MSE loss: 0.0004 | Bpp loss: 0.81 | Aux loss: 45.01
24-04-04 19:37:41.092 - INFO: Train epoch 476: [83200/94637 (88%)] Step: [2636096] | Lr: 0.000100 | Loss: 1.3133 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 39.86
24-04-04 19:38:32.299 - INFO: Train epoch 476: [86400/94637 (91%)] Step: [2636196] | Lr: 0.000100 | Loss: 1.3565 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 41.70
24-04-04 19:39:23.149 - INFO: Train epoch 476: [89600/94637 (95%)] Step: [2636296] | Lr: 0.000100 | Loss: 1.2686 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 41.35
24-04-04 19:40:14.300 - INFO: Train epoch 476: [92800/94637 (98%)] Step: [2636396] | Lr: 0.000100 | Loss: 0.9005 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 43.28
24-04-04 19:41:00.119 - INFO: Learning rate: 0.0001
24-04-04 19:41:01.446 - INFO: Train epoch 477: [    0/94637 (0%)] Step: [2636453] | Lr: 0.000100 | Loss: 0.8315 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 40.99
24-04-04 19:41:51.055 - INFO: Train epoch 477: [ 3200/94637 (3%)] Step: [2636553] | Lr: 0.000100 | Loss: 0.9774 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 43.98
24-04-04 19:42:41.450 - INFO: Train epoch 477: [ 6400/94637 (7%)] Step: [2636653] | Lr: 0.000100 | Loss: 1.0749 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 41.44
24-04-04 19:43:31.673 - INFO: Train epoch 477: [ 9600/94637 (10%)] Step: [2636753] | Lr: 0.000100 | Loss: 0.9978 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 42.67
24-04-04 19:44:21.933 - INFO: Train epoch 477: [12800/94637 (14%)] Step: [2636853] | Lr: 0.000100 | Loss: 1.0915 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 40.28
24-04-04 19:45:13.279 - INFO: Train epoch 477: [16000/94637 (17%)] Step: [2636953] | Lr: 0.000100 | Loss: 1.1044 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 43.24
24-04-04 19:46:04.650 - INFO: Train epoch 477: [19200/94637 (20%)] Step: [2637053] | Lr: 0.000100 | Loss: 1.1812 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 40.88
24-04-04 19:46:55.738 - INFO: Train epoch 477: [22400/94637 (24%)] Step: [2637153] | Lr: 0.000100 | Loss: 1.6117 | MSE loss: 0.0004 | Bpp loss: 1.03 | Aux loss: 39.74
24-04-04 19:47:46.582 - INFO: Train epoch 477: [25600/94637 (27%)] Step: [2637253] | Lr: 0.000100 | Loss: 1.2914 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 39.58
24-04-04 19:48:37.781 - INFO: Train epoch 477: [28800/94637 (30%)] Step: [2637353] | Lr: 0.000100 | Loss: 1.4940 | MSE loss: 0.0003 | Bpp loss: 0.96 | Aux loss: 39.34
24-04-04 19:49:28.401 - INFO: Train epoch 477: [32000/94637 (34%)] Step: [2637453] | Lr: 0.000100 | Loss: 1.0023 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 40.79
24-04-04 19:50:21.495 - INFO: Train epoch 477: [35200/94637 (37%)] Step: [2637553] | Lr: 0.000100 | Loss: 1.5978 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 41.52
24-04-04 19:51:11.826 - INFO: Train epoch 477: [38400/94637 (41%)] Step: [2637653] | Lr: 0.000100 | Loss: 1.3713 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 39.81
24-04-04 19:52:03.714 - INFO: Train epoch 477: [41600/94637 (44%)] Step: [2637753] | Lr: 0.000100 | Loss: 1.0982 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 41.63
24-04-04 19:52:55.074 - INFO: Train epoch 477: [44800/94637 (47%)] Step: [2637853] | Lr: 0.000100 | Loss: 1.1529 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 41.57
24-04-04 19:53:46.313 - INFO: Train epoch 477: [48000/94637 (51%)] Step: [2637953] | Lr: 0.000100 | Loss: 1.1432 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 39.41
24-04-04 19:54:38.670 - INFO: Train epoch 477: [51200/94637 (54%)] Step: [2638053] | Lr: 0.000100 | Loss: 1.4709 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 44.27
24-04-04 19:55:30.000 - INFO: Train epoch 477: [54400/94637 (57%)] Step: [2638153] | Lr: 0.000100 | Loss: 1.2130 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 40.60
24-04-04 19:56:21.780 - INFO: Train epoch 477: [57600/94637 (61%)] Step: [2638253] | Lr: 0.000100 | Loss: 1.0782 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 40.69
24-04-04 19:57:12.213 - INFO: Train epoch 477: [60800/94637 (64%)] Step: [2638353] | Lr: 0.000100 | Loss: 1.3382 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 40.14
24-04-04 19:58:02.651 - INFO: Train epoch 477: [64000/94637 (68%)] Step: [2638453] | Lr: 0.000100 | Loss: 1.1485 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 41.55
24-04-04 19:58:52.310 - INFO: Train epoch 477: [67200/94637 (71%)] Step: [2638553] | Lr: 0.000100 | Loss: 1.0514 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 40.07
24-04-04 19:59:42.745 - INFO: Train epoch 477: [70400/94637 (74%)] Step: [2638653] | Lr: 0.000100 | Loss: 1.5265 | MSE loss: 0.0004 | Bpp loss: 0.93 | Aux loss: 45.08
24-04-04 20:00:33.430 - INFO: Train epoch 477: [73600/94637 (78%)] Step: [2638753] | Lr: 0.000100 | Loss: 1.0183 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 42.07
24-04-04 20:01:24.225 - INFO: Train epoch 477: [76800/94637 (81%)] Step: [2638853] | Lr: 0.000100 | Loss: 1.2090 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 39.35
24-04-04 20:02:16.139 - INFO: Train epoch 477: [80000/94637 (85%)] Step: [2638953] | Lr: 0.000100 | Loss: 0.9586 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 42.52
24-04-04 20:03:06.723 - INFO: Train epoch 477: [83200/94637 (88%)] Step: [2639053] | Lr: 0.000100 | Loss: 0.9488 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 44.80
24-04-04 20:03:58.143 - INFO: Train epoch 477: [86400/94637 (91%)] Step: [2639153] | Lr: 0.000100 | Loss: 1.0130 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 41.30
24-04-04 20:04:49.184 - INFO: Train epoch 477: [89600/94637 (95%)] Step: [2639253] | Lr: 0.000100 | Loss: 1.1869 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 42.21
24-04-04 20:05:40.616 - INFO: Train epoch 477: [92800/94637 (98%)] Step: [2639353] | Lr: 0.000100 | Loss: 0.9912 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 40.30
24-04-04 20:06:21.211 - INFO: Learning rate: 0.0001
24-04-04 20:06:22.958 - INFO: Train epoch 478: [    0/94637 (0%)] Step: [2639410] | Lr: 0.000100 | Loss: 1.0936 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 39.85
24-04-04 20:07:13.801 - INFO: Train epoch 478: [ 3200/94637 (3%)] Step: [2639510] | Lr: 0.000100 | Loss: 1.2407 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 45.01
24-04-04 20:08:04.621 - INFO: Train epoch 478: [ 6400/94637 (7%)] Step: [2639610] | Lr: 0.000100 | Loss: 1.7398 | MSE loss: 0.0004 | Bpp loss: 1.10 | Aux loss: 41.43
24-04-04 20:08:54.964 - INFO: Train epoch 478: [ 9600/94637 (10%)] Step: [2639710] | Lr: 0.000100 | Loss: 1.0082 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 42.67
24-04-04 20:09:45.889 - INFO: Train epoch 478: [12800/94637 (14%)] Step: [2639810] | Lr: 0.000100 | Loss: 1.1029 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 43.95
24-04-04 20:10:35.753 - INFO: Train epoch 478: [16000/94637 (17%)] Step: [2639910] | Lr: 0.000100 | Loss: 1.2844 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 39.67
24-04-04 20:11:28.526 - INFO: Train epoch 478: [19200/94637 (20%)] Step: [2640010] | Lr: 0.000100 | Loss: 1.1669 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 45.34
24-04-04 20:12:18.733 - INFO: Train epoch 478: [22400/94637 (24%)] Step: [2640110] | Lr: 0.000100 | Loss: 0.8458 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 42.05
24-04-04 20:13:09.788 - INFO: Train epoch 478: [25600/94637 (27%)] Step: [2640210] | Lr: 0.000100 | Loss: 1.0696 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 42.74
24-04-04 20:14:00.536 - INFO: Train epoch 478: [28800/94637 (30%)] Step: [2640310] | Lr: 0.000100 | Loss: 0.7548 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 40.94
24-04-04 20:14:51.627 - INFO: Train epoch 478: [32000/94637 (34%)] Step: [2640410] | Lr: 0.000100 | Loss: 1.2398 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 43.90
24-04-04 20:15:43.230 - INFO: Train epoch 478: [35200/94637 (37%)] Step: [2640510] | Lr: 0.000100 | Loss: 1.0515 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 40.71
24-04-04 20:16:33.981 - INFO: Train epoch 478: [38400/94637 (41%)] Step: [2640610] | Lr: 0.000100 | Loss: 0.8791 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 38.91
24-04-04 20:17:24.965 - INFO: Train epoch 478: [41600/94637 (44%)] Step: [2640710] | Lr: 0.000100 | Loss: 0.9300 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 42.50
24-04-04 20:18:15.412 - INFO: Train epoch 478: [44800/94637 (47%)] Step: [2640810] | Lr: 0.000100 | Loss: 1.2473 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 41.89
24-04-04 20:19:06.331 - INFO: Train epoch 478: [48000/94637 (51%)] Step: [2640910] | Lr: 0.000100 | Loss: 1.2775 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 41.66
24-04-04 20:19:56.904 - INFO: Train epoch 478: [51200/94637 (54%)] Step: [2641010] | Lr: 0.000100 | Loss: 0.9815 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 38.92
24-04-04 20:20:48.262 - INFO: Train epoch 478: [54400/94637 (57%)] Step: [2641110] | Lr: 0.000100 | Loss: 1.4029 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 43.78
24-04-04 20:21:38.711 - INFO: Train epoch 478: [57600/94637 (61%)] Step: [2641210] | Lr: 0.000100 | Loss: 1.3384 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 43.32
24-04-04 20:22:29.982 - INFO: Train epoch 478: [60800/94637 (64%)] Step: [2641310] | Lr: 0.000100 | Loss: 0.9761 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 41.29
24-04-04 20:23:21.203 - INFO: Train epoch 478: [64000/94637 (68%)] Step: [2641410] | Lr: 0.000100 | Loss: 1.1806 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 38.43
24-04-04 20:24:11.543 - INFO: Train epoch 478: [67200/94637 (71%)] Step: [2641510] | Lr: 0.000100 | Loss: 1.2594 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 42.27
24-04-04 20:25:02.555 - INFO: Train epoch 478: [70400/94637 (74%)] Step: [2641610] | Lr: 0.000100 | Loss: 1.0391 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 40.06
24-04-04 20:25:52.706 - INFO: Train epoch 478: [73600/94637 (78%)] Step: [2641710] | Lr: 0.000100 | Loss: 1.3692 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 39.36
24-04-04 20:26:43.157 - INFO: Train epoch 478: [76800/94637 (81%)] Step: [2641810] | Lr: 0.000100 | Loss: 0.9630 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 41.19
24-04-04 20:27:34.492 - INFO: Train epoch 478: [80000/94637 (85%)] Step: [2641910] | Lr: 0.000100 | Loss: 1.1888 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 41.65
24-04-04 20:28:25.484 - INFO: Train epoch 478: [83200/94637 (88%)] Step: [2642010] | Lr: 0.000100 | Loss: 1.5676 | MSE loss: 0.0004 | Bpp loss: 0.99 | Aux loss: 43.89
24-04-04 20:29:17.020 - INFO: Train epoch 478: [86400/94637 (91%)] Step: [2642110] | Lr: 0.000100 | Loss: 1.2950 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 42.51
24-04-04 20:30:08.225 - INFO: Train epoch 478: [89600/94637 (95%)] Step: [2642210] | Lr: 0.000100 | Loss: 1.2801 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 38.49
24-04-04 20:30:59.034 - INFO: Train epoch 478: [92800/94637 (98%)] Step: [2642310] | Lr: 0.000100 | Loss: 1.0593 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 43.87
24-04-04 20:31:39.325 - INFO: Learning rate: 0.0001
24-04-04 20:31:41.117 - INFO: Train epoch 479: [    0/94637 (0%)] Step: [2642367] | Lr: 0.000100 | Loss: 1.5310 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 38.48
24-04-04 20:32:32.358 - INFO: Train epoch 479: [ 3200/94637 (3%)] Step: [2642467] | Lr: 0.000100 | Loss: 1.4098 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 38.94
24-04-04 20:33:25.110 - INFO: Train epoch 479: [ 6400/94637 (7%)] Step: [2642567] | Lr: 0.000100 | Loss: 1.0089 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 39.12
24-04-04 20:34:16.135 - INFO: Train epoch 479: [ 9600/94637 (10%)] Step: [2642667] | Lr: 0.000100 | Loss: 1.3060 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 40.13
24-04-04 20:35:06.474 - INFO: Train epoch 479: [12800/94637 (14%)] Step: [2642767] | Lr: 0.000100 | Loss: 1.4373 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 40.64
24-04-04 20:35:57.609 - INFO: Train epoch 479: [16000/94637 (17%)] Step: [2642867] | Lr: 0.000100 | Loss: 1.0931 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 41.21
24-04-04 20:36:48.675 - INFO: Train epoch 479: [19200/94637 (20%)] Step: [2642967] | Lr: 0.000100 | Loss: 1.0827 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 38.14
24-04-04 20:37:40.021 - INFO: Train epoch 479: [22400/94637 (24%)] Step: [2643067] | Lr: 0.000100 | Loss: 1.0830 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 37.93
24-04-04 20:38:31.134 - INFO: Train epoch 479: [25600/94637 (27%)] Step: [2643167] | Lr: 0.000100 | Loss: 0.8489 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 40.53
24-04-04 20:39:22.982 - INFO: Train epoch 479: [28800/94637 (30%)] Step: [2643267] | Lr: 0.000100 | Loss: 1.0733 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 39.57
24-04-04 20:40:14.566 - INFO: Train epoch 479: [32000/94637 (34%)] Step: [2643367] | Lr: 0.000100 | Loss: 1.2812 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 40.69
24-04-04 20:41:05.659 - INFO: Train epoch 479: [35200/94637 (37%)] Step: [2643467] | Lr: 0.000100 | Loss: 1.0796 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 38.17
24-04-04 20:41:56.736 - INFO: Train epoch 479: [38400/94637 (41%)] Step: [2643567] | Lr: 0.000100 | Loss: 1.3825 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 38.53
24-04-04 20:42:47.741 - INFO: Train epoch 479: [41600/94637 (44%)] Step: [2643667] | Lr: 0.000100 | Loss: 1.3027 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 37.83
24-04-04 20:43:39.386 - INFO: Train epoch 479: [44800/94637 (47%)] Step: [2643767] | Lr: 0.000100 | Loss: 1.3084 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 42.65
24-04-04 20:44:30.148 - INFO: Train epoch 479: [48000/94637 (51%)] Step: [2643867] | Lr: 0.000100 | Loss: 1.3907 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 39.92
24-04-04 20:45:21.390 - INFO: Train epoch 479: [51200/94637 (54%)] Step: [2643967] | Lr: 0.000100 | Loss: 1.1197 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 39.67
24-04-04 20:46:12.195 - INFO: Train epoch 479: [54400/94637 (57%)] Step: [2644067] | Lr: 0.000100 | Loss: 1.4866 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 39.88
24-04-04 20:47:03.451 - INFO: Train epoch 479: [57600/94637 (61%)] Step: [2644167] | Lr: 0.000100 | Loss: 1.0030 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 37.77
24-04-04 20:47:54.424 - INFO: Train epoch 479: [60800/94637 (64%)] Step: [2644267] | Lr: 0.000100 | Loss: 1.2399 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 41.61
24-04-04 20:48:44.219 - INFO: Train epoch 479: [64000/94637 (68%)] Step: [2644367] | Lr: 0.000100 | Loss: 1.9016 | MSE loss: 0.0005 | Bpp loss: 1.06 | Aux loss: 42.43
24-04-04 20:49:35.042 - INFO: Train epoch 479: [67200/94637 (71%)] Step: [2644467] | Lr: 0.000100 | Loss: 1.3444 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 42.22
24-04-04 20:50:25.867 - INFO: Train epoch 479: [70400/94637 (74%)] Step: [2644567] | Lr: 0.000100 | Loss: 1.5426 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 38.80
24-04-04 20:51:17.372 - INFO: Train epoch 479: [73600/94637 (78%)] Step: [2644667] | Lr: 0.000100 | Loss: 1.1243 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 38.54
24-04-04 20:52:08.468 - INFO: Train epoch 479: [76800/94637 (81%)] Step: [2644767] | Lr: 0.000100 | Loss: 0.9769 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 40.73
24-04-04 20:52:59.717 - INFO: Train epoch 479: [80000/94637 (85%)] Step: [2644867] | Lr: 0.000100 | Loss: 1.3900 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 40.54
24-04-04 20:53:51.277 - INFO: Train epoch 479: [83200/94637 (88%)] Step: [2644967] | Lr: 0.000100 | Loss: 1.1638 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 41.95
24-04-04 20:54:44.184 - INFO: Train epoch 479: [86400/94637 (91%)] Step: [2645067] | Lr: 0.000100 | Loss: 1.0451 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 43.11
24-04-04 20:55:35.106 - INFO: Train epoch 479: [89600/94637 (95%)] Step: [2645167] | Lr: 0.000100 | Loss: 0.9476 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 38.80
24-04-04 20:56:25.496 - INFO: Train epoch 479: [92800/94637 (98%)] Step: [2645267] | Lr: 0.000100 | Loss: 0.9734 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 40.84
24-04-04 20:57:05.899 - INFO: Learning rate: 0.0001
24-04-04 20:57:07.082 - INFO: Train epoch 480: [    0/94637 (0%)] Step: [2645324] | Lr: 0.000100 | Loss: 1.2282 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 42.36
24-04-04 20:57:58.552 - INFO: Train epoch 480: [ 3200/94637 (3%)] Step: [2645424] | Lr: 0.000100 | Loss: 1.6561 | MSE loss: 0.0004 | Bpp loss: 1.06 | Aux loss: 38.74
24-04-04 20:58:49.438 - INFO: Train epoch 480: [ 6400/94637 (7%)] Step: [2645524] | Lr: 0.000100 | Loss: 1.1938 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 39.38
24-04-04 20:59:40.159 - INFO: Train epoch 480: [ 9600/94637 (10%)] Step: [2645624] | Lr: 0.000100 | Loss: 0.9492 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 42.39
24-04-04 21:00:31.222 - INFO: Train epoch 480: [12800/94637 (14%)] Step: [2645724] | Lr: 0.000100 | Loss: 1.4646 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 41.15
24-04-04 21:01:22.834 - INFO: Train epoch 480: [16000/94637 (17%)] Step: [2645824] | Lr: 0.000100 | Loss: 1.0362 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 39.28
24-04-04 21:02:14.042 - INFO: Train epoch 480: [19200/94637 (20%)] Step: [2645924] | Lr: 0.000100 | Loss: 1.3688 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 38.26
24-04-04 21:03:04.883 - INFO: Train epoch 480: [22400/94637 (24%)] Step: [2646024] | Lr: 0.000100 | Loss: 0.7556 | MSE loss: 0.0002 | Bpp loss: 0.47 | Aux loss: 42.85
24-04-04 21:03:56.082 - INFO: Train epoch 480: [25600/94637 (27%)] Step: [2646124] | Lr: 0.000100 | Loss: 1.1786 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 39.72
24-04-04 21:04:47.756 - INFO: Train epoch 480: [28800/94637 (30%)] Step: [2646224] | Lr: 0.000100 | Loss: 1.3357 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 44.33
24-04-04 21:05:38.677 - INFO: Train epoch 480: [32000/94637 (34%)] Step: [2646324] | Lr: 0.000100 | Loss: 1.3355 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 36.08
24-04-04 21:06:29.998 - INFO: Train epoch 480: [35200/94637 (37%)] Step: [2646424] | Lr: 0.000100 | Loss: 1.2702 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 37.35
24-04-04 21:07:21.342 - INFO: Train epoch 480: [38400/94637 (41%)] Step: [2646524] | Lr: 0.000100 | Loss: 1.0011 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 42.25
24-04-04 21:08:12.645 - INFO: Train epoch 480: [41600/94637 (44%)] Step: [2646624] | Lr: 0.000100 | Loss: 1.3343 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 41.72
24-04-04 21:09:03.633 - INFO: Train epoch 480: [44800/94637 (47%)] Step: [2646724] | Lr: 0.000100 | Loss: 1.0184 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 41.35
24-04-04 21:09:54.446 - INFO: Train epoch 480: [48000/94637 (51%)] Step: [2646824] | Lr: 0.000100 | Loss: 1.2394 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 39.25
24-04-04 21:10:45.204 - INFO: Train epoch 480: [51200/94637 (54%)] Step: [2646924] | Lr: 0.000100 | Loss: 1.3300 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 42.03
24-04-04 21:11:36.510 - INFO: Train epoch 480: [54400/94637 (57%)] Step: [2647024] | Lr: 0.000100 | Loss: 1.4072 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 42.30
24-04-04 21:12:28.250 - INFO: Train epoch 480: [57600/94637 (61%)] Step: [2647124] | Lr: 0.000100 | Loss: 1.4808 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 39.16
24-04-04 21:13:19.928 - INFO: Train epoch 480: [60800/94637 (64%)] Step: [2647224] | Lr: 0.000100 | Loss: 1.1171 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 42.78
24-04-04 21:14:10.823 - INFO: Train epoch 480: [64000/94637 (68%)] Step: [2647324] | Lr: 0.000100 | Loss: 1.3016 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 38.49
24-04-04 21:15:02.449 - INFO: Train epoch 480: [67200/94637 (71%)] Step: [2647424] | Lr: 0.000100 | Loss: 1.3083 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 41.10
24-04-04 21:15:56.256 - INFO: Train epoch 480: [70400/94637 (74%)] Step: [2647524] | Lr: 0.000100 | Loss: 1.1133 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 41.09
24-04-04 21:16:48.242 - INFO: Train epoch 480: [73600/94637 (78%)] Step: [2647624] | Lr: 0.000100 | Loss: 1.2406 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 38.03
24-04-04 21:17:40.088 - INFO: Train epoch 480: [76800/94637 (81%)] Step: [2647724] | Lr: 0.000100 | Loss: 1.5101 | MSE loss: 0.0004 | Bpp loss: 0.82 | Aux loss: 38.24
24-04-04 21:18:31.526 - INFO: Train epoch 480: [80000/94637 (85%)] Step: [2647824] | Lr: 0.000100 | Loss: 1.0680 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 40.49
24-04-04 21:19:22.987 - INFO: Train epoch 480: [83200/94637 (88%)] Step: [2647924] | Lr: 0.000100 | Loss: 1.3915 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 43.94
24-04-04 21:20:14.702 - INFO: Train epoch 480: [86400/94637 (91%)] Step: [2648024] | Lr: 0.000100 | Loss: 1.3455 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 40.47
24-04-04 21:21:06.914 - INFO: Train epoch 480: [89600/94637 (95%)] Step: [2648124] | Lr: 0.000100 | Loss: 1.4477 | MSE loss: 0.0004 | Bpp loss: 0.83 | Aux loss: 41.95
24-04-04 21:21:58.348 - INFO: Train epoch 480: [92800/94637 (98%)] Step: [2648224] | Lr: 0.000100 | Loss: 1.3775 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 37.72
24-04-04 21:22:44.783 - INFO: Learning rate: 0.0001
24-04-04 21:22:46.691 - INFO: Train epoch 481: [    0/94637 (0%)] Step: [2648281] | Lr: 0.000100 | Loss: 1.4643 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 40.35
24-04-04 21:23:37.939 - INFO: Train epoch 481: [ 3200/94637 (3%)] Step: [2648381] | Lr: 0.000100 | Loss: 1.1809 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 41.23
24-04-04 21:24:28.636 - INFO: Train epoch 481: [ 6400/94637 (7%)] Step: [2648481] | Lr: 0.000100 | Loss: 1.1976 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 42.96
24-04-04 21:25:19.767 - INFO: Train epoch 481: [ 9600/94637 (10%)] Step: [2648581] | Lr: 0.000100 | Loss: 1.6413 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 41.81
24-04-04 21:26:10.185 - INFO: Train epoch 481: [12800/94637 (14%)] Step: [2648681] | Lr: 0.000100 | Loss: 1.1892 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 43.15
24-04-04 21:27:00.282 - INFO: Train epoch 481: [16000/94637 (17%)] Step: [2648781] | Lr: 0.000100 | Loss: 0.9757 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 41.43
24-04-04 21:27:50.771 - INFO: Train epoch 481: [19200/94637 (20%)] Step: [2648881] | Lr: 0.000100 | Loss: 1.2027 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 39.76
24-04-04 21:28:40.803 - INFO: Train epoch 481: [22400/94637 (24%)] Step: [2648981] | Lr: 0.000100 | Loss: 1.2371 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 37.96
24-04-04 21:29:32.138 - INFO: Train epoch 481: [25600/94637 (27%)] Step: [2649081] | Lr: 0.000100 | Loss: 1.0580 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 43.05
24-04-04 21:30:21.913 - INFO: Train epoch 481: [28800/94637 (30%)] Step: [2649181] | Lr: 0.000100 | Loss: 1.0734 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 43.99
24-04-04 21:31:12.945 - INFO: Train epoch 481: [32000/94637 (34%)] Step: [2649281] | Lr: 0.000100 | Loss: 1.0733 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 42.68
24-04-04 21:32:03.842 - INFO: Train epoch 481: [35200/94637 (37%)] Step: [2649381] | Lr: 0.000100 | Loss: 1.2454 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 41.90
24-04-04 21:32:54.937 - INFO: Train epoch 481: [38400/94637 (41%)] Step: [2649481] | Lr: 0.000100 | Loss: 1.7534 | MSE loss: 0.0005 | Bpp loss: 0.97 | Aux loss: 40.15
24-04-04 21:33:46.277 - INFO: Train epoch 481: [41600/94637 (44%)] Step: [2649581] | Lr: 0.000100 | Loss: 1.0831 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 39.46
24-04-04 21:34:36.854 - INFO: Train epoch 481: [44800/94637 (47%)] Step: [2649681] | Lr: 0.000100 | Loss: 0.9257 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 42.71
24-04-04 21:35:28.135 - INFO: Train epoch 481: [48000/94637 (51%)] Step: [2649781] | Lr: 0.000100 | Loss: 1.3415 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 37.65
24-04-04 21:36:18.994 - INFO: Train epoch 481: [51200/94637 (54%)] Step: [2649881] | Lr: 0.000100 | Loss: 1.0160 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 42.39
24-04-04 21:37:09.618 - INFO: Train epoch 481: [54400/94637 (57%)] Step: [2649981] | Lr: 0.000100 | Loss: 1.2363 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 42.73
24-04-04 21:38:01.627 - INFO: Train epoch 481: [57600/94637 (61%)] Step: [2650081] | Lr: 0.000100 | Loss: 1.7646 | MSE loss: 0.0004 | Bpp loss: 1.12 | Aux loss: 41.84
24-04-04 21:38:52.234 - INFO: Train epoch 481: [60800/94637 (64%)] Step: [2650181] | Lr: 0.000100 | Loss: 1.2237 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 42.97
24-04-04 21:39:42.839 - INFO: Train epoch 481: [64000/94637 (68%)] Step: [2650281] | Lr: 0.000100 | Loss: 1.0344 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 40.33
24-04-04 21:40:33.083 - INFO: Train epoch 481: [67200/94637 (71%)] Step: [2650381] | Lr: 0.000100 | Loss: 1.2211 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 42.28
24-04-04 21:41:24.009 - INFO: Train epoch 481: [70400/94637 (74%)] Step: [2650481] | Lr: 0.000100 | Loss: 1.3017 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 39.00
24-04-04 21:42:15.699 - INFO: Train epoch 481: [73600/94637 (78%)] Step: [2650581] | Lr: 0.000100 | Loss: 1.3648 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 39.11
24-04-04 21:43:06.865 - INFO: Train epoch 481: [76800/94637 (81%)] Step: [2650681] | Lr: 0.000100 | Loss: 1.0096 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 40.13
24-04-04 21:43:57.272 - INFO: Train epoch 481: [80000/94637 (85%)] Step: [2650781] | Lr: 0.000100 | Loss: 1.0640 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 38.47
24-04-04 21:44:48.064 - INFO: Train epoch 481: [83200/94637 (88%)] Step: [2650881] | Lr: 0.000100 | Loss: 1.3106 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 41.15
24-04-04 21:45:39.568 - INFO: Train epoch 481: [86400/94637 (91%)] Step: [2650981] | Lr: 0.000100 | Loss: 1.0646 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 42.34
24-04-04 21:46:30.437 - INFO: Train epoch 481: [89600/94637 (95%)] Step: [2651081] | Lr: 0.000100 | Loss: 1.5030 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 40.92
24-04-04 21:47:21.675 - INFO: Train epoch 481: [92800/94637 (98%)] Step: [2651181] | Lr: 0.000100 | Loss: 1.1217 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 38.78
24-04-04 21:48:07.833 - INFO: Learning rate: 0.0001
24-04-04 21:48:09.074 - INFO: Train epoch 482: [    0/94637 (0%)] Step: [2651238] | Lr: 0.000100 | Loss: 1.2759 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 40.33
24-04-04 21:49:00.219 - INFO: Train epoch 482: [ 3200/94637 (3%)] Step: [2651338] | Lr: 0.000100 | Loss: 1.5729 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 39.67
24-04-04 21:49:51.356 - INFO: Train epoch 482: [ 6400/94637 (7%)] Step: [2651438] | Lr: 0.000100 | Loss: 1.4433 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 42.05
24-04-04 21:50:43.300 - INFO: Train epoch 482: [ 9600/94637 (10%)] Step: [2651538] | Lr: 0.000100 | Loss: 1.2193 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 41.66
24-04-04 21:51:34.515 - INFO: Train epoch 482: [12800/94637 (14%)] Step: [2651638] | Lr: 0.000100 | Loss: 1.2231 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 38.72
24-04-04 21:52:25.480 - INFO: Train epoch 482: [16000/94637 (17%)] Step: [2651738] | Lr: 0.000100 | Loss: 1.1508 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 37.27
24-04-04 21:53:16.114 - INFO: Train epoch 482: [19200/94637 (20%)] Step: [2651838] | Lr: 0.000100 | Loss: 1.1499 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 39.10
24-04-04 21:54:07.043 - INFO: Train epoch 482: [22400/94637 (24%)] Step: [2651938] | Lr: 0.000100 | Loss: 1.7124 | MSE loss: 0.0004 | Bpp loss: 1.08 | Aux loss: 38.21
24-04-04 21:54:57.600 - INFO: Train epoch 482: [25600/94637 (27%)] Step: [2652038] | Lr: 0.000100 | Loss: 1.0093 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 39.07
24-04-04 21:55:48.538 - INFO: Train epoch 482: [28800/94637 (30%)] Step: [2652138] | Lr: 0.000100 | Loss: 1.2192 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 45.40
24-04-04 21:56:39.454 - INFO: Train epoch 482: [32000/94637 (34%)] Step: [2652238] | Lr: 0.000100 | Loss: 1.4298 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 38.49
24-04-04 21:57:30.466 - INFO: Train epoch 482: [35200/94637 (37%)] Step: [2652338] | Lr: 0.000100 | Loss: 1.2527 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 40.08
24-04-04 21:58:21.975 - INFO: Train epoch 482: [38400/94637 (41%)] Step: [2652438] | Lr: 0.000100 | Loss: 1.0091 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 38.65
24-04-04 21:59:15.426 - INFO: Train epoch 482: [41600/94637 (44%)] Step: [2652538] | Lr: 0.000100 | Loss: 1.6536 | MSE loss: 0.0004 | Bpp loss: 1.03 | Aux loss: 41.77
24-04-04 22:00:06.709 - INFO: Train epoch 482: [44800/94637 (47%)] Step: [2652638] | Lr: 0.000100 | Loss: 1.8877 | MSE loss: 0.0005 | Bpp loss: 1.08 | Aux loss: 39.00
24-04-04 22:00:58.103 - INFO: Train epoch 482: [48000/94637 (51%)] Step: [2652738] | Lr: 0.000100 | Loss: 1.5133 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 40.79
24-04-04 22:01:49.726 - INFO: Train epoch 482: [51200/94637 (54%)] Step: [2652838] | Lr: 0.000100 | Loss: 1.3939 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 37.27
24-04-04 22:02:40.531 - INFO: Train epoch 482: [54400/94637 (57%)] Step: [2652938] | Lr: 0.000100 | Loss: 0.8902 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 40.07
24-04-04 22:03:31.214 - INFO: Train epoch 482: [57600/94637 (61%)] Step: [2653038] | Lr: 0.000100 | Loss: 1.3002 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 40.37
24-04-04 22:04:22.103 - INFO: Train epoch 482: [60800/94637 (64%)] Step: [2653138] | Lr: 0.000100 | Loss: 1.3436 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 38.94
24-04-04 22:05:12.776 - INFO: Train epoch 482: [64000/94637 (68%)] Step: [2653238] | Lr: 0.000100 | Loss: 1.1631 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 39.22
24-04-04 22:06:03.329 - INFO: Train epoch 482: [67200/94637 (71%)] Step: [2653338] | Lr: 0.000100 | Loss: 0.9480 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 41.26
24-04-04 22:06:53.917 - INFO: Train epoch 482: [70400/94637 (74%)] Step: [2653438] | Lr: 0.000100 | Loss: 1.2491 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 38.73
24-04-04 22:07:44.427 - INFO: Train epoch 482: [73600/94637 (78%)] Step: [2653538] | Lr: 0.000100 | Loss: 1.1885 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 39.55
24-04-04 22:08:35.252 - INFO: Train epoch 482: [76800/94637 (81%)] Step: [2653638] | Lr: 0.000100 | Loss: 1.0864 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 42.24
24-04-04 22:09:25.494 - INFO: Train epoch 482: [80000/94637 (85%)] Step: [2653738] | Lr: 0.000100 | Loss: 0.9776 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 39.80
24-04-04 22:10:15.875 - INFO: Train epoch 482: [83200/94637 (88%)] Step: [2653838] | Lr: 0.000100 | Loss: 1.2551 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 38.77
24-04-04 22:11:06.911 - INFO: Train epoch 482: [86400/94637 (91%)] Step: [2653938] | Lr: 0.000100 | Loss: 1.3873 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 38.30
24-04-04 22:11:57.722 - INFO: Train epoch 482: [89600/94637 (95%)] Step: [2654038] | Lr: 0.000100 | Loss: 1.1857 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 39.82
24-04-04 22:12:48.422 - INFO: Train epoch 482: [92800/94637 (98%)] Step: [2654138] | Lr: 0.000100 | Loss: 1.0718 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 41.16
24-04-04 22:13:28.637 - INFO: Learning rate: 0.0001
24-04-04 22:13:29.818 - INFO: Train epoch 483: [    0/94637 (0%)] Step: [2654195] | Lr: 0.000100 | Loss: 1.2763 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 38.79
24-04-04 22:14:21.218 - INFO: Train epoch 483: [ 3200/94637 (3%)] Step: [2654295] | Lr: 0.000100 | Loss: 0.8862 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 39.10
24-04-04 22:15:12.012 - INFO: Train epoch 483: [ 6400/94637 (7%)] Step: [2654395] | Lr: 0.000100 | Loss: 1.3465 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 39.99
24-04-04 22:16:03.234 - INFO: Train epoch 483: [ 9600/94637 (10%)] Step: [2654495] | Lr: 0.000100 | Loss: 0.9345 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 39.99
24-04-04 22:16:53.692 - INFO: Train epoch 483: [12800/94637 (14%)] Step: [2654595] | Lr: 0.000100 | Loss: 1.1130 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 38.26
24-04-04 22:17:44.846 - INFO: Train epoch 483: [16000/94637 (17%)] Step: [2654695] | Lr: 0.000100 | Loss: 0.7775 | MSE loss: 0.0002 | Bpp loss: 0.46 | Aux loss: 40.31
24-04-04 22:18:36.038 - INFO: Train epoch 483: [19200/94637 (20%)] Step: [2654795] | Lr: 0.000100 | Loss: 1.4498 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 40.69
24-04-04 22:19:27.059 - INFO: Train epoch 483: [22400/94637 (24%)] Step: [2654895] | Lr: 0.000100 | Loss: 1.3204 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 41.29
24-04-04 22:20:18.597 - INFO: Train epoch 483: [25600/94637 (27%)] Step: [2654995] | Lr: 0.000100 | Loss: 0.9237 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 41.66
24-04-04 22:21:12.941 - INFO: Train epoch 483: [28800/94637 (30%)] Step: [2655095] | Lr: 0.000100 | Loss: 1.5081 | MSE loss: 0.0004 | Bpp loss: 0.88 | Aux loss: 39.32
24-04-04 22:22:04.685 - INFO: Train epoch 483: [32000/94637 (34%)] Step: [2655195] | Lr: 0.000100 | Loss: 1.1154 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 42.87
24-04-04 22:22:55.652 - INFO: Train epoch 483: [35200/94637 (37%)] Step: [2655295] | Lr: 0.000100 | Loss: 0.9877 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 38.24
24-04-04 22:23:47.234 - INFO: Train epoch 483: [38400/94637 (41%)] Step: [2655395] | Lr: 0.000100 | Loss: 1.1363 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 39.13
24-04-04 22:24:38.286 - INFO: Train epoch 483: [41600/94637 (44%)] Step: [2655495] | Lr: 0.000100 | Loss: 0.8452 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 40.19
24-04-04 22:25:29.284 - INFO: Train epoch 483: [44800/94637 (47%)] Step: [2655595] | Lr: 0.000100 | Loss: 1.0368 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 39.59
24-04-04 22:26:20.740 - INFO: Train epoch 483: [48000/94637 (51%)] Step: [2655695] | Lr: 0.000100 | Loss: 1.3262 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 39.15
24-04-04 22:27:12.364 - INFO: Train epoch 483: [51200/94637 (54%)] Step: [2655795] | Lr: 0.000100 | Loss: 1.0699 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 42.49
24-04-04 22:28:03.575 - INFO: Train epoch 483: [54400/94637 (57%)] Step: [2655895] | Lr: 0.000100 | Loss: 1.1417 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 41.13
24-04-04 22:28:54.848 - INFO: Train epoch 483: [57600/94637 (61%)] Step: [2655995] | Lr: 0.000100 | Loss: 0.9390 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 39.36
24-04-04 22:29:46.212 - INFO: Train epoch 483: [60800/94637 (64%)] Step: [2656095] | Lr: 0.000100 | Loss: 1.5311 | MSE loss: 0.0003 | Bpp loss: 0.96 | Aux loss: 43.47
24-04-04 22:30:37.792 - INFO: Train epoch 483: [64000/94637 (68%)] Step: [2656195] | Lr: 0.000100 | Loss: 0.9224 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 38.78
24-04-04 22:31:29.428 - INFO: Train epoch 483: [67200/94637 (71%)] Step: [2656295] | Lr: 0.000100 | Loss: 0.9975 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 41.04
24-04-04 22:32:21.279 - INFO: Train epoch 483: [70400/94637 (74%)] Step: [2656395] | Lr: 0.000100 | Loss: 1.1330 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 39.13
24-04-04 22:33:13.675 - INFO: Train epoch 483: [73600/94637 (78%)] Step: [2656495] | Lr: 0.000100 | Loss: 1.3658 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 41.91
24-04-04 22:34:05.460 - INFO: Train epoch 483: [76800/94637 (81%)] Step: [2656595] | Lr: 0.000100 | Loss: 1.0134 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 39.81
24-04-04 22:34:57.259 - INFO: Train epoch 483: [80000/94637 (85%)] Step: [2656695] | Lr: 0.000100 | Loss: 1.0475 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 37.97
24-04-04 22:35:49.785 - INFO: Train epoch 483: [83200/94637 (88%)] Step: [2656795] | Lr: 0.000100 | Loss: 1.4434 | MSE loss: 0.0004 | Bpp loss: 0.85 | Aux loss: 39.46
24-04-04 22:36:41.207 - INFO: Train epoch 483: [86400/94637 (91%)] Step: [2656895] | Lr: 0.000100 | Loss: 1.3339 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 38.10
24-04-04 22:37:32.858 - INFO: Train epoch 483: [89600/94637 (95%)] Step: [2656995] | Lr: 0.000100 | Loss: 1.1982 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 38.24
24-04-04 22:38:24.454 - INFO: Train epoch 483: [92800/94637 (98%)] Step: [2657095] | Lr: 0.000100 | Loss: 1.2225 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 34.92
24-04-04 22:39:10.813 - INFO: Learning rate: 0.0001
24-04-04 22:39:12.538 - INFO: Train epoch 484: [    0/94637 (0%)] Step: [2657152] | Lr: 0.000100 | Loss: 1.1171 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 38.52
24-04-04 22:40:03.732 - INFO: Train epoch 484: [ 3200/94637 (3%)] Step: [2657252] | Lr: 0.000100 | Loss: 1.2280 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 37.07
24-04-04 22:40:54.651 - INFO: Train epoch 484: [ 6400/94637 (7%)] Step: [2657352] | Lr: 0.000100 | Loss: 1.1457 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 40.74
24-04-04 22:41:45.991 - INFO: Train epoch 484: [ 9600/94637 (10%)] Step: [2657452] | Lr: 0.000100 | Loss: 1.1270 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 36.36
24-04-04 22:42:39.637 - INFO: Train epoch 484: [12800/94637 (14%)] Step: [2657552] | Lr: 0.000100 | Loss: 1.1522 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 43.64
24-04-04 22:43:30.716 - INFO: Train epoch 484: [16000/94637 (17%)] Step: [2657652] | Lr: 0.000100 | Loss: 1.2244 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 39.61
24-04-04 22:44:21.591 - INFO: Train epoch 484: [19200/94637 (20%)] Step: [2657752] | Lr: 0.000100 | Loss: 1.2919 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 40.98
24-04-04 22:45:12.509 - INFO: Train epoch 484: [22400/94637 (24%)] Step: [2657852] | Lr: 0.000100 | Loss: 1.0794 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 41.02
24-04-04 22:46:03.473 - INFO: Train epoch 484: [25600/94637 (27%)] Step: [2657952] | Lr: 0.000100 | Loss: 1.0025 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 39.50
24-04-04 22:46:54.614 - INFO: Train epoch 484: [28800/94637 (30%)] Step: [2658052] | Lr: 0.000100 | Loss: 1.2752 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 39.19
24-04-04 22:47:46.136 - INFO: Train epoch 484: [32000/94637 (34%)] Step: [2658152] | Lr: 0.000100 | Loss: 1.4111 | MSE loss: 0.0003 | Bpp loss: 0.97 | Aux loss: 40.44
24-04-04 22:48:37.741 - INFO: Train epoch 484: [35200/94637 (37%)] Step: [2658252] | Lr: 0.000100 | Loss: 0.9747 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 40.15
24-04-04 22:49:29.145 - INFO: Train epoch 484: [38400/94637 (41%)] Step: [2658352] | Lr: 0.000100 | Loss: 1.3465 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 36.24
24-04-04 22:50:19.250 - INFO: Train epoch 484: [41600/94637 (44%)] Step: [2658452] | Lr: 0.000100 | Loss: 0.9683 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 39.61
24-04-04 22:51:10.199 - INFO: Train epoch 484: [44800/94637 (47%)] Step: [2658552] | Lr: 0.000100 | Loss: 1.1702 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 38.99
24-04-04 22:52:01.502 - INFO: Train epoch 484: [48000/94637 (51%)] Step: [2658652] | Lr: 0.000100 | Loss: 1.3274 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 37.45
24-04-04 22:52:52.188 - INFO: Train epoch 484: [51200/94637 (54%)] Step: [2658752] | Lr: 0.000100 | Loss: 1.1874 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 42.44
24-04-04 22:53:43.012 - INFO: Train epoch 484: [54400/94637 (57%)] Step: [2658852] | Lr: 0.000100 | Loss: 1.0780 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 37.57
24-04-04 22:54:34.014 - INFO: Train epoch 484: [57600/94637 (61%)] Step: [2658952] | Lr: 0.000100 | Loss: 1.0509 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 39.01
24-04-04 22:55:24.219 - INFO: Train epoch 484: [60800/94637 (64%)] Step: [2659052] | Lr: 0.000100 | Loss: 1.2252 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 43.25
24-04-04 22:56:14.841 - INFO: Train epoch 484: [64000/94637 (68%)] Step: [2659152] | Lr: 0.000100 | Loss: 0.8332 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 39.92
24-04-04 22:57:05.571 - INFO: Train epoch 484: [67200/94637 (71%)] Step: [2659252] | Lr: 0.000100 | Loss: 0.8549 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 38.38
24-04-04 22:57:56.472 - INFO: Train epoch 484: [70400/94637 (74%)] Step: [2659352] | Lr: 0.000100 | Loss: 1.2268 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 36.26
24-04-04 22:58:47.129 - INFO: Train epoch 484: [73600/94637 (78%)] Step: [2659452] | Lr: 0.000100 | Loss: 1.4720 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 36.95
24-04-04 22:59:37.559 - INFO: Train epoch 484: [76800/94637 (81%)] Step: [2659552] | Lr: 0.000100 | Loss: 1.1707 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 37.58
24-04-04 23:00:28.027 - INFO: Train epoch 484: [80000/94637 (85%)] Step: [2659652] | Lr: 0.000100 | Loss: 1.3904 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 38.02
24-04-04 23:01:18.299 - INFO: Train epoch 484: [83200/94637 (88%)] Step: [2659752] | Lr: 0.000100 | Loss: 1.7233 | MSE loss: 0.0004 | Bpp loss: 1.05 | Aux loss: 33.79
24-04-04 23:02:09.700 - INFO: Train epoch 484: [86400/94637 (91%)] Step: [2659852] | Lr: 0.000100 | Loss: 1.3623 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 39.23
24-04-04 23:03:01.360 - INFO: Train epoch 484: [89600/94637 (95%)] Step: [2659952] | Lr: 0.000100 | Loss: 1.0867 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 37.73
24-04-04 23:03:54.808 - INFO: Train epoch 484: [92800/94637 (98%)] Step: [2660052] | Lr: 0.000100 | Loss: 1.3047 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 39.36
24-04-04 23:04:35.336 - INFO: Learning rate: 0.0001
24-04-04 23:04:37.003 - INFO: Train epoch 485: [    0/94637 (0%)] Step: [2660109] | Lr: 0.000100 | Loss: 1.2670 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 36.85
24-04-04 23:05:26.972 - INFO: Train epoch 485: [ 3200/94637 (3%)] Step: [2660209] | Lr: 0.000100 | Loss: 1.3863 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 37.02
24-04-04 23:06:18.414 - INFO: Train epoch 485: [ 6400/94637 (7%)] Step: [2660309] | Lr: 0.000100 | Loss: 1.3449 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 39.20
24-04-04 23:07:09.872 - INFO: Train epoch 485: [ 9600/94637 (10%)] Step: [2660409] | Lr: 0.000100 | Loss: 0.8769 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 36.50
24-04-04 23:08:00.641 - INFO: Train epoch 485: [12800/94637 (14%)] Step: [2660509] | Lr: 0.000100 | Loss: 1.0743 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 39.14
24-04-04 23:08:52.257 - INFO: Train epoch 485: [16000/94637 (17%)] Step: [2660609] | Lr: 0.000100 | Loss: 1.2375 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 34.83
24-04-04 23:09:43.258 - INFO: Train epoch 485: [19200/94637 (20%)] Step: [2660709] | Lr: 0.000100 | Loss: 1.1205 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 37.86
24-04-04 23:10:34.520 - INFO: Train epoch 485: [22400/94637 (24%)] Step: [2660809] | Lr: 0.000100 | Loss: 1.3517 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 35.67
24-04-04 23:11:26.261 - INFO: Train epoch 485: [25600/94637 (27%)] Step: [2660909] | Lr: 0.000100 | Loss: 1.8604 | MSE loss: 0.0004 | Bpp loss: 1.13 | Aux loss: 38.85
24-04-04 23:12:17.580 - INFO: Train epoch 485: [28800/94637 (30%)] Step: [2661009] | Lr: 0.000100 | Loss: 1.3902 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 39.06
24-04-04 23:13:09.167 - INFO: Train epoch 485: [32000/94637 (34%)] Step: [2661109] | Lr: 0.000100 | Loss: 1.3701 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 36.92
24-04-04 23:14:00.304 - INFO: Train epoch 485: [35200/94637 (37%)] Step: [2661209] | Lr: 0.000100 | Loss: 1.2932 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 37.17
24-04-04 23:14:51.388 - INFO: Train epoch 485: [38400/94637 (41%)] Step: [2661309] | Lr: 0.000100 | Loss: 1.0225 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 38.42
24-04-04 23:15:42.452 - INFO: Train epoch 485: [41600/94637 (44%)] Step: [2661409] | Lr: 0.000100 | Loss: 1.1331 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 35.73
24-04-04 23:16:33.098 - INFO: Train epoch 485: [44800/94637 (47%)] Step: [2661509] | Lr: 0.000100 | Loss: 1.3932 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 38.88
24-04-04 23:17:24.267 - INFO: Train epoch 485: [48000/94637 (51%)] Step: [2661609] | Lr: 0.000100 | Loss: 1.2167 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 38.14
24-04-04 23:18:14.991 - INFO: Train epoch 485: [51200/94637 (54%)] Step: [2661709] | Lr: 0.000100 | Loss: 1.0762 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 39.48
24-04-04 23:19:06.763 - INFO: Train epoch 485: [54400/94637 (57%)] Step: [2661809] | Lr: 0.000100 | Loss: 1.0255 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 37.84
24-04-04 23:19:58.916 - INFO: Train epoch 485: [57600/94637 (61%)] Step: [2661909] | Lr: 0.000100 | Loss: 1.0940 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 37.02
24-04-04 23:20:50.253 - INFO: Train epoch 485: [60800/94637 (64%)] Step: [2662009] | Lr: 0.000100 | Loss: 0.9824 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 39.07
24-04-04 23:21:41.014 - INFO: Train epoch 485: [64000/94637 (68%)] Step: [2662109] | Lr: 0.000100 | Loss: 1.6740 | MSE loss: 0.0004 | Bpp loss: 1.07 | Aux loss: 39.34
24-04-04 23:22:31.357 - INFO: Train epoch 485: [67200/94637 (71%)] Step: [2662209] | Lr: 0.000100 | Loss: 1.4109 | MSE loss: 0.0004 | Bpp loss: 0.74 | Aux loss: 34.84
24-04-04 23:23:22.049 - INFO: Train epoch 485: [70400/94637 (74%)] Step: [2662309] | Lr: 0.000100 | Loss: 0.9204 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 38.42
24-04-04 23:24:12.578 - INFO: Train epoch 485: [73600/94637 (78%)] Step: [2662409] | Lr: 0.000100 | Loss: 1.3837 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 37.27
24-04-04 23:25:05.953 - INFO: Train epoch 485: [76800/94637 (81%)] Step: [2662509] | Lr: 0.000100 | Loss: 0.8326 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 40.26
24-04-04 23:25:57.122 - INFO: Train epoch 485: [80000/94637 (85%)] Step: [2662609] | Lr: 0.000100 | Loss: 1.0801 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 36.74
24-04-04 23:26:48.166 - INFO: Train epoch 485: [83200/94637 (88%)] Step: [2662709] | Lr: 0.000100 | Loss: 1.3036 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 33.82
24-04-04 23:27:39.047 - INFO: Train epoch 485: [86400/94637 (91%)] Step: [2662809] | Lr: 0.000100 | Loss: 1.0389 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 36.95
24-04-04 23:28:30.128 - INFO: Train epoch 485: [89600/94637 (95%)] Step: [2662909] | Lr: 0.000100 | Loss: 1.3672 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 39.52
24-04-04 23:29:20.818 - INFO: Train epoch 485: [92800/94637 (98%)] Step: [2663009] | Lr: 0.000100 | Loss: 1.5909 | MSE loss: 0.0003 | Bpp loss: 1.03 | Aux loss: 35.81
24-04-04 23:30:00.727 - INFO: Learning rate: 0.0001
24-04-04 23:30:01.914 - INFO: Train epoch 486: [    0/94637 (0%)] Step: [2663066] | Lr: 0.000100 | Loss: 1.3072 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 40.34
24-04-04 23:30:52.308 - INFO: Train epoch 486: [ 3200/94637 (3%)] Step: [2663166] | Lr: 0.000100 | Loss: 1.3592 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 36.65
24-04-04 23:31:43.265 - INFO: Train epoch 486: [ 6400/94637 (7%)] Step: [2663266] | Lr: 0.000100 | Loss: 1.1752 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 43.38
24-04-04 23:32:33.868 - INFO: Train epoch 486: [ 9600/94637 (10%)] Step: [2663366] | Lr: 0.000100 | Loss: 1.3553 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 39.87
24-04-04 23:33:24.137 - INFO: Train epoch 486: [12800/94637 (14%)] Step: [2663466] | Lr: 0.000100 | Loss: 1.1960 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 34.67
24-04-04 23:34:14.583 - INFO: Train epoch 486: [16000/94637 (17%)] Step: [2663566] | Lr: 0.000100 | Loss: 1.5281 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 38.14
24-04-04 23:35:05.506 - INFO: Train epoch 486: [19200/94637 (20%)] Step: [2663666] | Lr: 0.000100 | Loss: 1.3137 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 34.94
24-04-04 23:35:56.245 - INFO: Train epoch 486: [22400/94637 (24%)] Step: [2663766] | Lr: 0.000100 | Loss: 1.3438 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 37.81
24-04-04 23:36:46.669 - INFO: Train epoch 486: [25600/94637 (27%)] Step: [2663866] | Lr: 0.000100 | Loss: 1.2418 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 35.71
24-04-04 23:37:37.362 - INFO: Train epoch 486: [28800/94637 (30%)] Step: [2663966] | Lr: 0.000100 | Loss: 1.0203 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 34.26
24-04-04 23:38:27.972 - INFO: Train epoch 486: [32000/94637 (34%)] Step: [2664066] | Lr: 0.000100 | Loss: 1.1461 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 37.34
24-04-04 23:39:19.310 - INFO: Train epoch 486: [35200/94637 (37%)] Step: [2664166] | Lr: 0.000100 | Loss: 0.9660 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 39.44
24-04-04 23:40:10.392 - INFO: Train epoch 486: [38400/94637 (41%)] Step: [2664266] | Lr: 0.000100 | Loss: 1.2562 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 37.58
24-04-04 23:41:01.518 - INFO: Train epoch 486: [41600/94637 (44%)] Step: [2664366] | Lr: 0.000100 | Loss: 0.9050 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 36.96
24-04-04 23:41:52.314 - INFO: Train epoch 486: [44800/94637 (47%)] Step: [2664466] | Lr: 0.000100 | Loss: 1.3776 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 38.36
24-04-04 23:42:43.532 - INFO: Train epoch 486: [48000/94637 (51%)] Step: [2664566] | Lr: 0.000100 | Loss: 0.8303 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 37.89
24-04-04 23:43:34.678 - INFO: Train epoch 486: [51200/94637 (54%)] Step: [2664666] | Lr: 0.000100 | Loss: 1.2418 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 35.26
24-04-04 23:44:25.757 - INFO: Train epoch 486: [54400/94637 (57%)] Step: [2664766] | Lr: 0.000100 | Loss: 1.3228 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 33.53
24-04-04 23:45:16.695 - INFO: Train epoch 486: [57600/94637 (61%)] Step: [2664866] | Lr: 0.000100 | Loss: 0.9862 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 34.18
24-04-04 23:46:07.101 - INFO: Train epoch 486: [60800/94637 (64%)] Step: [2664966] | Lr: 0.000100 | Loss: 1.2817 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 31.82
24-04-04 23:46:59.341 - INFO: Train epoch 486: [64000/94637 (68%)] Step: [2665066] | Lr: 0.000100 | Loss: 1.0275 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 31.22
24-04-04 23:47:49.867 - INFO: Train epoch 486: [67200/94637 (71%)] Step: [2665166] | Lr: 0.000100 | Loss: 1.1907 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 33.05
24-04-04 23:48:40.348 - INFO: Train epoch 486: [70400/94637 (74%)] Step: [2665266] | Lr: 0.000100 | Loss: 0.9685 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 31.96
24-04-04 23:49:31.067 - INFO: Train epoch 486: [73600/94637 (78%)] Step: [2665366] | Lr: 0.000100 | Loss: 1.1489 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 32.48
24-04-04 23:50:21.528 - INFO: Train epoch 486: [76800/94637 (81%)] Step: [2665466] | Lr: 0.000100 | Loss: 1.2869 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 36.90
24-04-04 23:51:11.841 - INFO: Train epoch 486: [80000/94637 (85%)] Step: [2665566] | Lr: 0.000100 | Loss: 1.1354 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 38.26
