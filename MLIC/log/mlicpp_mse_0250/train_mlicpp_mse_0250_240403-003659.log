24-04-03 00:38:20.318 - INFO: Namespace(experiment='mlicpp_mse_0250', dataset='/mnt/bn/jiangwei-lvc3/dataset/image', epochs=500, learning_rate=0.0001, num_workers=8, lmbda=0.025, metrics='mse', batch_size=4, test_batch_size=1, aux_learning_rate=0.001, patch_size=[384, 384], gpu_id=0, cuda=True, save=True, seed=1984.0, clip_max_norm=1.0, checkpoint='/mnt/bn/jiangwei-lvc3/work_space/MLICPlusPlus/playground/experiments/mlicpp_mse_0250/checkpoints', world_size=4, dist_url='env://', rank=3, gpu=3, distributed=True, dist_backend='nccl')
24-04-03 00:38:20.318 - INFO: {'N': 192, 'M': 320, 'enc_dims': [3, 192, 192, 192, 320], 'dec_dims': [320, 192, 192, 192, 16, 3], 'slice_num': 10, 'context_window': 5, 'slice_ch': [8, 8, 8, 8, 16, 16, 32, 32, 96, 96], 'max_support_slices': 5, 'quant': 'ste', 'lambda_list': [0.07, 0.08, 0.09], 'use_hyper_gain': False, 'interpolated_type': 'exponential', 'act': <class 'torch.nn.modules.activation.GELU'>, 'L': 10, 'target_bpp': [0.0761, 0.1854, 0.2752, 0.3652, 0.4282, 0.5238, 0.5653, 0.6334, 0.745], 'bpp_threshold': [0.02, 0.02, 0.02, 0.02, 0.03, 0.02, 0.02, 0.02, 0.02], 'min_lmbda': 0.001, 'init_lmbda': [0.001, 0.0018, 0.0035, 0.0035, 0.0067, 0.0067, 0.013, 0.013, 0.025, 0.0483], 'lower_bound': 1e-09, 'ki': 0.1, 'kp': 0.1}
24-04-03 00:38:20.318 - INFO: DistributedDataParallel(
  (module): MLICPlusPlus(
    (entropy_bottleneck): EntropyBottleneck(
      (likelihood_lower_bound): LowerBound()
    )
    (g_a): AnalysisTransform(
      (analysis_transform): Sequential(
        (0): ResidualBlockWithStride(
          (conv1): Conv2d(3, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (gdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (skip): Conv2d(3, 192, kernel_size=(1, 1), stride=(2, 2))
        )
        (1): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (2): ResidualBlockWithStride(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (gdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (skip): Conv2d(192, 192, kernel_size=(1, 1), stride=(2, 2))
        )
        (3): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (4): ResidualBlockWithStride(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (gdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (skip): Conv2d(192, 192, kernel_size=(1, 1), stride=(2, 2))
        )
        (5): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (6): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      )
    )
    (g_s): SynthesisTransform(
      (synthesis_transform): Sequential(
        (0): ResidualBlock(
          (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (1): ResidualBlockUpsample(
          (subpel_conv): Sequential(
            (0): Conv2d(320, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
          (act): GELU(approximate='none')
          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (igdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (upsample): Sequential(
            (0): Conv2d(320, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
        )
        (2): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (3): ResidualBlockUpsample(
          (subpel_conv): Sequential(
            (0): Conv2d(192, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
          (act): GELU(approximate='none')
          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (igdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (upsample): Sequential(
            (0): Conv2d(192, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
        )
        (4): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (5): ResidualBlockUpsample(
          (subpel_conv): Sequential(
            (0): Conv2d(192, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
          (act): GELU(approximate='none')
          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (igdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (upsample): Sequential(
            (0): Conv2d(192, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
        )
        (6): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (7): Sequential(
          (0): Conv2d(192, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): PixelShuffle(upscale_factor=2)
        )
      )
    )
    (h_a): HyperAnalysis(
      (reduction): Sequential(
        (0): Conv2d(320, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): GELU(approximate='none')
        (2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): GELU(approximate='none')
        (4): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (5): GELU(approximate='none')
        (6): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): GELU(approximate='none')
        (8): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      )
    )
    (h_s): HyperSynthesis(
      (increase): Sequential(
        (0): Conv2d(192, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): GELU(approximate='none')
        (2): Sequential(
          (0): Conv2d(320, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): PixelShuffle(upscale_factor=2)
        )
        (3): GELU(approximate='none')
        (4): Conv2d(320, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): GELU(approximate='none')
        (6): Sequential(
          (0): Conv2d(480, 1920, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): PixelShuffle(upscale_factor=2)
        )
        (7): GELU(approximate='none')
        (8): Conv2d(480, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (gaussian_conditional): GaussianConditional(
      (likelihood_lower_bound): LowerBound()
      (lower_bound_scale): LowerBound()
    )
    (local_context): ModuleList(
      (0-9): 10 x LocalContext(
        (qkv_proj): Linear(in_features=32, out_features=96, bias=True)
        (unfold): Unfold(kernel_size=5, dilation=1, padding=2, stride=1)
        (softmax): Softmax(dim=-1)
        (proj): Linear(in_features=64, out_features=64, bias=True)
        (mlp): MLP(
          (fc1): Linear(in_features=64, out_features=128, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=128, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (fusion): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
      )
    )
    (channel_context): ModuleList(
      (0): None
      (1): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(32, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (2): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (3): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (4): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (5): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(160, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (6): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (7): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(224, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (8): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (9): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(288, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (global_inter_context): ModuleList(
      (0): None
      (1): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (queries): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (values): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (reprojection): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
        )
        (queries): Sequential(
          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
        )
        (values): Sequential(
          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
        )
        (reprojection): Conv2d(64, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (3): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
        )
        (queries): Sequential(
          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
        )
        (values): Sequential(
          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
        )
        (reprojection): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (4): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
        )
        (queries): Sequential(
          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
        )
        (values): Sequential(
          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
        )
        (reprojection): Conv2d(128, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (5): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)
        )
        (queries): Sequential(
          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)
        )
        (values): Sequential(
          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)
        )
        (reprojection): Conv2d(160, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (6): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
        )
        (queries): Sequential(
          (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
        )
        (values): Sequential(
          (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
        )
        (reprojection): Conv2d(192, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (7): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(224, 224, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=224)
        )
        (queries): Sequential(
          (0): Conv2d(224, 224, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=224)
        )
        (values): Sequential(
          (0): Conv2d(224, 224, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=224)
        )
        (reprojection): Conv2d(224, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (8): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
        )
        (queries): Sequential(
          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
        )
        (values): Sequential(
          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
        )
        (reprojection): Conv2d(256, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (9): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)
        )
        (queries): Sequential(
          (0): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)
        )
        (values): Sequential(
          (0): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)
        )
        (reprojection): Conv2d(288, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (global_intra_context): ModuleList(
      (0): None
      (1-9): 9 x LinearGlobalIntraContext(
        (keys): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (queries): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (values): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (reprojection): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
    (entropy_parameters_anchor): ModuleList(
      (0): EntropyParameters(
        (fusion): Sequential(
          (0): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
          (5): GELU(approximate='none')
          (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (1-9): 9 x EntropyParameters(
        (fusion): Sequential(
          (0): Conv2d(832, 320, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
          (5): GELU(approximate='none')
          (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
    (entropy_parameters_nonanchor): ModuleList(
      (0): EntropyParameters(
        (fusion): Sequential(
          (0): Conv2d(704, 320, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
          (5): GELU(approximate='none')
          (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (1-9): 9 x EntropyParameters(
        (fusion): Sequential(
          (0): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
          (5): GELU(approximate='none')
          (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
    (lrp_anchor): ModuleList(
      (0): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(352, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (1): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(384, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (2): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(416, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (3): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(448, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (4): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(480, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (5): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(512, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (6): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(544, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (7): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(576, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (8): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(608, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (9): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(640, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (lrp_nonanchor): ModuleList(
      (0): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(352, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (1): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(384, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (2): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(416, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (3): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(448, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (4): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(480, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (5): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(512, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (6): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(544, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (7): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(576, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (8): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(608, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (9): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(640, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
  )
)
24-04-03 00:38:20.327 - INFO: Learning rate: 0.0001
24-04-03 01:13:22.052 - INFO: Learning rate: 0.0001
24-04-03 01:47:57.874 - INFO: Learning rate: 0.0001
24-04-03 02:22:42.559 - INFO: Learning rate: 0.0001
24-04-03 02:57:39.199 - INFO: Learning rate: 0.0001
24-04-03 03:32:37.022 - INFO: Learning rate: 0.0001
24-04-03 04:07:33.239 - INFO: Learning rate: 0.0001
24-04-03 04:42:33.494 - INFO: Learning rate: 0.0001
24-04-03 05:17:48.113 - INFO: Learning rate: 0.0001
24-04-03 05:52:35.842 - INFO: Learning rate: 0.0001
24-04-03 06:27:33.251 - INFO: Learning rate: 0.0001
24-04-03 07:02:35.334 - INFO: Learning rate: 0.0001
24-04-03 07:37:31.321 - INFO: Learning rate: 0.0001
24-04-03 08:12:19.290 - INFO: Learning rate: 0.0001
24-04-03 08:47:15.168 - INFO: Learning rate: 0.0001
24-04-03 09:21:59.297 - INFO: Learning rate: 0.0001
24-04-03 09:56:40.194 - INFO: Learning rate: 0.0001
24-04-03 10:31:31.724 - INFO: Learning rate: 0.0001
24-04-03 11:06:14.805 - INFO: Learning rate: 0.0001
24-04-03 11:41:07.697 - INFO: Learning rate: 0.0001
24-04-03 12:16:02.375 - INFO: Learning rate: 0.0001
8: [ 9600/94637 (10%)] Step: [2290601] | Lr: 0.000100 | Loss: 1.1286 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 58.37
24-04-03 00:42:34.601 - INFO: Train epoch 388: [11200/94637 (12%)] Step: [2290701] | Lr: 0.000100 | Loss: 0.7624 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 67.78
24-04-03 00:43:09.467 - INFO: Train epoch 388: [12800/94637 (14%)] Step: [2290801] | Lr: 0.000100 | Loss: 1.1653 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 65.30
24-04-03 00:43:43.760 - INFO: Train epoch 388: [14400/94637 (15%)] Step: [2290901] | Lr: 0.000100 | Loss: 1.6988 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 59.86
24-04-03 00:44:19.138 - INFO: Train epoch 388: [16000/94637 (17%)] Step: [2291001] | Lr: 0.000100 | Loss: 1.3543 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 57.31
24-04-03 00:44:53.659 - INFO: Train epoch 388: [17600/94637 (19%)] Step: [2291101] | Lr: 0.000100 | Loss: 1.4540 | MSE loss: 0.0004 | Bpp loss: 0.88 | Aux loss: 54.42
24-04-03 00:45:27.222 - INFO: Train epoch 388: [19200/94637 (20%)] Step: [2291201] | Lr: 0.000100 | Loss: 1.5427 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 52.17
24-04-03 00:46:01.361 - INFO: Train epoch 388: [20800/94637 (22%)] Step: [2291301] | Lr: 0.000100 | Loss: 2.4444 | MSE loss: 0.0006 | Bpp loss: 1.41 | Aux loss: 58.94
24-04-03 00:46:35.958 - INFO: Train epoch 388: [22400/94637 (24%)] Step: [2291401] | Lr: 0.000100 | Loss: 1.4353 | MSE loss: 0.0004 | Bpp loss: 0.84 | Aux loss: 58.15
24-04-03 00:47:10.101 - INFO: Train epoch 388: [24000/94637 (25%)] Step: [2291501] | Lr: 0.000100 | Loss: 0.9820 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 59.84
24-04-03 00:47:43.987 - INFO: Train epoch 388: [25600/94637 (27%)] Step: [2291601] | Lr: 0.000100 | Loss: 1.4034 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 58.48
24-04-03 00:48:18.734 - INFO: Train epoch 388: [27200/94637 (29%)] Step: [2291701] | Lr: 0.000100 | Loss: 0.8405 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 58.84
24-04-03 00:48:54.232 - INFO: Train epoch 388: [28800/94637 (30%)] Step: [2291801] | Lr: 0.000100 | Loss: 1.4311 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 56.17
24-04-03 00:49:29.124 - INFO: Train epoch 388: [30400/94637 (32%)] Step: [2291901] | Lr: 0.000100 | Loss: 1.2816 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 56.65
24-04-03 00:50:03.658 - INFO: Train epoch 388: [32000/94637 (34%)] Step: [2292001] | Lr: 0.000100 | Loss: 1.7964 | MSE loss: 0.0005 | Bpp loss: 1.03 | Aux loss: 57.04
24-04-03 00:50:39.717 - INFO: Train epoch 388: [33600/94637 (36%)] Step: [2292101] | Lr: 0.000100 | Loss: 1.2065 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 56.55
24-04-03 00:51:15.499 - INFO: Train epoch 388: [35200/94637 (37%)] Step: [2292201] | Lr: 0.000100 | Loss: 1.2220 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 55.74
24-04-03 00:51:51.083 - INFO: Train epoch 388: [36800/94637 (39%)] Step: [2292301] | Lr: 0.000100 | Loss: 1.2382 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 60.46
24-04-03 00:52:26.561 - INFO: Train epoch 388: [38400/94637 (41%)] Step: [2292401] | Lr: 0.000100 | Loss: 1.1236 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 55.51
24-04-03 00:53:02.892 - INFO: Train epoch 388: [40000/94637 (42%)] Step: [2292501] | Lr: 0.000100 | Loss: 1.0768 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 57.69
24-04-03 00:53:38.628 - INFO: Train epoch 388: [41600/94637 (44%)] Step: [2292601] | Lr: 0.000100 | Loss: 1.6922 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 58.78
24-04-03 00:54:13.646 - INFO: Train epoch 388: [43200/94637 (46%)] Step: [2292701] | Lr: 0.000100 | Loss: 1.0080 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 56.45
24-04-03 00:54:47.805 - INFO: Train epoch 388: [44800/94637 (47%)] Step: [2292801] | Lr: 0.000100 | Loss: 0.9734 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 59.68
24-04-03 00:55:22.538 - INFO: Train epoch 388: [46400/94637 (49%)] Step: [2292901] | Lr: 0.000100 | Loss: 1.7686 | MSE loss: 0.0004 | Bpp loss: 1.08 | Aux loss: 57.12
24-04-03 00:55:57.842 - INFO: Train epoch 388: [48000/94637 (51%)] Step: [2293001] | Lr: 0.000100 | Loss: 1.4319 | MSE loss: 0.0004 | Bpp loss: 0.86 | Aux loss: 59.05
24-04-03 00:56:33.109 - INFO: Train epoch 388: [49600/94637 (52%)] Step: [2293101] | Lr: 0.000100 | Loss: 0.8517 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 59.54
24-04-03 00:57:08.155 - INFO: Train epoch 388: [51200/94637 (54%)] Step: [2293201] | Lr: 0.000100 | Loss: 1.5743 | MSE loss: 0.0004 | Bpp loss: 0.99 | Aux loss: 55.03
24-04-03 00:57:42.748 - INFO: Train epoch 388: [52800/94637 (56%)] Step: [2293301] | Lr: 0.000100 | Loss: 2.1281 | MSE loss: 0.0005 | Bpp loss: 1.30 | Aux loss: 54.75
24-04-03 00:58:19.277 - INFO: Train epoch 388: [54400/94637 (57%)] Step: [2293401] | Lr: 0.000100 | Loss: 1.5832 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 58.24
24-04-03 00:58:55.573 - INFO: Train epoch 388: [56000/94637 (59%)] Step: [2293501] | Lr: 0.000100 | Loss: 1.5526 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 58.10
24-04-03 00:59:31.492 - INFO: Train epoch 388: [57600/94637 (61%)] Step: [2293601] | Lr: 0.000100 | Loss: 1.2537 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 64.27
24-04-03 01:00:07.372 - INFO: Train epoch 388: [59200/94637 (63%)] Step: [2293701] | Lr: 0.000100 | Loss: 1.7272 | MSE loss: 0.0004 | Bpp loss: 1.12 | Aux loss: 62.21
24-04-03 01:00:42.350 - INFO: Train epoch 388: [60800/94637 (64%)] Step: [2293801] | Lr: 0.000100 | Loss: 1.6292 | MSE loss: 0.0004 | Bpp loss: 1.03 | Aux loss: 57.71
24-04-03 01:01:17.933 - INFO: Train epoch 388: [62400/94637 (66%)] Step: [2293901] | Lr: 0.000100 | Loss: 1.3888 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 58.69
24-04-03 01:01:53.210 - INFO: Train epoch 388: [64000/94637 (68%)] Step: [2294001] | Lr: 0.000100 | Loss: 1.3208 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 58.98
24-04-03 01:02:28.471 - INFO: Train epoch 388: [65600/94637 (69%)] Step: [2294101] | Lr: 0.000100 | Loss: 0.6402 | MSE loss: 0.0001 | Bpp loss: 0.43 | Aux loss: 52.09
24-04-03 01:03:03.859 - INFO: Train epoch 388: [67200/94637 (71%)] Step: [2294201] | Lr: 0.000100 | Loss: 1.1720 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 55.95
24-04-03 01:03:38.787 - INFO: Train epoch 388: [68800/94637 (73%)] Step: [2294301] | Lr: 0.000100 | Loss: 1.3218 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 58.69
24-04-03 01:04:14.029 - INFO: Train epoch 388: [70400/94637 (74%)] Step: [2294401] | Lr: 0.000100 | Loss: 1.2643 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 58.62
24-04-03 01:04:49.617 - INFO: Train epoch 388: [72000/94637 (76%)] Step: [2294501] | Lr: 0.000100 | Loss: 1.0285 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 62.56
24-04-03 01:05:24.904 - INFO: Train epoch 388: [73600/94637 (78%)] Step: [2294601] | Lr: 0.000100 | Loss: 1.0603 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 59.56
24-04-03 01:06:00.731 - INFO: Train epoch 388: [75200/94637 (79%)] Step: [2294701] | Lr: 0.000100 | Loss: 1.5473 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 57.44
24-04-03 01:06:37.088 - INFO: Train epoch 388: [76800/94637 (81%)] Step: [2294801] | Lr: 0.000100 | Loss: 1.6461 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 62.12
24-04-03 01:07:12.832 - INFO: Train epoch 388: [78400/94637 (83%)] Step: [2294901] | Lr: 0.000100 | Loss: 1.0854 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 62.66
24-04-03 01:07:51.212 - INFO: Train epoch 388: [80000/94637 (85%)] Step: [2295001] | Lr: 0.000100 | Loss: 1.6195 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 56.30
24-04-03 01:08:27.177 - INFO: Train epoch 388: [81600/94637 (86%)] Step: [2295101] | Lr: 0.000100 | Loss: 0.8633 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 56.32
24-04-03 01:09:03.256 - INFO: Train epoch 388: [83200/94637 (88%)] Step: [2295201] | Lr: 0.000100 | Loss: 1.1340 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 61.75
24-04-03 01:09:39.156 - INFO: Train epoch 388: [84800/94637 (90%)] Step: [2295301] | Lr: 0.000100 | Loss: 1.0713 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 61.27
24-04-03 01:10:15.652 - INFO: Train epoch 388: [86400/94637 (91%)] Step: [2295401] | Lr: 0.000100 | Loss: 1.5947 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 57.52
24-04-03 01:10:51.504 - INFO: Train epoch 388: [88000/94637 (93%)] Step: [2295501] | Lr: 0.000100 | Loss: 1.0501 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 53.60
24-04-03 01:11:27.552 - INFO: Train epoch 388: [89600/94637 (95%)] Step: [2295601] | Lr: 0.000100 | Loss: 1.2788 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 54.57
24-04-03 01:12:04.060 - INFO: Train epoch 388: [91200/94637 (96%)] Step: [2295701] | Lr: 0.000100 | Loss: 1.4516 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 60.33
24-04-03 01:12:40.975 - INFO: Train epoch 388: [92800/94637 (98%)] Step: [2295801] | Lr: 0.000100 | Loss: 1.0223 | MSE loss: 0.0003 | Bpp loss: 0.60 | Aux loss: 57.95
24-04-03 01:13:16.714 - INFO: Train epoch 388: [94400/94637 (100%)] Step: [2295901] | Lr: 0.000100 | Loss: 1.4832 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 58.95
24-04-03 01:13:40.939 - INFO: Learning rate: 0.0001
24-04-03 01:13:42.278 - INFO: Train epoch 389: [    0/94637 (0%)] Step: [2295916] | Lr: 0.000100 | Loss: 0.6229 | MSE loss: 0.0001 | Bpp loss: 0.41 | Aux loss: 56.98
24-04-03 01:14:17.523 - INFO: Train epoch 389: [ 1600/94637 (2%)] Step: [2296016] | Lr: 0.000100 | Loss: 1.3635 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 56.18
24-04-03 01:14:53.033 - INFO: Train epoch 389: [ 3200/94637 (3%)] Step: [2296116] | Lr: 0.000100 | Loss: 1.1686 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 59.15
24-04-03 01:15:27.551 - INFO: Train epoch 389: [ 4800/94637 (5%)] Step: [2296216] | Lr: 0.000100 | Loss: 1.0603 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 56.43
24-04-03 01:16:00.287 - INFO: Train epoch 389: [ 6400/94637 (7%)] Step: [2296316] | Lr: 0.000100 | Loss: 1.0711 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 57.18
24-04-03 01:16:33.786 - INFO: Train epoch 389: [ 8000/94637 (8%)] Step: [2296416] | Lr: 0.000100 | Loss: 1.0643 | MSE loss: 0.0003 | Bpp loss: 0.62 | Aux loss: 62.29
24-04-03 01:17:07.827 - INFO: Train epoch 389: [ 9600/94637 (10%)] Step: [2296516] | Lr: 0.000100 | Loss: 1.2445 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 60.08
24-04-03 01:17:41.276 - INFO: Train epoch 389: [11200/94637 (12%)] Step: [2296616] | Lr: 0.000100 | Loss: 1.0884 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 59.25
24-04-03 01:18:15.666 - INFO: Train epoch 389: [12800/94637 (14%)] Step: [2296716] | Lr: 0.000100 | Loss: 0.9399 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 55.31
24-04-03 01:18:49.902 - INFO: Train epoch 389: [14400/94637 (15%)] Step: [2296816] | Lr: 0.000100 | Loss: 0.9955 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 56.66
24-04-03 01:19:24.873 - INFO: Train epoch 389: [16000/94637 (17%)] Step: [2296916] | Lr: 0.000100 | Loss: 1.4809 | MSE loss: 0.0004 | Bpp loss: 0.86 | Aux loss: 58.46
24-04-03 01:20:00.795 - INFO: Train epoch 389: [17600/94637 (19%)] Step: [2297016] | Lr: 0.000100 | Loss: 1.1372 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 59.03
24-04-03 01:20:36.228 - INFO: Train epoch 389: [19200/94637 (20%)] Step: [2297116] | Lr: 0.000100 | Loss: 0.9489 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 56.62
24-04-03 01:21:09.821 - INFO: Train epoch 389: [20800/94637 (22%)] Step: [2297216] | Lr: 0.000100 | Loss: 1.4425 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 57.54
24-04-03 01:21:45.283 - INFO: Train epoch 389: [22400/94637 (24%)] Step: [2297316] | Lr: 0.000100 | Loss: 1.1645 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 57.28
24-04-03 01:22:20.731 - INFO: Train epoch 389: [24000/94637 (25%)] Step: [2297416] | Lr: 0.000100 | Loss: 1.0780 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 59.94
24-04-03 01:22:57.112 - INFO: Train epoch 389: [25600/94637 (27%)] Step: [2297516] | Lr: 0.000100 | Loss: 1.8357 | MSE loss: 0.0006 | Bpp loss: 0.94 | Aux loss: 60.46
24-04-03 01:23:33.354 - INFO: Train epoch 389: [27200/94637 (29%)] Step: [2297616] | Lr: 0.000100 | Loss: 1.2997 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 58.86
24-04-03 01:24:10.357 - INFO: Train epoch 389: [28800/94637 (30%)] Step: [2297716] | Lr: 0.000100 | Loss: 0.9468 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 54.49
24-04-03 01:24:46.308 - INFO: Train epoch 389: [30400/94637 (32%)] Step: [2297816] | Lr: 0.000100 | Loss: 1.4450 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 57.80
24-04-03 01:25:21.254 - INFO: Train epoch 389: [32000/94637 (34%)] Step: [2297916] | Lr: 0.000100 | Loss: 1.2365 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 56.55
24-04-03 01:25:55.758 - INFO: Train epoch 389: [33600/94637 (36%)] Step: [2298016] | Lr: 0.000100 | Loss: 1.4045 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 59.34
24-04-03 01:26:30.031 - INFO: Train epoch 389: [35200/94637 (37%)] Step: [2298116] | Lr: 0.000100 | Loss: 1.0219 | MSE loss: 0.0003 | Bpp loss: 0.61 | Aux loss: 55.02
24-04-03 01:27:05.723 - INFO: Train epoch 389: [36800/94637 (39%)] Step: [2298216] | Lr: 0.000100 | Loss: 1.2507 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 62.61
24-04-03 01:27:41.235 - INFO: Train epoch 389: [38400/94637 (41%)] Step: [2298316] | Lr: 0.000100 | Loss: 1.0228 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 62.30
24-04-03 01:28:16.638 - INFO: Train epoch 389: [40000/94637 (42%)] Step: [2298416] | Lr: 0.000100 | Loss: 0.9785 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 55.38
24-04-03 01:28:52.422 - INFO: Train epoch 389: [41600/94637 (44%)] Step: [2298516] | Lr: 0.000100 | Loss: 0.9459 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 58.14
24-04-03 01:29:27.885 - INFO: Train epoch 389: [43200/94637 (46%)] Step: [2298616] | Lr: 0.000100 | Loss: 1.4519 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 54.65
24-04-03 01:30:02.809 - INFO: Train epoch 389: [44800/94637 (47%)] Step: [2298716] | Lr: 0.000100 | Loss: 1.2050 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 60.06
24-04-03 01:30:36.725 - INFO: Train epoch 389: [46400/94637 (49%)] Step: [2298816] | Lr: 0.000100 | Loss: 0.9964 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 60.54
24-04-03 01:31:11.061 - INFO: Train epoch 389: [48000/94637 (51%)] Step: [2298916] | Lr: 0.000100 | Loss: 1.2754 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 56.90
24-04-03 01:31:45.444 - INFO: Train epoch 389: [49600/94637 (52%)] Step: [2299016] | Lr: 0.000100 | Loss: 1.3276 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 58.11
24-04-03 01:32:19.816 - INFO: Train epoch 389: [51200/94637 (54%)] Step: [2299116] | Lr: 0.000100 | Loss: 1.0314 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 59.66
24-04-03 01:32:55.199 - INFO: Train epoch 389: [52800/94637 (56%)] Step: [2299216] | Lr: 0.000100 | Loss: 1.1105 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 59.09
24-04-03 01:33:29.911 - INFO: Train epoch 389: [54400/94637 (57%)] Step: [2299316] | Lr: 0.000100 | Loss: 0.9303 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 57.32
24-04-03 01:34:04.311 - INFO: Train epoch 389: [56000/94637 (59%)] Step: [2299416] | Lr: 0.000100 | Loss: 1.1392 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 59.90
24-04-03 01:34:38.973 - INFO: Train epoch 389: [57600/94637 (61%)] Step: [2299516] | Lr: 0.000100 | Loss: 1.2945 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 56.58
24-04-03 01:35:13.391 - INFO: Train epoch 389: [59200/94637 (63%)] Step: [2299616] | Lr: 0.000100 | Loss: 0.9956 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 57.66
24-04-03 01:35:46.715 - INFO: Train epoch 389: [60800/94637 (64%)] Step: [2299716] | Lr: 0.000100 | Loss: 1.4124 | MSE loss: 0.0004 | Bpp loss: 0.75 | Aux loss: 59.35
24-04-03 01:36:20.326 - INFO: Train epoch 389: [62400/94637 (66%)] Step: [2299816] | Lr: 0.000100 | Loss: 1.5251 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 59.40
24-04-03 01:36:53.958 - INFO: Train epoch 389: [64000/94637 (68%)] Step: [2299916] | Lr: 0.000100 | Loss: 1.2921 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 59.49
24-04-03 01:37:29.020 - INFO: Train epoch 389: [65600/94637 (69%)] Step: [2300016] | Lr: 0.000100 | Loss: 1.2595 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 55.30
24-04-03 01:38:02.707 - INFO: Train epoch 389: [67200/94637 (71%)] Step: [2300116] | Lr: 0.000100 | Loss: 1.6411 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 59.48
24-04-03 01:38:37.025 - INFO: Train epoch 389: [68800/94637 (73%)] Step: [2300216] | Lr: 0.000100 | Loss: 1.2638 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 61.26
24-04-03 01:39:10.911 - INFO: Train epoch 389: [70400/94637 (74%)] Step: [2300316] | Lr: 0.000100 | Loss: 1.5609 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 57.25
24-04-03 01:39:44.925 - INFO: Train epoch 389: [72000/94637 (76%)] Step: [2300416] | Lr: 0.000100 | Loss: 1.3621 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 61.16
24-04-03 01:40:20.854 - INFO: Train epoch 389: [73600/94637 (78%)] Step: [2300516] | Lr: 0.000100 | Loss: 1.8527 | MSE loss: 0.0005 | Bpp loss: 1.12 | Aux loss: 55.01
24-04-03 01:40:56.849 - INFO: Train epoch 389: [75200/94637 (79%)] Step: [2300616] | Lr: 0.000100 | Loss: 0.9855 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 59.63
24-04-03 01:41:32.217 - INFO: Train epoch 389: [76800/94637 (81%)] Step: [2300716] | Lr: 0.000100 | Loss: 1.5792 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 52.20
24-04-03 01:42:06.247 - INFO: Train epoch 389: [78400/94637 (83%)] Step: [2300816] | Lr: 0.000100 | Loss: 1.7497 | MSE loss: 0.0004 | Bpp loss: 1.05 | Aux loss: 51.15
24-04-03 01:42:40.473 - INFO: Train epoch 389: [80000/94637 (85%)] Step: [2300916] | Lr: 0.000100 | Loss: 1.4142 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 51.22
24-04-03 01:43:14.748 - INFO: Train epoch 389: [81600/94637 (86%)] Step: [2301016] | Lr: 0.000100 | Loss: 0.9805 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 50.48
24-04-03 01:43:49.258 - INFO: Train epoch 389: [83200/94637 (88%)] Step: [2301116] | Lr: 0.000100 | Loss: 1.1199 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 50.88
24-04-03 01:44:23.483 - INFO: Train epoch 389: [84800/94637 (90%)] Step: [2301216] | Lr: 0.000100 | Loss: 1.7322 | MSE loss: 0.0005 | Bpp loss: 0.97 | Aux loss: 51.01
24-04-03 01:44:58.545 - INFO: Train epoch 389: [86400/94637 (91%)] Step: [2301316] | Lr: 0.000100 | Loss: 1.1373 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 55.11
24-04-03 01:45:34.371 - INFO: Train epoch 389: [88000/94637 (93%)] Step: [2301416] | Lr: 0.000100 | Loss: 0.8594 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 46.59
24-04-03 01:46:08.292 - INFO: Train epoch 389: [89600/94637 (95%)] Step: [2301516] | Lr: 0.000100 | Loss: 1.4030 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 49.41
24-04-03 01:46:42.385 - INFO: Train epoch 389: [91200/94637 (96%)] Step: [2301616] | Lr: 0.000100 | Loss: 1.7229 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 56.35
24-04-03 01:47:17.380 - INFO: Train epoch 389: [92800/94637 (98%)] Step: [2301716] | Lr: 0.000100 | Loss: 1.3270 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 51.56
24-04-03 01:47:52.713 - INFO: Train epoch 389: [94400/94637 (100%)] Step: [2301816] | Lr: 0.000100 | Loss: 1.1908 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 51.31
24-04-03 01:48:15.082 - INFO: Learning rate: 0.0001
24-04-03 01:48:16.079 - INFO: Train epoch 390: [    0/94637 (0%)] Step: [2301831] | Lr: 0.000100 | Loss: 1.8223 | MSE loss: 0.0005 | Bpp loss: 1.04 | Aux loss: 49.25
24-04-03 01:48:50.488 - INFO: Train epoch 390: [ 1600/94637 (2%)] Step: [2301931] | Lr: 0.000100 | Loss: 1.0949 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 51.61
24-04-03 01:49:24.511 - INFO: Train epoch 390: [ 3200/94637 (3%)] Step: [2302031] | Lr: 0.000100 | Loss: 1.6102 | MSE loss: 0.0004 | Bpp loss: 0.99 | Aux loss: 53.25
24-04-03 01:49:59.370 - INFO: Train epoch 390: [ 4800/94637 (5%)] Step: [2302131] | Lr: 0.000100 | Loss: 0.8527 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 51.03
24-04-03 01:50:33.632 - INFO: Train epoch 390: [ 6400/94637 (7%)] Step: [2302231] | Lr: 0.000100 | Loss: 1.3275 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 52.91
24-04-03 01:51:08.210 - INFO: Train epoch 390: [ 8000/94637 (8%)] Step: [2302331] | Lr: 0.000100 | Loss: 1.1962 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 54.18
24-04-03 01:51:42.735 - INFO: Train epoch 390: [ 9600/94637 (10%)] Step: [2302431] | Lr: 0.000100 | Loss: 1.2803 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 50.32
24-04-03 01:52:19.487 - INFO: Train epoch 390: [11200/94637 (12%)] Step: [2302531] | Lr: 0.000100 | Loss: 1.1419 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 54.22
24-04-03 01:52:54.631 - INFO: Train epoch 390: [12800/94637 (14%)] Step: [2302631] | Lr: 0.000100 | Loss: 1.6328 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 53.19
24-04-03 01:53:29.386 - INFO: Train epoch 390: [14400/94637 (15%)] Step: [2302731] | Lr: 0.000100 | Loss: 1.1188 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 53.87
24-04-03 01:54:03.881 - INFO: Train epoch 390: [16000/94637 (17%)] Step: [2302831] | Lr: 0.000100 | Loss: 0.9845 | MSE loss: 0.0003 | Bpp loss: 0.55 | Aux loss: 55.09
24-04-03 01:54:38.060 - INFO: Train epoch 390: [17600/94637 (19%)] Step: [2302931] | Lr: 0.000100 | Loss: 1.3839 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 54.89
24-04-03 01:55:12.965 - INFO: Train epoch 390: [19200/94637 (20%)] Step: [2303031] | Lr: 0.000100 | Loss: 1.2320 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 50.06
24-04-03 01:55:47.822 - INFO: Train epoch 390: [20800/94637 (22%)] Step: [2303131] | Lr: 0.000100 | Loss: 1.2032 | MSE loss: 0.0002 | Bpp loss: 0.82 | Aux loss: 53.41
24-04-03 01:56:22.374 - INFO: Train epoch 390: [22400/94637 (24%)] Step: [2303231] | Lr: 0.000100 | Loss: 1.0067 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 53.69
24-04-03 01:56:57.248 - INFO: Train epoch 390: [24000/94637 (25%)] Step: [2303331] | Lr: 0.000100 | Loss: 1.1860 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 56.68
24-04-03 01:57:31.576 - INFO: Train epoch 390: [25600/94637 (27%)] Step: [2303431] | Lr: 0.000100 | Loss: 0.9799 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 51.08
24-04-03 01:58:05.651 - INFO: Train epoch 390: [27200/94637 (29%)] Step: [2303531] | Lr: 0.000100 | Loss: 0.7704 | MSE loss: 0.0002 | Bpp loss: 0.47 | Aux loss: 55.59
24-04-03 01:58:40.458 - INFO: Train epoch 390: [28800/94637 (30%)] Step: [2303631] | Lr: 0.000100 | Loss: 1.2898 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 56.64
24-04-03 01:59:15.286 - INFO: Train epoch 390: [30400/94637 (32%)] Step: [2303731] | Lr: 0.000100 | Loss: 1.2995 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 60.38
24-04-03 01:59:49.857 - INFO: Train epoch 390: [32000/94637 (34%)] Step: [2303831] | Lr: 0.000100 | Loss: 1.2506 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 51.01
24-04-03 02:00:24.750 - INFO: Train epoch 390: [33600/94637 (36%)] Step: [2303931] | Lr: 0.000100 | Loss: 0.7431 | MSE loss: 0.0001 | Bpp loss: 0.50 | Aux loss: 53.89
24-04-03 02:00:59.559 - INFO: Train epoch 390: [35200/94637 (37%)] Step: [2304031] | Lr: 0.000100 | Loss: 0.9382 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 56.25
24-04-03 02:01:34.843 - INFO: Train epoch 390: [36800/94637 (39%)] Step: [2304131] | Lr: 0.000100 | Loss: 1.0561 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 57.15
24-04-03 02:02:10.414 - INFO: Train epoch 390: [38400/94637 (41%)] Step: [2304231] | Lr: 0.000100 | Loss: 0.8260 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 56.75
24-04-03 02:02:45.915 - INFO: Train epoch 390: [40000/94637 (42%)] Step: [2304331] | Lr: 0.000100 | Loss: 1.2525 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 57.09
24-04-03 02:03:21.086 - INFO: Train epoch 390: [41600/94637 (44%)] Step: [2304431] | Lr: 0.000100 | Loss: 1.1617 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 58.54
24-04-03 02:03:55.723 - INFO: Train epoch 390: [43200/94637 (46%)] Step: [2304531] | Lr: 0.000100 | Loss: 0.7719 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 52.71
24-04-03 02:04:30.113 - INFO: Train epoch 390: [44800/94637 (47%)] Step: [2304631] | Lr: 0.000100 | Loss: 1.3196 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 51.12
24-04-03 02:05:04.548 - INFO: Train epoch 390: [46400/94637 (49%)] Step: [2304731] | Lr: 0.000100 | Loss: 2.2848 | MSE loss: 0.0005 | Bpp loss: 1.41 | Aux loss: 51.72
24-04-03 02:05:39.599 - INFO: Train epoch 390: [48000/94637 (51%)] Step: [2304831] | Lr: 0.000100 | Loss: 1.4360 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 56.15
24-04-03 02:06:15.098 - INFO: Train epoch 390: [49600/94637 (52%)] Step: [2304931] | Lr: 0.000100 | Loss: 1.6481 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 53.23
24-04-03 02:06:52.313 - INFO: Train epoch 390: [51200/94637 (54%)] Step: [2305031] | Lr: 0.000100 | Loss: 1.0064 | MSE loss: 0.0003 | Bpp loss: 0.58 | Aux loss: 52.11
24-04-03 02:07:26.953 - INFO: Train epoch 390: [52800/94637 (56%)] Step: [2305131] | Lr: 0.000100 | Loss: 1.5583 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 51.32
24-04-03 02:08:01.855 - INFO: Train epoch 390: [54400/94637 (57%)] Step: [2305231] | Lr: 0.000100 | Loss: 0.9897 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 52.63
24-04-03 02:08:36.657 - INFO: Train epoch 390: [56000/94637 (59%)] Step: [2305331] | Lr: 0.000100 | Loss: 0.8860 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 58.06
24-04-03 02:09:11.149 - INFO: Train epoch 390: [57600/94637 (61%)] Step: [2305431] | Lr: 0.000100 | Loss: 0.9023 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 56.40
24-04-03 02:09:45.984 - INFO: Train epoch 390: [59200/94637 (63%)] Step: [2305531] | Lr: 0.000100 | Loss: 1.0952 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 51.00
24-04-03 02:10:20.358 - INFO: Train epoch 390: [60800/94637 (64%)] Step: [2305631] | Lr: 0.000100 | Loss: 1.5738 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 56.20
24-04-03 02:10:55.359 - INFO: Train epoch 390: [62400/94637 (66%)] Step: [2305731] | Lr: 0.000100 | Loss: 1.5797 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 56.36
24-04-03 02:11:30.888 - INFO: Train epoch 390: [64000/94637 (68%)] Step: [2305831] | Lr: 0.000100 | Loss: 0.9649 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 52.22
24-04-03 02:12:06.414 - INFO: Train epoch 390: [65600/94637 (69%)] Step: [2305931] | Lr: 0.000100 | Loss: 1.1753 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 52.92
24-04-03 02:12:41.149 - INFO: Train epoch 390: [67200/94637 (71%)] Step: [2306031] | Lr: 0.000100 | Loss: 1.3436 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 56.98
24-04-03 02:13:15.850 - INFO: Train epoch 390: [68800/94637 (73%)] Step: [2306131] | Lr: 0.000100 | Loss: 1.3484 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 56.51
24-04-03 02:13:50.860 - INFO: Train epoch 390: [70400/94637 (74%)] Step: [2306231] | Lr: 0.000100 | Loss: 1.4571 | MSE loss: 0.0004 | Bpp loss: 0.88 | Aux loss: 54.03
24-04-03 02:14:25.438 - INFO: Train epoch 390: [72000/94637 (76%)] Step: [2306331] | Lr: 0.000100 | Loss: 0.9622 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 50.99
24-04-03 02:15:00.913 - INFO: Train epoch 390: [73600/94637 (78%)] Step: [2306431] | Lr: 0.000100 | Loss: 1.2787 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 58.50
24-04-03 02:15:35.951 - INFO: Train epoch 390: [75200/94637 (79%)] Step: [2306531] | Lr: 0.000100 | Loss: 1.0070 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 54.81
24-04-03 02:16:10.815 - INFO: Train epoch 390: [76800/94637 (81%)] Step: [2306631] | Lr: 0.000100 | Loss: 1.1561 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 56.83
24-04-03 02:16:45.535 - INFO: Train epoch 390: [78400/94637 (83%)] Step: [2306731] | Lr: 0.000100 | Loss: 1.5787 | MSE loss: 0.0004 | Bpp loss: 0.86 | Aux loss: 61.86
24-04-03 02:17:20.470 - INFO: Train epoch 390: [80000/94637 (85%)] Step: [2306831] | Lr: 0.000100 | Loss: 1.0742 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 55.60
24-04-03 02:17:55.554 - INFO: Train epoch 390: [81600/94637 (86%)] Step: [2306931] | Lr: 0.000100 | Loss: 0.7346 | MSE loss: 0.0002 | Bpp loss: 0.46 | Aux loss: 56.32
24-04-03 02:18:29.852 - INFO: Train epoch 390: [83200/94637 (88%)] Step: [2307031] | Lr: 0.000100 | Loss: 0.8283 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 54.58
24-04-03 02:19:04.911 - INFO: Train epoch 390: [84800/94637 (90%)] Step: [2307131] | Lr: 0.000100 | Loss: 1.2395 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 53.12
24-04-03 02:19:40.605 - INFO: Train epoch 390: [86400/94637 (91%)] Step: [2307231] | Lr: 0.000100 | Loss: 0.8927 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 55.74
24-04-03 02:20:15.939 - INFO: Train epoch 390: [88000/94637 (93%)] Step: [2307331] | Lr: 0.000100 | Loss: 1.1646 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 54.31
24-04-03 02:20:50.997 - INFO: Train epoch 390: [89600/94637 (95%)] Step: [2307431] | Lr: 0.000100 | Loss: 1.7619 | MSE loss: 0.0004 | Bpp loss: 1.03 | Aux loss: 54.53
24-04-03 02:21:28.218 - INFO: Train epoch 390: [91200/94637 (96%)] Step: [2307531] | Lr: 0.000100 | Loss: 0.8264 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 54.82
24-04-03 02:22:02.957 - INFO: Train epoch 390: [92800/94637 (98%)] Step: [2307631] | Lr: 0.000100 | Loss: 1.1161 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 57.45
24-04-03 02:22:37.738 - INFO: Train epoch 390: [94400/94637 (100%)] Step: [2307731] | Lr: 0.000100 | Loss: 1.8178 | MSE loss: 0.0005 | Bpp loss: 1.03 | Aux loss: 54.81
24-04-03 02:22:54.141 - INFO: Learning rate: 0.0001
24-04-03 02:22:55.530 - INFO: Train epoch 391: [    0/94637 (0%)] Step: [2307746] | Lr: 0.000100 | Loss: 0.9772 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 52.17
24-04-03 02:23:29.490 - INFO: Train epoch 391: [ 1600/94637 (2%)] Step: [2307846] | Lr: 0.000100 | Loss: 1.0018 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 51.20
24-04-03 02:24:03.512 - INFO: Train epoch 391: [ 3200/94637 (3%)] Step: [2307946] | Lr: 0.000100 | Loss: 1.1391 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 56.73
24-04-03 02:24:37.706 - INFO: Train epoch 391: [ 4800/94637 (5%)] Step: [2308046] | Lr: 0.000100 | Loss: 0.9492 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 55.73
24-04-03 02:25:12.211 - INFO: Train epoch 391: [ 6400/94637 (7%)] Step: [2308146] | Lr: 0.000100 | Loss: 1.0040 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 53.25
24-04-03 02:25:48.177 - INFO: Train epoch 391: [ 8000/94637 (8%)] Step: [2308246] | Lr: 0.000100 | Loss: 1.6574 | MSE loss: 0.0004 | Bpp loss: 1.08 | Aux loss: 53.69
24-04-03 02:26:23.455 - INFO: Train epoch 391: [ 9600/94637 (10%)] Step: [2308346] | Lr: 0.000100 | Loss: 1.2607 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 57.16
24-04-03 02:26:58.504 - INFO: Train epoch 391: [11200/94637 (12%)] Step: [2308446] | Lr: 0.000100 | Loss: 1.1861 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 57.38
24-04-03 02:27:32.780 - INFO: Train epoch 391: [12800/94637 (14%)] Step: [2308546] | Lr: 0.000100 | Loss: 1.5456 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 52.27
24-04-03 02:28:06.206 - INFO: Train epoch 391: [14400/94637 (15%)] Step: [2308646] | Lr: 0.000100 | Loss: 1.5485 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 57.48
24-04-03 02:28:40.986 - INFO: Train epoch 391: [16000/94637 (17%)] Step: [2308746] | Lr: 0.000100 | Loss: 1.5377 | MSE loss: 0.0003 | Bpp loss: 1.00 | Aux loss: 51.94
24-04-03 02:29:15.648 - INFO: Train epoch 391: [17600/94637 (19%)] Step: [2308846] | Lr: 0.000100 | Loss: 0.9860 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 55.84
24-04-03 02:29:51.196 - INFO: Train epoch 391: [19200/94637 (20%)] Step: [2308946] | Lr: 0.000100 | Loss: 1.4571 | MSE loss: 0.0004 | Bpp loss: 0.88 | Aux loss: 56.31
24-04-03 02:30:26.934 - INFO: Train epoch 391: [20800/94637 (22%)] Step: [2309046] | Lr: 0.000100 | Loss: 1.0729 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 56.20
24-04-03 02:31:02.935 - INFO: Train epoch 391: [22400/94637 (24%)] Step: [2309146] | Lr: 0.000100 | Loss: 1.6230 | MSE loss: 0.0004 | Bpp loss: 0.99 | Aux loss: 56.52
24-04-03 02:31:37.950 - INFO: Train epoch 391: [24000/94637 (25%)] Step: [2309246] | Lr: 0.000100 | Loss: 1.0684 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 54.69
24-04-03 02:32:13.638 - INFO: Train epoch 391: [25600/94637 (27%)] Step: [2309346] | Lr: 0.000100 | Loss: 1.1739 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 57.44
24-04-03 02:32:49.268 - INFO: Train epoch 391: [27200/94637 (29%)] Step: [2309446] | Lr: 0.000100 | Loss: 1.0224 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 50.39
24-04-03 02:33:24.667 - INFO: Train epoch 391: [28800/94637 (30%)] Step: [2309546] | Lr: 0.000100 | Loss: 1.1185 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 57.43
24-04-03 02:34:00.115 - INFO: Train epoch 391: [30400/94637 (32%)] Step: [2309646] | Lr: 0.000100 | Loss: 1.0632 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 54.57
24-04-03 02:34:35.600 - INFO: Train epoch 391: [32000/94637 (34%)] Step: [2309746] | Lr: 0.000100 | Loss: 1.3615 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 56.53
24-04-03 02:35:10.613 - INFO: Train epoch 391: [33600/94637 (36%)] Step: [2309846] | Lr: 0.000100 | Loss: 1.5830 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 54.98
24-04-03 02:35:45.795 - INFO: Train epoch 391: [35200/94637 (37%)] Step: [2309946] | Lr: 0.000100 | Loss: 1.2741 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 52.97
24-04-03 02:36:23.226 - INFO: Train epoch 391: [36800/94637 (39%)] Step: [2310046] | Lr: 0.000100 | Loss: 0.7664 | MSE loss: 0.0002 | Bpp loss: 0.47 | Aux loss: 51.49
24-04-03 02:36:58.589 - INFO: Train epoch 391: [38400/94637 (41%)] Step: [2310146] | Lr: 0.000100 | Loss: 1.2965 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 56.30
24-04-03 02:37:34.397 - INFO: Train epoch 391: [40000/94637 (42%)] Step: [2310246] | Lr: 0.000100 | Loss: 1.1378 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 56.93
24-04-03 02:38:09.817 - INFO: Train epoch 391: [41600/94637 (44%)] Step: [2310346] | Lr: 0.000100 | Loss: 1.3087 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 57.45
24-04-03 02:38:45.912 - INFO: Train epoch 391: [43200/94637 (46%)] Step: [2310446] | Lr: 0.000100 | Loss: 1.0120 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 54.21
24-04-03 02:39:22.163 - INFO: Train epoch 391: [44800/94637 (47%)] Step: [2310546] | Lr: 0.000100 | Loss: 1.1734 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 53.82
24-04-03 02:39:57.608 - INFO: Train epoch 391: [46400/94637 (49%)] Step: [2310646] | Lr: 0.000100 | Loss: 1.5089 | MSE loss: 0.0003 | Bpp loss: 0.98 | Aux loss: 56.91
24-04-03 02:40:34.320 - INFO: Train epoch 391: [48000/94637 (51%)] Step: [2310746] | Lr: 0.000100 | Loss: 1.0328 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 54.28
24-04-03 02:41:10.247 - INFO: Train epoch 391: [49600/94637 (52%)] Step: [2310846] | Lr: 0.000100 | Loss: 1.7979 | MSE loss: 0.0005 | Bpp loss: 1.06 | Aux loss: 57.16
24-04-03 02:41:46.126 - INFO: Train epoch 391: [51200/94637 (54%)] Step: [2310946] | Lr: 0.000100 | Loss: 0.8832 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 53.15
24-04-03 02:42:21.457 - INFO: Train epoch 391: [52800/94637 (56%)] Step: [2311046] | Lr: 0.000100 | Loss: 1.1079 | MSE loss: 0.0003 | Bpp loss: 0.62 | Aux loss: 52.40
24-04-03 02:42:55.960 - INFO: Train epoch 391: [54400/94637 (57%)] Step: [2311146] | Lr: 0.000100 | Loss: 1.1830 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 57.09
24-04-03 02:43:30.553 - INFO: Train epoch 391: [56000/94637 (59%)] Step: [2311246] | Lr: 0.000100 | Loss: 1.4134 | MSE loss: 0.0004 | Bpp loss: 0.81 | Aux loss: 55.13
24-04-03 02:44:04.928 - INFO: Train epoch 391: [57600/94637 (61%)] Step: [2311346] | Lr: 0.000100 | Loss: 1.2390 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 56.53
24-04-03 02:44:39.405 - INFO: Train epoch 391: [59200/94637 (63%)] Step: [2311446] | Lr: 0.000100 | Loss: 1.2266 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 56.95
24-04-03 02:45:14.555 - INFO: Train epoch 391: [60800/94637 (64%)] Step: [2311546] | Lr: 0.000100 | Loss: 1.6160 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 53.36
24-04-03 02:45:49.658 - INFO: Train epoch 391: [62400/94637 (66%)] Step: [2311646] | Lr: 0.000100 | Loss: 1.0749 | MSE loss: 0.0003 | Bpp loss: 0.60 | Aux loss: 54.40
24-04-03 02:46:24.841 - INFO: Train epoch 391: [64000/94637 (68%)] Step: [2311746] | Lr: 0.000100 | Loss: 1.9615 | MSE loss: 0.0005 | Bpp loss: 1.20 | Aux loss: 60.05
24-04-03 02:47:00.180 - INFO: Train epoch 391: [65600/94637 (69%)] Step: [2311846] | Lr: 0.000100 | Loss: 0.8643 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 52.81
24-04-03 02:47:34.760 - INFO: Train epoch 391: [67200/94637 (71%)] Step: [2311946] | Lr: 0.000100 | Loss: 1.1494 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 58.10
24-04-03 02:48:10.481 - INFO: Train epoch 391: [68800/94637 (73%)] Step: [2312046] | Lr: 0.000100 | Loss: 1.1015 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 56.43
24-04-03 02:48:45.335 - INFO: Train epoch 391: [70400/94637 (74%)] Step: [2312146] | Lr: 0.000100 | Loss: 1.1977 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 53.75
24-04-03 02:49:20.285 - INFO: Train epoch 391: [72000/94637 (76%)] Step: [2312246] | Lr: 0.000100 | Loss: 0.8788 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 55.48
24-04-03 02:49:56.554 - INFO: Train epoch 391: [73600/94637 (78%)] Step: [2312346] | Lr: 0.000100 | Loss: 1.4213 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 53.58
24-04-03 02:50:32.099 - INFO: Train epoch 391: [75200/94637 (79%)] Step: [2312446] | Lr: 0.000100 | Loss: 0.8614 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 54.47
24-04-03 02:51:10.631 - INFO: Train epoch 391: [76800/94637 (81%)] Step: [2312546] | Lr: 0.000100 | Loss: 1.4951 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 52.44
24-04-03 02:51:46.403 - INFO: Train epoch 391: [78400/94637 (83%)] Step: [2312646] | Lr: 0.000100 | Loss: 0.8900 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 51.09
24-04-03 02:52:22.125 - INFO: Train epoch 391: [80000/94637 (85%)] Step: [2312746] | Lr: 0.000100 | Loss: 0.9205 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 56.29
24-04-03 02:52:57.619 - INFO: Train epoch 391: [81600/94637 (86%)] Step: [2312846] | Lr: 0.000100 | Loss: 1.4183 | MSE loss: 0.0004 | Bpp loss: 0.75 | Aux loss: 56.64
24-04-03 02:53:32.573 - INFO: Train epoch 391: [83200/94637 (88%)] Step: [2312946] | Lr: 0.000100 | Loss: 1.8371 | MSE loss: 0.0004 | Bpp loss: 1.18 | Aux loss: 57.44
24-04-03 02:54:08.060 - INFO: Train epoch 391: [84800/94637 (90%)] Step: [2313046] | Lr: 0.000100 | Loss: 1.4936 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 53.71
24-04-03 02:54:42.540 - INFO: Train epoch 391: [86400/94637 (91%)] Step: [2313146] | Lr: 0.000100 | Loss: 1.0764 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 54.97
24-04-03 02:55:17.135 - INFO: Train epoch 391: [88000/94637 (93%)] Step: [2313246] | Lr: 0.000100 | Loss: 1.4817 | MSE loss: 0.0003 | Bpp loss: 0.96 | Aux loss: 52.38
24-04-03 02:55:52.738 - INFO: Train epoch 391: [89600/94637 (95%)] Step: [2313346] | Lr: 0.000100 | Loss: 0.7984 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 54.52
24-04-03 02:56:27.178 - INFO: Train epoch 391: [91200/94637 (96%)] Step: [2313446] | Lr: 0.000100 | Loss: 0.9937 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 55.57
24-04-03 02:57:00.523 - INFO: Train epoch 391: [92800/94637 (98%)] Step: [2313546] | Lr: 0.000100 | Loss: 0.8618 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 55.55
24-04-03 02:57:34.161 - INFO: Train epoch 391: [94400/94637 (100%)] Step: [2313646] | Lr: 0.000100 | Loss: 1.3870 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 56.62
24-04-03 02:57:51.140 - INFO: Learning rate: 0.0001
24-04-03 02:57:52.033 - INFO: Train epoch 392: [    0/94637 (0%)] Step: [2313661] | Lr: 0.000100 | Loss: 0.9827 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 56.93
24-04-03 02:58:26.938 - INFO: Train epoch 392: [ 1600/94637 (2%)] Step: [2313761] | Lr: 0.000100 | Loss: 0.8890 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 54.57
24-04-03 02:59:02.397 - INFO: Train epoch 392: [ 3200/94637 (3%)] Step: [2313861] | Lr: 0.000100 | Loss: 0.9814 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 54.09
24-04-03 02:59:37.311 - INFO: Train epoch 392: [ 4800/94637 (5%)] Step: [2313961] | Lr: 0.000100 | Loss: 1.5737 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 51.42
24-04-03 03:00:10.683 - INFO: Train epoch 392: [ 6400/94637 (7%)] Step: [2314061] | Lr: 0.000100 | Loss: 1.1629 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 53.23
24-04-03 03:00:44.892 - INFO: Train epoch 392: [ 8000/94637 (8%)] Step: [2314161] | Lr: 0.000100 | Loss: 0.9241 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 55.82
24-04-03 03:01:19.667 - INFO: Train epoch 392: [ 9600/94637 (10%)] Step: [2314261] | Lr: 0.000100 | Loss: 1.0990 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 59.09
24-04-03 03:01:53.913 - INFO: Train epoch 392: [11200/94637 (12%)] Step: [2314361] | Lr: 0.000100 | Loss: 0.9292 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 58.25
24-04-03 03:02:28.875 - INFO: Train epoch 392: [12800/94637 (14%)] Step: [2314461] | Lr: 0.000100 | Loss: 0.8352 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 58.89
24-04-03 03:03:03.984 - INFO: Train epoch 392: [14400/94637 (15%)] Step: [2314561] | Lr: 0.000100 | Loss: 1.4296 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 51.30
24-04-03 03:03:39.115 - INFO: Train epoch 392: [16000/94637 (17%)] Step: [2314661] | Lr: 0.000100 | Loss: 0.8687 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 56.43
24-04-03 03:04:14.312 - INFO: Train epoch 392: [17600/94637 (19%)] Step: [2314761] | Lr: 0.000100 | Loss: 0.7634 | MSE loss: 0.0002 | Bpp loss: 0.47 | Aux loss: 55.05
24-04-03 03:04:49.527 - INFO: Train epoch 392: [19200/94637 (20%)] Step: [2314861] | Lr: 0.000100 | Loss: 1.2449 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 55.42
24-04-03 03:05:24.665 - INFO: Train epoch 392: [20800/94637 (22%)] Step: [2314961] | Lr: 0.000100 | Loss: 1.5357 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 57.33
24-04-03 03:06:01.665 - INFO: Train epoch 392: [22400/94637 (24%)] Step: [2315061] | Lr: 0.000100 | Loss: 1.3120 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 58.37
24-04-03 03:06:37.118 - INFO: Train epoch 392: [24000/94637 (25%)] Step: [2315161] | Lr: 0.000100 | Loss: 0.9381 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 56.24
24-04-03 03:07:13.749 - INFO: Train epoch 392: [25600/94637 (27%)] Step: [2315261] | Lr: 0.000100 | Loss: 0.9041 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 54.57
24-04-03 03:07:47.766 - INFO: Train epoch 392: [27200/94637 (29%)] Step: [2315361] | Lr: 0.000100 | Loss: 1.6036 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 56.15
24-04-03 03:08:21.975 - INFO: Train epoch 392: [28800/94637 (30%)] Step: [2315461] | Lr: 0.000100 | Loss: 1.2612 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 57.29
24-04-03 03:08:58.025 - INFO: Train epoch 392: [30400/94637 (32%)] Step: [2315561] | Lr: 0.000100 | Loss: 1.4892 | MSE loss: 0.0003 | Bpp loss: 0.99 | Aux loss: 53.49
24-04-03 03:09:34.517 - INFO: Train epoch 392: [32000/94637 (34%)] Step: [2315661] | Lr: 0.000100 | Loss: 0.7453 | MSE loss: 0.0001 | Bpp loss: 0.50 | Aux loss: 58.89
24-04-03 03:10:09.809 - INFO: Train epoch 392: [33600/94637 (36%)] Step: [2315761] | Lr: 0.000100 | Loss: 0.5819 | MSE loss: 0.0001 | Bpp loss: 0.40 | Aux loss: 56.67
24-04-03 03:10:44.570 - INFO: Train epoch 392: [35200/94637 (37%)] Step: [2315861] | Lr: 0.000100 | Loss: 1.1947 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 51.70
24-04-03 03:11:19.960 - INFO: Train epoch 392: [36800/94637 (39%)] Step: [2315961] | Lr: 0.000100 | Loss: 0.6660 | MSE loss: 0.0002 | Bpp loss: 0.42 | Aux loss: 58.96
24-04-03 03:11:55.373 - INFO: Train epoch 392: [38400/94637 (41%)] Step: [2316061] | Lr: 0.000100 | Loss: 1.2421 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 52.66
24-04-03 03:12:31.205 - INFO: Train epoch 392: [40000/94637 (42%)] Step: [2316161] | Lr: 0.000100 | Loss: 1.8744 | MSE loss: 0.0004 | Bpp loss: 1.15 | Aux loss: 54.12
24-04-03 03:13:07.583 - INFO: Train epoch 392: [41600/94637 (44%)] Step: [2316261] | Lr: 0.000100 | Loss: 1.0564 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 57.18
24-04-03 03:13:43.376 - INFO: Train epoch 392: [43200/94637 (46%)] Step: [2316361] | Lr: 0.000100 | Loss: 1.0405 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 54.70
24-04-03 03:14:17.945 - INFO: Train epoch 392: [44800/94637 (47%)] Step: [2316461] | Lr: 0.000100 | Loss: 0.6177 | MSE loss: 0.0001 | Bpp loss: 0.43 | Aux loss: 59.38
24-04-03 03:14:53.332 - INFO: Train epoch 392: [46400/94637 (49%)] Step: [2316561] | Lr: 0.000100 | Loss: 1.7107 | MSE loss: 0.0004 | Bpp loss: 1.03 | Aux loss: 53.05
24-04-03 03:15:28.977 - INFO: Train epoch 392: [48000/94637 (51%)] Step: [2316661] | Lr: 0.000100 | Loss: 1.3704 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 54.94
24-04-03 03:16:04.019 - INFO: Train epoch 392: [49600/94637 (52%)] Step: [2316761] | Lr: 0.000100 | Loss: 1.0115 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 57.60
24-04-03 03:16:38.863 - INFO: Train epoch 392: [51200/94637 (54%)] Step: [2316861] | Lr: 0.000100 | Loss: 1.2099 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 56.95
24-04-03 03:17:12.678 - INFO: Train epoch 392: [52800/94637 (56%)] Step: [2316961] | Lr: 0.000100 | Loss: 1.3022 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 54.86
24-04-03 03:17:46.590 - INFO: Train epoch 392: [54400/94637 (57%)] Step: [2317061] | Lr: 0.000100 | Loss: 1.0647 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 55.80
24-04-03 03:18:21.550 - INFO: Train epoch 392: [56000/94637 (59%)] Step: [2317161] | Lr: 0.000100 | Loss: 1.1577 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 50.50
24-04-03 03:18:56.075 - INFO: Train epoch 392: [57600/94637 (61%)] Step: [2317261] | Lr: 0.000100 | Loss: 0.7231 | MSE loss: 0.0001 | Bpp loss: 0.49 | Aux loss: 56.94
24-04-03 03:19:29.970 - INFO: Train epoch 392: [59200/94637 (63%)] Step: [2317361] | Lr: 0.000100 | Loss: 0.9554 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 56.83
24-04-03 03:20:04.188 - INFO: Train epoch 392: [60800/94637 (64%)] Step: [2317461] | Lr: 0.000100 | Loss: 1.3752 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 54.46
24-04-03 03:20:40.422 - INFO: Train epoch 392: [62400/94637 (66%)] Step: [2317561] | Lr: 0.000100 | Loss: 1.2757 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 56.80
24-04-03 03:21:16.292 - INFO: Train epoch 392: [64000/94637 (68%)] Step: [2317661] | Lr: 0.000100 | Loss: 1.2202 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 55.26
24-04-03 03:21:52.407 - INFO: Train epoch 392: [65600/94637 (69%)] Step: [2317761] | Lr: 0.000100 | Loss: 1.0064 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 57.58
24-04-03 03:22:27.353 - INFO: Train epoch 392: [67200/94637 (71%)] Step: [2317861] | Lr: 0.000100 | Loss: 1.0513 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 54.07
24-04-03 03:23:02.256 - INFO: Train epoch 392: [68800/94637 (73%)] Step: [2317961] | Lr: 0.000100 | Loss: 1.2971 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 56.20
24-04-03 03:23:37.470 - INFO: Train epoch 392: [70400/94637 (74%)] Step: [2318061] | Lr: 0.000100 | Loss: 1.1925 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 57.14
24-04-03 03:24:13.566 - INFO: Train epoch 392: [72000/94637 (76%)] Step: [2318161] | Lr: 0.000100 | Loss: 1.3356 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 54.74
24-04-03 03:24:48.897 - INFO: Train epoch 392: [73600/94637 (78%)] Step: [2318261] | Lr: 0.000100 | Loss: 1.6562 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 56.62
24-04-03 03:25:22.830 - INFO: Train epoch 392: [75200/94637 (79%)] Step: [2318361] | Lr: 0.000100 | Loss: 1.3186 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 54.58
24-04-03 03:25:58.058 - INFO: Train epoch 392: [76800/94637 (81%)] Step: [2318461] | Lr: 0.000100 | Loss: 0.9704 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 56.71
24-04-03 03:26:33.719 - INFO: Train epoch 392: [78400/94637 (83%)] Step: [2318561] | Lr: 0.000100 | Loss: 1.4832 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 59.15
24-04-03 03:27:10.048 - INFO: Train epoch 392: [80000/94637 (85%)] Step: [2318661] | Lr: 0.000100 | Loss: 1.0008 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 55.48
24-04-03 03:27:45.646 - INFO: Train epoch 392: [81600/94637 (86%)] Step: [2318761] | Lr: 0.000100 | Loss: 1.1868 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 58.53
24-04-03 03:28:21.809 - INFO: Train epoch 392: [83200/94637 (88%)] Step: [2318861] | Lr: 0.000100 | Loss: 1.3341 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 58.56
24-04-03 03:28:57.056 - INFO: Train epoch 392: [84800/94637 (90%)] Step: [2318961] | Lr: 0.000100 | Loss: 1.3530 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 59.47
24-04-03 03:29:33.322 - INFO: Train epoch 392: [86400/94637 (91%)] Step: [2319061] | Lr: 0.000100 | Loss: 2.0384 | MSE loss: 0.0005 | Bpp loss: 1.25 | Aux loss: 57.85
24-04-03 03:30:08.903 - INFO: Train epoch 392: [88000/94637 (93%)] Step: [2319161] | Lr: 0.000100 | Loss: 1.2507 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 57.89
24-04-03 03:30:44.934 - INFO: Train epoch 392: [89600/94637 (95%)] Step: [2319261] | Lr: 0.000100 | Loss: 1.1342 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 58.36
24-04-03 03:31:20.911 - INFO: Train epoch 392: [91200/94637 (96%)] Step: [2319361] | Lr: 0.000100 | Loss: 1.0334 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 57.40
24-04-03 03:31:56.400 - INFO: Train epoch 392: [92800/94637 (98%)] Step: [2319461] | Lr: 0.000100 | Loss: 1.1449 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 59.24
24-04-03 03:32:31.743 - INFO: Train epoch 392: [94400/94637 (100%)] Step: [2319561] | Lr: 0.000100 | Loss: 1.3608 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 55.46
24-04-03 03:32:54.255 - INFO: Learning rate: 0.0001
24-04-03 03:32:55.131 - INFO: Train epoch 393: [    0/94637 (0%)] Step: [2319576] | Lr: 0.000100 | Loss: 1.6215 | MSE loss: 0.0004 | Bpp loss: 1.05 | Aux loss: 63.31
24-04-03 03:33:30.634 - INFO: Train epoch 393: [ 1600/94637 (2%)] Step: [2319676] | Lr: 0.000100 | Loss: 0.8683 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 61.17
24-04-03 03:34:05.164 - INFO: Train epoch 393: [ 3200/94637 (3%)] Step: [2319776] | Lr: 0.000100 | Loss: 1.7921 | MSE loss: 0.0004 | Bpp loss: 1.09 | Aux loss: 54.55
24-04-03 03:34:39.285 - INFO: Train epoch 393: [ 4800/94637 (5%)] Step: [2319876] | Lr: 0.000100 | Loss: 1.3794 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 59.08
24-04-03 03:35:13.444 - INFO: Train epoch 393: [ 6400/94637 (7%)] Step: [2319976] | Lr: 0.000100 | Loss: 1.3719 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 59.68
24-04-03 03:35:48.850 - INFO: Train epoch 393: [ 8000/94637 (8%)] Step: [2320076] | Lr: 0.000100 | Loss: 1.1259 | MSE loss: 0.0002 | Bpp loss: 0.77 | Aux loss: 60.89
24-04-03 03:36:22.288 - INFO: Train epoch 393: [ 9600/94637 (10%)] Step: [2320176] | Lr: 0.000100 | Loss: 1.4626 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 62.02
24-04-03 03:36:54.801 - INFO: Train epoch 393: [11200/94637 (12%)] Step: [2320276] | Lr: 0.000100 | Loss: 1.1566 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 58.40
24-04-03 03:37:29.193 - INFO: Train epoch 393: [12800/94637 (14%)] Step: [2320376] | Lr: 0.000100 | Loss: 0.7360 | MSE loss: 0.0002 | Bpp loss: 0.43 | Aux loss: 55.95
24-04-03 03:38:02.997 - INFO: Train epoch 393: [14400/94637 (15%)] Step: [2320476] | Lr: 0.000100 | Loss: 1.5036 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 58.77
24-04-03 03:38:36.812 - INFO: Train epoch 393: [16000/94637 (17%)] Step: [2320576] | Lr: 0.000100 | Loss: 0.7891 | MSE loss: 0.0002 | Bpp loss: 0.48 | Aux loss: 55.13
24-04-03 03:39:11.442 - INFO: Train epoch 393: [17600/94637 (19%)] Step: [2320676] | Lr: 0.000100 | Loss: 1.1596 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 59.52
24-04-03 03:39:46.753 - INFO: Train epoch 393: [19200/94637 (20%)] Step: [2320776] | Lr: 0.000100 | Loss: 1.0740 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 58.36
24-04-03 03:40:22.578 - INFO: Train epoch 393: [20800/94637 (22%)] Step: [2320876] | Lr: 0.000100 | Loss: 1.4572 | MSE loss: 0.0004 | Bpp loss: 0.85 | Aux loss: 54.43
24-04-03 03:40:57.439 - INFO: Train epoch 393: [22400/94637 (24%)] Step: [2320976] | Lr: 0.000100 | Loss: 1.6357 | MSE loss: 0.0004 | Bpp loss: 0.99 | Aux loss: 54.69
24-04-03 03:41:33.233 - INFO: Train epoch 393: [24000/94637 (25%)] Step: [2321076] | Lr: 0.000100 | Loss: 1.8655 | MSE loss: 0.0005 | Bpp loss: 1.10 | Aux loss: 58.55
24-04-03 03:42:08.922 - INFO: Train epoch 393: [25600/94637 (27%)] Step: [2321176] | Lr: 0.000100 | Loss: 1.9064 | MSE loss: 0.0005 | Bpp loss: 1.14 | Aux loss: 60.99
24-04-03 03:42:44.379 - INFO: Train epoch 393: [27200/94637 (29%)] Step: [2321276] | Lr: 0.000100 | Loss: 1.0108 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 52.01
24-04-03 03:43:20.152 - INFO: Train epoch 393: [28800/94637 (30%)] Step: [2321376] | Lr: 0.000100 | Loss: 1.1647 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 59.41
24-04-03 03:43:55.208 - INFO: Train epoch 393: [30400/94637 (32%)] Step: [2321476] | Lr: 0.000100 | Loss: 1.1966 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 58.31
24-04-03 03:44:30.610 - INFO: Train epoch 393: [32000/94637 (34%)] Step: [2321576] | Lr: 0.000100 | Loss: 1.2496 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 54.82
24-04-03 03:45:04.306 - INFO: Train epoch 393: [33600/94637 (36%)] Step: [2321676] | Lr: 0.000100 | Loss: 1.2263 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 54.89
24-04-03 03:45:38.928 - INFO: Train epoch 393: [35200/94637 (37%)] Step: [2321776] | Lr: 0.000100 | Loss: 1.4069 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 58.10
24-04-03 03:46:14.216 - INFO: Train epoch 393: [36800/94637 (39%)] Step: [2321876] | Lr: 0.000100 | Loss: 1.4975 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 54.56
24-04-03 03:46:50.288 - INFO: Train epoch 393: [38400/94637 (41%)] Step: [2321976] | Lr: 0.000100 | Loss: 1.0122 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 60.58
24-04-03 03:47:25.335 - INFO: Train epoch 393: [40000/94637 (42%)] Step: [2322076] | Lr: 0.000100 | Loss: 1.3121 | MSE loss: 0.0004 | Bpp loss: 0.73 | Aux loss: 62.39
24-04-03 03:47:59.995 - INFO: Train epoch 393: [41600/94637 (44%)] Step: [2322176] | Lr: 0.000100 | Loss: 1.1170 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 58.07
24-04-03 03:48:36.536 - INFO: Train epoch 393: [43200/94637 (46%)] Step: [2322276] | Lr: 0.000100 | Loss: 1.4573 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 56.27
24-04-03 03:49:12.296 - INFO: Train epoch 393: [44800/94637 (47%)] Step: [2322376] | Lr: 0.000100 | Loss: 0.8764 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 55.48
24-04-03 03:49:47.326 - INFO: Train epoch 393: [46400/94637 (49%)] Step: [2322476] | Lr: 0.000100 | Loss: 1.0754 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 61.96
24-04-03 03:50:24.572 - INFO: Train epoch 393: [48000/94637 (51%)] Step: [2322576] | Lr: 0.000100 | Loss: 0.9549 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 58.38
24-04-03 03:50:59.343 - INFO: Train epoch 393: [49600/94637 (52%)] Step: [2322676] | Lr: 0.000100 | Loss: 0.6986 | MSE loss: 0.0002 | Bpp loss: 0.44 | Aux loss: 55.99
24-04-03 03:51:34.018 - INFO: Train epoch 393: [51200/94637 (54%)] Step: [2322776] | Lr: 0.000100 | Loss: 1.0041 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 58.32
24-04-03 03:52:09.174 - INFO: Train epoch 393: [52800/94637 (56%)] Step: [2322876] | Lr: 0.000100 | Loss: 0.9295 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 57.31
24-04-03 03:52:44.498 - INFO: Train epoch 393: [54400/94637 (57%)] Step: [2322976] | Lr: 0.000100 | Loss: 1.3887 | MSE loss: 0.0004 | Bpp loss: 0.81 | Aux loss: 58.03
24-04-03 03:53:19.102 - INFO: Train epoch 393: [56000/94637 (59%)] Step: [2323076] | Lr: 0.000100 | Loss: 1.0654 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 61.66
24-04-03 03:53:55.152 - INFO: Train epoch 393: [57600/94637 (61%)] Step: [2323176] | Lr: 0.000100 | Loss: 1.4932 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 57.80
24-04-03 03:54:30.321 - INFO: Train epoch 393: [59200/94637 (63%)] Step: [2323276] | Lr: 0.000100 | Loss: 1.0965 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 61.89
24-04-03 03:55:05.836 - INFO: Train epoch 393: [60800/94637 (64%)] Step: [2323376] | Lr: 0.000100 | Loss: 1.0545 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 51.03
24-04-03 03:55:42.025 - INFO: Train epoch 393: [62400/94637 (66%)] Step: [2323476] | Lr: 0.000100 | Loss: 0.9752 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 54.87
24-04-03 03:56:16.856 - INFO: Train epoch 393: [64000/94637 (68%)] Step: [2323576] | Lr: 0.000100 | Loss: 1.7676 | MSE loss: 0.0004 | Bpp loss: 1.14 | Aux loss: 57.34
24-04-03 03:56:51.754 - INFO: Train epoch 393: [65600/94637 (69%)] Step: [2323676] | Lr: 0.000100 | Loss: 1.0378 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 57.85
24-04-03 03:57:27.337 - INFO: Train epoch 393: [67200/94637 (71%)] Step: [2323776] | Lr: 0.000100 | Loss: 1.3175 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 55.05
24-04-03 03:58:03.160 - INFO: Train epoch 393: [68800/94637 (73%)] Step: [2323876] | Lr: 0.000100 | Loss: 2.1225 | MSE loss: 0.0005 | Bpp loss: 1.27 | Aux loss: 54.88
24-04-03 03:58:38.504 - INFO: Train epoch 393: [70400/94637 (74%)] Step: [2323976] | Lr: 0.000100 | Loss: 1.3777 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 55.65
24-04-03 03:59:13.768 - INFO: Train epoch 393: [72000/94637 (76%)] Step: [2324076] | Lr: 0.000100 | Loss: 0.7217 | MSE loss: 0.0002 | Bpp loss: 0.47 | Aux loss: 57.31
24-04-03 03:59:49.208 - INFO: Train epoch 393: [73600/94637 (78%)] Step: [2324176] | Lr: 0.000100 | Loss: 1.1952 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 54.41
24-04-03 04:00:23.604 - INFO: Train epoch 393: [75200/94637 (79%)] Step: [2324276] | Lr: 0.000100 | Loss: 0.9235 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 54.87
24-04-03 04:00:58.837 - INFO: Train epoch 393: [76800/94637 (81%)] Step: [2324376] | Lr: 0.000100 | Loss: 0.7879 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 53.66
24-04-03 04:01:34.806 - INFO: Train epoch 393: [78400/94637 (83%)] Step: [2324476] | Lr: 0.000100 | Loss: 1.4927 | MSE loss: 0.0003 | Bpp loss: 0.97 | Aux loss: 59.97
24-04-03 04:02:10.615 - INFO: Train epoch 393: [80000/94637 (85%)] Step: [2324576] | Lr: 0.000100 | Loss: 1.8702 | MSE loss: 0.0004 | Bpp loss: 1.17 | Aux loss: 59.29
24-04-03 04:02:46.119 - INFO: Train epoch 393: [81600/94637 (86%)] Step: [2324676] | Lr: 0.000100 | Loss: 1.4119 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 58.65
24-04-03 04:03:21.838 - INFO: Train epoch 393: [83200/94637 (88%)] Step: [2324776] | Lr: 0.000100 | Loss: 0.5976 | MSE loss: 0.0001 | Bpp loss: 0.40 | Aux loss: 60.13
24-04-03 04:03:56.947 - INFO: Train epoch 393: [84800/94637 (90%)] Step: [2324876] | Lr: 0.000100 | Loss: 1.0368 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 58.50
24-04-03 04:04:31.987 - INFO: Train epoch 393: [86400/94637 (91%)] Step: [2324976] | Lr: 0.000100 | Loss: 1.1476 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 59.32
24-04-03 04:05:08.006 - INFO: Train epoch 393: [88000/94637 (93%)] Step: [2325076] | Lr: 0.000100 | Loss: 0.8708 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 62.37
24-04-03 04:05:43.781 - INFO: Train epoch 393: [89600/94637 (95%)] Step: [2325176] | Lr: 0.000100 | Loss: 0.9520 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 55.39
24-04-03 04:06:19.138 - INFO: Train epoch 393: [91200/94637 (96%)] Step: [2325276] | Lr: 0.000100 | Loss: 1.5264 | MSE loss: 0.0003 | Bpp loss: 0.98 | Aux loss: 54.63
24-04-03 04:06:54.744 - INFO: Train epoch 393: [92800/94637 (98%)] Step: [2325376] | Lr: 0.000100 | Loss: 0.8401 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 56.69
24-04-03 04:07:27.854 - INFO: Train epoch 393: [94400/94637 (100%)] Step: [2325476] | Lr: 0.000100 | Loss: 1.4427 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 55.16
24-04-03 04:07:44.890 - INFO: Learning rate: 0.0001
24-04-03 04:07:45.780 - INFO: Train epoch 394: [    0/94637 (0%)] Step: [2325491] | Lr: 0.000100 | Loss: 1.2010 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 56.88
24-04-03 04:08:19.905 - INFO: Train epoch 394: [ 1600/94637 (2%)] Step: [2325591] | Lr: 0.000100 | Loss: 1.3177 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 60.25
24-04-03 04:08:55.692 - INFO: Train epoch 394: [ 3200/94637 (3%)] Step: [2325691] | Lr: 0.000100 | Loss: 1.1802 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 59.86
24-04-03 04:09:31.019 - INFO: Train epoch 394: [ 4800/94637 (5%)] Step: [2325791] | Lr: 0.000100 | Loss: 1.1134 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 56.69
24-04-03 04:10:05.351 - INFO: Train epoch 394: [ 6400/94637 (7%)] Step: [2325891] | Lr: 0.000100 | Loss: 1.0321 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 57.72
24-04-03 04:10:40.406 - INFO: Train epoch 394: [ 8000/94637 (8%)] Step: [2325991] | Lr: 0.000100 | Loss: 0.8840 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 57.14
24-04-03 04:11:15.844 - INFO: Train epoch 394: [ 9600/94637 (10%)] Step: [2326091] | Lr: 0.000100 | Loss: 0.9897 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 56.37
24-04-03 04:11:50.025 - INFO: Train epoch 394: [11200/94637 (12%)] Step: [2326191] | Lr: 0.000100 | Loss: 1.4862 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 56.73
24-04-03 04:12:25.745 - INFO: Train epoch 394: [12800/94637 (14%)] Step: [2326291] | Lr: 0.000100 | Loss: 1.2484 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 56.61
24-04-03 04:13:01.678 - INFO: Train epoch 394: [14400/94637 (15%)] Step: [2326391] | Lr: 0.000100 | Loss: 0.8201 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 56.97
24-04-03 04:13:36.199 - INFO: Train epoch 394: [16000/94637 (17%)] Step: [2326491] | Lr: 0.000100 | Loss: 1.2097 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 54.34
24-04-03 04:14:11.336 - INFO: Train epoch 394: [17600/94637 (19%)] Step: [2326591] | Lr: 0.000100 | Loss: 1.6200 | MSE loss: 0.0004 | Bpp loss: 0.93 | Aux loss: 56.52
24-04-03 04:14:46.375 - INFO: Train epoch 394: [19200/94637 (20%)] Step: [2326691] | Lr: 0.000100 | Loss: 1.1164 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 55.51
24-04-03 04:15:21.489 - INFO: Train epoch 394: [20800/94637 (22%)] Step: [2326791] | Lr: 0.000100 | Loss: 0.9103 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 56.05
24-04-03 04:15:57.585 - INFO: Train epoch 394: [22400/94637 (24%)] Step: [2326891] | Lr: 0.000100 | Loss: 0.9176 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 53.42
24-04-03 04:16:32.950 - INFO: Train epoch 394: [24000/94637 (25%)] Step: [2326991] | Lr: 0.000100 | Loss: 0.9777 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 53.58
24-04-03 04:17:06.596 - INFO: Train epoch 394: [25600/94637 (27%)] Step: [2327091] | Lr: 0.000100 | Loss: 1.1857 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 52.83
24-04-03 04:17:42.081 - INFO: Train epoch 394: [27200/94637 (29%)] Step: [2327191] | Lr: 0.000100 | Loss: 1.3738 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 55.35
24-04-03 04:18:16.312 - INFO: Train epoch 394: [28800/94637 (30%)] Step: [2327291] | Lr: 0.000100 | Loss: 1.5928 | MSE loss: 0.0004 | Bpp loss: 0.99 | Aux loss: 55.04
24-04-03 04:18:50.745 - INFO: Train epoch 394: [30400/94637 (32%)] Step: [2327391] | Lr: 0.000100 | Loss: 1.1295 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 51.57
24-04-03 04:19:25.681 - INFO: Train epoch 394: [32000/94637 (34%)] Step: [2327491] | Lr: 0.000100 | Loss: 1.0176 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 50.90
24-04-03 04:20:02.297 - INFO: Train epoch 394: [33600/94637 (36%)] Step: [2327591] | Lr: 0.000100 | Loss: 0.9449 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 55.48
24-04-03 04:20:36.781 - INFO: Train epoch 394: [35200/94637 (37%)] Step: [2327691] | Lr: 0.000100 | Loss: 1.2925 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 49.26
24-04-03 04:21:12.051 - INFO: Train epoch 394: [36800/94637 (39%)] Step: [2327791] | Lr: 0.000100 | Loss: 1.1320 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 56.59
24-04-03 04:21:46.810 - INFO: Train epoch 394: [38400/94637 (41%)] Step: [2327891] | Lr: 0.000100 | Loss: 1.1904 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 54.43
24-04-03 04:22:21.457 - INFO: Train epoch 394: [40000/94637 (42%)] Step: [2327991] | Lr: 0.000100 | Loss: 1.0565 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 52.28
24-04-03 04:22:55.091 - INFO: Train epoch 394: [41600/94637 (44%)] Step: [2328091] | Lr: 0.000100 | Loss: 1.5567 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 53.24
24-04-03 04:23:30.970 - INFO: Train epoch 394: [43200/94637 (46%)] Step: [2328191] | Lr: 0.000100 | Loss: 1.4771 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 55.84
24-04-03 04:24:06.911 - INFO: Train epoch 394: [44800/94637 (47%)] Step: [2328291] | Lr: 0.000100 | Loss: 1.3628 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 57.18
24-04-03 04:24:41.892 - INFO: Train epoch 394: [46400/94637 (49%)] Step: [2328391] | Lr: 0.000100 | Loss: 1.2656 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 54.62
24-04-03 04:25:18.521 - INFO: Train epoch 394: [48000/94637 (51%)] Step: [2328491] | Lr: 0.000100 | Loss: 1.1440 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 54.05
24-04-03 04:25:54.910 - INFO: Train epoch 394: [49600/94637 (52%)] Step: [2328591] | Lr: 0.000100 | Loss: 1.3501 | MSE loss: 0.0004 | Bpp loss: 0.75 | Aux loss: 53.81
24-04-03 04:26:29.744 - INFO: Train epoch 394: [51200/94637 (54%)] Step: [2328691] | Lr: 0.000100 | Loss: 1.4694 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 54.18
24-04-03 04:27:05.357 - INFO: Train epoch 394: [52800/94637 (56%)] Step: [2328791] | Lr: 0.000100 | Loss: 1.3901 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 55.74
24-04-03 04:27:41.265 - INFO: Train epoch 394: [54400/94637 (57%)] Step: [2328891] | Lr: 0.000100 | Loss: 1.3200 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 57.79
24-04-03 04:28:16.976 - INFO: Train epoch 394: [56000/94637 (59%)] Step: [2328991] | Lr: 0.000100 | Loss: 1.2215 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 54.63
24-04-03 04:28:51.717 - INFO: Train epoch 394: [57600/94637 (61%)] Step: [2329091] | Lr: 0.000100 | Loss: 1.4081 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 48.80
24-04-03 04:29:27.426 - INFO: Train epoch 394: [59200/94637 (63%)] Step: [2329191] | Lr: 0.000100 | Loss: 1.2629 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 56.27
24-04-03 04:30:03.306 - INFO: Train epoch 394: [60800/94637 (64%)] Step: [2329291] | Lr: 0.000100 | Loss: 1.8362 | MSE loss: 0.0004 | Bpp loss: 1.14 | Aux loss: 56.58
24-04-03 04:30:38.857 - INFO: Train epoch 394: [62400/94637 (66%)] Step: [2329391] | Lr: 0.000100 | Loss: 0.9682 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 56.22
24-04-03 04:31:14.532 - INFO: Train epoch 394: [64000/94637 (68%)] Step: [2329491] | Lr: 0.000100 | Loss: 1.3420 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 58.44
24-04-03 04:31:50.430 - INFO: Train epoch 394: [65600/94637 (69%)] Step: [2329591] | Lr: 0.000100 | Loss: 1.9234 | MSE loss: 0.0006 | Bpp loss: 1.02 | Aux loss: 55.88
24-04-03 04:32:25.513 - INFO: Train epoch 394: [67200/94637 (71%)] Step: [2329691] | Lr: 0.000100 | Loss: 0.9669 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 56.35
24-04-03 04:33:00.551 - INFO: Train epoch 394: [68800/94637 (73%)] Step: [2329791] | Lr: 0.000100 | Loss: 1.7367 | MSE loss: 0.0004 | Bpp loss: 1.12 | Aux loss: 53.12
24-04-03 04:33:35.949 - INFO: Train epoch 394: [70400/94637 (74%)] Step: [2329891] | Lr: 0.000100 | Loss: 0.8897 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 53.92
24-04-03 04:34:11.767 - INFO: Train epoch 394: [72000/94637 (76%)] Step: [2329991] | Lr: 0.000100 | Loss: 1.3856 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 55.03
24-04-03 04:34:49.078 - INFO: Train epoch 394: [73600/94637 (78%)] Step: [2330091] | Lr: 0.000100 | Loss: 1.6325 | MSE loss: 0.0004 | Bpp loss: 1.05 | Aux loss: 55.24
24-04-03 04:35:24.473 - INFO: Train epoch 394: [75200/94637 (79%)] Step: [2330191] | Lr: 0.000100 | Loss: 1.3294 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 60.19
24-04-03 04:36:00.331 - INFO: Train epoch 394: [76800/94637 (81%)] Step: [2330291] | Lr: 0.000100 | Loss: 1.5598 | MSE loss: 0.0003 | Bpp loss: 1.00 | Aux loss: 51.24
24-04-03 04:36:36.593 - INFO: Train epoch 394: [78400/94637 (83%)] Step: [2330391] | Lr: 0.000100 | Loss: 1.6663 | MSE loss: 0.0004 | Bpp loss: 1.06 | Aux loss: 55.99
24-04-03 04:37:12.297 - INFO: Train epoch 394: [80000/94637 (85%)] Step: [2330491] | Lr: 0.000100 | Loss: 1.1804 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 51.17
24-04-03 04:37:48.435 - INFO: Train epoch 394: [81600/94637 (86%)] Step: [2330591] | Lr: 0.000100 | Loss: 0.8033 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 55.95
24-04-03 04:38:23.239 - INFO: Train epoch 394: [83200/94637 (88%)] Step: [2330691] | Lr: 0.000100 | Loss: 2.0259 | MSE loss: 0.0005 | Bpp loss: 1.22 | Aux loss: 54.96
24-04-03 04:38:57.985 - INFO: Train epoch 394: [84800/94637 (90%)] Step: [2330791] | Lr: 0.000100 | Loss: 1.4931 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 52.35
24-04-03 04:39:33.197 - INFO: Train epoch 394: [86400/94637 (91%)] Step: [2330891] | Lr: 0.000100 | Loss: 0.8675 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 54.46
24-04-03 04:40:07.084 - INFO: Train epoch 394: [88000/94637 (93%)] Step: [2330991] | Lr: 0.000100 | Loss: 0.8584 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 54.43
24-04-03 04:40:42.835 - INFO: Train epoch 394: [89600/94637 (95%)] Step: [2331091] | Lr: 0.000100 | Loss: 1.7131 | MSE loss: 0.0004 | Bpp loss: 0.99 | Aux loss: 55.28
24-04-03 04:41:18.709 - INFO: Train epoch 394: [91200/94637 (96%)] Step: [2331191] | Lr: 0.000100 | Loss: 0.8051 | MSE loss: 0.0002 | Bpp loss: 0.48 | Aux loss: 54.45
24-04-03 04:41:54.000 - INFO: Train epoch 394: [92800/94637 (98%)] Step: [2331291] | Lr: 0.000100 | Loss: 1.8721 | MSE loss: 0.0005 | Bpp loss: 1.09 | Aux loss: 56.85
24-04-03 04:42:28.515 - INFO: Train epoch 394: [94400/94637 (100%)] Step: [2331391] | Lr: 0.000100 | Loss: 1.8830 | MSE loss: 0.0005 | Bpp loss: 1.12 | Aux loss: 53.88
24-04-03 04:42:45.518 - INFO: Learning rate: 0.0001
24-04-03 04:42:46.402 - INFO: Train epoch 395: [    0/94637 (0%)] Step: [2331406] | Lr: 0.000100 | Loss: 1.1160 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 54.72
24-04-03 04:43:22.338 - INFO: Train epoch 395: [ 1600/94637 (2%)] Step: [2331506] | Lr: 0.000100 | Loss: 0.9850 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 55.29
24-04-03 04:43:57.642 - INFO: Train epoch 395: [ 3200/94637 (3%)] Step: [2331606] | Lr: 0.000100 | Loss: 1.5020 | MSE loss: 0.0004 | Bpp loss: 0.85 | Aux loss: 59.06
24-04-03 04:44:32.851 - INFO: Train epoch 395: [ 4800/94637 (5%)] Step: [2331706] | Lr: 0.000100 | Loss: 1.0351 | MSE loss: 0.0003 | Bpp loss: 0.58 | Aux loss: 53.44
24-04-03 04:45:08.250 - INFO: Train epoch 395: [ 6400/94637 (7%)] Step: [2331806] | Lr: 0.000100 | Loss: 1.3969 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 54.07
24-04-03 04:45:43.201 - INFO: Train epoch 395: [ 8000/94637 (8%)] Step: [2331906] | Lr: 0.000100 | Loss: 1.5110 | MSE loss: 0.0003 | Bpp loss: 0.97 | Aux loss: 53.91
24-04-03 04:46:18.538 - INFO: Train epoch 395: [ 9600/94637 (10%)] Step: [2332006] | Lr: 0.000100 | Loss: 1.5048 | MSE loss: 0.0003 | Bpp loss: 0.96 | Aux loss: 57.20
24-04-03 04:46:53.299 - INFO: Train epoch 395: [11200/94637 (12%)] Step: [2332106] | Lr: 0.000100 | Loss: 1.5830 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 54.28
24-04-03 04:47:28.551 - INFO: Train epoch 395: [12800/94637 (14%)] Step: [2332206] | Lr: 0.000100 | Loss: 0.9077 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 62.14
24-04-03 04:48:31.189 - INFO: Train epoch 395: [14400/94637 (15%)] Step: [2332306] | Lr: 0.000100 | Loss: 1.1366 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 56.89
24-04-03 04:49:06.517 - INFO: Train epoch 395: [16000/94637 (17%)] Step: [2332406] | Lr: 0.000100 | Loss: 1.3124 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 54.72
24-04-03 04:49:43.412 - INFO: Train epoch 395: [17600/94637 (19%)] Step: [2332506] | Lr: 0.000100 | Loss: 1.2787 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 50.99
24-04-03 04:50:19.108 - INFO: Train epoch 395: [19200/94637 (20%)] Step: [2332606] | Lr: 0.000100 | Loss: 2.2299 | MSE loss: 0.0006 | Bpp loss: 1.28 | Aux loss: 56.92
24-04-03 04:50:53.980 - INFO: Train epoch 395: [20800/94637 (22%)] Step: [2332706] | Lr: 0.000100 | Loss: 0.8280 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 57.17
24-04-03 04:51:29.064 - INFO: Train epoch 395: [22400/94637 (24%)] Step: [2332806] | Lr: 0.000100 | Loss: 1.0600 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 56.73
24-04-03 04:52:03.924 - INFO: Train epoch 395: [24000/94637 (25%)] Step: [2332906] | Lr: 0.000100 | Loss: 0.8128 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 61.04
24-04-03 04:52:38.392 - INFO: Train epoch 395: [25600/94637 (27%)] Step: [2333006] | Lr: 0.000100 | Loss: 1.1758 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 54.60
24-04-03 04:53:13.583 - INFO: Train epoch 395: [27200/94637 (29%)] Step: [2333106] | Lr: 0.000100 | Loss: 1.8184 | MSE loss: 0.0004 | Bpp loss: 1.14 | Aux loss: 50.01
24-04-03 04:53:48.780 - INFO: Train epoch 395: [28800/94637 (30%)] Step: [2333206] | Lr: 0.000100 | Loss: 1.3394 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 52.57
24-04-03 04:54:23.992 - INFO: Train epoch 395: [30400/94637 (32%)] Step: [2333306] | Lr: 0.000100 | Loss: 0.7824 | MSE loss: 0.0002 | Bpp loss: 0.48 | Aux loss: 56.06
24-04-03 04:54:58.652 - INFO: Train epoch 395: [32000/94637 (34%)] Step: [2333406] | Lr: 0.000100 | Loss: 1.1623 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 55.60
24-04-03 04:55:33.334 - INFO: Train epoch 395: [33600/94637 (36%)] Step: [2333506] | Lr: 0.000100 | Loss: 1.5935 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 55.18
24-04-03 04:56:08.292 - INFO: Train epoch 395: [35200/94637 (37%)] Step: [2333606] | Lr: 0.000100 | Loss: 1.1644 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 50.99
24-04-03 04:56:43.663 - INFO: Train epoch 395: [36800/94637 (39%)] Step: [2333706] | Lr: 0.000100 | Loss: 1.6469 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 54.30
24-04-03 04:57:18.249 - INFO: Train epoch 395: [38400/94637 (41%)] Step: [2333806] | Lr: 0.000100 | Loss: 2.2506 | MSE loss: 0.0005 | Bpp loss: 1.48 | Aux loss: 51.36
24-04-03 04:57:51.591 - INFO: Train epoch 395: [40000/94637 (42%)] Step: [2333906] | Lr: 0.000100 | Loss: 1.3004 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 51.43
24-04-03 04:58:25.854 - INFO: Train epoch 395: [41600/94637 (44%)] Step: [2334006] | Lr: 0.000100 | Loss: 1.5269 | MSE loss: 0.0003 | Bpp loss: 1.00 | Aux loss: 55.97
24-04-03 04:59:00.609 - INFO: Train epoch 395: [43200/94637 (46%)] Step: [2334106] | Lr: 0.000100 | Loss: 1.2847 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 53.67
24-04-03 04:59:35.469 - INFO: Train epoch 395: [44800/94637 (47%)] Step: [2334206] | Lr: 0.000100 | Loss: 0.9176 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 58.44
24-04-03 05:00:10.021 - INFO: Train epoch 395: [46400/94637 (49%)] Step: [2334306] | Lr: 0.000100 | Loss: 1.2775 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 55.83
24-04-03 05:00:44.671 - INFO: Train epoch 395: [48000/94637 (51%)] Step: [2334406] | Lr: 0.000100 | Loss: 1.0083 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 54.14
24-04-03 05:01:19.943 - INFO: Train epoch 395: [49600/94637 (52%)] Step: [2334506] | Lr: 0.000100 | Loss: 1.7990 | MSE loss: 0.0004 | Bpp loss: 1.09 | Aux loss: 55.06
24-04-03 05:01:54.569 - INFO: Train epoch 395: [51200/94637 (54%)] Step: [2334606] | Lr: 0.000100 | Loss: 1.7405 | MSE loss: 0.0004 | Bpp loss: 1.14 | Aux loss: 55.08
24-04-03 05:02:29.793 - INFO: Train epoch 395: [52800/94637 (56%)] Step: [2334706] | Lr: 0.000100 | Loss: 0.9239 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 56.31
24-04-03 05:03:04.662 - INFO: Train epoch 395: [54400/94637 (57%)] Step: [2334806] | Lr: 0.000100 | Loss: 1.4016 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 50.99
24-04-03 05:03:39.592 - INFO: Train epoch 395: [56000/94637 (59%)] Step: [2334906] | Lr: 0.000100 | Loss: 1.2600 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 52.58
24-04-03 05:04:16.445 - INFO: Train epoch 395: [57600/94637 (61%)] Step: [2335006] | Lr: 0.000100 | Loss: 1.0703 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 57.56
24-04-03 05:04:51.078 - INFO: Train epoch 395: [59200/94637 (63%)] Step: [2335106] | Lr: 0.000100 | Loss: 0.8217 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 53.75
24-04-03 05:05:25.327 - INFO: Train epoch 395: [60800/94637 (64%)] Step: [2335206] | Lr: 0.000100 | Loss: 1.6524 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 56.69
24-04-03 05:06:01.363 - INFO: Train epoch 395: [62400/94637 (66%)] Step: [2335306] | Lr: 0.000100 | Loss: 1.3039 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 56.20
24-04-03 05:06:36.708 - INFO: Train epoch 395: [64000/94637 (68%)] Step: [2335406] | Lr: 0.000100 | Loss: 1.3274 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 55.95
24-04-03 05:07:11.567 - INFO: Train epoch 395: [65600/94637 (69%)] Step: [2335506] | Lr: 0.000100 | Loss: 0.8971 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 58.10
24-04-03 05:07:47.248 - INFO: Train epoch 395: [67200/94637 (71%)] Step: [2335606] | Lr: 0.000100 | Loss: 1.2585 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 57.58
24-04-03 05:08:22.521 - INFO: Train epoch 395: [68800/94637 (73%)] Step: [2335706] | Lr: 0.000100 | Loss: 1.0466 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 57.92
24-04-03 05:08:57.021 - INFO: Train epoch 395: [70400/94637 (74%)] Step: [2335806] | Lr: 0.000100 | Loss: 1.5373 | MSE loss: 0.0003 | Bpp loss: 0.99 | Aux loss: 57.23
24-04-03 05:09:31.775 - INFO: Train epoch 395: [72000/94637 (76%)] Step: [2335906] | Lr: 0.000100 | Loss: 1.6475 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 56.29
24-04-03 05:10:05.789 - INFO: Train epoch 395: [73600/94637 (78%)] Step: [2336006] | Lr: 0.000100 | Loss: 1.6439 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 56.32
24-04-03 05:10:40.212 - INFO: Train epoch 395: [75200/94637 (79%)] Step: [2336106] | Lr: 0.000100 | Loss: 1.1856 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 54.23
24-04-03 05:11:16.449 - INFO: Train epoch 395: [76800/94637 (81%)] Step: [2336206] | Lr: 0.000100 | Loss: 0.7541 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 54.73
24-04-03 05:11:52.266 - INFO: Train epoch 395: [78400/94637 (83%)] Step: [2336306] | Lr: 0.000100 | Loss: 1.4464 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 55.29
24-04-03 05:12:28.991 - INFO: Train epoch 395: [80000/94637 (85%)] Step: [2336406] | Lr: 0.000100 | Loss: 1.3499 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 56.67
24-04-03 05:13:04.624 - INFO: Train epoch 395: [81600/94637 (86%)] Step: [2336506] | Lr: 0.000100 | Loss: 1.1692 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 58.84
24-04-03 05:13:38.315 - INFO: Train epoch 395: [83200/94637 (88%)] Step: [2336606] | Lr: 0.000100 | Loss: 1.5683 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 54.60
24-04-03 05:14:14.037 - INFO: Train epoch 395: [84800/94637 (90%)] Step: [2336706] | Lr: 0.000100 | Loss: 1.2900 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 53.94
24-04-03 05:14:49.102 - INFO: Train epoch 395: [86400/94637 (91%)] Step: [2336806] | Lr: 0.000100 | Loss: 1.0023 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 55.64
24-04-03 05:15:24.668 - INFO: Train epoch 395: [88000/94637 (93%)] Step: [2336906] | Lr: 0.000100 | Loss: 1.5767 | MSE loss: 0.0004 | Bpp loss: 0.88 | Aux loss: 57.65
24-04-03 05:15:59.180 - INFO: Train epoch 395: [89600/94637 (95%)] Step: [2337006] | Lr: 0.000100 | Loss: 1.4888 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 56.87
24-04-03 05:16:34.215 - INFO: Train epoch 395: [91200/94637 (96%)] Step: [2337106] | Lr: 0.000100 | Loss: 1.2833 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 52.36
24-04-03 05:17:08.523 - INFO: Train epoch 395: [92800/94637 (98%)] Step: [2337206] | Lr: 0.000100 | Loss: 0.9793 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 53.89
24-04-03 05:17:42.903 - INFO: Train epoch 395: [94400/94637 (100%)] Step: [2337306] | Lr: 0.000100 | Loss: 1.9134 | MSE loss: 0.0005 | Bpp loss: 1.04 | Aux loss: 55.70
24-04-03 05:18:00.092 - INFO: Learning rate: 0.0001
24-04-03 05:18:01.228 - INFO: Train epoch 396: [    0/94637 (0%)] Step: [2337321] | Lr: 0.000100 | Loss: 1.4306 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 55.69
24-04-03 05:18:35.795 - INFO: Train epoch 396: [ 1600/94637 (2%)] Step: [2337421] | Lr: 0.000100 | Loss: 1.8679 | MSE loss: 0.0004 | Bpp loss: 1.16 | Aux loss: 58.03
24-04-03 05:19:12.147 - INFO: Train epoch 396: [ 3200/94637 (3%)] Step: [2337521] | Lr: 0.000100 | Loss: 1.1212 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 52.67
24-04-03 05:19:46.781 - INFO: Train epoch 396: [ 4800/94637 (5%)] Step: [2337621] | Lr: 0.000100 | Loss: 1.3758 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 53.45
24-04-03 05:20:20.878 - INFO: Train epoch 396: [ 6400/94637 (7%)] Step: [2337721] | Lr: 0.000100 | Loss: 1.4201 | MSE loss: 0.0004 | Bpp loss: 0.77 | Aux loss: 57.91
24-04-03 05:20:54.470 - INFO: Train epoch 396: [ 8000/94637 (8%)] Step: [2337821] | Lr: 0.000100 | Loss: 0.9914 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 54.50
24-04-03 05:21:28.998 - INFO: Train epoch 396: [ 9600/94637 (10%)] Step: [2337921] | Lr: 0.000100 | Loss: 1.2508 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 50.41
24-04-03 05:22:03.102 - INFO: Train epoch 396: [11200/94637 (12%)] Step: [2338021] | Lr: 0.000100 | Loss: 1.2590 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 52.03
24-04-03 05:22:36.817 - INFO: Train epoch 396: [12800/94637 (14%)] Step: [2338121] | Lr: 0.000100 | Loss: 1.2993 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 58.94
24-04-03 05:23:11.301 - INFO: Train epoch 396: [14400/94637 (15%)] Step: [2338221] | Lr: 0.000100 | Loss: 1.0593 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 58.20
24-04-03 05:23:45.654 - INFO: Train epoch 396: [16000/94637 (17%)] Step: [2338321] | Lr: 0.000100 | Loss: 1.1345 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 54.66
24-04-03 05:24:20.541 - INFO: Train epoch 396: [17600/94637 (19%)] Step: [2338421] | Lr: 0.000100 | Loss: 1.0978 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 57.10
24-04-03 05:24:55.601 - INFO: Train epoch 396: [19200/94637 (20%)] Step: [2338521] | Lr: 0.000100 | Loss: 0.8209 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 56.05
24-04-03 05:25:29.938 - INFO: Train epoch 396: [20800/94637 (22%)] Step: [2338621] | Lr: 0.000100 | Loss: 1.4238 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 56.72
24-04-03 05:26:06.067 - INFO: Train epoch 396: [22400/94637 (24%)] Step: [2338721] | Lr: 0.000100 | Loss: 1.8021 | MSE loss: 0.0004 | Bpp loss: 1.09 | Aux loss: 56.05
24-04-03 05:26:42.248 - INFO: Train epoch 396: [24000/94637 (25%)] Step: [2338821] | Lr: 0.000100 | Loss: 1.3335 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 55.43
24-04-03 05:27:17.795 - INFO: Train epoch 396: [25600/94637 (27%)] Step: [2338921] | Lr: 0.000100 | Loss: 1.3028 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 54.80
24-04-03 05:27:54.278 - INFO: Train epoch 396: [27200/94637 (29%)] Step: [2339021] | Lr: 0.000100 | Loss: 0.9660 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 54.30
24-04-03 05:28:28.175 - INFO: Train epoch 396: [28800/94637 (30%)] Step: [2339121] | Lr: 0.000100 | Loss: 1.5473 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 59.16
24-04-03 05:29:04.290 - INFO: Train epoch 396: [30400/94637 (32%)] Step: [2339221] | Lr: 0.000100 | Loss: 1.3769 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 55.20
24-04-03 05:29:40.008 - INFO: Train epoch 396: [32000/94637 (34%)] Step: [2339321] | Lr: 0.000100 | Loss: 1.3105 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 56.27
24-04-03 05:30:15.433 - INFO: Train epoch 396: [33600/94637 (36%)] Step: [2339421] | Lr: 0.000100 | Loss: 1.1469 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 55.40
24-04-03 05:30:50.545 - INFO: Train epoch 396: [35200/94637 (37%)] Step: [2339521] | Lr: 0.000100 | Loss: 1.3291 | MSE loss: 0.0004 | Bpp loss: 0.73 | Aux loss: 55.43
24-04-03 05:31:24.881 - INFO: Train epoch 396: [36800/94637 (39%)] Step: [2339621] | Lr: 0.000100 | Loss: 1.8089 | MSE loss: 0.0005 | Bpp loss: 0.97 | Aux loss: 54.54
24-04-03 05:31:59.335 - INFO: Train epoch 396: [38400/94637 (41%)] Step: [2339721] | Lr: 0.000100 | Loss: 1.2815 | MSE loss: 0.0004 | Bpp loss: 0.68 | Aux loss: 56.81
24-04-03 05:32:35.819 - INFO: Train epoch 396: [40000/94637 (42%)] Step: [2339821] | Lr: 0.000100 | Loss: 1.1833 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 54.67
24-04-03 05:33:12.654 - INFO: Train epoch 396: [41600/94637 (44%)] Step: [2339921] | Lr: 0.000100 | Loss: 0.9810 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 54.68
24-04-03 05:33:50.444 - INFO: Train epoch 396: [43200/94637 (46%)] Step: [2340021] | Lr: 0.000100 | Loss: 1.2776 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 54.97
24-04-03 05:34:26.009 - INFO: Train epoch 396: [44800/94637 (47%)] Step: [2340121] | Lr: 0.000100 | Loss: 0.9656 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 57.10
24-04-03 05:35:00.261 - INFO: Train epoch 396: [46400/94637 (49%)] Step: [2340221] | Lr: 0.000100 | Loss: 1.5060 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 53.57
24-04-03 05:35:35.134 - INFO: Train epoch 396: [48000/94637 (51%)] Step: [2340321] | Lr: 0.000100 | Loss: 0.7755 | MSE loss: 0.0002 | Bpp loss: 0.48 | Aux loss: 54.60
24-04-03 05:36:08.898 - INFO: Train epoch 396: [49600/94637 (52%)] Step: [2340421] | Lr: 0.000100 | Loss: 0.9523 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 57.40
24-04-03 05:36:42.535 - INFO: Train epoch 396: [51200/94637 (54%)] Step: [2340521] | Lr: 0.000100 | Loss: 1.1261 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 55.12
24-04-03 05:37:17.903 - INFO: Train epoch 396: [52800/94637 (56%)] Step: [2340621] | Lr: 0.000100 | Loss: 1.1801 | MSE loss: 0.0002 | Bpp loss: 0.80 | Aux loss: 57.36
24-04-03 05:37:52.334 - INFO: Train epoch 396: [54400/94637 (57%)] Step: [2340721] | Lr: 0.000100 | Loss: 1.7491 | MSE loss: 0.0004 | Bpp loss: 1.05 | Aux loss: 56.70
24-04-03 05:38:27.138 - INFO: Train epoch 396: [56000/94637 (59%)] Step: [2340821] | Lr: 0.000100 | Loss: 1.3469 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 50.97
24-04-03 05:39:02.192 - INFO: Train epoch 396: [57600/94637 (61%)] Step: [2340921] | Lr: 0.000100 | Loss: 1.9464 | MSE loss: 0.0004 | Bpp loss: 1.24 | Aux loss: 53.64
24-04-03 05:39:36.507 - INFO: Train epoch 396: [59200/94637 (63%)] Step: [2341021] | Lr: 0.000100 | Loss: 1.5030 | MSE loss: 0.0004 | Bpp loss: 0.86 | Aux loss: 58.18
24-04-03 05:40:11.550 - INFO: Train epoch 396: [60800/94637 (64%)] Step: [2341121] | Lr: 0.000100 | Loss: 1.2179 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 53.60
24-04-03 05:40:46.340 - INFO: Train epoch 396: [62400/94637 (66%)] Step: [2341221] | Lr: 0.000100 | Loss: 1.7730 | MSE loss: 0.0004 | Bpp loss: 1.12 | Aux loss: 56.75
24-04-03 05:41:21.481 - INFO: Train epoch 396: [64000/94637 (68%)] Step: [2341321] | Lr: 0.000100 | Loss: 1.1810 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 55.40
24-04-03 05:41:57.833 - INFO: Train epoch 396: [65600/94637 (69%)] Step: [2341421] | Lr: 0.000100 | Loss: 1.6461 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 54.21
24-04-03 05:42:32.867 - INFO: Train epoch 396: [67200/94637 (71%)] Step: [2341521] | Lr: 0.000100 | Loss: 1.1086 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 53.30
24-04-03 05:43:07.280 - INFO: Train epoch 396: [68800/94637 (73%)] Step: [2341621] | Lr: 0.000100 | Loss: 1.1597 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 53.17
24-04-03 05:43:42.288 - INFO: Train epoch 396: [70400/94637 (74%)] Step: [2341721] | Lr: 0.000100 | Loss: 1.1972 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 57.66
24-04-03 05:44:16.789 - INFO: Train epoch 396: [72000/94637 (76%)] Step: [2341821] | Lr: 0.000100 | Loss: 1.0582 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 53.36
24-04-03 05:44:51.871 - INFO: Train epoch 396: [73600/94637 (78%)] Step: [2341921] | Lr: 0.000100 | Loss: 0.9776 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 54.50
24-04-03 05:45:26.487 - INFO: Train epoch 396: [75200/94637 (79%)] Step: [2342021] | Lr: 0.000100 | Loss: 1.4486 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 57.07
24-04-03 05:46:01.196 - INFO: Train epoch 396: [76800/94637 (81%)] Step: [2342121] | Lr: 0.000100 | Loss: 1.8067 | MSE loss: 0.0004 | Bpp loss: 1.19 | Aux loss: 56.36
24-04-03 05:46:36.197 - INFO: Train epoch 396: [78400/94637 (83%)] Step: [2342221] | Lr: 0.000100 | Loss: 0.7143 | MSE loss: 0.0001 | Bpp loss: 0.48 | Aux loss: 54.95
24-04-03 05:47:11.443 - INFO: Train epoch 396: [80000/94637 (85%)] Step: [2342321] | Lr: 0.000100 | Loss: 1.8813 | MSE loss: 0.0004 | Bpp loss: 1.18 | Aux loss: 56.73
24-04-03 05:47:46.000 - INFO: Train epoch 396: [81600/94637 (86%)] Step: [2342421] | Lr: 0.000100 | Loss: 0.7050 | MSE loss: 0.0002 | Bpp loss: 0.46 | Aux loss: 56.18
24-04-03 05:48:22.510 - INFO: Train epoch 396: [83200/94637 (88%)] Step: [2342521] | Lr: 0.000100 | Loss: 1.3699 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 52.87
24-04-03 05:48:57.438 - INFO: Train epoch 396: [84800/94637 (90%)] Step: [2342621] | Lr: 0.000100 | Loss: 1.6491 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 54.12
24-04-03 05:49:32.671 - INFO: Train epoch 396: [86400/94637 (91%)] Step: [2342721] | Lr: 0.000100 | Loss: 1.3459 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 57.28
24-04-03 05:50:08.368 - INFO: Train epoch 396: [88000/94637 (93%)] Step: [2342821] | Lr: 0.000100 | Loss: 1.3842 | MSE loss: 0.0004 | Bpp loss: 0.80 | Aux loss: 55.91
24-04-03 05:50:43.773 - INFO: Train epoch 396: [89600/94637 (95%)] Step: [2342921] | Lr: 0.000100 | Loss: 1.5589 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 54.51
24-04-03 05:51:18.878 - INFO: Train epoch 396: [91200/94637 (96%)] Step: [2343021] | Lr: 0.000100 | Loss: 1.0151 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 55.21
24-04-03 05:51:54.174 - INFO: Train epoch 396: [92800/94637 (98%)] Step: [2343121] | Lr: 0.000100 | Loss: 1.0552 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 55.80
24-04-03 05:52:30.478 - INFO: Train epoch 396: [94400/94637 (100%)] Step: [2343221] | Lr: 0.000100 | Loss: 0.9282 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 56.39
24-04-03 05:52:47.410 - INFO: Learning rate: 0.0001
24-04-03 05:52:48.538 - INFO: Train epoch 397: [    0/94637 (0%)] Step: [2343236] | Lr: 0.000100 | Loss: 0.7256 | MSE loss: 0.0002 | Bpp loss: 0.45 | Aux loss: 56.33
24-04-03 05:53:22.681 - INFO: Train epoch 397: [ 1600/94637 (2%)] Step: [2343336] | Lr: 0.000100 | Loss: 1.7055 | MSE loss: 0.0005 | Bpp loss: 0.93 | Aux loss: 56.77
24-04-03 05:53:57.747 - INFO: Train epoch 397: [ 3200/94637 (3%)] Step: [2343436] | Lr: 0.000100 | Loss: 1.4320 | MSE loss: 0.0004 | Bpp loss: 0.83 | Aux loss: 57.05
24-04-03 05:54:32.338 - INFO: Train epoch 397: [ 4800/94637 (5%)] Step: [2343536] | Lr: 0.000100 | Loss: 0.7764 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 58.59
24-04-03 05:55:06.581 - INFO: Train epoch 397: [ 6400/94637 (7%)] Step: [2343636] | Lr: 0.000100 | Loss: 0.9150 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 55.44
24-04-03 05:55:41.542 - INFO: Train epoch 397: [ 8000/94637 (8%)] Step: [2343736] | Lr: 0.000100 | Loss: 1.9347 | MSE loss: 0.0005 | Bpp loss: 1.10 | Aux loss: 59.68
24-04-03 05:56:17.098 - INFO: Train epoch 397: [ 9600/94637 (10%)] Step: [2343836] | Lr: 0.000100 | Loss: 1.9359 | MSE loss: 0.0005 | Bpp loss: 1.14 | Aux loss: 57.09
24-04-03 05:56:52.613 - INFO: Train epoch 397: [11200/94637 (12%)] Step: [2343936] | Lr: 0.000100 | Loss: 1.4395 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 52.98
24-04-03 05:57:27.859 - INFO: Train epoch 397: [12800/94637 (14%)] Step: [2344036] | Lr: 0.000100 | Loss: 1.0699 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 61.55
24-04-03 05:58:02.575 - INFO: Train epoch 397: [14400/94637 (15%)] Step: [2344136] | Lr: 0.000100 | Loss: 0.9368 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 53.61
24-04-03 05:58:38.715 - INFO: Train epoch 397: [16000/94637 (17%)] Step: [2344236] | Lr: 0.000100 | Loss: 1.4571 | MSE loss: 0.0004 | Bpp loss: 0.86 | Aux loss: 55.74
24-04-03 05:59:15.107 - INFO: Train epoch 397: [17600/94637 (19%)] Step: [2344336] | Lr: 0.000100 | Loss: 1.4487 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 58.02
24-04-03 05:59:51.322 - INFO: Train epoch 397: [19200/94637 (20%)] Step: [2344436] | Lr: 0.000100 | Loss: 0.9273 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 55.34
24-04-03 06:00:27.449 - INFO: Train epoch 397: [20800/94637 (22%)] Step: [2344536] | Lr: 0.000100 | Loss: 1.4823 | MSE loss: 0.0003 | Bpp loss: 0.97 | Aux loss: 55.74
24-04-03 06:01:03.168 - INFO: Train epoch 397: [22400/94637 (24%)] Step: [2344636] | Lr: 0.000100 | Loss: 1.2916 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 54.63
24-04-03 06:01:39.264 - INFO: Train epoch 397: [24000/94637 (25%)] Step: [2344736] | Lr: 0.000100 | Loss: 1.5032 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 54.06
24-04-03 06:02:14.526 - INFO: Train epoch 397: [25600/94637 (27%)] Step: [2344836] | Lr: 0.000100 | Loss: 1.0282 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 55.29
24-04-03 06:02:50.309 - INFO: Train epoch 397: [27200/94637 (29%)] Step: [2344936] | Lr: 0.000100 | Loss: 1.3010 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 56.15
24-04-03 06:03:27.986 - INFO: Train epoch 397: [28800/94637 (30%)] Step: [2345036] | Lr: 0.000100 | Loss: 1.3380 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 54.81
24-04-03 06:04:03.960 - INFO: Train epoch 397: [30400/94637 (32%)] Step: [2345136] | Lr: 0.000100 | Loss: 1.1081 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 56.20
24-04-03 06:04:39.416 - INFO: Train epoch 397: [32000/94637 (34%)] Step: [2345236] | Lr: 0.000100 | Loss: 1.0497 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 56.17
24-04-03 06:05:14.790 - INFO: Train epoch 397: [33600/94637 (36%)] Step: [2345336] | Lr: 0.000100 | Loss: 0.6211 | MSE loss: 0.0001 | Bpp loss: 0.39 | Aux loss: 53.70
24-04-03 06:05:50.655 - INFO: Train epoch 397: [35200/94637 (37%)] Step: [2345436] | Lr: 0.000100 | Loss: 0.8823 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 50.66
24-04-03 06:06:26.467 - INFO: Train epoch 397: [36800/94637 (39%)] Step: [2345536] | Lr: 0.000100 | Loss: 0.7922 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 55.59
24-04-03 06:07:02.318 - INFO: Train epoch 397: [38400/94637 (41%)] Step: [2345636] | Lr: 0.000100 | Loss: 0.6897 | MSE loss: 0.0002 | Bpp loss: 0.38 | Aux loss: 62.90
24-04-03 06:07:37.396 - INFO: Train epoch 397: [40000/94637 (42%)] Step: [2345736] | Lr: 0.000100 | Loss: 1.7682 | MSE loss: 0.0004 | Bpp loss: 1.08 | Aux loss: 55.65
24-04-03 06:08:11.614 - INFO: Train epoch 397: [41600/94637 (44%)] Step: [2345836] | Lr: 0.000100 | Loss: 1.1170 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 55.36
24-04-03 06:08:46.158 - INFO: Train epoch 397: [43200/94637 (46%)] Step: [2345936] | Lr: 0.000100 | Loss: 1.1495 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 55.66
24-04-03 06:09:21.511 - INFO: Train epoch 397: [44800/94637 (47%)] Step: [2346036] | Lr: 0.000100 | Loss: 1.1237 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 55.90
24-04-03 06:09:55.621 - INFO: Train epoch 397: [46400/94637 (49%)] Step: [2346136] | Lr: 0.000100 | Loss: 1.1970 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 54.97
24-04-03 06:10:30.306 - INFO: Train epoch 397: [48000/94637 (51%)] Step: [2346236] | Lr: 0.000100 | Loss: 1.3487 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 56.68
24-04-03 06:11:07.398 - INFO: Train epoch 397: [49600/94637 (52%)] Step: [2346336] | Lr: 0.000100 | Loss: 1.7971 | MSE loss: 0.0004 | Bpp loss: 1.11 | Aux loss: 53.79
24-04-03 06:11:41.637 - INFO: Train epoch 397: [51200/94637 (54%)] Step: [2346436] | Lr: 0.000100 | Loss: 1.0324 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 55.03
24-04-03 06:12:16.422 - INFO: Train epoch 397: [52800/94637 (56%)] Step: [2346536] | Lr: 0.000100 | Loss: 1.2918 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 56.85
24-04-03 06:12:51.097 - INFO: Train epoch 397: [54400/94637 (57%)] Step: [2346636] | Lr: 0.000100 | Loss: 0.9839 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 58.04
24-04-03 06:13:26.714 - INFO: Train epoch 397: [56000/94637 (59%)] Step: [2346736] | Lr: 0.000100 | Loss: 1.9643 | MSE loss: 0.0004 | Bpp loss: 1.26 | Aux loss: 51.34
24-04-03 06:14:01.373 - INFO: Train epoch 397: [57600/94637 (61%)] Step: [2346836] | Lr: 0.000100 | Loss: 1.1361 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 55.82
24-04-03 06:14:36.335 - INFO: Train epoch 397: [59200/94637 (63%)] Step: [2346936] | Lr: 0.000100 | Loss: 1.4574 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 59.28
24-04-03 06:15:11.611 - INFO: Train epoch 397: [60800/94637 (64%)] Step: [2347036] | Lr: 0.000100 | Loss: 0.8464 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 54.73
24-04-03 06:15:46.606 - INFO: Train epoch 397: [62400/94637 (66%)] Step: [2347136] | Lr: 0.000100 | Loss: 1.1756 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 50.79
24-04-03 06:16:22.268 - INFO: Train epoch 397: [64000/94637 (68%)] Step: [2347236] | Lr: 0.000100 | Loss: 1.5249 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 54.28
24-04-03 06:16:56.850 - INFO: Train epoch 397: [65600/94637 (69%)] Step: [2347336] | Lr: 0.000100 | Loss: 1.8287 | MSE loss: 0.0004 | Bpp loss: 1.13 | Aux loss: 54.24
24-04-03 06:17:32.395 - INFO: Train epoch 397: [67200/94637 (71%)] Step: [2347436] | Lr: 0.000100 | Loss: 0.9715 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 55.47
24-04-03 06:18:09.323 - INFO: Train epoch 397: [68800/94637 (73%)] Step: [2347536] | Lr: 0.000100 | Loss: 1.4557 | MSE loss: 0.0004 | Bpp loss: 0.85 | Aux loss: 57.84
24-04-03 06:18:44.766 - INFO: Train epoch 397: [70400/94637 (74%)] Step: [2347636] | Lr: 0.000100 | Loss: 0.8964 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 52.51
24-04-03 06:19:19.978 - INFO: Train epoch 397: [72000/94637 (76%)] Step: [2347736] | Lr: 0.000100 | Loss: 1.0773 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 57.65
24-04-03 06:19:56.013 - INFO: Train epoch 397: [73600/94637 (78%)] Step: [2347836] | Lr: 0.000100 | Loss: 1.1542 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 55.03
24-04-03 06:20:31.786 - INFO: Train epoch 397: [75200/94637 (79%)] Step: [2347936] | Lr: 0.000100 | Loss: 1.3329 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 54.16
24-04-03 06:21:06.691 - INFO: Train epoch 397: [76800/94637 (81%)] Step: [2348036] | Lr: 0.000100 | Loss: 1.1448 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 55.79
24-04-03 06:21:42.326 - INFO: Train epoch 397: [78400/94637 (83%)] Step: [2348136] | Lr: 0.000100 | Loss: 1.1888 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 62.26
24-04-03 06:22:17.930 - INFO: Train epoch 397: [80000/94637 (85%)] Step: [2348236] | Lr: 0.000100 | Loss: 1.3408 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 56.34
24-04-03 06:22:51.962 - INFO: Train epoch 397: [81600/94637 (86%)] Step: [2348336] | Lr: 0.000100 | Loss: 1.3428 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 56.75
24-04-03 06:23:26.891 - INFO: Train epoch 397: [83200/94637 (88%)] Step: [2348436] | Lr: 0.000100 | Loss: 1.5824 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 55.92
24-04-03 06:24:01.826 - INFO: Train epoch 397: [84800/94637 (90%)] Step: [2348536] | Lr: 0.000100 | Loss: 1.3176 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 57.90
24-04-03 06:24:35.115 - INFO: Train epoch 397: [86400/94637 (91%)] Step: [2348636] | Lr: 0.000100 | Loss: 0.7499 | MSE loss: 0.0002 | Bpp loss: 0.44 | Aux loss: 58.00
24-04-03 06:25:09.152 - INFO: Train epoch 397: [88000/94637 (93%)] Step: [2348736] | Lr: 0.000100 | Loss: 1.1079 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 59.43
24-04-03 06:25:43.414 - INFO: Train epoch 397: [89600/94637 (95%)] Step: [2348836] | Lr: 0.000100 | Loss: 1.4296 | MSE loss: 0.0004 | Bpp loss: 0.84 | Aux loss: 54.43
24-04-03 06:26:17.554 - INFO: Train epoch 397: [91200/94637 (96%)] Step: [2348936] | Lr: 0.000100 | Loss: 0.9008 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 57.51
24-04-03 06:26:52.212 - INFO: Train epoch 397: [92800/94637 (98%)] Step: [2349036] | Lr: 0.000100 | Loss: 1.0760 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 54.98
24-04-03 06:27:28.111 - INFO: Train epoch 397: [94400/94637 (100%)] Step: [2349136] | Lr: 0.000100 | Loss: 0.9279 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 54.22
24-04-03 06:27:50.845 - INFO: Learning rate: 0.0001
24-04-03 06:27:51.680 - INFO: Train epoch 398: [    0/94637 (0%)] Step: [2349151] | Lr: 0.000100 | Loss: 1.1314 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 54.46
24-04-03 06:28:25.977 - INFO: Train epoch 398: [ 1600/94637 (2%)] Step: [2349251] | Lr: 0.000100 | Loss: 1.5669 | MSE loss: 0.0004 | Bpp loss: 0.99 | Aux loss: 55.99
24-04-03 06:28:59.925 - INFO: Train epoch 398: [ 3200/94637 (3%)] Step: [2349351] | Lr: 0.000100 | Loss: 0.8462 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 56.12
24-04-03 06:29:33.751 - INFO: Train epoch 398: [ 4800/94637 (5%)] Step: [2349451] | Lr: 0.000100 | Loss: 0.9774 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 55.93
24-04-03 06:30:07.549 - INFO: Train epoch 398: [ 6400/94637 (7%)] Step: [2349551] | Lr: 0.000100 | Loss: 0.7590 | MSE loss: 0.0002 | Bpp loss: 0.45 | Aux loss: 54.99
24-04-03 06:30:41.895 - INFO: Train epoch 398: [ 8000/94637 (8%)] Step: [2349651] | Lr: 0.000100 | Loss: 1.2290 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 58.98
24-04-03 06:31:16.800 - INFO: Train epoch 398: [ 9600/94637 (10%)] Step: [2349751] | Lr: 0.000100 | Loss: 0.8252 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 53.46
24-04-03 06:31:51.874 - INFO: Train epoch 398: [11200/94637 (12%)] Step: [2349851] | Lr: 0.000100 | Loss: 1.5661 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 56.90
24-04-03 06:32:27.323 - INFO: Train epoch 398: [12800/94637 (14%)] Step: [2349951] | Lr: 0.000100 | Loss: 1.1711 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 56.66
24-04-03 06:33:03.981 - INFO: Train epoch 398: [14400/94637 (15%)] Step: [2350051] | Lr: 0.000100 | Loss: 1.5588 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 56.55
24-04-03 06:33:39.665 - INFO: Train epoch 398: [16000/94637 (17%)] Step: [2350151] | Lr: 0.000100 | Loss: 1.2155 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 59.79
24-04-03 06:34:16.574 - INFO: Train epoch 398: [17600/94637 (19%)] Step: [2350251] | Lr: 0.000100 | Loss: 0.9975 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 57.29
24-04-03 06:34:52.408 - INFO: Train epoch 398: [19200/94637 (20%)] Step: [2350351] | Lr: 0.000100 | Loss: 0.9312 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 53.68
24-04-03 06:35:28.866 - INFO: Train epoch 398: [20800/94637 (22%)] Step: [2350451] | Lr: 0.000100 | Loss: 1.2083 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 52.14
24-04-03 06:36:04.704 - INFO: Train epoch 398: [22400/94637 (24%)] Step: [2350551] | Lr: 0.000100 | Loss: 1.2383 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 62.73
24-04-03 06:36:40.749 - INFO: Train epoch 398: [24000/94637 (25%)] Step: [2350651] | Lr: 0.000100 | Loss: 1.6347 | MSE loss: 0.0004 | Bpp loss: 1.03 | Aux loss: 56.63
24-04-03 06:37:16.029 - INFO: Train epoch 398: [25600/94637 (27%)] Step: [2350751] | Lr: 0.000100 | Loss: 2.0368 | MSE loss: 0.0005 | Bpp loss: 1.15 | Aux loss: 55.24
24-04-03 06:37:50.891 - INFO: Train epoch 398: [27200/94637 (29%)] Step: [2350851] | Lr: 0.000100 | Loss: 1.3310 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 58.69
24-04-03 06:38:26.788 - INFO: Train epoch 398: [28800/94637 (30%)] Step: [2350951] | Lr: 0.000100 | Loss: 1.2529 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 55.96
24-04-03 06:39:01.460 - INFO: Train epoch 398: [30400/94637 (32%)] Step: [2351051] | Lr: 0.000100 | Loss: 1.1648 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 54.10
24-04-03 06:39:36.355 - INFO: Train epoch 398: [32000/94637 (34%)] Step: [2351151] | Lr: 0.000100 | Loss: 1.3069 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 55.53
24-04-03 06:40:10.941 - INFO: Train epoch 398: [33600/94637 (36%)] Step: [2351251] | Lr: 0.000100 | Loss: 1.1699 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 52.59
24-04-03 06:40:45.399 - INFO: Train epoch 398: [35200/94637 (37%)] Step: [2351351] | Lr: 0.000100 | Loss: 2.5184 | MSE loss: 0.0008 | Bpp loss: 1.30 | Aux loss: 54.53
24-04-03 06:41:19.292 - INFO: Train epoch 398: [36800/94637 (39%)] Step: [2351451] | Lr: 0.000100 | Loss: 1.2387 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 59.81
24-04-03 06:41:53.822 - INFO: Train epoch 398: [38400/94637 (41%)] Step: [2351551] | Lr: 0.000100 | Loss: 1.2153 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 53.81
24-04-03 06:42:28.999 - INFO: Train epoch 398: [40000/94637 (42%)] Step: [2351651] | Lr: 0.000100 | Loss: 1.6034 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 57.13
24-04-03 06:43:05.317 - INFO: Train epoch 398: [41600/94637 (44%)] Step: [2351751] | Lr: 0.000100 | Loss: 1.2905 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 56.77
24-04-03 06:43:40.991 - INFO: Train epoch 398: [43200/94637 (46%)] Step: [2351851] | Lr: 0.000100 | Loss: 2.0217 | MSE loss: 0.0007 | Bpp loss: 0.93 | Aux loss: 55.75
24-04-03 06:44:16.334 - INFO: Train epoch 398: [44800/94637 (47%)] Step: [2351951] | Lr: 0.000100 | Loss: 1.6194 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 55.96
24-04-03 06:44:50.939 - INFO: Train epoch 398: [46400/94637 (49%)] Step: [2352051] | Lr: 0.000100 | Loss: 0.8795 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 57.36
24-04-03 06:45:25.495 - INFO: Train epoch 398: [48000/94637 (51%)] Step: [2352151] | Lr: 0.000100 | Loss: 0.9378 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 52.38
24-04-03 06:46:00.015 - INFO: Train epoch 398: [49600/94637 (52%)] Step: [2352251] | Lr: 0.000100 | Loss: 1.5308 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 56.06
24-04-03 06:46:34.763 - INFO: Train epoch 398: [51200/94637 (54%)] Step: [2352351] | Lr: 0.000100 | Loss: 1.9702 | MSE loss: 0.0005 | Bpp loss: 1.20 | Aux loss: 53.39
24-04-03 06:47:09.583 - INFO: Train epoch 398: [52800/94637 (56%)] Step: [2352451] | Lr: 0.000100 | Loss: 0.9764 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 58.41
24-04-03 06:47:47.024 - INFO: Train epoch 398: [54400/94637 (57%)] Step: [2352551] | Lr: 0.000100 | Loss: 1.4817 | MSE loss: 0.0004 | Bpp loss: 0.85 | Aux loss: 57.20
24-04-03 06:48:21.670 - INFO: Train epoch 398: [56000/94637 (59%)] Step: [2352651] | Lr: 0.000100 | Loss: 1.3403 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 56.35
24-04-03 06:48:56.405 - INFO: Train epoch 398: [57600/94637 (61%)] Step: [2352751] | Lr: 0.000100 | Loss: 1.4714 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 54.76
24-04-03 06:49:31.195 - INFO: Train epoch 398: [59200/94637 (63%)] Step: [2352851] | Lr: 0.000100 | Loss: 2.0905 | MSE loss: 0.0006 | Bpp loss: 1.15 | Aux loss: 53.40
24-04-03 06:50:05.760 - INFO: Train epoch 398: [60800/94637 (64%)] Step: [2352951] | Lr: 0.000100 | Loss: 0.9576 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 58.46
24-04-03 06:50:40.507 - INFO: Train epoch 398: [62400/94637 (66%)] Step: [2353051] | Lr: 0.000100 | Loss: 1.1206 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 55.59
24-04-03 06:51:16.400 - INFO: Train epoch 398: [64000/94637 (68%)] Step: [2353151] | Lr: 0.000100 | Loss: 0.9567 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 57.39
24-04-03 06:51:52.772 - INFO: Train epoch 398: [65600/94637 (69%)] Step: [2353251] | Lr: 0.000100 | Loss: 1.3265 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 52.86
24-04-03 06:52:29.213 - INFO: Train epoch 398: [67200/94637 (71%)] Step: [2353351] | Lr: 0.000100 | Loss: 1.0228 | MSE loss: 0.0003 | Bpp loss: 0.60 | Aux loss: 52.61
24-04-03 06:53:05.553 - INFO: Train epoch 398: [68800/94637 (73%)] Step: [2353451] | Lr: 0.000100 | Loss: 1.5827 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 53.37
24-04-03 06:53:41.485 - INFO: Train epoch 398: [70400/94637 (74%)] Step: [2353551] | Lr: 0.000100 | Loss: 1.2233 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 58.06
24-04-03 06:54:16.636 - INFO: Train epoch 398: [72000/94637 (76%)] Step: [2353651] | Lr: 0.000100 | Loss: 1.1419 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 54.52
24-04-03 06:54:52.141 - INFO: Train epoch 398: [73600/94637 (78%)] Step: [2353751] | Lr: 0.000100 | Loss: 1.1978 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 57.25
24-04-03 06:55:28.069 - INFO: Train epoch 398: [75200/94637 (79%)] Step: [2353851] | Lr: 0.000100 | Loss: 1.2090 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 54.09
24-04-03 06:56:01.991 - INFO: Train epoch 398: [76800/94637 (81%)] Step: [2353951] | Lr: 0.000100 | Loss: 1.1441 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 58.55
24-04-03 06:56:37.440 - INFO: Train epoch 398: [78400/94637 (83%)] Step: [2354051] | Lr: 0.000100 | Loss: 1.6460 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 60.07
24-04-03 06:57:12.305 - INFO: Train epoch 398: [80000/94637 (85%)] Step: [2354151] | Lr: 0.000100 | Loss: 1.5804 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 54.55
24-04-03 06:57:45.772 - INFO: Train epoch 398: [81600/94637 (86%)] Step: [2354251] | Lr: 0.000100 | Loss: 1.1950 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 53.10
24-04-03 06:58:20.057 - INFO: Train epoch 398: [83200/94637 (88%)] Step: [2354351] | Lr: 0.000100 | Loss: 1.0621 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 53.00
24-04-03 06:58:55.175 - INFO: Train epoch 398: [84800/94637 (90%)] Step: [2354451] | Lr: 0.000100 | Loss: 0.7140 | MSE loss: 0.0001 | Bpp loss: 0.48 | Aux loss: 55.40
24-04-03 06:59:29.774 - INFO: Train epoch 398: [86400/94637 (91%)] Step: [2354551] | Lr: 0.000100 | Loss: 1.4204 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 53.93
24-04-03 07:00:04.957 - INFO: Train epoch 398: [88000/94637 (93%)] Step: [2354651] | Lr: 0.000100 | Loss: 1.6433 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 55.56
24-04-03 07:00:40.706 - INFO: Train epoch 398: [89600/94637 (95%)] Step: [2354751] | Lr: 0.000100 | Loss: 1.7449 | MSE loss: 0.0004 | Bpp loss: 1.03 | Aux loss: 58.35
24-04-03 07:01:16.378 - INFO: Train epoch 398: [91200/94637 (96%)] Step: [2354851] | Lr: 0.000100 | Loss: 0.8680 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 57.55
24-04-03 07:01:52.432 - INFO: Train epoch 398: [92800/94637 (98%)] Step: [2354951] | Lr: 0.000100 | Loss: 1.4973 | MSE loss: 0.0003 | Bpp loss: 0.96 | Aux loss: 55.34
24-04-03 07:02:30.095 - INFO: Train epoch 398: [94400/94637 (100%)] Step: [2355051] | Lr: 0.000100 | Loss: 1.3809 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 56.95
24-04-03 07:02:47.027 - INFO: Learning rate: 0.0001
24-04-03 07:02:47.922 - INFO: Train epoch 399: [    0/94637 (0%)] Step: [2355066] | Lr: 0.000100 | Loss: 1.2904 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 54.18
24-04-03 07:03:21.703 - INFO: Train epoch 399: [ 1600/94637 (2%)] Step: [2355166] | Lr: 0.000100 | Loss: 1.4491 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 57.41
24-04-03 07:03:55.922 - INFO: Train epoch 399: [ 3200/94637 (3%)] Step: [2355266] | Lr: 0.000100 | Loss: 1.5699 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 53.96
24-04-03 07:04:30.819 - INFO: Train epoch 399: [ 4800/94637 (5%)] Step: [2355366] | Lr: 0.000100 | Loss: 1.7500 | MSE loss: 0.0005 | Bpp loss: 0.89 | Aux loss: 55.69
24-04-03 07:05:05.515 - INFO: Train epoch 399: [ 6400/94637 (7%)] Step: [2355466] | Lr: 0.000100 | Loss: 2.1908 | MSE loss: 0.0006 | Bpp loss: 1.26 | Aux loss: 56.85
24-04-03 07:05:41.160 - INFO: Train epoch 399: [ 8000/94637 (8%)] Step: [2355566] | Lr: 0.000100 | Loss: 2.2963 | MSE loss: 0.0006 | Bpp loss: 1.37 | Aux loss: 55.15
24-04-03 07:06:15.577 - INFO: Train epoch 399: [ 9600/94637 (10%)] Step: [2355666] | Lr: 0.000100 | Loss: 0.8595 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 55.43
24-04-03 07:06:49.997 - INFO: Train epoch 399: [11200/94637 (12%)] Step: [2355766] | Lr: 0.000100 | Loss: 0.9385 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 55.45
24-04-03 07:07:25.707 - INFO: Train epoch 399: [12800/94637 (14%)] Step: [2355866] | Lr: 0.000100 | Loss: 0.9607 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 53.52
24-04-03 07:08:02.076 - INFO: Train epoch 399: [14400/94637 (15%)] Step: [2355966] | Lr: 0.000100 | Loss: 0.8905 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 52.18
24-04-03 07:08:38.136 - INFO: Train epoch 399: [16000/94637 (17%)] Step: [2356066] | Lr: 0.000100 | Loss: 1.1268 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 53.24
24-04-03 07:09:14.195 - INFO: Train epoch 399: [17600/94637 (19%)] Step: [2356166] | Lr: 0.000100 | Loss: 1.2568 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 56.01
24-04-03 07:09:50.328 - INFO: Train epoch 399: [19200/94637 (20%)] Step: [2356266] | Lr: 0.000100 | Loss: 0.5987 | MSE loss: 0.0001 | Bpp loss: 0.40 | Aux loss: 52.56
24-04-03 07:10:26.312 - INFO: Train epoch 399: [20800/94637 (22%)] Step: [2356366] | Lr: 0.000100 | Loss: 1.9007 | MSE loss: 0.0004 | Bpp loss: 1.21 | Aux loss: 53.43
24-04-03 07:11:01.211 - INFO: Train epoch 399: [22400/94637 (24%)] Step: [2356466] | Lr: 0.000100 | Loss: 0.9688 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 56.31
24-04-03 07:11:35.906 - INFO: Train epoch 399: [24000/94637 (25%)] Step: [2356566] | Lr: 0.000100 | Loss: 1.5539 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 53.92
24-04-03 07:12:10.853 - INFO: Train epoch 399: [25600/94637 (27%)] Step: [2356666] | Lr: 0.000100 | Loss: 0.9791 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 55.58
24-04-03 07:12:46.177 - INFO: Train epoch 399: [27200/94637 (29%)] Step: [2356766] | Lr: 0.000100 | Loss: 1.0403 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 52.52
24-04-03 07:13:20.974 - INFO: Train epoch 399: [28800/94637 (30%)] Step: [2356866] | Lr: 0.000100 | Loss: 1.0933 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 51.06
24-04-03 07:13:56.113 - INFO: Train epoch 399: [30400/94637 (32%)] Step: [2356966] | Lr: 0.000100 | Loss: 1.3120 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 55.52
24-04-03 07:14:31.191 - INFO: Train epoch 399: [32000/94637 (34%)] Step: [2357066] | Lr: 0.000100 | Loss: 1.1925 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 55.78
24-04-03 07:15:06.311 - INFO: Train epoch 399: [33600/94637 (36%)] Step: [2357166] | Lr: 0.000100 | Loss: 1.1678 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 52.87
24-04-03 07:15:41.284 - INFO: Train epoch 399: [35200/94637 (37%)] Step: [2357266] | Lr: 0.000100 | Loss: 1.1734 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 52.89
24-04-03 07:16:15.572 - INFO: Train epoch 399: [36800/94637 (39%)] Step: [2357366] | Lr: 0.000100 | Loss: 1.1443 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 54.69
24-04-03 07:16:50.747 - INFO: Train epoch 399: [38400/94637 (41%)] Step: [2357466] | Lr: 0.000100 | Loss: 1.7701 | MSE loss: 0.0004 | Bpp loss: 1.11 | Aux loss: 52.82
24-04-03 07:17:27.783 - INFO: Train epoch 399: [40000/94637 (42%)] Step: [2357566] | Lr: 0.000100 | Loss: 0.8424 | MSE loss: 0.0002 | Bpp loss: 0.46 | Aux loss: 52.07
24-04-03 07:18:03.754 - INFO: Train epoch 399: [41600/94637 (44%)] Step: [2357666] | Lr: 0.000100 | Loss: 1.8530 | MSE loss: 0.0004 | Bpp loss: 1.12 | Aux loss: 54.09
24-04-03 07:18:37.306 - INFO: Train epoch 399: [43200/94637 (46%)] Step: [2357766] | Lr: 0.000100 | Loss: 1.3577 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 53.15
24-04-03 07:19:10.940 - INFO: Train epoch 399: [44800/94637 (47%)] Step: [2357866] | Lr: 0.000100 | Loss: 1.2670 | MSE loss: 0.0004 | Bpp loss: 0.69 | Aux loss: 52.04
24-04-03 07:19:45.476 - INFO: Train epoch 399: [46400/94637 (49%)] Step: [2357966] | Lr: 0.000100 | Loss: 1.1089 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 53.38
24-04-03 07:20:19.358 - INFO: Train epoch 399: [48000/94637 (51%)] Step: [2358066] | Lr: 0.000100 | Loss: 0.8472 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 56.68
24-04-03 07:20:53.248 - INFO: Train epoch 399: [49600/94637 (52%)] Step: [2358166] | Lr: 0.000100 | Loss: 1.6881 | MSE loss: 0.0004 | Bpp loss: 1.08 | Aux loss: 54.31
24-04-03 07:21:28.000 - INFO: Train epoch 399: [51200/94637 (54%)] Step: [2358266] | Lr: 0.000100 | Loss: 1.2502 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 51.50
24-04-03 07:22:04.152 - INFO: Train epoch 399: [52800/94637 (56%)] Step: [2358366] | Lr: 0.000100 | Loss: 0.9764 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 52.01
24-04-03 07:22:40.922 - INFO: Train epoch 399: [54400/94637 (57%)] Step: [2358466] | Lr: 0.000100 | Loss: 1.4677 | MSE loss: 0.0004 | Bpp loss: 0.83 | Aux loss: 52.41
24-04-03 07:23:17.029 - INFO: Train epoch 399: [56000/94637 (59%)] Step: [2358566] | Lr: 0.000100 | Loss: 1.3366 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 54.95
24-04-03 07:23:52.676 - INFO: Train epoch 399: [57600/94637 (61%)] Step: [2358666] | Lr: 0.000100 | Loss: 1.0122 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 54.98
24-04-03 07:24:28.644 - INFO: Train epoch 399: [59200/94637 (63%)] Step: [2358766] | Lr: 0.000100 | Loss: 1.1099 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 56.13
24-04-03 07:25:03.105 - INFO: Train epoch 399: [60800/94637 (64%)] Step: [2358866] | Lr: 0.000100 | Loss: 0.7040 | MSE loss: 0.0002 | Bpp loss: 0.45 | Aux loss: 53.75
24-04-03 07:25:37.656 - INFO: Train epoch 399: [62400/94637 (66%)] Step: [2358966] | Lr: 0.000100 | Loss: 1.9191 | MSE loss: 0.0005 | Bpp loss: 1.03 | Aux loss: 54.67
24-04-03 07:26:12.431 - INFO: Train epoch 399: [64000/94637 (68%)] Step: [2359066] | Lr: 0.000100 | Loss: 0.9858 | MSE loss: 0.0003 | Bpp loss: 0.56 | Aux loss: 48.49
24-04-03 07:26:47.565 - INFO: Train epoch 399: [65600/94637 (69%)] Step: [2359166] | Lr: 0.000100 | Loss: 0.7810 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 53.88
24-04-03 07:27:21.724 - INFO: Train epoch 399: [67200/94637 (71%)] Step: [2359266] | Lr: 0.000100 | Loss: 0.8867 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 55.35
24-04-03 07:27:55.816 - INFO: Train epoch 399: [68800/94637 (73%)] Step: [2359366] | Lr: 0.000100 | Loss: 0.9367 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 54.79
24-04-03 07:28:31.675 - INFO: Train epoch 399: [70400/94637 (74%)] Step: [2359466] | Lr: 0.000100 | Loss: 1.1918 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 56.25
24-04-03 07:29:06.724 - INFO: Train epoch 399: [72000/94637 (76%)] Step: [2359566] | Lr: 0.000100 | Loss: 1.8578 | MSE loss: 0.0005 | Bpp loss: 1.06 | Aux loss: 53.60
24-04-03 07:29:41.336 - INFO: Train epoch 399: [73600/94637 (78%)] Step: [2359666] | Lr: 0.000100 | Loss: 1.5374 | MSE loss: 0.0004 | Bpp loss: 0.93 | Aux loss: 58.16
24-04-03 07:30:16.923 - INFO: Train epoch 399: [75200/94637 (79%)] Step: [2359766] | Lr: 0.000100 | Loss: 1.3294 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 51.35
24-04-03 07:30:51.855 - INFO: Train epoch 399: [76800/94637 (81%)] Step: [2359866] | Lr: 0.000100 | Loss: 1.0945 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 57.30
24-04-03 07:31:27.183 - INFO: Train epoch 399: [78400/94637 (83%)] Step: [2359966] | Lr: 0.000100 | Loss: 1.2914 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 53.90
24-04-03 07:32:05.387 - INFO: Train epoch 399: [80000/94637 (85%)] Step: [2360066] | Lr: 0.000100 | Loss: 1.2889 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 53.56
24-04-03 07:32:40.232 - INFO: Train epoch 399: [81600/94637 (86%)] Step: [2360166] | Lr: 0.000100 | Loss: 1.5701 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 50.91
24-04-03 07:33:15.990 - INFO: Train epoch 399: [83200/94637 (88%)] Step: [2360266] | Lr: 0.000100 | Loss: 1.6495 | MSE loss: 0.0004 | Bpp loss: 1.06 | Aux loss: 57.19
24-04-03 07:33:51.940 - INFO: Train epoch 399: [84800/94637 (90%)] Step: [2360366] | Lr: 0.000100 | Loss: 1.3316 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 52.87
24-04-03 07:34:26.727 - INFO: Train epoch 399: [86400/94637 (91%)] Step: [2360466] | Lr: 0.000100 | Loss: 1.0534 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 55.14
24-04-03 07:35:02.405 - INFO: Train epoch 399: [88000/94637 (93%)] Step: [2360566] | Lr: 0.000100 | Loss: 0.7650 | MSE loss: 0.0002 | Bpp loss: 0.48 | Aux loss: 56.91
24-04-03 07:35:38.483 - INFO: Train epoch 399: [89600/94637 (95%)] Step: [2360666] | Lr: 0.000100 | Loss: 1.6834 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 57.70
24-04-03 07:36:14.581 - INFO: Train epoch 399: [91200/94637 (96%)] Step: [2360766] | Lr: 0.000100 | Loss: 0.8096 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 52.98
24-04-03 07:36:50.578 - INFO: Train epoch 399: [92800/94637 (98%)] Step: [2360866] | Lr: 0.000100 | Loss: 1.4206 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 53.87
24-04-03 07:37:26.103 - INFO: Train epoch 399: [94400/94637 (100%)] Step: [2360966] | Lr: 0.000100 | Loss: 1.0236 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 57.95
24-04-03 07:37:43.111 - INFO: Learning rate: 0.0001
24-04-03 07:37:44.103 - INFO: Train epoch 400: [    0/94637 (0%)] Step: [2360981] | Lr: 0.000100 | Loss: 1.6231 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 54.24
24-04-03 07:38:18.906 - INFO: Train epoch 400: [ 1600/94637 (2%)] Step: [2361081] | Lr: 0.000100 | Loss: 1.7744 | MSE loss: 0.0004 | Bpp loss: 1.10 | Aux loss: 56.37
24-04-03 07:38:52.883 - INFO: Train epoch 400: [ 3200/94637 (3%)] Step: [2361181] | Lr: 0.000100 | Loss: 1.1439 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 54.39
24-04-03 07:39:26.741 - INFO: Train epoch 400: [ 4800/94637 (5%)] Step: [2361281] | Lr: 0.000100 | Loss: 1.0528 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 55.72
24-04-03 07:40:00.689 - INFO: Train epoch 400: [ 6400/94637 (7%)] Step: [2361381] | Lr: 0.000100 | Loss: 1.3033 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 53.07
24-04-03 07:40:34.577 - INFO: Train epoch 400: [ 8000/94637 (8%)] Step: [2361481] | Lr: 0.000100 | Loss: 2.2047 | MSE loss: 0.0006 | Bpp loss: 1.22 | Aux loss: 53.35
24-04-03 07:41:09.390 - INFO: Train epoch 400: [ 9600/94637 (10%)] Step: [2361581] | Lr: 0.000100 | Loss: 0.9140 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 52.86
24-04-03 07:41:44.128 - INFO: Train epoch 400: [11200/94637 (12%)] Step: [2361681] | Lr: 0.000100 | Loss: 1.0024 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 52.51
24-04-03 07:42:18.202 - INFO: Train epoch 400: [12800/94637 (14%)] Step: [2361781] | Lr: 0.000100 | Loss: 1.5069 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 52.80
24-04-03 07:42:52.792 - INFO: Train epoch 400: [14400/94637 (15%)] Step: [2361881] | Lr: 0.000100 | Loss: 0.7453 | MSE loss: 0.0002 | Bpp loss: 0.48 | Aux loss: 53.82
24-04-03 07:43:27.639 - INFO: Train epoch 400: [16000/94637 (17%)] Step: [2361981] | Lr: 0.000100 | Loss: 2.3144 | MSE loss: 0.0006 | Bpp loss: 1.38 | Aux loss: 54.36
24-04-03 07:44:04.060 - INFO: Train epoch 400: [17600/94637 (19%)] Step: [2362081] | Lr: 0.000100 | Loss: 1.0883 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 60.30
24-04-03 07:44:39.324 - INFO: Train epoch 400: [19200/94637 (20%)] Step: [2362181] | Lr: 0.000100 | Loss: 0.9745 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 55.85
24-04-03 07:45:15.000 - INFO: Train epoch 400: [20800/94637 (22%)] Step: [2362281] | Lr: 0.000100 | Loss: 1.0677 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 51.63
24-04-03 07:45:51.154 - INFO: Train epoch 400: [22400/94637 (24%)] Step: [2362381] | Lr: 0.000100 | Loss: 1.2160 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 55.60
24-04-03 07:46:25.648 - INFO: Train epoch 400: [24000/94637 (25%)] Step: [2362481] | Lr: 0.000100 | Loss: 2.1559 | MSE loss: 0.0005 | Bpp loss: 1.31 | Aux loss: 53.50
24-04-03 07:47:02.390 - INFO: Train epoch 400: [25600/94637 (27%)] Step: [2362581] | Lr: 0.000100 | Loss: 1.2536 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 53.65
24-04-03 07:47:37.341 - INFO: Train epoch 400: [27200/94637 (29%)] Step: [2362681] | Lr: 0.000100 | Loss: 1.6273 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 52.94
24-04-03 07:48:13.194 - INFO: Train epoch 400: [28800/94637 (30%)] Step: [2362781] | Lr: 0.000100 | Loss: 1.5600 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 51.01
24-04-03 07:48:49.158 - INFO: Train epoch 400: [30400/94637 (32%)] Step: [2362881] | Lr: 0.000100 | Loss: 1.5932 | MSE loss: 0.0004 | Bpp loss: 0.93 | Aux loss: 56.53
24-04-03 07:49:24.553 - INFO: Train epoch 400: [32000/94637 (34%)] Step: [2362981] | Lr: 0.000100 | Loss: 1.3111 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 51.17
24-04-03 07:50:00.191 - INFO: Train epoch 400: [33600/94637 (36%)] Step: [2363081] | Lr: 0.000100 | Loss: 0.8944 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 58.51
24-04-03 07:50:36.554 - INFO: Train epoch 400: [35200/94637 (37%)] Step: [2363181] | Lr: 0.000100 | Loss: 0.9898 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 50.84
24-04-03 07:51:11.564 - INFO: Train epoch 400: [36800/94637 (39%)] Step: [2363281] | Lr: 0.000100 | Loss: 1.4583 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 53.58
24-04-03 07:51:46.043 - INFO: Train epoch 400: [38400/94637 (41%)] Step: [2363381] | Lr: 0.000100 | Loss: 1.1736 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 54.57
24-04-03 07:52:21.078 - INFO: Train epoch 400: [40000/94637 (42%)] Step: [2363481] | Lr: 0.000100 | Loss: 1.1608 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 54.03
24-04-03 07:52:55.831 - INFO: Train epoch 400: [41600/94637 (44%)] Step: [2363581] | Lr: 0.000100 | Loss: 1.2242 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 55.82
24-04-03 07:53:31.137 - INFO: Train epoch 400: [43200/94637 (46%)] Step: [2363681] | Lr: 0.000100 | Loss: 1.5294 | MSE loss: 0.0003 | Bpp loss: 0.97 | Aux loss: 49.05
24-04-03 07:54:06.617 - INFO: Train epoch 400: [44800/94637 (47%)] Step: [2363781] | Lr: 0.000100 | Loss: 1.2575 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 53.71
24-04-03 07:54:41.493 - INFO: Train epoch 400: [46400/94637 (49%)] Step: [2363881] | Lr: 0.000100 | Loss: 2.0399 | MSE loss: 0.0004 | Bpp loss: 1.32 | Aux loss: 50.98
24-04-03 07:55:15.993 - INFO: Train epoch 400: [48000/94637 (51%)] Step: [2363981] | Lr: 0.000100 | Loss: 1.4447 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 52.03
24-04-03 07:55:50.652 - INFO: Train epoch 400: [49600/94637 (52%)] Step: [2364081] | Lr: 0.000100 | Loss: 2.0521 | MSE loss: 0.0006 | Bpp loss: 1.15 | Aux loss: 55.80
24-04-03 07:56:26.039 - INFO: Train epoch 400: [51200/94637 (54%)] Step: [2364181] | Lr: 0.000100 | Loss: 1.2662 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 53.14
24-04-03 07:57:00.904 - INFO: Train epoch 400: [52800/94637 (56%)] Step: [2364281] | Lr: 0.000100 | Loss: 1.0771 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 53.94
24-04-03 07:57:36.263 - INFO: Train epoch 400: [54400/94637 (57%)] Step: [2364381] | Lr: 0.000100 | Loss: 1.2015 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 56.64
24-04-03 07:58:11.226 - INFO: Train epoch 400: [56000/94637 (59%)] Step: [2364481] | Lr: 0.000100 | Loss: 1.6232 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 54.18
24-04-03 07:58:46.234 - INFO: Train epoch 400: [57600/94637 (61%)] Step: [2364581] | Lr: 0.000100 | Loss: 0.8874 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 52.72
24-04-03 07:59:21.370 - INFO: Train epoch 400: [59200/94637 (63%)] Step: [2364681] | Lr: 0.000100 | Loss: 1.1896 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 51.09
24-04-03 07:59:56.876 - INFO: Train epoch 400: [60800/94637 (64%)] Step: [2364781] | Lr: 0.000100 | Loss: 1.1294 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 56.57
24-04-03 08:00:32.637 - INFO: Train epoch 400: [62400/94637 (66%)] Step: [2364881] | Lr: 0.000100 | Loss: 1.0703 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 58.54
24-04-03 08:01:07.854 - INFO: Train epoch 400: [64000/94637 (68%)] Step: [2364981] | Lr: 0.000100 | Loss: 1.6643 | MSE loss: 0.0005 | Bpp loss: 0.90 | Aux loss: 61.20
24-04-03 08:01:45.740 - INFO: Train epoch 400: [65600/94637 (69%)] Step: [2365081] | Lr: 0.000100 | Loss: 1.4916 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 57.55
24-04-03 08:02:21.762 - INFO: Train epoch 400: [67200/94637 (71%)] Step: [2365181] | Lr: 0.000100 | Loss: 1.0930 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 54.27
24-04-03 08:02:56.901 - INFO: Train epoch 400: [68800/94637 (73%)] Step: [2365281] | Lr: 0.000100 | Loss: 1.3217 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 50.34
24-04-03 08:03:31.433 - INFO: Train epoch 400: [70400/94637 (74%)] Step: [2365381] | Lr: 0.000100 | Loss: 0.5347 | MSE loss: 0.0001 | Bpp loss: 0.37 | Aux loss: 54.28
24-04-03 08:04:06.228 - INFO: Train epoch 400: [72000/94637 (76%)] Step: [2365481] | Lr: 0.000100 | Loss: 1.8464 | MSE loss: 0.0005 | Bpp loss: 1.08 | Aux loss: 55.59
24-04-03 08:04:41.264 - INFO: Train epoch 400: [73600/94637 (78%)] Step: [2365581] | Lr: 0.000100 | Loss: 1.3709 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 52.90
24-04-03 08:05:16.752 - INFO: Train epoch 400: [75200/94637 (79%)] Step: [2365681] | Lr: 0.000100 | Loss: 1.1112 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 52.51
24-04-03 08:05:51.594 - INFO: Train epoch 400: [76800/94637 (81%)] Step: [2365781] | Lr: 0.000100 | Loss: 0.8736 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 54.37
24-04-03 08:06:26.371 - INFO: Train epoch 400: [78400/94637 (83%)] Step: [2365881] | Lr: 0.000100 | Loss: 2.0250 | MSE loss: 0.0005 | Bpp loss: 1.20 | Aux loss: 54.33
24-04-03 08:07:01.902 - INFO: Train epoch 400: [80000/94637 (85%)] Step: [2365981] | Lr: 0.000100 | Loss: 1.8423 | MSE loss: 0.0004 | Bpp loss: 1.13 | Aux loss: 52.82
24-04-03 08:07:36.179 - INFO: Train epoch 400: [81600/94637 (86%)] Step: [2366081] | Lr: 0.000100 | Loss: 0.7588 | MSE loss: 0.0002 | Bpp loss: 0.46 | Aux loss: 57.69
24-04-03 08:08:10.996 - INFO: Train epoch 400: [83200/94637 (88%)] Step: [2366181] | Lr: 0.000100 | Loss: 1.4684 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 53.72
24-04-03 08:08:45.449 - INFO: Train epoch 400: [84800/94637 (90%)] Step: [2366281] | Lr: 0.000100 | Loss: 1.1260 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 55.26
24-04-03 08:09:19.992 - INFO: Train epoch 400: [86400/94637 (91%)] Step: [2366381] | Lr: 0.000100 | Loss: 1.5435 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 54.57
24-04-03 08:09:55.489 - INFO: Train epoch 400: [88000/94637 (93%)] Step: [2366481] | Lr: 0.000100 | Loss: 1.9513 | MSE loss: 0.0005 | Bpp loss: 1.11 | Aux loss: 51.15
24-04-03 08:10:30.338 - INFO: Train epoch 400: [89600/94637 (95%)] Step: [2366581] | Lr: 0.000100 | Loss: 1.3357 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 53.97
24-04-03 08:11:04.626 - INFO: Train epoch 400: [91200/94637 (96%)] Step: [2366681] | Lr: 0.000100 | Loss: 0.9395 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 55.47
24-04-03 08:11:38.818 - INFO: Train epoch 400: [92800/94637 (98%)] Step: [2366781] | Lr: 0.000100 | Loss: 1.4665 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 52.71
24-04-03 08:12:14.174 - INFO: Train epoch 400: [94400/94637 (100%)] Step: [2366881] | Lr: 0.000100 | Loss: 1.4447 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 56.93
24-04-03 08:12:30.772 - INFO: Learning rate: 0.0001
24-04-03 08:12:31.624 - INFO: Train epoch 401: [    0/94637 (0%)] Step: [2366896] | Lr: 0.000100 | Loss: 1.3719 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 56.04
24-04-03 08:13:06.206 - INFO: Train epoch 401: [ 1600/94637 (2%)] Step: [2366996] | Lr: 0.000100 | Loss: 0.9638 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 53.62
24-04-03 08:13:39.998 - INFO: Train epoch 401: [ 3200/94637 (3%)] Step: [2367096] | Lr: 0.000100 | Loss: 1.1820 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 51.90
24-04-03 08:14:14.723 - INFO: Train epoch 401: [ 4800/94637 (5%)] Step: [2367196] | Lr: 0.000100 | Loss: 1.8814 | MSE loss: 0.0004 | Bpp loss: 1.21 | Aux loss: 52.62
24-04-03 08:14:50.269 - INFO: Train epoch 401: [ 6400/94637 (7%)] Step: [2367296] | Lr: 0.000100 | Loss: 2.0282 | MSE loss: 0.0006 | Bpp loss: 1.13 | Aux loss: 58.10
24-04-03 08:15:25.577 - INFO: Train epoch 401: [ 8000/94637 (8%)] Step: [2367396] | Lr: 0.000100 | Loss: 1.5122 | MSE loss: 0.0003 | Bpp loss: 0.98 | Aux loss: 53.18
24-04-03 08:16:00.491 - INFO: Train epoch 401: [ 9600/94637 (10%)] Step: [2367496] | Lr: 0.000100 | Loss: 1.0548 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 56.33
24-04-03 08:16:37.281 - INFO: Train epoch 401: [11200/94637 (12%)] Step: [2367596] | Lr: 0.000100 | Loss: 1.4981 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 53.92
24-04-03 08:17:12.967 - INFO: Train epoch 401: [12800/94637 (14%)] Step: [2367696] | Lr: 0.000100 | Loss: 1.5783 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 56.07
24-04-03 08:17:48.772 - INFO: Train epoch 401: [14400/94637 (15%)] Step: [2367796] | Lr: 0.000100 | Loss: 1.8078 | MSE loss: 0.0005 | Bpp loss: 1.04 | Aux loss: 53.58
24-04-03 08:18:24.000 - INFO: Train epoch 401: [16000/94637 (17%)] Step: [2367896] | Lr: 0.000100 | Loss: 1.0053 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 54.20
24-04-03 08:18:59.340 - INFO: Train epoch 401: [17600/94637 (19%)] Step: [2367996] | Lr: 0.000100 | Loss: 1.4791 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 54.94
24-04-03 08:19:34.568 - INFO: Train epoch 401: [19200/94637 (20%)] Step: [2368096] | Lr: 0.000100 | Loss: 1.2655 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 52.76
24-04-03 08:20:10.708 - INFO: Train epoch 401: [20800/94637 (22%)] Step: [2368196] | Lr: 0.000100 | Loss: 0.8974 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 52.98
24-04-03 08:20:46.342 - INFO: Train epoch 401: [22400/94637 (24%)] Step: [2368296] | Lr: 0.000100 | Loss: 1.1054 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 54.68
24-04-03 08:21:21.423 - INFO: Train epoch 401: [24000/94637 (25%)] Step: [2368396] | Lr: 0.000100 | Loss: 0.9574 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 52.65
24-04-03 08:21:57.025 - INFO: Train epoch 401: [25600/94637 (27%)] Step: [2368496] | Lr: 0.000100 | Loss: 1.1143 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 52.59
24-04-03 08:22:32.316 - INFO: Train epoch 401: [27200/94637 (29%)] Step: [2368596] | Lr: 0.000100 | Loss: 2.1938 | MSE loss: 0.0006 | Bpp loss: 1.19 | Aux loss: 55.03
24-04-03 08:23:07.709 - INFO: Train epoch 401: [28800/94637 (30%)] Step: [2368696] | Lr: 0.000100 | Loss: 0.8515 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 53.04
24-04-03 08:23:42.186 - INFO: Train epoch 401: [30400/94637 (32%)] Step: [2368796] | Lr: 0.000100 | Loss: 1.0138 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 53.95
24-04-03 08:24:16.749 - INFO: Train epoch 401: [32000/94637 (34%)] Step: [2368896] | Lr: 0.000100 | Loss: 1.2605 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 55.65
24-04-03 08:24:51.544 - INFO: Train epoch 401: [33600/94637 (36%)] Step: [2368996] | Lr: 0.000100 | Loss: 1.4809 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 51.64
24-04-03 08:25:26.977 - INFO: Train epoch 401: [35200/94637 (37%)] Step: [2369096] | Lr: 0.000100 | Loss: 1.1291 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 47.93
24-04-03 08:26:02.215 - INFO: Train epoch 401: [36800/94637 (39%)] Step: [2369196] | Lr: 0.000100 | Loss: 1.2480 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 52.62
24-04-03 08:26:36.964 - INFO: Train epoch 401: [38400/94637 (41%)] Step: [2369296] | Lr: 0.000100 | Loss: 1.4168 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 55.06
24-04-03 08:27:11.221 - INFO: Train epoch 401: [40000/94637 (42%)] Step: [2369396] | Lr: 0.000100 | Loss: 1.3678 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 52.97
24-04-03 08:27:45.595 - INFO: Train epoch 401: [41600/94637 (44%)] Step: [2369496] | Lr: 0.000100 | Loss: 1.0662 | MSE loss: 0.0003 | Bpp loss: 0.62 | Aux loss: 54.20
24-04-03 08:28:21.025 - INFO: Train epoch 401: [43200/94637 (46%)] Step: [2369596] | Lr: 0.000100 | Loss: 1.1643 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 54.13
24-04-03 08:28:56.490 - INFO: Train epoch 401: [44800/94637 (47%)] Step: [2369696] | Lr: 0.000100 | Loss: 0.8747 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 52.94
24-04-03 08:29:32.437 - INFO: Train epoch 401: [46400/94637 (49%)] Step: [2369796] | Lr: 0.000100 | Loss: 1.7961 | MSE loss: 0.0005 | Bpp loss: 1.05 | Aux loss: 57.06
24-04-03 08:30:08.013 - INFO: Train epoch 401: [48000/94637 (51%)] Step: [2369896] | Lr: 0.000100 | Loss: 1.5339 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 56.54
24-04-03 08:30:43.704 - INFO: Train epoch 401: [49600/94637 (52%)] Step: [2369996] | Lr: 0.000100 | Loss: 0.7439 | MSE loss: 0.0002 | Bpp loss: 0.47 | Aux loss: 57.07
24-04-03 08:31:19.619 - INFO: Train epoch 401: [51200/94637 (54%)] Step: [2370096] | Lr: 0.000100 | Loss: 1.4417 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 52.47
24-04-03 08:31:53.348 - INFO: Train epoch 401: [52800/94637 (56%)] Step: [2370196] | Lr: 0.000100 | Loss: 1.1724 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 58.09
24-04-03 08:32:27.494 - INFO: Train epoch 401: [54400/94637 (57%)] Step: [2370296] | Lr: 0.000100 | Loss: 1.1025 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 56.45
24-04-03 08:33:01.517 - INFO: Train epoch 401: [56000/94637 (59%)] Step: [2370396] | Lr: 0.000100 | Loss: 0.8010 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 53.74
24-04-03 08:33:35.306 - INFO: Train epoch 401: [57600/94637 (61%)] Step: [2370496] | Lr: 0.000100 | Loss: 1.3987 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 53.54
24-04-03 08:34:08.702 - INFO: Train epoch 401: [59200/94637 (63%)] Step: [2370596] | Lr: 0.000100 | Loss: 1.0163 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 55.34
24-04-03 08:34:43.772 - INFO: Train epoch 401: [60800/94637 (64%)] Step: [2370696] | Lr: 0.000100 | Loss: 1.0349 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 57.04
24-04-03 08:35:18.090 - INFO: Train epoch 401: [62400/94637 (66%)] Step: [2370796] | Lr: 0.000100 | Loss: 1.5610 | MSE loss: 0.0003 | Bpp loss: 1.00 | Aux loss: 58.22
24-04-03 08:35:53.241 - INFO: Train epoch 401: [64000/94637 (68%)] Step: [2370896] | Lr: 0.000100 | Loss: 1.2181 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 58.38
24-04-03 08:36:27.973 - INFO: Train epoch 401: [65600/94637 (69%)] Step: [2370996] | Lr: 0.000100 | Loss: 1.2493 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 52.69
24-04-03 08:37:02.211 - INFO: Train epoch 401: [67200/94637 (71%)] Step: [2371096] | Lr: 0.000100 | Loss: 1.8005 | MSE loss: 0.0005 | Bpp loss: 0.97 | Aux loss: 56.42
24-04-03 08:37:37.035 - INFO: Train epoch 401: [68800/94637 (73%)] Step: [2371196] | Lr: 0.000100 | Loss: 1.9442 | MSE loss: 0.0004 | Bpp loss: 1.23 | Aux loss: 56.74
24-04-03 08:38:11.564 - INFO: Train epoch 401: [70400/94637 (74%)] Step: [2371296] | Lr: 0.000100 | Loss: 1.4269 | MSE loss: 0.0004 | Bpp loss: 0.81 | Aux loss: 54.96
24-04-03 08:38:47.046 - INFO: Train epoch 401: [72000/94637 (76%)] Step: [2371396] | Lr: 0.000100 | Loss: 1.2666 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 54.11
24-04-03 08:39:22.424 - INFO: Train epoch 401: [73600/94637 (78%)] Step: [2371496] | Lr: 0.000100 | Loss: 0.9964 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 53.91
24-04-03 08:39:58.442 - INFO: Train epoch 401: [75200/94637 (79%)] Step: [2371596] | Lr: 0.000100 | Loss: 0.8362 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 55.70
24-04-03 08:40:35.122 - INFO: Train epoch 401: [76800/94637 (81%)] Step: [2371696] | Lr: 0.000100 | Loss: 2.2083 | MSE loss: 0.0006 | Bpp loss: 1.30 | Aux loss: 58.61
24-04-03 08:41:10.688 - INFO: Train epoch 401: [78400/94637 (83%)] Step: [2371796] | Lr: 0.000100 | Loss: 1.3651 | MSE loss: 0.0004 | Bpp loss: 0.75 | Aux loss: 52.33
24-04-03 08:41:46.876 - INFO: Train epoch 401: [80000/94637 (85%)] Step: [2371896] | Lr: 0.000100 | Loss: 1.2178 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 53.43
24-04-03 08:42:22.189 - INFO: Train epoch 401: [81600/94637 (86%)] Step: [2371996] | Lr: 0.000100 | Loss: 1.7084 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 58.03
24-04-03 08:42:57.710 - INFO: Train epoch 401: [83200/94637 (88%)] Step: [2372096] | Lr: 0.000100 | Loss: 0.8416 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 56.18
24-04-03 08:43:33.703 - INFO: Train epoch 401: [84800/94637 (90%)] Step: [2372196] | Lr: 0.000100 | Loss: 1.1584 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 55.86
24-04-03 08:44:09.489 - INFO: Train epoch 401: [86400/94637 (91%)] Step: [2372296] | Lr: 0.000100 | Loss: 1.2029 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 56.08
24-04-03 08:44:44.779 - INFO: Train epoch 401: [88000/94637 (93%)] Step: [2372396] | Lr: 0.000100 | Loss: 1.2735 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 54.65
24-04-03 08:45:20.571 - INFO: Train epoch 401: [89600/94637 (95%)] Step: [2372496] | Lr: 0.000100 | Loss: 1.2521 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 54.14
24-04-03 08:45:58.928 - INFO: Train epoch 401: [91200/94637 (96%)] Step: [2372596] | Lr: 0.000100 | Loss: 1.0160 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 56.45
24-04-03 08:46:33.731 - INFO: Train epoch 401: [92800/94637 (98%)] Step: [2372696] | Lr: 0.000100 | Loss: 1.4705 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 56.23
24-04-03 08:47:10.156 - INFO: Train epoch 401: [94400/94637 (100%)] Step: [2372796] | Lr: 0.000100 | Loss: 0.8030 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 56.69
24-04-03 08:47:26.734 - INFO: Learning rate: 0.0001
24-04-03 08:47:27.554 - INFO: Train epoch 402: [    0/94637 (0%)] Step: [2372811] | Lr: 0.000100 | Loss: 1.8457 | MSE loss: 0.0005 | Bpp loss: 1.10 | Aux loss: 54.73
24-04-03 08:48:01.973 - INFO: Train epoch 402: [ 1600/94637 (2%)] Step: [2372911] | Lr: 0.000100 | Loss: 1.8209 | MSE loss: 0.0004 | Bpp loss: 1.10 | Aux loss: 52.30
24-04-03 08:48:36.209 - INFO: Train epoch 402: [ 3200/94637 (3%)] Step: [2373011] | Lr: 0.000100 | Loss: 1.2036 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 57.54
24-04-03 08:49:11.677 - INFO: Train epoch 402: [ 4800/94637 (5%)] Step: [2373111] | Lr: 0.000100 | Loss: 1.0161 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 53.06
24-04-03 08:49:46.203 - INFO: Train epoch 402: [ 6400/94637 (7%)] Step: [2373211] | Lr: 0.000100 | Loss: 1.1153 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 57.65
24-04-03 08:50:22.669 - INFO: Train epoch 402: [ 8000/94637 (8%)] Step: [2373311] | Lr: 0.000100 | Loss: 0.9755 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 57.12
24-04-03 08:50:58.218 - INFO: Train epoch 402: [ 9600/94637 (10%)] Step: [2373411] | Lr: 0.000100 | Loss: 1.0023 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 56.13
24-04-03 08:51:34.382 - INFO: Train epoch 402: [11200/94637 (12%)] Step: [2373511] | Lr: 0.000100 | Loss: 0.8926 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 55.07
24-04-03 08:52:09.518 - INFO: Train epoch 402: [12800/94637 (14%)] Step: [2373611] | Lr: 0.000100 | Loss: 1.2040 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 57.38
24-04-03 08:52:43.851 - INFO: Train epoch 402: [14400/94637 (15%)] Step: [2373711] | Lr: 0.000100 | Loss: 1.2705 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 50.63
24-04-03 08:53:17.710 - INFO: Train epoch 402: [16000/94637 (17%)] Step: [2373811] | Lr: 0.000100 | Loss: 1.4628 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 51.84
24-04-03 08:53:53.157 - INFO: Train epoch 402: [17600/94637 (19%)] Step: [2373911] | Lr: 0.000100 | Loss: 1.5890 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 54.00
24-04-03 08:54:27.947 - INFO: Train epoch 402: [19200/94637 (20%)] Step: [2374011] | Lr: 0.000100 | Loss: 1.5325 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 52.64
24-04-03 08:55:02.680 - INFO: Train epoch 402: [20800/94637 (22%)] Step: [2374111] | Lr: 0.000100 | Loss: 1.4774 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 51.78
24-04-03 08:55:37.078 - INFO: Train epoch 402: [22400/94637 (24%)] Step: [2374211] | Lr: 0.000100 | Loss: 1.9738 | MSE loss: 0.0004 | Bpp loss: 1.27 | Aux loss: 53.70
24-04-03 08:56:12.411 - INFO: Train epoch 402: [24000/94637 (25%)] Step: [2374311] | Lr: 0.000100 | Loss: 1.3219 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 52.51
24-04-03 08:56:46.512 - INFO: Train epoch 402: [25600/94637 (27%)] Step: [2374411] | Lr: 0.000100 | Loss: 1.1689 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 52.47
24-04-03 08:57:21.229 - INFO: Train epoch 402: [27200/94637 (29%)] Step: [2374511] | Lr: 0.000100 | Loss: 1.9636 | MSE loss: 0.0006 | Bpp loss: 1.01 | Aux loss: 55.25
24-04-03 08:57:55.378 - INFO: Train epoch 402: [28800/94637 (30%)] Step: [2374611] | Lr: 0.000100 | Loss: 1.3285 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 52.92
24-04-03 08:58:29.753 - INFO: Train epoch 402: [30400/94637 (32%)] Step: [2374711] | Lr: 0.000100 | Loss: 0.8024 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 55.17
24-04-03 08:59:04.834 - INFO: Train epoch 402: [32000/94637 (34%)] Step: [2374811] | Lr: 0.000100 | Loss: 1.4166 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 53.59
24-04-03 08:59:39.908 - INFO: Train epoch 402: [33600/94637 (36%)] Step: [2374911] | Lr: 0.000100 | Loss: 1.1714 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 52.69
24-04-03 09:00:15.818 - INFO: Train epoch 402: [35200/94637 (37%)] Step: [2375011] | Lr: 0.000100 | Loss: 1.9182 | MSE loss: 0.0005 | Bpp loss: 1.14 | Aux loss: 52.25
24-04-03 09:00:49.782 - INFO: Train epoch 402: [36800/94637 (39%)] Step: [2375111] | Lr: 0.000100 | Loss: 0.8078 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 55.65
24-04-03 09:01:23.489 - INFO: Train epoch 402: [38400/94637 (41%)] Step: [2375211] | Lr: 0.000100 | Loss: 1.0189 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 52.78
24-04-03 09:01:57.576 - INFO: Train epoch 402: [40000/94637 (42%)] Step: [2375311] | Lr: 0.000100 | Loss: 1.0385 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 52.71
24-04-03 09:02:32.210 - INFO: Train epoch 402: [41600/94637 (44%)] Step: [2375411] | Lr: 0.000100 | Loss: 1.2312 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 53.92
24-04-03 09:03:07.197 - INFO: Train epoch 402: [43200/94637 (46%)] Step: [2375511] | Lr: 0.000100 | Loss: 1.2771 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 59.89
24-04-03 09:03:41.815 - INFO: Train epoch 402: [44800/94637 (47%)] Step: [2375611] | Lr: 0.000100 | Loss: 1.6363 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 55.19
24-04-03 09:04:15.354 - INFO: Train epoch 402: [46400/94637 (49%)] Step: [2375711] | Lr: 0.000100 | Loss: 1.0646 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 52.98
24-04-03 09:04:50.464 - INFO: Train epoch 402: [48000/94637 (51%)] Step: [2375811] | Lr: 0.000100 | Loss: 1.8019 | MSE loss: 0.0005 | Bpp loss: 0.99 | Aux loss: 55.47
24-04-03 09:05:26.511 - INFO: Train epoch 402: [49600/94637 (52%)] Step: [2375911] | Lr: 0.000100 | Loss: 0.8363 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 56.82
24-04-03 09:06:01.760 - INFO: Train epoch 402: [51200/94637 (54%)] Step: [2376011] | Lr: 0.000100 | Loss: 1.0584 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 53.52
24-04-03 09:06:37.459 - INFO: Train epoch 402: [52800/94637 (56%)] Step: [2376111] | Lr: 0.000100 | Loss: 1.3358 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 51.08
24-04-03 09:07:13.289 - INFO: Train epoch 402: [54400/94637 (57%)] Step: [2376211] | Lr: 0.000100 | Loss: 0.7963 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 53.93
24-04-03 09:07:47.920 - INFO: Train epoch 402: [56000/94637 (59%)] Step: [2376311] | Lr: 0.000100 | Loss: 1.0910 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 52.13
24-04-03 09:08:22.864 - INFO: Train epoch 402: [57600/94637 (61%)] Step: [2376411] | Lr: 0.000100 | Loss: 1.3604 | MSE loss: 0.0004 | Bpp loss: 0.64 | Aux loss: 51.87
24-04-03 09:08:57.497 - INFO: Train epoch 402: [59200/94637 (63%)] Step: [2376511] | Lr: 0.000100 | Loss: 1.5542 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 55.24
24-04-03 09:09:32.240 - INFO: Train epoch 402: [60800/94637 (64%)] Step: [2376611] | Lr: 0.000100 | Loss: 0.8032 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 54.24
24-04-03 09:10:07.816 - INFO: Train epoch 402: [62400/94637 (66%)] Step: [2376711] | Lr: 0.000100 | Loss: 1.3604 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 55.80
24-04-03 09:10:43.315 - INFO: Train epoch 402: [64000/94637 (68%)] Step: [2376811] | Lr: 0.000100 | Loss: 0.9390 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 55.65
24-04-03 09:11:18.111 - INFO: Train epoch 402: [65600/94637 (69%)] Step: [2376911] | Lr: 0.000100 | Loss: 1.0413 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 51.72
24-04-03 09:11:53.869 - INFO: Train epoch 402: [67200/94637 (71%)] Step: [2377011] | Lr: 0.000100 | Loss: 1.0446 | MSE loss: 0.0003 | Bpp loss: 0.61 | Aux loss: 55.37
24-04-03 09:12:30.348 - INFO: Train epoch 402: [68800/94637 (73%)] Step: [2377111] | Lr: 0.000100 | Loss: 1.0936 | MSE loss: 0.0003 | Bpp loss: 0.62 | Aux loss: 52.19
24-04-03 09:13:05.679 - INFO: Train epoch 402: [70400/94637 (74%)] Step: [2377211] | Lr: 0.000100 | Loss: 1.2061 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 54.14
24-04-03 09:13:41.508 - INFO: Train epoch 402: [72000/94637 (76%)] Step: [2377311] | Lr: 0.000100 | Loss: 1.3566 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 53.76
24-04-03 09:14:17.673 - INFO: Train epoch 402: [73600/94637 (78%)] Step: [2377411] | Lr: 0.000100 | Loss: 1.6886 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 51.69
24-04-03 09:14:55.033 - INFO: Train epoch 402: [75200/94637 (79%)] Step: [2377511] | Lr: 0.000100 | Loss: 1.5628 | MSE loss: 0.0004 | Bpp loss: 0.88 | Aux loss: 55.48
24-04-03 09:15:30.254 - INFO: Train epoch 402: [76800/94637 (81%)] Step: [2377611] | Lr: 0.000100 | Loss: 1.8801 | MSE loss: 0.0005 | Bpp loss: 1.02 | Aux loss: 57.03
24-04-03 09:16:04.479 - INFO: Train epoch 402: [78400/94637 (83%)] Step: [2377711] | Lr: 0.000100 | Loss: 1.3587 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 56.64
24-04-03 09:16:38.470 - INFO: Train epoch 402: [80000/94637 (85%)] Step: [2377811] | Lr: 0.000100 | Loss: 1.4226 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 56.38
24-04-03 09:17:11.930 - INFO: Train epoch 402: [81600/94637 (86%)] Step: [2377911] | Lr: 0.000100 | Loss: 1.1369 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 54.18
24-04-03 09:17:46.045 - INFO: Train epoch 402: [83200/94637 (88%)] Step: [2378011] | Lr: 0.000100 | Loss: 1.4008 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 52.92
24-04-03 09:18:21.353 - INFO: Train epoch 402: [84800/94637 (90%)] Step: [2378111] | Lr: 0.000100 | Loss: 1.0384 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 54.71
24-04-03 09:18:56.744 - INFO: Train epoch 402: [86400/94637 (91%)] Step: [2378211] | Lr: 0.000100 | Loss: 1.1530 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 59.82
24-04-03 09:19:32.729 - INFO: Train epoch 402: [88000/94637 (93%)] Step: [2378311] | Lr: 0.000100 | Loss: 1.4525 | MSE loss: 0.0003 | Bpp loss: 0.96 | Aux loss: 54.76
24-04-03 09:20:08.601 - INFO: Train epoch 402: [89600/94637 (95%)] Step: [2378411] | Lr: 0.000100 | Loss: 1.3355 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 55.08
24-04-03 09:20:43.775 - INFO: Train epoch 402: [91200/94637 (96%)] Step: [2378511] | Lr: 0.000100 | Loss: 1.7476 | MSE loss: 0.0004 | Bpp loss: 1.06 | Aux loss: 52.61
24-04-03 09:21:18.765 - INFO: Train epoch 402: [92800/94637 (98%)] Step: [2378611] | Lr: 0.000100 | Loss: 1.2313 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 58.80
24-04-03 09:21:54.110 - INFO: Train epoch 402: [94400/94637 (100%)] Step: [2378711] | Lr: 0.000100 | Loss: 1.2716 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 52.83
24-04-03 09:22:10.949 - INFO: Learning rate: 0.0001
24-04-03 09:22:11.884 - INFO: Train epoch 403: [    0/94637 (0%)] Step: [2378726] | Lr: 0.000100 | Loss: 1.7038 | MSE loss: 0.0004 | Bpp loss: 1.08 | Aux loss: 53.07
24-04-03 09:22:46.635 - INFO: Train epoch 403: [ 1600/94637 (2%)] Step: [2378826] | Lr: 0.000100 | Loss: 1.3257 | MSE loss: 0.0004 | Bpp loss: 0.73 | Aux loss: 54.87
24-04-03 09:23:21.380 - INFO: Train epoch 403: [ 3200/94637 (3%)] Step: [2378926] | Lr: 0.000100 | Loss: 1.8718 | MSE loss: 0.0005 | Bpp loss: 1.11 | Aux loss: 51.45
24-04-03 09:23:55.443 - INFO: Train epoch 403: [ 4800/94637 (5%)] Step: [2379026] | Lr: 0.000100 | Loss: 0.8738 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 51.05
24-04-03 09:24:30.163 - INFO: Train epoch 403: [ 6400/94637 (7%)] Step: [2379126] | Lr: 0.000100 | Loss: 1.5254 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 58.19
24-04-03 09:25:04.933 - INFO: Train epoch 403: [ 8000/94637 (8%)] Step: [2379226] | Lr: 0.000100 | Loss: 1.1713 | MSE loss: 0.0002 | Bpp loss: 0.79 | Aux loss: 52.96
24-04-03 09:25:40.307 - INFO: Train epoch 403: [ 9600/94637 (10%)] Step: [2379326] | Lr: 0.000100 | Loss: 1.0288 | MSE loss: 0.0003 | Bpp loss: 0.58 | Aux loss: 52.46
24-04-03 09:26:15.506 - INFO: Train epoch 403: [11200/94637 (12%)] Step: [2379426] | Lr: 0.000100 | Loss: 1.2417 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 49.69
24-04-03 09:26:50.606 - INFO: Train epoch 403: [12800/94637 (14%)] Step: [2379526] | Lr: 0.000100 | Loss: 0.8316 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 53.59
24-04-03 09:27:25.726 - INFO: Train epoch 403: [14400/94637 (15%)] Step: [2379626] | Lr: 0.000100 | Loss: 1.1004 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 52.85
24-04-03 09:28:00.769 - INFO: Train epoch 403: [16000/94637 (17%)] Step: [2379726] | Lr: 0.000100 | Loss: 1.2981 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 55.43
24-04-03 09:28:36.264 - INFO: Train epoch 403: [17600/94637 (19%)] Step: [2379826] | Lr: 0.000100 | Loss: 1.1523 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 57.26
24-04-03 09:29:11.820 - INFO: Train epoch 403: [19200/94637 (20%)] Step: [2379926] | Lr: 0.000100 | Loss: 1.2233 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 50.22
24-04-03 09:29:49.657 - INFO: Train epoch 403: [20800/94637 (22%)] Step: [2380026] | Lr: 0.000100 | Loss: 1.2097 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 55.06
24-04-03 09:30:24.438 - INFO: Train epoch 403: [22400/94637 (24%)] Step: [2380126] | Lr: 0.000100 | Loss: 1.6512 | MSE loss: 0.0004 | Bpp loss: 0.99 | Aux loss: 56.44
24-04-03 09:30:59.777 - INFO: Train epoch 403: [24000/94637 (25%)] Step: [2380226] | Lr: 0.000100 | Loss: 1.6385 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 55.36
24-04-03 09:31:33.985 - INFO: Train epoch 403: [25600/94637 (27%)] Step: [2380326] | Lr: 0.000100 | Loss: 1.1328 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 57.03
24-04-03 09:32:09.060 - INFO: Train epoch 403: [27200/94637 (29%)] Step: [2380426] | Lr: 0.000100 | Loss: 1.1423 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 54.65
24-04-03 09:32:43.572 - INFO: Train epoch 403: [28800/94637 (30%)] Step: [2380526] | Lr: 0.000100 | Loss: 1.7712 | MSE loss: 0.0004 | Bpp loss: 1.10 | Aux loss: 57.37
24-04-03 09:33:18.587 - INFO: Train epoch 403: [30400/94637 (32%)] Step: [2380626] | Lr: 0.000100 | Loss: 0.8515 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 51.99
24-04-03 09:33:53.519 - INFO: Train epoch 403: [32000/94637 (34%)] Step: [2380726] | Lr: 0.000100 | Loss: 1.1587 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 50.28
24-04-03 09:34:27.722 - INFO: Train epoch 403: [33600/94637 (36%)] Step: [2380826] | Lr: 0.000100 | Loss: 0.9400 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 53.08
24-04-03 09:35:02.307 - INFO: Train epoch 403: [35200/94637 (37%)] Step: [2380926] | Lr: 0.000100 | Loss: 1.3449 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 55.16
24-04-03 09:35:36.532 - INFO: Train epoch 403: [36800/94637 (39%)] Step: [2381026] | Lr: 0.000100 | Loss: 1.1098 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 53.96
24-04-03 09:36:11.834 - INFO: Train epoch 403: [38400/94637 (41%)] Step: [2381126] | Lr: 0.000100 | Loss: 1.6047 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 54.54
24-04-03 09:36:46.209 - INFO: Train epoch 403: [40000/94637 (42%)] Step: [2381226] | Lr: 0.000100 | Loss: 0.8183 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 52.33
24-04-03 09:37:21.319 - INFO: Train epoch 403: [41600/94637 (44%)] Step: [2381326] | Lr: 0.000100 | Loss: 1.4652 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 52.00
24-04-03 09:37:55.823 - INFO: Train epoch 403: [43200/94637 (46%)] Step: [2381426] | Lr: 0.000100 | Loss: 2.1971 | MSE loss: 0.0006 | Bpp loss: 1.24 | Aux loss: 52.65
24-04-03 09:38:30.687 - INFO: Train epoch 403: [44800/94637 (47%)] Step: [2381526] | Lr: 0.000100 | Loss: 1.4911 | MSE loss: 0.0003 | Bpp loss: 0.97 | Aux loss: 59.06
24-04-03 09:39:06.013 - INFO: Train epoch 403: [46400/94637 (49%)] Step: [2381626] | Lr: 0.000100 | Loss: 0.8869 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 54.31
24-04-03 09:39:40.958 - INFO: Train epoch 403: [48000/94637 (51%)] Step: [2381726] | Lr: 0.000100 | Loss: 2.3110 | MSE loss: 0.0006 | Bpp loss: 1.35 | Aux loss: 51.81
24-04-03 09:40:16.651 - INFO: Train epoch 403: [49600/94637 (52%)] Step: [2381826] | Lr: 0.000100 | Loss: 1.4610 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 52.18
24-04-03 09:40:51.930 - INFO: Train epoch 403: [51200/94637 (54%)] Step: [2381926] | Lr: 0.000100 | Loss: 0.9856 | MSE loss: 0.0003 | Bpp loss: 0.56 | Aux loss: 55.98
24-04-03 09:41:26.712 - INFO: Train epoch 403: [52800/94637 (56%)] Step: [2382026] | Lr: 0.000100 | Loss: 1.1787 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 56.50
24-04-03 09:42:01.257 - INFO: Train epoch 403: [54400/94637 (57%)] Step: [2382126] | Lr: 0.000100 | Loss: 0.9690 | MSE loss: 0.0003 | Bpp loss: 0.51 | Aux loss: 53.12
24-04-03 09:42:35.153 - INFO: Train epoch 403: [56000/94637 (59%)] Step: [2382226] | Lr: 0.000100 | Loss: 1.3697 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 52.11
24-04-03 09:43:10.141 - INFO: Train epoch 403: [57600/94637 (61%)] Step: [2382326] | Lr: 0.000100 | Loss: 1.2142 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 57.69
24-04-03 09:43:44.862 - INFO: Train epoch 403: [59200/94637 (63%)] Step: [2382426] | Lr: 0.000100 | Loss: 1.0042 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 52.08
24-04-03 09:44:21.301 - INFO: Train epoch 403: [60800/94637 (64%)] Step: [2382526] | Lr: 0.000100 | Loss: 0.8385 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 54.88
24-04-03 09:44:56.245 - INFO: Train epoch 403: [62400/94637 (66%)] Step: [2382626] | Lr: 0.000100 | Loss: 1.7424 | MSE loss: 0.0004 | Bpp loss: 1.10 | Aux loss: 54.71
24-04-03 09:45:30.930 - INFO: Train epoch 403: [64000/94637 (68%)] Step: [2382726] | Lr: 0.000100 | Loss: 1.1107 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 52.81
24-04-03 09:46:05.722 - INFO: Train epoch 403: [65600/94637 (69%)] Step: [2382826] | Lr: 0.000100 | Loss: 0.9839 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 55.55
24-04-03 09:46:40.086 - INFO: Train epoch 403: [67200/94637 (71%)] Step: [2382926] | Lr: 0.000100 | Loss: 0.8145 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 54.69
24-04-03 09:47:14.615 - INFO: Train epoch 403: [68800/94637 (73%)] Step: [2383026] | Lr: 0.000100 | Loss: 0.7318 | MSE loss: 0.0002 | Bpp loss: 0.46 | Aux loss: 48.55
24-04-03 09:47:48.970 - INFO: Train epoch 403: [70400/94637 (74%)] Step: [2383126] | Lr: 0.000100 | Loss: 0.7402 | MSE loss: 0.0002 | Bpp loss: 0.41 | Aux loss: 56.62
24-04-03 09:48:23.989 - INFO: Train epoch 403: [72000/94637 (76%)] Step: [2383226] | Lr: 0.000100 | Loss: 1.3491 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 50.68
24-04-03 09:48:58.810 - INFO: Train epoch 403: [73600/94637 (78%)] Step: [2383326] | Lr: 0.000100 | Loss: 1.1005 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 54.38
24-04-03 09:49:34.030 - INFO: Train epoch 403: [75200/94637 (79%)] Step: [2383426] | Lr: 0.000100 | Loss: 0.9976 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 55.01
24-04-03 09:50:09.718 - INFO: Train epoch 403: [76800/94637 (81%)] Step: [2383526] | Lr: 0.000100 | Loss: 1.2259 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 53.12
24-04-03 09:50:44.921 - INFO: Train epoch 403: [78400/94637 (83%)] Step: [2383626] | Lr: 0.000100 | Loss: 1.5088 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 51.84
24-04-03 09:51:20.654 - INFO: Train epoch 403: [80000/94637 (85%)] Step: [2383726] | Lr: 0.000100 | Loss: 0.9174 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 51.68
24-04-03 09:51:56.231 - INFO: Train epoch 403: [81600/94637 (86%)] Step: [2383826] | Lr: 0.000100 | Loss: 0.8786 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 53.07
24-04-03 09:52:32.083 - INFO: Train epoch 403: [83200/94637 (88%)] Step: [2383926] | Lr: 0.000100 | Loss: 1.4862 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 55.68
24-04-03 09:53:06.745 - INFO: Train epoch 403: [84800/94637 (90%)] Step: [2384026] | Lr: 0.000100 | Loss: 1.2835 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 56.20
24-04-03 09:53:41.212 - INFO: Train epoch 403: [86400/94637 (91%)] Step: [2384126] | Lr: 0.000100 | Loss: 1.7984 | MSE loss: 0.0005 | Bpp loss: 1.06 | Aux loss: 53.09
24-04-03 09:54:15.928 - INFO: Train epoch 403: [88000/94637 (93%)] Step: [2384226] | Lr: 0.000100 | Loss: 2.0960 | MSE loss: 0.0006 | Bpp loss: 1.16 | Aux loss: 54.98
24-04-03 09:54:51.152 - INFO: Train epoch 403: [89600/94637 (95%)] Step: [2384326] | Lr: 0.000100 | Loss: 0.9362 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 53.82
24-04-03 09:55:26.139 - INFO: Train epoch 403: [91200/94637 (96%)] Step: [2384426] | Lr: 0.000100 | Loss: 1.4562 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 51.89
24-04-03 09:56:00.691 - INFO: Train epoch 403: [92800/94637 (98%)] Step: [2384526] | Lr: 0.000100 | Loss: 1.3655 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 56.29
24-04-03 09:56:35.273 - INFO: Train epoch 403: [94400/94637 (100%)] Step: [2384626] | Lr: 0.000100 | Loss: 1.0389 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 52.40
24-04-03 09:56:57.771 - INFO: Learning rate: 0.0001
24-04-03 09:56:58.810 - INFO: Train epoch 404: [    0/94637 (0%)] Step: [2384641] | Lr: 0.000100 | Loss: 1.8022 | MSE loss: 0.0005 | Bpp loss: 0.93 | Aux loss: 55.50
24-04-03 09:57:33.868 - INFO: Train epoch 404: [ 1600/94637 (2%)] Step: [2384741] | Lr: 0.000100 | Loss: 1.8737 | MSE loss: 0.0005 | Bpp loss: 1.12 | Aux loss: 50.85
24-04-03 09:58:09.439 - INFO: Train epoch 404: [ 3200/94637 (3%)] Step: [2384841] | Lr: 0.000100 | Loss: 0.9472 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 51.40
24-04-03 09:58:44.182 - INFO: Train epoch 404: [ 4800/94637 (5%)] Step: [2384941] | Lr: 0.000100 | Loss: 1.2871 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 56.97
24-04-03 09:59:20.761 - INFO: Train epoch 404: [ 6400/94637 (7%)] Step: [2385041] | Lr: 0.000100 | Loss: 1.2008 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 52.02
24-04-03 09:59:56.284 - INFO: Train epoch 404: [ 8000/94637 (8%)] Step: [2385141] | Lr: 0.000100 | Loss: 1.4674 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 60.23
24-04-03 10:00:31.338 - INFO: Train epoch 404: [ 9600/94637 (10%)] Step: [2385241] | Lr: 0.000100 | Loss: 1.0156 | MSE loss: 0.0003 | Bpp loss: 0.60 | Aux loss: 48.78
24-04-03 10:01:05.615 - INFO: Train epoch 404: [11200/94637 (12%)] Step: [2385341] | Lr: 0.000100 | Loss: 1.3668 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 54.86
24-04-03 10:01:41.018 - INFO: Train epoch 404: [12800/94637 (14%)] Step: [2385441] | Lr: 0.000100 | Loss: 1.3260 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 51.97
24-04-03 10:02:15.951 - INFO: Train epoch 404: [14400/94637 (15%)] Step: [2385541] | Lr: 0.000100 | Loss: 1.1347 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 55.99
24-04-03 10:02:50.567 - INFO: Train epoch 404: [16000/94637 (17%)] Step: [2385641] | Lr: 0.000100 | Loss: 1.5383 | MSE loss: 0.0005 | Bpp loss: 0.73 | Aux loss: 53.56
24-04-03 10:03:25.432 - INFO: Train epoch 404: [17600/94637 (19%)] Step: [2385741] | Lr: 0.000100 | Loss: 1.5987 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 53.79
24-04-03 10:04:00.503 - INFO: Train epoch 404: [19200/94637 (20%)] Step: [2385841] | Lr: 0.000100 | Loss: 1.3782 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 54.87
24-04-03 10:04:35.446 - INFO: Train epoch 404: [20800/94637 (22%)] Step: [2385941] | Lr: 0.000100 | Loss: 1.8084 | MSE loss: 0.0004 | Bpp loss: 1.15 | Aux loss: 56.85
24-04-03 10:05:10.261 - INFO: Train epoch 404: [22400/94637 (24%)] Step: [2386041] | Lr: 0.000100 | Loss: 0.8547 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 51.60
24-04-03 10:05:44.772 - INFO: Train epoch 404: [24000/94637 (25%)] Step: [2386141] | Lr: 0.000100 | Loss: 0.9446 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 54.08
24-04-03 10:06:19.021 - INFO: Train epoch 404: [25600/94637 (27%)] Step: [2386241] | Lr: 0.000100 | Loss: 1.7351 | MSE loss: 0.0004 | Bpp loss: 1.12 | Aux loss: 51.65
24-04-03 10:06:53.848 - INFO: Train epoch 404: [27200/94637 (29%)] Step: [2386341] | Lr: 0.000100 | Loss: 0.9857 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 55.54
24-04-03 10:07:28.383 - INFO: Train epoch 404: [28800/94637 (30%)] Step: [2386441] | Lr: 0.000100 | Loss: 1.1423 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 50.63
24-04-03 10:08:02.788 - INFO: Train epoch 404: [30400/94637 (32%)] Step: [2386541] | Lr: 0.000100 | Loss: 1.2705 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 50.82
24-04-03 10:08:37.450 - INFO: Train epoch 404: [32000/94637 (34%)] Step: [2386641] | Lr: 0.000100 | Loss: 0.6825 | MSE loss: 0.0001 | Bpp loss: 0.45 | Aux loss: 54.31
24-04-03 10:09:12.683 - INFO: Train epoch 404: [33600/94637 (36%)] Step: [2386741] | Lr: 0.000100 | Loss: 1.4567 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 55.48
24-04-03 10:09:47.856 - INFO: Train epoch 404: [35200/94637 (37%)] Step: [2386841] | Lr: 0.000100 | Loss: 1.4288 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 50.39
24-04-03 10:10:23.140 - INFO: Train epoch 404: [36800/94637 (39%)] Step: [2386941] | Lr: 0.000100 | Loss: 1.0137 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 54.83
24-04-03 10:10:57.803 - INFO: Train epoch 404: [38400/94637 (41%)] Step: [2387041] | Lr: 0.000100 | Loss: 0.9233 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 52.68
24-04-03 10:11:32.311 - INFO: Train epoch 404: [40000/94637 (42%)] Step: [2387141] | Lr: 0.000100 | Loss: 1.6048 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 55.06
24-04-03 10:12:06.156 - INFO: Train epoch 404: [41600/94637 (44%)] Step: [2387241] | Lr: 0.000100 | Loss: 1.1858 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 52.81
24-04-03 10:12:40.911 - INFO: Train epoch 404: [43200/94637 (46%)] Step: [2387341] | Lr: 0.000100 | Loss: 1.0828 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 54.84
24-04-03 10:13:15.821 - INFO: Train epoch 404: [44800/94637 (47%)] Step: [2387441] | Lr: 0.000100 | Loss: 1.2942 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 51.08
24-04-03 10:13:53.207 - INFO: Train epoch 404: [46400/94637 (49%)] Step: [2387541] | Lr: 0.000100 | Loss: 1.1752 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 53.92
24-04-03 10:14:28.548 - INFO: Train epoch 404: [48000/94637 (51%)] Step: [2387641] | Lr: 0.000100 | Loss: 1.9882 | MSE loss: 0.0005 | Bpp loss: 1.17 | Aux loss: 53.65
24-04-03 10:15:04.088 - INFO: Train epoch 404: [49600/94637 (52%)] Step: [2387741] | Lr: 0.000100 | Loss: 1.4791 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 56.60
24-04-03 10:15:39.238 - INFO: Train epoch 404: [51200/94637 (54%)] Step: [2387841] | Lr: 0.000100 | Loss: 1.9153 | MSE loss: 0.0005 | Bpp loss: 1.12 | Aux loss: 51.83
24-04-03 10:16:13.622 - INFO: Train epoch 404: [52800/94637 (56%)] Step: [2387941] | Lr: 0.000100 | Loss: 1.1448 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 49.84
24-04-03 10:16:48.096 - INFO: Train epoch 404: [54400/94637 (57%)] Step: [2388041] | Lr: 0.000100 | Loss: 1.3928 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 51.55
24-04-03 10:17:23.687 - INFO: Train epoch 404: [56000/94637 (59%)] Step: [2388141] | Lr: 0.000100 | Loss: 1.0208 | MSE loss: 0.0003 | Bpp loss: 0.60 | Aux loss: 52.18
24-04-03 10:17:59.468 - INFO: Train epoch 404: [57600/94637 (61%)] Step: [2388241] | Lr: 0.000100 | Loss: 0.9600 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 55.12
24-04-03 10:18:34.648 - INFO: Train epoch 404: [59200/94637 (63%)] Step: [2388341] | Lr: 0.000100 | Loss: 0.8967 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 52.96
24-04-03 10:19:10.198 - INFO: Train epoch 404: [60800/94637 (64%)] Step: [2388441] | Lr: 0.000100 | Loss: 0.7843 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 52.30
24-04-03 10:19:45.123 - INFO: Train epoch 404: [62400/94637 (66%)] Step: [2388541] | Lr: 0.000100 | Loss: 1.1727 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 54.18
24-04-03 10:20:20.652 - INFO: Train epoch 404: [64000/94637 (68%)] Step: [2388641] | Lr: 0.000100 | Loss: 1.1193 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 55.77
24-04-03 10:20:56.216 - INFO: Train epoch 404: [65600/94637 (69%)] Step: [2388741] | Lr: 0.000100 | Loss: 1.3843 | MSE loss: 0.0004 | Bpp loss: 0.76 | Aux loss: 48.20
24-04-03 10:21:30.993 - INFO: Train epoch 404: [67200/94637 (71%)] Step: [2388841] | Lr: 0.000100 | Loss: 1.0037 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 54.09
24-04-03 10:22:06.474 - INFO: Train epoch 404: [68800/94637 (73%)] Step: [2388941] | Lr: 0.000100 | Loss: 1.3398 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 53.49
24-04-03 10:22:41.801 - INFO: Train epoch 404: [70400/94637 (74%)] Step: [2389041] | Lr: 0.000100 | Loss: 1.3515 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 52.41
24-04-03 10:23:17.147 - INFO: Train epoch 404: [72000/94637 (76%)] Step: [2389141] | Lr: 0.000100 | Loss: 0.9704 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 54.72
24-04-03 10:23:51.270 - INFO: Train epoch 404: [73600/94637 (78%)] Step: [2389241] | Lr: 0.000100 | Loss: 1.2669 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 51.75
24-04-03 10:24:24.635 - INFO: Train epoch 404: [75200/94637 (79%)] Step: [2389341] | Lr: 0.000100 | Loss: 1.7981 | MSE loss: 0.0004 | Bpp loss: 1.13 | Aux loss: 49.18
24-04-03 10:24:59.049 - INFO: Train epoch 404: [76800/94637 (81%)] Step: [2389441] | Lr: 0.000100 | Loss: 0.9272 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 55.13
24-04-03 10:25:33.719 - INFO: Train epoch 404: [78400/94637 (83%)] Step: [2389541] | Lr: 0.000100 | Loss: 1.6392 | MSE loss: 0.0004 | Bpp loss: 0.99 | Aux loss: 53.98
24-04-03 10:26:09.095 - INFO: Train epoch 404: [80000/94637 (85%)] Step: [2389641] | Lr: 0.000100 | Loss: 0.9717 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 55.48
24-04-03 10:26:44.470 - INFO: Train epoch 404: [81600/94637 (86%)] Step: [2389741] | Lr: 0.000100 | Loss: 1.1726 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 49.94
24-04-03 10:27:19.403 - INFO: Train epoch 404: [83200/94637 (88%)] Step: [2389841] | Lr: 0.000100 | Loss: 0.7557 | MSE loss: 0.0002 | Bpp loss: 0.48 | Aux loss: 54.53
24-04-03 10:27:54.444 - INFO: Train epoch 404: [84800/94637 (90%)] Step: [2389941] | Lr: 0.000100 | Loss: 1.4295 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 53.52
24-04-03 10:28:31.306 - INFO: Train epoch 404: [86400/94637 (91%)] Step: [2390041] | Lr: 0.000100 | Loss: 1.5404 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 51.54
24-04-03 10:29:06.968 - INFO: Train epoch 404: [88000/94637 (93%)] Step: [2390141] | Lr: 0.000100 | Loss: 1.3617 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 48.99
24-04-03 10:29:42.029 - INFO: Train epoch 404: [89600/94637 (95%)] Step: [2390241] | Lr: 0.000100 | Loss: 1.4665 | MSE loss: 0.0004 | Bpp loss: 0.84 | Aux loss: 49.07
24-04-03 10:30:16.653 - INFO: Train epoch 404: [91200/94637 (96%)] Step: [2390341] | Lr: 0.000100 | Loss: 1.2867 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 53.07
24-04-03 10:30:51.973 - INFO: Train epoch 404: [92800/94637 (98%)] Step: [2390441] | Lr: 0.000100 | Loss: 1.3197 | MSE loss: 0.0004 | Bpp loss: 0.68 | Aux loss: 51.34
24-04-03 10:31:26.726 - INFO: Train epoch 404: [94400/94637 (100%)] Step: [2390541] | Lr: 0.000100 | Loss: 0.9951 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 53.67
24-04-03 10:31:43.278 - INFO: Learning rate: 0.0001
24-04-03 10:31:44.165 - INFO: Train epoch 405: [    0/94637 (0%)] Step: [2390556] | Lr: 0.000100 | Loss: 0.9280 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 51.49
24-04-03 10:32:19.009 - INFO: Train epoch 405: [ 1600/94637 (2%)] Step: [2390656] | Lr: 0.000100 | Loss: 1.0083 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 54.47
24-04-03 10:32:54.152 - INFO: Train epoch 405: [ 3200/94637 (3%)] Step: [2390756] | Lr: 0.000100 | Loss: 2.6137 | MSE loss: 0.0007 | Bpp loss: 1.53 | Aux loss: 52.28
24-04-03 10:33:28.895 - INFO: Train epoch 405: [ 4800/94637 (5%)] Step: [2390856] | Lr: 0.000100 | Loss: 1.0564 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 52.01
24-04-03 10:34:03.966 - INFO: Train epoch 405: [ 6400/94637 (7%)] Step: [2390956] | Lr: 0.000100 | Loss: 1.6703 | MSE loss: 0.0004 | Bpp loss: 1.05 | Aux loss: 52.55
24-04-03 10:34:38.920 - INFO: Train epoch 405: [ 8000/94637 (8%)] Step: [2391056] | Lr: 0.000100 | Loss: 0.9210 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 56.49
24-04-03 10:35:14.009 - INFO: Train epoch 405: [ 9600/94637 (10%)] Step: [2391156] | Lr: 0.000100 | Loss: 0.9979 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 50.81
24-04-03 10:35:49.159 - INFO: Train epoch 405: [11200/94637 (12%)] Step: [2391256] | Lr: 0.000100 | Loss: 1.1939 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 52.01
24-04-03 10:36:24.376 - INFO: Train epoch 405: [12800/94637 (14%)] Step: [2391356] | Lr: 0.000100 | Loss: 1.0943 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 57.73
24-04-03 10:37:00.162 - INFO: Train epoch 405: [14400/94637 (15%)] Step: [2391456] | Lr: 0.000100 | Loss: 1.0079 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 53.44
24-04-03 10:37:35.838 - INFO: Train epoch 405: [16000/94637 (17%)] Step: [2391556] | Lr: 0.000100 | Loss: 1.0721 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 51.35
24-04-03 10:38:10.035 - INFO: Train epoch 405: [17600/94637 (19%)] Step: [2391656] | Lr: 0.000100 | Loss: 1.5265 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 49.31
24-04-03 10:38:45.699 - INFO: Train epoch 405: [19200/94637 (20%)] Step: [2391756] | Lr: 0.000100 | Loss: 1.5392 | MSE loss: 0.0003 | Bpp loss: 0.98 | Aux loss: 50.47
24-04-03 10:39:20.065 - INFO: Train epoch 405: [20800/94637 (22%)] Step: [2391856] | Lr: 0.000100 | Loss: 1.5953 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 52.61
24-04-03 10:39:54.801 - INFO: Train epoch 405: [22400/94637 (24%)] Step: [2391956] | Lr: 0.000100 | Loss: 0.9105 | MSE loss: 0.0003 | Bpp loss: 0.50 | Aux loss: 57.43
24-04-03 10:40:30.333 - INFO: Train epoch 405: [24000/94637 (25%)] Step: [2392056] | Lr: 0.000100 | Loss: 1.1418 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 53.82
24-04-03 10:41:05.825 - INFO: Train epoch 405: [25600/94637 (27%)] Step: [2392156] | Lr: 0.000100 | Loss: 1.4314 | MSE loss: 0.0003 | Bpp loss: 0.96 | Aux loss: 54.82
24-04-03 10:41:41.228 - INFO: Train epoch 405: [27200/94637 (29%)] Step: [2392256] | Lr: 0.000100 | Loss: 0.9494 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 49.54
24-04-03 10:42:15.451 - INFO: Train epoch 405: [28800/94637 (30%)] Step: [2392356] | Lr: 0.000100 | Loss: 0.9955 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 52.45
24-04-03 10:42:51.421 - INFO: Train epoch 405: [30400/94637 (32%)] Step: [2392456] | Lr: 0.000100 | Loss: 1.1455 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 53.27
24-04-03 10:43:29.167 - INFO: Train epoch 405: [32000/94637 (34%)] Step: [2392556] | Lr: 0.000100 | Loss: 1.2219 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 50.64
24-04-03 10:44:04.744 - INFO: Train epoch 405: [33600/94637 (36%)] Step: [2392656] | Lr: 0.000100 | Loss: 1.1050 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 49.16
24-04-03 10:44:38.942 - INFO: Train epoch 405: [35200/94637 (37%)] Step: [2392756] | Lr: 0.000100 | Loss: 1.2280 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 52.14
24-04-03 10:45:13.647 - INFO: Train epoch 405: [36800/94637 (39%)] Step: [2392856] | Lr: 0.000100 | Loss: 2.2322 | MSE loss: 0.0006 | Bpp loss: 1.28 | Aux loss: 50.99
24-04-03 10:45:49.067 - INFO: Train epoch 405: [38400/94637 (41%)] Step: [2392956] | Lr: 0.000100 | Loss: 1.5205 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 54.05
24-04-03 10:46:24.886 - INFO: Train epoch 405: [40000/94637 (42%)] Step: [2393056] | Lr: 0.000100 | Loss: 0.8512 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 54.92
24-04-03 10:46:59.641 - INFO: Train epoch 405: [41600/94637 (44%)] Step: [2393156] | Lr: 0.000100 | Loss: 0.8007 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 56.69
24-04-03 10:47:34.632 - INFO: Train epoch 405: [43200/94637 (46%)] Step: [2393256] | Lr: 0.000100 | Loss: 1.4686 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 53.81
24-04-03 10:48:10.232 - INFO: Train epoch 405: [44800/94637 (47%)] Step: [2393356] | Lr: 0.000100 | Loss: 1.3481 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 52.85
24-04-03 10:48:45.845 - INFO: Train epoch 405: [46400/94637 (49%)] Step: [2393456] | Lr: 0.000100 | Loss: 1.7517 | MSE loss: 0.0004 | Bpp loss: 1.05 | Aux loss: 52.35
24-04-03 10:49:21.011 - INFO: Train epoch 405: [48000/94637 (51%)] Step: [2393556] | Lr: 0.000100 | Loss: 1.1463 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 56.13
24-04-03 10:49:56.529 - INFO: Train epoch 405: [49600/94637 (52%)] Step: [2393656] | Lr: 0.000100 | Loss: 1.0163 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 52.13
24-04-03 10:50:31.449 - INFO: Train epoch 405: [51200/94637 (54%)] Step: [2393756] | Lr: 0.000100 | Loss: 1.5883 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 50.05
24-04-03 10:51:06.406 - INFO: Train epoch 405: [52800/94637 (56%)] Step: [2393856] | Lr: 0.000100 | Loss: 0.8942 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 53.88
24-04-03 10:51:41.196 - INFO: Train epoch 405: [54400/94637 (57%)] Step: [2393956] | Lr: 0.000100 | Loss: 1.1074 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 46.64
24-04-03 10:52:15.020 - INFO: Train epoch 405: [56000/94637 (59%)] Step: [2394056] | Lr: 0.000100 | Loss: 1.4171 | MSE loss: 0.0004 | Bpp loss: 0.84 | Aux loss: 49.93
24-04-03 10:52:49.118 - INFO: Train epoch 405: [57600/94637 (61%)] Step: [2394156] | Lr: 0.000100 | Loss: 1.1643 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 49.64
24-04-03 10:53:23.463 - INFO: Train epoch 405: [59200/94637 (63%)] Step: [2394256] | Lr: 0.000100 | Loss: 1.0759 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 51.16
24-04-03 10:53:57.311 - INFO: Train epoch 405: [60800/94637 (64%)] Step: [2394356] | Lr: 0.000100 | Loss: 1.2104 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 50.92
24-04-03 10:54:31.638 - INFO: Train epoch 405: [62400/94637 (66%)] Step: [2394456] | Lr: 0.000100 | Loss: 1.6757 | MSE loss: 0.0004 | Bpp loss: 1.07 | Aux loss: 53.45
24-04-03 10:55:06.016 - INFO: Train epoch 405: [64000/94637 (68%)] Step: [2394556] | Lr: 0.000100 | Loss: 0.7426 | MSE loss: 0.0002 | Bpp loss: 0.47 | Aux loss: 48.21
24-04-03 10:55:40.701 - INFO: Train epoch 405: [65600/94637 (69%)] Step: [2394656] | Lr: 0.000100 | Loss: 2.1593 | MSE loss: 0.0005 | Bpp loss: 1.30 | Aux loss: 51.70
24-04-03 10:56:15.573 - INFO: Train epoch 405: [67200/94637 (71%)] Step: [2394756] | Lr: 0.000100 | Loss: 2.0279 | MSE loss: 0.0006 | Bpp loss: 1.07 | Aux loss: 53.90
24-04-03 10:56:50.664 - INFO: Train epoch 405: [68800/94637 (73%)] Step: [2394856] | Lr: 0.000100 | Loss: 1.1981 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 49.57
24-04-03 10:57:24.493 - INFO: Train epoch 405: [70400/94637 (74%)] Step: [2394956] | Lr: 0.000100 | Loss: 1.7978 | MSE loss: 0.0004 | Bpp loss: 1.14 | Aux loss: 52.42
24-04-03 10:58:01.890 - INFO: Train epoch 405: [72000/94637 (76%)] Step: [2395056] | Lr: 0.000100 | Loss: 1.3897 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 55.51
24-04-03 10:58:36.788 - INFO: Train epoch 405: [73600/94637 (78%)] Step: [2395156] | Lr: 0.000100 | Loss: 1.2041 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 50.05
24-04-03 10:59:11.814 - INFO: Train epoch 405: [75200/94637 (79%)] Step: [2395256] | Lr: 0.000100 | Loss: 0.9391 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 49.65
24-04-03 10:59:46.397 - INFO: Train epoch 405: [76800/94637 (81%)] Step: [2395356] | Lr: 0.000100 | Loss: 0.6758 | MSE loss: 0.0001 | Bpp loss: 0.47 | Aux loss: 52.21
24-04-03 11:00:22.684 - INFO: Train epoch 405: [78400/94637 (83%)] Step: [2395456] | Lr: 0.000100 | Loss: 0.9249 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 51.27
24-04-03 11:00:57.431 - INFO: Train epoch 405: [80000/94637 (85%)] Step: [2395556] | Lr: 0.000100 | Loss: 1.0816 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 50.90
24-04-03 11:01:32.029 - INFO: Train epoch 405: [81600/94637 (86%)] Step: [2395656] | Lr: 0.000100 | Loss: 0.8048 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 55.92
24-04-03 11:02:06.935 - INFO: Train epoch 405: [83200/94637 (88%)] Step: [2395756] | Lr: 0.000100 | Loss: 1.6641 | MSE loss: 0.0004 | Bpp loss: 1.08 | Aux loss: 56.01
24-04-03 11:02:41.110 - INFO: Train epoch 405: [84800/94637 (90%)] Step: [2395856] | Lr: 0.000100 | Loss: 2.0184 | MSE loss: 0.0007 | Bpp loss: 0.84 | Aux loss: 49.16
24-04-03 11:03:15.717 - INFO: Train epoch 405: [86400/94637 (91%)] Step: [2395956] | Lr: 0.000100 | Loss: 2.1361 | MSE loss: 0.0006 | Bpp loss: 1.11 | Aux loss: 53.09
24-04-03 11:03:49.558 - INFO: Train epoch 405: [88000/94637 (93%)] Step: [2396056] | Lr: 0.000100 | Loss: 1.3317 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 50.49
24-04-03 11:04:25.038 - INFO: Train epoch 405: [89600/94637 (95%)] Step: [2396156] | Lr: 0.000100 | Loss: 0.8438 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 55.69
24-04-03 11:04:59.928 - INFO: Train epoch 405: [91200/94637 (96%)] Step: [2396256] | Lr: 0.000100 | Loss: 0.6419 | MSE loss: 0.0001 | Bpp loss: 0.42 | Aux loss: 47.37
24-04-03 11:05:34.728 - INFO: Train epoch 405: [92800/94637 (98%)] Step: [2396356] | Lr: 0.000100 | Loss: 1.1397 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 51.68
24-04-03 11:06:09.434 - INFO: Train epoch 405: [94400/94637 (100%)] Step: [2396456] | Lr: 0.000100 | Loss: 0.7863 | MSE loss: 0.0002 | Bpp loss: 0.44 | Aux loss: 53.02
24-04-03 11:06:26.316 - INFO: Learning rate: 0.0001
24-04-03 11:06:27.839 - INFO: Train epoch 406: [    0/94637 (0%)] Step: [2396471] | Lr: 0.000100 | Loss: 1.1710 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 50.56
24-04-03 11:07:01.748 - INFO: Train epoch 406: [ 1600/94637 (2%)] Step: [2396571] | Lr: 0.000100 | Loss: 0.8621 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 52.94
24-04-03 11:07:36.399 - INFO: Train epoch 406: [ 3200/94637 (3%)] Step: [2396671] | Lr: 0.000100 | Loss: 0.9491 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 48.65
24-04-03 11:08:11.546 - INFO: Train epoch 406: [ 4800/94637 (5%)] Step: [2396771] | Lr: 0.000100 | Loss: 1.5875 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 54.39
24-04-03 11:08:46.218 - INFO: Train epoch 406: [ 6400/94637 (7%)] Step: [2396871] | Lr: 0.000100 | Loss: 1.0500 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 54.00
24-04-03 11:09:20.709 - INFO: Train epoch 406: [ 8000/94637 (8%)] Step: [2396971] | Lr: 0.000100 | Loss: 1.2312 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 51.50
24-04-03 11:09:55.627 - INFO: Train epoch 406: [ 9600/94637 (10%)] Step: [2397071] | Lr: 0.000100 | Loss: 1.4944 | MSE loss: 0.0004 | Bpp loss: 0.85 | Aux loss: 53.49
24-04-03 11:10:30.658 - INFO: Train epoch 406: [11200/94637 (12%)] Step: [2397171] | Lr: 0.000100 | Loss: 1.4070 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 53.40
24-04-03 11:11:06.101 - INFO: Train epoch 406: [12800/94637 (14%)] Step: [2397271] | Lr: 0.000100 | Loss: 1.5621 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 53.02
24-04-03 11:11:40.779 - INFO: Train epoch 406: [14400/94637 (15%)] Step: [2397371] | Lr: 0.000100 | Loss: 0.7706 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 51.54
24-04-03 11:12:15.969 - INFO: Train epoch 406: [16000/94637 (17%)] Step: [2397471] | Lr: 0.000100 | Loss: 1.0568 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 51.64
24-04-03 11:12:53.546 - INFO: Train epoch 406: [17600/94637 (19%)] Step: [2397571] | Lr: 0.000100 | Loss: 0.9614 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 52.49
24-04-03 11:13:28.575 - INFO: Train epoch 406: [19200/94637 (20%)] Step: [2397671] | Lr: 0.000100 | Loss: 0.8510 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 49.16
24-04-03 11:14:03.591 - INFO: Train epoch 406: [20800/94637 (22%)] Step: [2397771] | Lr: 0.000100 | Loss: 0.8069 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 51.99
24-04-03 11:14:38.265 - INFO: Train epoch 406: [22400/94637 (24%)] Step: [2397871] | Lr: 0.000100 | Loss: 1.6761 | MSE loss: 0.0004 | Bpp loss: 1.03 | Aux loss: 48.94
24-04-03 11:15:13.386 - INFO: Train epoch 406: [24000/94637 (25%)] Step: [2397971] | Lr: 0.000100 | Loss: 1.4128 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 51.23
24-04-03 11:15:48.146 - INFO: Train epoch 406: [25600/94637 (27%)] Step: [2398071] | Lr: 0.000100 | Loss: 1.3737 | MSE loss: 0.0004 | Bpp loss: 0.71 | Aux loss: 54.85
24-04-03 11:16:23.299 - INFO: Train epoch 406: [27200/94637 (29%)] Step: [2398171] | Lr: 0.000100 | Loss: 0.8074 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 50.91
24-04-03 11:16:58.033 - INFO: Train epoch 406: [28800/94637 (30%)] Step: [2398271] | Lr: 0.000100 | Loss: 1.5179 | MSE loss: 0.0004 | Bpp loss: 0.93 | Aux loss: 52.79
24-04-03 11:17:32.790 - INFO: Train epoch 406: [30400/94637 (32%)] Step: [2398371] | Lr: 0.000100 | Loss: 1.2896 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 52.61
24-04-03 11:18:07.278 - INFO: Train epoch 406: [32000/94637 (34%)] Step: [2398471] | Lr: 0.000100 | Loss: 1.2432 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 50.96
24-04-03 11:18:41.630 - INFO: Train epoch 406: [33600/94637 (36%)] Step: [2398571] | Lr: 0.000100 | Loss: 0.7664 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 53.68
24-04-03 11:19:17.584 - INFO: Train epoch 406: [35200/94637 (37%)] Step: [2398671] | Lr: 0.000100 | Loss: 0.9818 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 52.52
24-04-03 11:19:54.266 - INFO: Train epoch 406: [36800/94637 (39%)] Step: [2398771] | Lr: 0.000100 | Loss: 1.8449 | MSE loss: 0.0006 | Bpp loss: 0.85 | Aux loss: 54.50
24-04-03 11:20:30.538 - INFO: Train epoch 406: [38400/94637 (41%)] Step: [2398871] | Lr: 0.000100 | Loss: 0.7878 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 52.28
24-04-03 11:21:05.849 - INFO: Train epoch 406: [40000/94637 (42%)] Step: [2398971] | Lr: 0.000100 | Loss: 0.9523 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 51.84
24-04-03 11:21:40.467 - INFO: Train epoch 406: [41600/94637 (44%)] Step: [2399071] | Lr: 0.000100 | Loss: 1.7120 | MSE loss: 0.0004 | Bpp loss: 1.09 | Aux loss: 51.24
24-04-03 11:22:15.074 - INFO: Train epoch 406: [43200/94637 (46%)] Step: [2399171] | Lr: 0.000100 | Loss: 0.8370 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 49.33
24-04-03 11:22:49.974 - INFO: Train epoch 406: [44800/94637 (47%)] Step: [2399271] | Lr: 0.000100 | Loss: 1.1323 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 51.95
24-04-03 11:23:24.040 - INFO: Train epoch 406: [46400/94637 (49%)] Step: [2399371] | Lr: 0.000100 | Loss: 0.9177 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 51.06
24-04-03 11:23:58.878 - INFO: Train epoch 406: [48000/94637 (51%)] Step: [2399471] | Lr: 0.000100 | Loss: 1.0986 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 51.41
24-04-03 11:24:34.132 - INFO: Train epoch 406: [49600/94637 (52%)] Step: [2399571] | Lr: 0.000100 | Loss: 1.1421 | MSE loss: 0.0002 | Bpp loss: 0.76 | Aux loss: 55.51
24-04-03 11:25:09.145 - INFO: Train epoch 406: [51200/94637 (54%)] Step: [2399671] | Lr: 0.000100 | Loss: 0.9875 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 48.72
24-04-03 11:25:43.895 - INFO: Train epoch 406: [52800/94637 (56%)] Step: [2399771] | Lr: 0.000100 | Loss: 1.4715 | MSE loss: 0.0004 | Bpp loss: 0.76 | Aux loss: 51.55
24-04-03 11:26:19.373 - INFO: Train epoch 406: [54400/94637 (57%)] Step: [2399871] | Lr: 0.000100 | Loss: 0.8930 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 49.07
24-04-03 11:26:54.838 - INFO: Train epoch 406: [56000/94637 (59%)] Step: [2399971] | Lr: 0.000100 | Loss: 1.3089 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 52.09
24-04-03 11:27:33.222 - INFO: Train epoch 406: [57600/94637 (61%)] Step: [2400071] | Lr: 0.000100 | Loss: 0.8726 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 49.98
24-04-03 11:28:08.387 - INFO: Train epoch 406: [59200/94637 (63%)] Step: [2400171] | Lr: 0.000100 | Loss: 2.0352 | MSE loss: 0.0004 | Bpp loss: 1.31 | Aux loss: 52.27
24-04-03 11:28:44.495 - INFO: Train epoch 406: [60800/94637 (64%)] Step: [2400271] | Lr: 0.000100 | Loss: 1.2760 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 56.22
24-04-03 11:29:20.594 - INFO: Train epoch 406: [62400/94637 (66%)] Step: [2400371] | Lr: 0.000100 | Loss: 0.7684 | MSE loss: 0.0002 | Bpp loss: 0.47 | Aux loss: 55.72
24-04-03 11:29:55.406 - INFO: Train epoch 406: [64000/94637 (68%)] Step: [2400471] | Lr: 0.000100 | Loss: 1.0952 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 52.10
24-04-03 11:30:30.405 - INFO: Train epoch 406: [65600/94637 (69%)] Step: [2400571] | Lr: 0.000100 | Loss: 0.9663 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 49.46
24-04-03 11:31:05.269 - INFO: Train epoch 406: [67200/94637 (71%)] Step: [2400671] | Lr: 0.000100 | Loss: 1.4072 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 51.70
24-04-03 11:31:40.287 - INFO: Train epoch 406: [68800/94637 (73%)] Step: [2400771] | Lr: 0.000100 | Loss: 1.0403 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 52.02
24-04-03 11:32:16.152 - INFO: Train epoch 406: [70400/94637 (74%)] Step: [2400871] | Lr: 0.000100 | Loss: 1.4025 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 51.62
24-04-03 11:32:51.047 - INFO: Train epoch 406: [72000/94637 (76%)] Step: [2400971] | Lr: 0.000100 | Loss: 1.1385 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 52.63
24-04-03 11:33:26.318 - INFO: Train epoch 406: [73600/94637 (78%)] Step: [2401071] | Lr: 0.000100 | Loss: 1.1977 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 53.19
24-04-03 11:34:01.744 - INFO: Train epoch 406: [75200/94637 (79%)] Step: [2401171] | Lr: 0.000100 | Loss: 0.8138 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 50.28
24-04-03 11:34:37.245 - INFO: Train epoch 406: [76800/94637 (81%)] Step: [2401271] | Lr: 0.000100 | Loss: 1.1783 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 51.62
24-04-03 11:35:13.055 - INFO: Train epoch 406: [78400/94637 (83%)] Step: [2401371] | Lr: 0.000100 | Loss: 1.5496 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 51.12
24-04-03 11:35:48.417 - INFO: Train epoch 406: [80000/94637 (85%)] Step: [2401471] | Lr: 0.000100 | Loss: 0.9290 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 54.34
24-04-03 11:36:22.620 - INFO: Train epoch 406: [81600/94637 (86%)] Step: [2401571] | Lr: 0.000100 | Loss: 1.0141 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 50.83
24-04-03 11:36:56.759 - INFO: Train epoch 406: [83200/94637 (88%)] Step: [2401671] | Lr: 0.000100 | Loss: 2.3573 | MSE loss: 0.0006 | Bpp loss: 1.44 | Aux loss: 54.68
24-04-03 11:37:30.971 - INFO: Train epoch 406: [84800/94637 (90%)] Step: [2401771] | Lr: 0.000100 | Loss: 1.4805 | MSE loss: 0.0004 | Bpp loss: 0.88 | Aux loss: 51.33
24-04-03 11:38:05.178 - INFO: Train epoch 406: [86400/94637 (91%)] Step: [2401871] | Lr: 0.000100 | Loss: 1.0750 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 50.65
24-04-03 11:38:40.048 - INFO: Train epoch 406: [88000/94637 (93%)] Step: [2401971] | Lr: 0.000100 | Loss: 1.1901 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 50.87
24-04-03 11:39:15.172 - INFO: Train epoch 406: [89600/94637 (95%)] Step: [2402071] | Lr: 0.000100 | Loss: 0.7340 | MSE loss: 0.0002 | Bpp loss: 0.44 | Aux loss: 52.66
24-04-03 11:39:51.122 - INFO: Train epoch 406: [91200/94637 (96%)] Step: [2402171] | Lr: 0.000100 | Loss: 0.6188 | MSE loss: 0.0001 | Bpp loss: 0.42 | Aux loss: 49.07
24-04-03 11:40:26.683 - INFO: Train epoch 406: [92800/94637 (98%)] Step: [2402271] | Lr: 0.000100 | Loss: 0.8822 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 55.42
24-04-03 11:41:02.345 - INFO: Train epoch 406: [94400/94637 (100%)] Step: [2402371] | Lr: 0.000100 | Loss: 1.7366 | MSE loss: 0.0005 | Bpp loss: 0.99 | Aux loss: 53.69
24-04-03 11:41:19.682 - INFO: Learning rate: 0.0001
24-04-03 11:41:20.597 - INFO: Train epoch 407: [    0/94637 (0%)] Step: [2402386] | Lr: 0.000100 | Loss: 1.8854 | MSE loss: 0.0005 | Bpp loss: 1.06 | Aux loss: 49.22
24-04-03 11:41:54.496 - INFO: Train epoch 407: [ 1600/94637 (2%)] Step: [2402486] | Lr: 0.000100 | Loss: 1.1738 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 53.84
24-04-03 11:42:30.661 - INFO: Train epoch 407: [ 3200/94637 (3%)] Step: [2402586] | Lr: 0.000100 | Loss: 1.0776 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 52.11
24-04-03 11:43:05.814 - INFO: Train epoch 407: [ 4800/94637 (5%)] Step: [2402686] | Lr: 0.000100 | Loss: 0.8049 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 54.27
24-04-03 11:43:40.647 - INFO: Train epoch 407: [ 6400/94637 (7%)] Step: [2402786] | Lr: 0.000100 | Loss: 1.6542 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 50.09
24-04-03 11:44:16.104 - INFO: Train epoch 407: [ 8000/94637 (8%)] Step: [2402886] | Lr: 0.000100 | Loss: 0.9126 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 48.07
24-04-03 11:44:50.864 - INFO: Train epoch 407: [ 9600/94637 (10%)] Step: [2402986] | Lr: 0.000100 | Loss: 1.0186 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 54.57
24-04-03 11:45:25.978 - INFO: Train epoch 407: [11200/94637 (12%)] Step: [2403086] | Lr: 0.000100 | Loss: 0.8174 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 53.89
24-04-03 11:46:01.774 - INFO: Train epoch 407: [12800/94637 (14%)] Step: [2403186] | Lr: 0.000100 | Loss: 1.0216 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 50.18
24-04-03 11:46:37.785 - INFO: Train epoch 407: [14400/94637 (15%)] Step: [2403286] | Lr: 0.000100 | Loss: 1.0759 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 49.08
24-04-03 11:47:13.027 - INFO: Train epoch 407: [16000/94637 (17%)] Step: [2403386] | Lr: 0.000100 | Loss: 1.5623 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 50.11
24-04-03 11:47:48.227 - INFO: Train epoch 407: [17600/94637 (19%)] Step: [2403486] | Lr: 0.000100 | Loss: 1.6384 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 52.39
24-04-03 11:48:23.706 - INFO: Train epoch 407: [19200/94637 (20%)] Step: [2403586] | Lr: 0.000100 | Loss: 1.3965 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 51.43
24-04-03 11:48:59.073 - INFO: Train epoch 407: [20800/94637 (22%)] Step: [2403686] | Lr: 0.000100 | Loss: 0.9274 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 50.91
24-04-03 11:49:33.691 - INFO: Train epoch 407: [22400/94637 (24%)] Step: [2403786] | Lr: 0.000100 | Loss: 0.8848 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 48.50
24-04-03 11:50:08.957 - INFO: Train epoch 407: [24000/94637 (25%)] Step: [2403886] | Lr: 0.000100 | Loss: 0.9289 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 51.73
24-04-03 11:50:43.222 - INFO: Train epoch 407: [25600/94637 (27%)] Step: [2403986] | Lr: 0.000100 | Loss: 1.5824 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 50.19
24-04-03 11:51:18.655 - INFO: Train epoch 407: [27200/94637 (29%)] Step: [2404086] | Lr: 0.000100 | Loss: 1.3547 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 51.36
24-04-03 11:51:53.813 - INFO: Train epoch 407: [28800/94637 (30%)] Step: [2404186] | Lr: 0.000100 | Loss: 0.8165 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 49.88
24-04-03 11:52:28.295 - INFO: Train epoch 407: [30400/94637 (32%)] Step: [2404286] | Lr: 0.000100 | Loss: 1.1735 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 50.85
24-04-03 11:53:03.561 - INFO: Train epoch 407: [32000/94637 (34%)] Step: [2404386] | Lr: 0.000100 | Loss: 1.2970 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 50.52
24-04-03 11:53:38.196 - INFO: Train epoch 407: [33600/94637 (36%)] Step: [2404486] | Lr: 0.000100 | Loss: 1.1996 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 49.92
24-04-03 11:54:12.596 - INFO: Train epoch 407: [35200/94637 (37%)] Step: [2404586] | Lr: 0.000100 | Loss: 0.8190 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 49.72
24-04-03 11:54:46.673 - INFO: Train epoch 407: [36800/94637 (39%)] Step: [2404686] | Lr: 0.000100 | Loss: 1.4893 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 52.76
24-04-03 11:55:20.747 - INFO: Train epoch 407: [38400/94637 (41%)] Step: [2404786] | Lr: 0.000100 | Loss: 1.1036 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 52.64
24-04-03 11:55:55.736 - INFO: Train epoch 407: [40000/94637 (42%)] Step: [2404886] | Lr: 0.000100 | Loss: 1.4175 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 50.90
24-04-03 11:56:30.573 - INFO: Train epoch 407: [41600/94637 (44%)] Step: [2404986] | Lr: 0.000100 | Loss: 0.9976 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 52.12
24-04-03 11:57:06.686 - INFO: Train epoch 407: [43200/94637 (46%)] Step: [2405086] | Lr: 0.000100 | Loss: 1.2939 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 52.27
24-04-03 11:57:41.683 - INFO: Train epoch 407: [44800/94637 (47%)] Step: [2405186] | Lr: 0.000100 | Loss: 1.0357 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 49.18
24-04-03 11:58:16.427 - INFO: Train epoch 407: [46400/94637 (49%)] Step: [2405286] | Lr: 0.000100 | Loss: 1.5243 | MSE loss: 0.0004 | Bpp loss: 0.85 | Aux loss: 52.67
24-04-03 11:58:52.080 - INFO: Train epoch 407: [48000/94637 (51%)] Step: [2405386] | Lr: 0.000100 | Loss: 1.3112 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 48.61
24-04-03 11:59:27.507 - INFO: Train epoch 407: [49600/94637 (52%)] Step: [2405486] | Lr: 0.000100 | Loss: 1.1402 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 49.05
24-04-03 12:00:01.552 - INFO: Train epoch 407: [51200/94637 (54%)] Step: [2405586] | Lr: 0.000100 | Loss: 1.4493 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 51.49
24-04-03 12:00:35.927 - INFO: Train epoch 407: [52800/94637 (56%)] Step: [2405686] | Lr: 0.000100 | Loss: 1.4398 | MSE loss: 0.0004 | Bpp loss: 0.86 | Aux loss: 52.55
24-04-03 12:01:10.737 - INFO: Train epoch 407: [54400/94637 (57%)] Step: [2405786] | Lr: 0.000100 | Loss: 1.7771 | MSE loss: 0.0004 | Bpp loss: 1.05 | Aux loss: 51.23
24-04-03 12:01:45.377 - INFO: Train epoch 407: [56000/94637 (59%)] Step: [2405886] | Lr: 0.000100 | Loss: 1.1506 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 52.38
24-04-03 12:02:20.874 - INFO: Train epoch 407: [57600/94637 (61%)] Step: [2405986] | Lr: 0.000100 | Loss: 1.2713 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 52.48
24-04-03 12:02:55.424 - INFO: Train epoch 407: [59200/94637 (63%)] Step: [2406086] | Lr: 0.000100 | Loss: 1.0385 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 54.45
24-04-03 12:03:31.182 - INFO: Train epoch 407: [60800/94637 (64%)] Step: [2406186] | Lr: 0.000100 | Loss: 1.0387 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 48.46
24-04-03 12:04:06.450 - INFO: Train epoch 407: [62400/94637 (66%)] Step: [2406286] | Lr: 0.000100 | Loss: 0.9187 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 51.70
24-04-03 12:04:40.450 - INFO: Train epoch 407: [64000/94637 (68%)] Step: [2406386] | Lr: 0.000100 | Loss: 1.2674 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 50.58
24-04-03 12:05:15.600 - INFO: Train epoch 407: [65600/94637 (69%)] Step: [2406486] | Lr: 0.000100 | Loss: 1.4737 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 51.86
24-04-03 12:05:50.760 - INFO: Train epoch 407: [67200/94637 (71%)] Step: [2406586] | Lr: 0.000100 | Loss: 1.0999 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 46.46
24-04-03 12:06:25.727 - INFO: Train epoch 407: [68800/94637 (73%)] Step: [2406686] | Lr: 0.000100 | Loss: 1.0731 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 49.81
24-04-03 12:07:00.791 - INFO: Train epoch 407: [70400/94637 (74%)] Step: [2406786] | Lr: 0.000100 | Loss: 0.8218 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 62.98
24-04-03 12:07:34.583 - INFO: Train epoch 407: [72000/94637 (76%)] Step: [2406886] | Lr: 0.000100 | Loss: 1.5195 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 51.75
24-04-03 12:08:10.800 - INFO: Train epoch 407: [73600/94637 (78%)] Step: [2406986] | Lr: 0.000100 | Loss: 1.6388 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 45.82
24-04-03 12:08:46.534 - INFO: Train epoch 407: [75200/94637 (79%)] Step: [2407086] | Lr: 0.000100 | Loss: 0.7242 | MSE loss: 0.0002 | Bpp loss: 0.46 | Aux loss: 50.12
24-04-03 12:09:21.920 - INFO: Train epoch 407: [76800/94637 (81%)] Step: [2407186] | Lr: 0.000100 | Loss: 1.1738 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 45.83
24-04-03 12:09:57.389 - INFO: Train epoch 407: [78400/94637 (83%)] Step: [2407286] | Lr: 0.000100 | Loss: 1.5093 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 43.67
24-04-03 12:10:33.972 - INFO: Train epoch 407: [80000/94637 (85%)] Step: [2407386] | Lr: 0.000100 | Loss: 1.3370 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 47.93
24-04-03 12:11:08.875 - INFO: Train epoch 407: [81600/94637 (86%)] Step: [2407486] | Lr: 0.000100 | Loss: 1.2011 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 46.63
24-04-03 12:11:46.337 - INFO: Train epoch 407: [83200/94637 (88%)] Step: [2407586] | Lr: 0.000100 | Loss: 1.1244 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 44.11
24-04-03 12:12:22.598 - INFO: Train epoch 407: [84800/94637 (90%)] Step: [2407686] | Lr: 0.000100 | Loss: 1.3328 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 50.12
24-04-03 12:12:58.874 - INFO: Train epoch 407: [86400/94637 (91%)] Step: [2407786] | Lr: 0.000100 | Loss: 1.2162 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 46.94
24-04-03 12:13:34.293 - INFO: Train epoch 407: [88000/94637 (93%)] Step: [2407886] | Lr: 0.000100 | Loss: 1.0642 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 48.84
24-04-03 12:14:09.832 - INFO: Train epoch 407: [89600/94637 (95%)] Step: [2407986] | Lr: 0.000100 | Loss: 0.9291 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 45.89
24-04-03 12:14:45.882 - INFO: Train epoch 407: [91200/94637 (96%)] Step: [2408086] | Lr: 0.000100 | Loss: 1.2033 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 44.06
24-04-03 12:15:21.702 - INFO: Train epoch 407: [92800/94637 (98%)] Step: [2408186] | Lr: 0.000100 | Loss: 0.8208 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 48.51
24-04-03 12:15:57.300 - INFO: Train epoch 407: [94400/94637 (100%)] Step: [2408286] | Lr: 0.000100 | Loss: 1.6729 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 43.99
24-04-03 12:16:19.548 - INFO: Learning rate: 0.0001
24-04-03 12:16:20.601 - INFO: Train epoch 408: [    0/94637 (0%)] Step: [2408301] | Lr: 0.000100 | Loss: 1.6125 | MSE loss: 0.0004 | Bpp loss: 0.99 | Aux loss: 48.08
24-04-03 12:16:55.865 - INFO: Train epoch 408: [ 1600/94637 (2%)] Step: [2408401] | Lr: 0.000100 | Loss: 2.3863 | MSE loss: 0.0006 | Bpp loss: 1.45 | Aux loss: 49.08
24-04-03 12:17:31.764 - INFO: Train epoch 408: [ 3200/94637 (3%)] Step: [2408501] | Lr: 0.000100 | Loss: 1.4439 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 49.45
24-04-03 12:18:07.156 - INFO: Train epoch 408: [ 4800/94637 (5%)] Step: [2408601] | Lr: 0.000100 | Loss: 0.9018 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 46.42
24-04-03 12:18:43.081 - INFO: Train epoch 408: [ 6400/94637 (7%)] Step: [2408701] | Lr: 0.000100 | Loss: 1.3663 | MSE loss: 0.0004 | Bpp loss: 0.78 | Aux loss: 47.57
24-04-03 12:19:17.818 - INFO: Train epoch 408: [ 8000/94637 (8%)] Step: [2408801] | Lr: 0.000100 | Loss: 1.4942 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 50.18
24-04-03 12:19:52.992 - INFO: Train epoch 408: [ 9600/94637 (10%)] Step: [2408901] | Lr: 0.000100 | Loss: 1.1782 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 45.22
24-04-03 12:20:28.671 - INFO: Train epoch 408: [11200/94637 (12%)] Step: [2409001] | Lr: 0.000100 | Loss: 1.6824 | MSE loss: 0.0005 | Bpp loss: 0.84 | Aux loss: 47.58
24-04-03 12:21:03.016 - INFO: Train epoch 408: [12800/94637 (14%)] Step: [2409101] | Lr: 0.000100 | Loss: 0.7708 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 49.55
24-04-03 12:21:37.752 - INFO: Train epoch 408: [14400/94637 (15%)] Step: [2409201] | Lr: 0.000100 | Loss: 0.9357 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 48.90
24-04-03 12:22:12.219 - INFO: Train epoch 408: [16000/94637 (17%)] Step: [2409301] | Lr: 0.000100 | Loss: 1.1064 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 44.98
24-04-03 12:22:47.240 - INFO: Train epoch 408: [17600/94637 (19%)] Step: [2409401] | Lr: 0.000100 | Loss: 1.2491 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 50.19
24-04-03 12:23:21.901 - INFO: Train epoch 408: [19200/94637 (20%)] Step: [2409501] | Lr: 0.000100 | Loss: 1.3323 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 45.63
24-04-03 12:23:57.040 - INFO: Train epoch 408: [20800/94637 (22%)] Step: [2409601] | Lr: 0.000100 | Loss: 2.0021 | MSE loss: 0.0005 | Bpp loss: 1.16 | Aux loss: 48.27
24-04-03 12:24:32.525 - INFO: Train epoch 408: [22400/94637 (24%)] Step: [2409701] | Lr: 0.000100 | Loss: 1.0959 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 48.66
24-04-03 12:25:08.778 - INFO: Train epoch 408: [24000/94637 (25%)] Step: [2409801] | Lr: 0.000100 | Loss: 1.1806 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 48.06
24-04-03 12:25:44.217 - INFO: Train epoch 408: [25600/94637 (27%)] Step: [2409901] | Lr: 0.000100 | Loss: 0.8460 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 48.98
24-04-03 12:26:21.383 - INFO: Train epoch 408: [27200/94637 (29%)] Step: [2410001] | Lr: 0.000100 | Loss: 1.8959 | MSE loss: 0.0005 | Bpp loss: 1.12 | Aux loss: 47.87
24-04-03 12:26:56.904 - INFO: Train epoch 408: [28800/94637 (30%)] Step: [2410101] | Lr: 0.000100 | Loss: 1.5175 | MSE loss: 0.0004 | Bpp loss: 0.93 | Aux loss: 44.71
24-04-03 12:27:32.491 - INFO: Train epoch 408: [30400/94637 (32%)] Step: [2410201] | Lr: 0.000100 | Loss: 1.0012 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 44.67
24-04-03 12:28:07.176 - INFO: Train epoch 408: [32000/94637 (34%)] Step: [2410301] | Lr: 0.000100 | Loss: 1.5247 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 45.09
24-04-03 12:28:42.104 - INFO: Train epoch 408: [33600/94637 (36%)] Step: [2410401] | Lr: 0.000100 | Loss: 1.1047 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 47.36
24-04-03 12:29:17.421 - INFO: Train epoch 408: [35200/94637 (37%)] Step: [2410501] | Lr: 0.000100 | Loss: 1.1798 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 47.67
24-04-03 12:29:52.451 - INFO: Train epoch 408: [36800/94637 (39%)] Step: [2410601] | Lr: 0.000100 | Loss: 1.0602 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 47.58
24-04-03 12:30:27.532 - INFO: Train epoch 408: [38400/94637 (41%)] Step: [2410701] | Lr: 0.000100 | Loss: 1.1133 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 46.18
24-04-03 12:31:02.505 - INFO: Train epoch 408: [40000/94637 (42%)] Step: [2410801] | Lr: 0.000100 | Loss: 1.3119 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 45.59
24-04-03 12:31:37.119 - INFO: Train epoch 408: [41600/94637 (44%)] Step: [2410901] | Lr: 0.000100 | Loss: 1.0873 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 47.07
24-04-03 12:32:12.050 - INFO: Train epoch 408: [43200/94637 (46%)] Step: [2411001] | Lr: 0.000100 | Loss: 0.8203 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 48.57
24-04-03 12:32:46.019 - INFO: Train epoch 408: [44800/94637 (47%)] Step: [2411101] | Lr: 0.000100 | Loss: 1.0503 | MSE loss: 0.0003 | Bpp loss: 0.60 | Aux loss: 46.67
24-04-03 12:33:21.337 - INFO: Train epoch 408: [46400/94637 (49%)] Step: [2411201] | Lr: 0.000100 | Loss: 0.9578 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 45.22
24-04-03 12:33:56.667 - INFO: Train epoch 408: [48000/94637 (51%)] Step: [2411301] | Lr: 0.000100 | Loss: 1.5397 | MSE loss: 0.0003 | Bpp loss: 1.02 | Aux loss: 51.19
24-04-03 12:34:30.915 - INFO: Train epoch 408: [49600/94637 (52%)] Step: [2411401] | Lr: 0.000100 | Loss: 0.8961 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 42.77
24-04-03 12:35:06.591 - INFO: Train epoch 408: [51200/94637 (54%)] Step: [2411501] | Lr: 0.000100 | Loss: 0.9196 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 46.55
24-04-03 12:35:42.562 - INFO: Train epoch 408: [52800/94637 (56%)] Step: [2411601] | Lr: 0.000100 | Loss: 1.0071 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 45.13
24-04-03 12:36:17.294 - INFO: Train epoch 408: [54400/94637 (57%)] Step: [2411701] | Lr: 0.000100 | Loss: 1.1031 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 45.64
24-04-03 12:36:51.899 - INFO: Train epoch 408: [56000/94637 (59%)] Step: [2411801] | Lr: 0.000100 | Loss: 1.2028 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 47.26
24-04-03 12:37:26.323 - INFO: Train epoch 408: [57600/94637 (61%)] Step: [2411901] | Lr: 0.000100 | Loss: 2.0729 | MSE loss: 0.0007 | Bpp loss: 1.01 | Aux loss: 48.83
24-04-03 12:38:00.828 - INFO: Train epoch 408: [59200/94637 (63%)] Step: [2412001] | Lr: 0.000100 | Loss: 1.0655 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 48.44
24-04-03 12:38:36.080 - INFO: Train epoch 408: [60800/94637 (64%)] Step: [2412101] | Lr: 0.000100 | Loss: 1.5009 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 50.34
24-04-03 12:39:10.915 - INFO: Train epoch 408: [62400/94637 (66%)] Step: [2412201] | Lr: 0.000100 | Loss: 0.8500 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 47.68
24-04-03 12:39:44.664 - INFO: Train epoch 408: [64000/94637 (68%)] Step: [2412301] | Lr: 0.000100 | Loss: 1.2734 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 48.15
24-04-03 12:40:18.600 - INFO: Train epoch 408: [65600/94637 (69%)] Step: [2412401] | Lr: 0.000100 | Loss: 1.3805 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 46.98
