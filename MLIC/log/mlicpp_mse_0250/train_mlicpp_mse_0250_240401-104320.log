24-04-01 10:44:30.626 - INFO: Namespace(experiment='mlicpp_mse_0250', dataset='/mnt/bn/jiangwei-lvc3/dataset/image', epochs=500, learning_rate=0.0001, num_workers=8, lmbda=0.025, metrics='mse', batch_size=4, test_batch_size=1, aux_learning_rate=0.001, patch_size=[320, 320], gpu_id=0, cuda=True, save=True, seed=1984.0, clip_max_norm=1.0, checkpoint='/mnt/bn/jiangwei-lvc3/work_space/MLICPlusPlus/playground/experiments/mlicpp_mse_0250/checkpoints', world_size=4, dist_url='env://', rank=1, gpu=1, distributed=True, dist_backend='nccl')
24-04-01 10:44:30.627 - INFO: {'N': 192, 'M': 320, 'enc_dims': [3, 192, 192, 192, 320], 'dec_dims': [320, 192, 192, 192, 16, 3], 'slice_num': 10, 'context_window': 5, 'slice_ch': [8, 8, 8, 8, 16, 16, 32, 32, 96, 96], 'max_support_slices': 5, 'quant': 'ste', 'lambda_list': [0.07, 0.08, 0.09], 'use_hyper_gain': False, 'interpolated_type': 'exponential', 'act': <class 'torch.nn.modules.activation.GELU'>, 'L': 10, 'target_bpp': [0.0761, 0.1854, 0.2752, 0.3652, 0.4282, 0.5238, 0.5653, 0.6334, 0.745], 'bpp_threshold': [0.02, 0.02, 0.02, 0.02, 0.03, 0.02, 0.02, 0.02, 0.02], 'min_lmbda': 0.001, 'init_lmbda': [0.001, 0.0018, 0.0035, 0.0035, 0.0067, 0.0067, 0.013, 0.013, 0.025, 0.0483], 'lower_bound': 1e-09, 'ki': 0.1, 'kp': 0.1}
24-04-01 10:44:30.627 - INFO: DistributedDataParallel(
  (module): MLICPlusPlus(
    (entropy_bottleneck): EntropyBottleneck(
      (likelihood_lower_bound): LowerBound()
    )
    (g_a): AnalysisTransform(
      (analysis_transform): Sequential(
        (0): ResidualBlockWithStride(
          (conv1): Conv2d(3, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (gdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (skip): Conv2d(3, 192, kernel_size=(1, 1), stride=(2, 2))
        )
        (1): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (2): ResidualBlockWithStride(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (gdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (skip): Conv2d(192, 192, kernel_size=(1, 1), stride=(2, 2))
        )
        (3): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (4): ResidualBlockWithStride(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (gdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (skip): Conv2d(192, 192, kernel_size=(1, 1), stride=(2, 2))
        )
        (5): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (6): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      )
    )
    (g_s): SynthesisTransform(
      (synthesis_transform): Sequential(
        (0): ResidualBlock(
          (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (1): ResidualBlockUpsample(
          (subpel_conv): Sequential(
            (0): Conv2d(320, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
          (act): GELU(approximate='none')
          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (igdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (upsample): Sequential(
            (0): Conv2d(320, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
        )
        (2): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (3): ResidualBlockUpsample(
          (subpel_conv): Sequential(
            (0): Conv2d(192, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
          (act): GELU(approximate='none')
          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (igdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (upsample): Sequential(
            (0): Conv2d(192, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
        )
        (4): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (5): ResidualBlockUpsample(
          (subpel_conv): Sequential(
            (0): Conv2d(192, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
          (act): GELU(approximate='none')
          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (igdn): GDN(
            (beta_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
            (gamma_reparam): NonNegativeParametrizer(
              (lower_bound): LowerBound()
            )
          )
          (upsample): Sequential(
            (0): Conv2d(192, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
        )
        (6): ResidualBlock(
          (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (act): GELU(approximate='none')
          (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (7): Sequential(
          (0): Conv2d(192, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): PixelShuffle(upscale_factor=2)
        )
      )
    )
    (h_a): HyperAnalysis(
      (reduction): Sequential(
        (0): Conv2d(320, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): GELU(approximate='none')
        (2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): GELU(approximate='none')
        (4): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (5): GELU(approximate='none')
        (6): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): GELU(approximate='none')
        (8): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      )
    )
    (h_s): HyperSynthesis(
      (increase): Sequential(
        (0): Conv2d(192, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): GELU(approximate='none')
        (2): Sequential(
          (0): Conv2d(320, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): PixelShuffle(upscale_factor=2)
        )
        (3): GELU(approximate='none')
        (4): Conv2d(320, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (5): GELU(approximate='none')
        (6): Sequential(
          (0): Conv2d(480, 1920, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): PixelShuffle(upscale_factor=2)
        )
        (7): GELU(approximate='none')
        (8): Conv2d(480, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (gaussian_conditional): GaussianConditional(
      (likelihood_lower_bound): LowerBound()
      (lower_bound_scale): LowerBound()
    )
    (local_context): ModuleList(
      (0-9): 10 x LocalContext(
        (qkv_proj): Linear(in_features=32, out_features=96, bias=True)
        (unfold): Unfold(kernel_size=5, dilation=1, padding=2, stride=1)
        (softmax): Softmax(dim=-1)
        (proj): Linear(in_features=64, out_features=64, bias=True)
        (mlp): MLP(
          (fc1): Linear(in_features=64, out_features=128, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=128, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (fusion): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
      )
    )
    (channel_context): ModuleList(
      (0): None
      (1): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(32, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (2): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (3): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (4): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (5): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(160, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (6): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (7): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(224, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (8): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (9): ChannelContext(
        (fushion): Sequential(
          (0): Conv2d(288, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (global_inter_context): ModuleList(
      (0): None
      (1): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (queries): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (values): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (reprojection): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
        )
        (queries): Sequential(
          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
        )
        (values): Sequential(
          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
        )
        (reprojection): Conv2d(64, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (3): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
        )
        (queries): Sequential(
          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
        )
        (values): Sequential(
          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
        )
        (reprojection): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (4): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
        )
        (queries): Sequential(
          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
        )
        (values): Sequential(
          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
        )
        (reprojection): Conv2d(128, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (5): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)
        )
        (queries): Sequential(
          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)
        )
        (values): Sequential(
          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)
        )
        (reprojection): Conv2d(160, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (6): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
        )
        (queries): Sequential(
          (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
        )
        (values): Sequential(
          (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
        )
        (reprojection): Conv2d(192, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (7): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(224, 224, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=224)
        )
        (queries): Sequential(
          (0): Conv2d(224, 224, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=224)
        )
        (values): Sequential(
          (0): Conv2d(224, 224, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=224)
        )
        (reprojection): Conv2d(224, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (8): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
        )
        (queries): Sequential(
          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
        )
        (values): Sequential(
          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
        )
        (reprojection): Conv2d(256, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
      (9): LinearGlobalInterContext(
        (keys): Sequential(
          (0): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)
        )
        (queries): Sequential(
          (0): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)
        )
        (values): Sequential(
          (0): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)
        )
        (reprojection): Conv2d(288, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (global_intra_context): ModuleList(
      (0): None
      (1-9): 9 x LinearGlobalIntraContext(
        (keys): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (queries): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (values): Sequential(
          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
        )
        (reprojection): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (mlp): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (3): GELU(approximate='none')
          (4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
    (entropy_parameters_anchor): ModuleList(
      (0): EntropyParameters(
        (fusion): Sequential(
          (0): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
          (5): GELU(approximate='none')
          (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (1-9): 9 x EntropyParameters(
        (fusion): Sequential(
          (0): Conv2d(832, 320, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
          (5): GELU(approximate='none')
          (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
    (entropy_parameters_nonanchor): ModuleList(
      (0): EntropyParameters(
        (fusion): Sequential(
          (0): Conv2d(704, 320, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
          (5): GELU(approximate='none')
          (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (1-9): 9 x EntropyParameters(
        (fusion): Sequential(
          (0): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
          (5): GELU(approximate='none')
          (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
    (lrp_anchor): ModuleList(
      (0): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(352, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (1): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(384, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (2): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(416, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (3): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(448, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (4): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(480, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (5): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(512, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (6): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(544, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (7): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(576, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (8): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(608, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (9): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(640, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (lrp_nonanchor): ModuleList(
      (0): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(352, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (1): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(384, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (2): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(416, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (3): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(448, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (4): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(480, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (5): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(512, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (6): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(544, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (7): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(576, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (8): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(608, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (9): LatentResidualPrediction(
        (lrp_transform): Sequential(
          (0): Conv2d(640, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): GELU(approximate='none')
          (2): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (3): GELU(approximate='none')
          (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
  )
)
24-04-01 10:44:30.636 - INFO: Learning rate: 0.0001
24-04-01 11:13:48.770 - INFO: Learning rate: 0.0001
24-04-01 11:42:32.310 - INFO: Learning rate: 0.0001
24-04-01 12:11:47.640 - INFO: Learning rate: 0.0001
24-04-01 12:40:49.350 - INFO: Learning rate: 0.0001
24-04-01 13:09:46.704 - INFO: Learning rate: 0.0001
24-04-01 13:38:28.376 - INFO: Learning rate: 0.0001
24-04-01 14:07:01.439 - INFO: Learning rate: 0.0001
24-04-01 14:36:18.467 - INFO: Learning rate: 0.0001
24-04-01 15:05:14.401 - INFO: Learning rate: 0.0001
24-04-01 15:33:58.064 - INFO: Learning rate: 0.0001
24-04-01 16:02:56.995 - INFO: Learning rate: 0.0001
24-04-01 16:31:54.309 - INFO: Learning rate: 0.0001
24-04-01 17:01:00.766 - INFO: Learning rate: 0.0001
24-04-01 17:29:37.588 - INFO: Learning rate: 0.0001
24-04-01 17:58:21.317 - INFO: Learning rate: 0.0001
24-04-01 18:27:19.193 - INFO: Learning rate: 0.0001
24-04-01 18:56:22.340 - INFO: Learning rate: 0.0001
24-04-01 19:25:33.581 - INFO: Learning rate: 0.0001
24-04-01 19:54:06.099 - INFO: Learning rate: 0.0001
24-04-01 20:22:35.249 - INFO: Learning rate: 0.0001
8: [ 9600/94637 (10%)] Step: [1881571] | Lr: 0.000100 | Loss: 1.6309 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 78.50
24-04-01 10:48:04.936 - INFO: Train epoch 318: [11200/94637 (12%)] Step: [1881671] | Lr: 0.000100 | Loss: 1.1523 | MSE loss: 0.0002 | Bpp loss: 0.76 | Aux loss: 78.98
24-04-01 10:48:33.787 - INFO: Train epoch 318: [12800/94637 (14%)] Step: [1881771] | Lr: 0.000100 | Loss: 0.9878 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 77.70
24-04-01 10:49:02.592 - INFO: Train epoch 318: [14400/94637 (15%)] Step: [1881871] | Lr: 0.000100 | Loss: 1.5116 | MSE loss: 0.0004 | Bpp loss: 0.93 | Aux loss: 76.25
24-04-01 10:49:31.578 - INFO: Train epoch 318: [16000/94637 (17%)] Step: [1881971] | Lr: 0.000100 | Loss: 0.8280 | MSE loss: 0.0002 | Bpp loss: 0.45 | Aux loss: 73.06
24-04-01 10:50:00.264 - INFO: Train epoch 318: [17600/94637 (19%)] Step: [1882071] | Lr: 0.000100 | Loss: 1.1593 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 77.79
24-04-01 10:50:29.374 - INFO: Train epoch 318: [19200/94637 (20%)] Step: [1882171] | Lr: 0.000100 | Loss: 1.0539 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 72.76
24-04-01 10:50:58.925 - INFO: Train epoch 318: [20800/94637 (22%)] Step: [1882271] | Lr: 0.000100 | Loss: 1.4141 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 69.69
24-04-01 10:51:29.185 - INFO: Train epoch 318: [22400/94637 (24%)] Step: [1882371] | Lr: 0.000100 | Loss: 1.3195 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 75.55
24-04-01 10:51:58.670 - INFO: Train epoch 318: [24000/94637 (25%)] Step: [1882471] | Lr: 0.000100 | Loss: 1.4093 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 82.27
24-04-01 10:52:30.350 - INFO: Train epoch 318: [25600/94637 (27%)] Step: [1882571] | Lr: 0.000100 | Loss: 1.1057 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 72.25
24-04-01 10:52:59.980 - INFO: Train epoch 318: [27200/94637 (29%)] Step: [1882671] | Lr: 0.000100 | Loss: 1.3557 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 74.64
24-04-01 10:53:29.945 - INFO: Train epoch 318: [28800/94637 (30%)] Step: [1882771] | Lr: 0.000100 | Loss: 0.8624 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 71.22
24-04-01 10:53:59.820 - INFO: Train epoch 318: [30400/94637 (32%)] Step: [1882871] | Lr: 0.000100 | Loss: 1.1752 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 72.60
24-04-01 10:54:29.621 - INFO: Train epoch 318: [32000/94637 (34%)] Step: [1882971] | Lr: 0.000100 | Loss: 1.2860 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 73.47
24-04-01 10:55:00.164 - INFO: Train epoch 318: [33600/94637 (36%)] Step: [1883071] | Lr: 0.000100 | Loss: 1.5411 | MSE loss: 0.0003 | Bpp loss: 0.99 | Aux loss: 72.26
24-04-01 10:55:30.090 - INFO: Train epoch 318: [35200/94637 (37%)] Step: [1883171] | Lr: 0.000100 | Loss: 0.9201 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 71.98
24-04-01 10:56:00.095 - INFO: Train epoch 318: [36800/94637 (39%)] Step: [1883271] | Lr: 0.000100 | Loss: 2.4666 | MSE loss: 0.0007 | Bpp loss: 1.25 | Aux loss: 69.75
24-04-01 10:56:29.774 - INFO: Train epoch 318: [38400/94637 (41%)] Step: [1883371] | Lr: 0.000100 | Loss: 1.6596 | MSE loss: 0.0004 | Bpp loss: 0.93 | Aux loss: 75.94
24-04-01 10:56:59.111 - INFO: Train epoch 318: [40000/94637 (42%)] Step: [1883471] | Lr: 0.000100 | Loss: 0.9352 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 78.82
24-04-01 10:57:28.931 - INFO: Train epoch 318: [41600/94637 (44%)] Step: [1883571] | Lr: 0.000100 | Loss: 1.3214 | MSE loss: 0.0004 | Bpp loss: 0.70 | Aux loss: 69.93
24-04-01 10:57:58.059 - INFO: Train epoch 318: [43200/94637 (46%)] Step: [1883671] | Lr: 0.000100 | Loss: 1.1692 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 71.45
24-04-01 10:58:27.014 - INFO: Train epoch 318: [44800/94637 (47%)] Step: [1883771] | Lr: 0.000100 | Loss: 1.8413 | MSE loss: 0.0005 | Bpp loss: 1.07 | Aux loss: 71.35
24-04-01 10:58:56.060 - INFO: Train epoch 318: [46400/94637 (49%)] Step: [1883871] | Lr: 0.000100 | Loss: 0.9243 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 71.58
24-04-01 10:59:25.680 - INFO: Train epoch 318: [48000/94637 (51%)] Step: [1883971] | Lr: 0.000100 | Loss: 1.8132 | MSE loss: 0.0004 | Bpp loss: 1.10 | Aux loss: 76.90
24-04-01 10:59:54.776 - INFO: Train epoch 318: [49600/94637 (52%)] Step: [1884071] | Lr: 0.000100 | Loss: 1.2030 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 73.97
24-04-01 11:00:24.140 - INFO: Train epoch 318: [51200/94637 (54%)] Step: [1884171] | Lr: 0.000100 | Loss: 1.2765 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 73.80
24-04-01 11:00:53.458 - INFO: Train epoch 318: [52800/94637 (56%)] Step: [1884271] | Lr: 0.000100 | Loss: 1.1947 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 72.29
24-04-01 11:01:22.795 - INFO: Train epoch 318: [54400/94637 (57%)] Step: [1884371] | Lr: 0.000100 | Loss: 0.8216 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 74.19
24-04-01 11:01:52.188 - INFO: Train epoch 318: [56000/94637 (59%)] Step: [1884471] | Lr: 0.000100 | Loss: 1.8691 | MSE loss: 0.0005 | Bpp loss: 1.09 | Aux loss: 70.11
24-04-01 11:02:21.593 - INFO: Train epoch 318: [57600/94637 (61%)] Step: [1884571] | Lr: 0.000100 | Loss: 1.3507 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 72.75
24-04-01 11:02:51.519 - INFO: Train epoch 318: [59200/94637 (63%)] Step: [1884671] | Lr: 0.000100 | Loss: 1.3242 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 76.88
24-04-01 11:03:20.437 - INFO: Train epoch 318: [60800/94637 (64%)] Step: [1884771] | Lr: 0.000100 | Loss: 1.1805 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 76.64
24-04-01 11:03:49.606 - INFO: Train epoch 318: [62400/94637 (66%)] Step: [1884871] | Lr: 0.000100 | Loss: 0.9700 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 73.30
24-04-01 11:04:19.365 - INFO: Train epoch 318: [64000/94637 (68%)] Step: [1884971] | Lr: 0.000100 | Loss: 1.2697 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 69.39
24-04-01 11:04:50.539 - INFO: Train epoch 318: [65600/94637 (69%)] Step: [1885071] | Lr: 0.000100 | Loss: 1.4125 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 68.31
24-04-01 11:05:20.714 - INFO: Train epoch 318: [67200/94637 (71%)] Step: [1885171] | Lr: 0.000100 | Loss: 1.1252 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 77.27
24-04-01 11:05:50.541 - INFO: Train epoch 318: [68800/94637 (73%)] Step: [1885271] | Lr: 0.000100 | Loss: 1.2186 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 79.29
24-04-01 11:06:20.599 - INFO: Train epoch 318: [70400/94637 (74%)] Step: [1885371] | Lr: 0.000100 | Loss: 1.3824 | MSE loss: 0.0004 | Bpp loss: 0.78 | Aux loss: 73.56
24-04-01 11:06:50.105 - INFO: Train epoch 318: [72000/94637 (76%)] Step: [1885471] | Lr: 0.000100 | Loss: 1.2337 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 82.31
24-04-01 11:07:19.376 - INFO: Train epoch 318: [73600/94637 (78%)] Step: [1885571] | Lr: 0.000100 | Loss: 0.9687 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 72.80
24-04-01 11:07:49.168 - INFO: Train epoch 318: [75200/94637 (79%)] Step: [1885671] | Lr: 0.000100 | Loss: 1.0787 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 78.16
24-04-01 11:08:18.609 - INFO: Train epoch 318: [76800/94637 (81%)] Step: [1885771] | Lr: 0.000100 | Loss: 1.5094 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 75.68
24-04-01 11:08:48.115 - INFO: Train epoch 318: [78400/94637 (83%)] Step: [1885871] | Lr: 0.000100 | Loss: 2.0688 | MSE loss: 0.0006 | Bpp loss: 1.13 | Aux loss: 74.17
24-04-01 11:09:17.441 - INFO: Train epoch 318: [80000/94637 (85%)] Step: [1885971] | Lr: 0.000100 | Loss: 1.8344 | MSE loss: 0.0005 | Bpp loss: 0.97 | Aux loss: 76.48
24-04-01 11:09:47.259 - INFO: Train epoch 318: [81600/94637 (86%)] Step: [1886071] | Lr: 0.000100 | Loss: 1.0351 | MSE loss: 0.0003 | Bpp loss: 0.56 | Aux loss: 76.64
24-04-01 11:10:16.407 - INFO: Train epoch 318: [83200/94637 (88%)] Step: [1886171] | Lr: 0.000100 | Loss: 1.1891 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 76.52
24-04-01 11:10:46.082 - INFO: Train epoch 318: [84800/94637 (90%)] Step: [1886271] | Lr: 0.000100 | Loss: 1.3520 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 78.54
24-04-01 11:11:15.267 - INFO: Train epoch 318: [86400/94637 (91%)] Step: [1886371] | Lr: 0.000100 | Loss: 1.7867 | MSE loss: 0.0005 | Bpp loss: 1.03 | Aux loss: 76.60
24-04-01 11:11:44.901 - INFO: Train epoch 318: [88000/94637 (93%)] Step: [1886471] | Lr: 0.000100 | Loss: 1.2734 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 77.29
24-04-01 11:12:14.894 - INFO: Train epoch 318: [89600/94637 (95%)] Step: [1886571] | Lr: 0.000100 | Loss: 1.9677 | MSE loss: 0.0005 | Bpp loss: 1.11 | Aux loss: 75.00
24-04-01 11:12:44.190 - INFO: Train epoch 318: [91200/94637 (96%)] Step: [1886671] | Lr: 0.000100 | Loss: 1.3142 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 80.05
24-04-01 11:13:14.889 - INFO: Train epoch 318: [92800/94637 (98%)] Step: [1886771] | Lr: 0.000100 | Loss: 1.2402 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 81.04
24-04-01 11:13:44.428 - INFO: Train epoch 318: [94400/94637 (100%)] Step: [1886871] | Lr: 0.000100 | Loss: 0.4972 | MSE loss: 0.0001 | Bpp loss: 0.35 | Aux loss: 74.74
24-04-01 11:14:07.245 - INFO: Learning rate: 0.0001
24-04-01 11:14:07.997 - INFO: Train epoch 319: [    0/94637 (0%)] Step: [1886886] | Lr: 0.000100 | Loss: 1.0915 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 74.61
24-04-01 11:14:35.829 - INFO: Train epoch 319: [ 1600/94637 (2%)] Step: [1886986] | Lr: 0.000100 | Loss: 1.3438 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 72.76
24-04-01 11:15:04.757 - INFO: Train epoch 319: [ 3200/94637 (3%)] Step: [1887086] | Lr: 0.000100 | Loss: 0.9501 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 77.44
24-04-01 11:15:33.022 - INFO: Train epoch 319: [ 4800/94637 (5%)] Step: [1887186] | Lr: 0.000100 | Loss: 1.2037 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 81.89
24-04-01 11:16:01.513 - INFO: Train epoch 319: [ 6400/94637 (7%)] Step: [1887286] | Lr: 0.000100 | Loss: 1.1202 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 79.79
24-04-01 11:16:30.043 - INFO: Train epoch 319: [ 8000/94637 (8%)] Step: [1887386] | Lr: 0.000100 | Loss: 1.8475 | MSE loss: 0.0005 | Bpp loss: 1.09 | Aux loss: 74.12
24-04-01 11:16:58.838 - INFO: Train epoch 319: [ 9600/94637 (10%)] Step: [1887486] | Lr: 0.000100 | Loss: 1.1872 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 73.39
24-04-01 11:17:28.695 - INFO: Train epoch 319: [11200/94637 (12%)] Step: [1887586] | Lr: 0.000100 | Loss: 1.2178 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 78.58
24-04-01 11:17:56.665 - INFO: Train epoch 319: [12800/94637 (14%)] Step: [1887686] | Lr: 0.000100 | Loss: 1.1896 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 76.05
24-04-01 11:18:24.981 - INFO: Train epoch 319: [14400/94637 (15%)] Step: [1887786] | Lr: 0.000100 | Loss: 1.2272 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 75.61
24-04-01 11:18:53.231 - INFO: Train epoch 319: [16000/94637 (17%)] Step: [1887886] | Lr: 0.000100 | Loss: 1.2867 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 77.58
24-04-01 11:19:22.012 - INFO: Train epoch 319: [17600/94637 (19%)] Step: [1887986] | Lr: 0.000100 | Loss: 1.7720 | MSE loss: 0.0004 | Bpp loss: 1.05 | Aux loss: 75.70
24-04-01 11:19:50.237 - INFO: Train epoch 319: [19200/94637 (20%)] Step: [1888086] | Lr: 0.000100 | Loss: 1.4007 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 78.98
24-04-01 11:20:19.315 - INFO: Train epoch 319: [20800/94637 (22%)] Step: [1888186] | Lr: 0.000100 | Loss: 0.6683 | MSE loss: 0.0001 | Bpp loss: 0.48 | Aux loss: 73.01
24-04-01 11:20:47.903 - INFO: Train epoch 319: [22400/94637 (24%)] Step: [1888286] | Lr: 0.000100 | Loss: 0.6324 | MSE loss: 0.0001 | Bpp loss: 0.42 | Aux loss: 77.81
24-04-01 11:21:16.648 - INFO: Train epoch 319: [24000/94637 (25%)] Step: [1888386] | Lr: 0.000100 | Loss: 1.4412 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 73.97
24-04-01 11:21:45.469 - INFO: Train epoch 319: [25600/94637 (27%)] Step: [1888486] | Lr: 0.000100 | Loss: 0.7220 | MSE loss: 0.0002 | Bpp loss: 0.47 | Aux loss: 76.44
24-04-01 11:22:13.938 - INFO: Train epoch 319: [27200/94637 (29%)] Step: [1888586] | Lr: 0.000100 | Loss: 1.4329 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 74.35
24-04-01 11:22:42.783 - INFO: Train epoch 319: [28800/94637 (30%)] Step: [1888686] | Lr: 0.000100 | Loss: 1.9690 | MSE loss: 0.0005 | Bpp loss: 1.23 | Aux loss: 80.33
24-04-01 11:23:11.244 - INFO: Train epoch 319: [30400/94637 (32%)] Step: [1888786] | Lr: 0.000100 | Loss: 1.8078 | MSE loss: 0.0004 | Bpp loss: 1.13 | Aux loss: 74.60
24-04-01 11:23:39.945 - INFO: Train epoch 319: [32000/94637 (34%)] Step: [1888886] | Lr: 0.000100 | Loss: 1.3629 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 79.32
24-04-01 11:24:08.568 - INFO: Train epoch 319: [33600/94637 (36%)] Step: [1888986] | Lr: 0.000100 | Loss: 1.2973 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 79.55
24-04-01 11:24:37.466 - INFO: Train epoch 319: [35200/94637 (37%)] Step: [1889086] | Lr: 0.000100 | Loss: 0.9006 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 80.51
24-04-01 11:25:06.277 - INFO: Train epoch 319: [36800/94637 (39%)] Step: [1889186] | Lr: 0.000100 | Loss: 1.2334 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 77.26
24-04-01 11:25:34.551 - INFO: Train epoch 319: [38400/94637 (41%)] Step: [1889286] | Lr: 0.000100 | Loss: 1.1924 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 75.96
24-04-01 11:26:02.839 - INFO: Train epoch 319: [40000/94637 (42%)] Step: [1889386] | Lr: 0.000100 | Loss: 1.0120 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 76.66
24-04-01 11:26:31.057 - INFO: Train epoch 319: [41600/94637 (44%)] Step: [1889486] | Lr: 0.000100 | Loss: 1.3596 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 78.65
24-04-01 11:26:59.049 - INFO: Train epoch 319: [43200/94637 (46%)] Step: [1889586] | Lr: 0.000100 | Loss: 1.2361 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 83.33
24-04-01 11:27:26.871 - INFO: Train epoch 319: [44800/94637 (47%)] Step: [1889686] | Lr: 0.000100 | Loss: 1.1237 | MSE loss: 0.0003 | Bpp loss: 0.60 | Aux loss: 75.18
24-04-01 11:27:55.291 - INFO: Train epoch 319: [46400/94637 (49%)] Step: [1889786] | Lr: 0.000100 | Loss: 0.9162 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 73.43
24-04-01 11:28:23.530 - INFO: Train epoch 319: [48000/94637 (51%)] Step: [1889886] | Lr: 0.000100 | Loss: 1.3027 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 79.97
24-04-01 11:28:51.590 - INFO: Train epoch 319: [49600/94637 (52%)] Step: [1889986] | Lr: 0.000100 | Loss: 1.6933 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 78.64
24-04-01 11:29:21.670 - INFO: Train epoch 319: [51200/94637 (54%)] Step: [1890086] | Lr: 0.000100 | Loss: 1.4900 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 76.41
24-04-01 11:29:49.875 - INFO: Train epoch 319: [52800/94637 (56%)] Step: [1890186] | Lr: 0.000100 | Loss: 1.3848 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 75.51
24-04-01 11:30:18.597 - INFO: Train epoch 319: [54400/94637 (57%)] Step: [1890286] | Lr: 0.000100 | Loss: 0.6078 | MSE loss: 0.0001 | Bpp loss: 0.42 | Aux loss: 79.23
24-04-01 11:30:47.153 - INFO: Train epoch 319: [56000/94637 (59%)] Step: [1890386] | Lr: 0.000100 | Loss: 1.2374 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 82.69
24-04-01 11:31:15.584 - INFO: Train epoch 319: [57600/94637 (61%)] Step: [1890486] | Lr: 0.000100 | Loss: 1.7106 | MSE loss: 0.0004 | Bpp loss: 1.09 | Aux loss: 76.79
24-04-01 11:31:43.735 - INFO: Train epoch 319: [59200/94637 (63%)] Step: [1890586] | Lr: 0.000100 | Loss: 1.0199 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 79.65
24-04-01 11:32:12.182 - INFO: Train epoch 319: [60800/94637 (64%)] Step: [1890686] | Lr: 0.000100 | Loss: 1.5704 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 82.59
24-04-01 11:32:40.590 - INFO: Train epoch 319: [62400/94637 (66%)] Step: [1890786] | Lr: 0.000100 | Loss: 1.3713 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 79.26
24-04-01 11:33:08.973 - INFO: Train epoch 319: [64000/94637 (68%)] Step: [1890886] | Lr: 0.000100 | Loss: 1.4947 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 80.95
24-04-01 11:33:37.969 - INFO: Train epoch 319: [65600/94637 (69%)] Step: [1890986] | Lr: 0.000100 | Loss: 1.0945 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 75.89
24-04-01 11:34:07.468 - INFO: Train epoch 319: [67200/94637 (71%)] Step: [1891086] | Lr: 0.000100 | Loss: 1.0955 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 80.84
24-04-01 11:34:37.937 - INFO: Train epoch 319: [68800/94637 (73%)] Step: [1891186] | Lr: 0.000100 | Loss: 1.5334 | MSE loss: 0.0004 | Bpp loss: 0.93 | Aux loss: 77.87
24-04-01 11:35:07.583 - INFO: Train epoch 319: [70400/94637 (74%)] Step: [1891286] | Lr: 0.000100 | Loss: 1.7778 | MSE loss: 0.0005 | Bpp loss: 0.97 | Aux loss: 86.08
24-04-01 11:35:35.896 - INFO: Train epoch 319: [72000/94637 (76%)] Step: [1891386] | Lr: 0.000100 | Loss: 0.7849 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 77.45
24-04-01 11:36:04.922 - INFO: Train epoch 319: [73600/94637 (78%)] Step: [1891486] | Lr: 0.000100 | Loss: 1.1809 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 77.58
24-04-01 11:36:33.513 - INFO: Train epoch 319: [75200/94637 (79%)] Step: [1891586] | Lr: 0.000100 | Loss: 1.3807 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 76.82
24-04-01 11:37:01.715 - INFO: Train epoch 319: [76800/94637 (81%)] Step: [1891686] | Lr: 0.000100 | Loss: 1.0914 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 74.05
24-04-01 11:37:29.801 - INFO: Train epoch 319: [78400/94637 (83%)] Step: [1891786] | Lr: 0.000100 | Loss: 1.4499 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 72.48
24-04-01 11:37:58.462 - INFO: Train epoch 319: [80000/94637 (85%)] Step: [1891886] | Lr: 0.000100 | Loss: 1.2573 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 77.52
24-04-01 11:38:26.619 - INFO: Train epoch 319: [81600/94637 (86%)] Step: [1891986] | Lr: 0.000100 | Loss: 0.8464 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 76.41
24-04-01 11:38:56.140 - INFO: Train epoch 319: [83200/94637 (88%)] Step: [1892086] | Lr: 0.000100 | Loss: 1.1452 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 70.25
24-04-01 11:39:25.967 - INFO: Train epoch 319: [84800/94637 (90%)] Step: [1892186] | Lr: 0.000100 | Loss: 1.6112 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 74.03
24-04-01 11:39:55.621 - INFO: Train epoch 319: [86400/94637 (91%)] Step: [1892286] | Lr: 0.000100 | Loss: 1.0296 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 72.17
24-04-01 11:40:26.057 - INFO: Train epoch 319: [88000/94637 (93%)] Step: [1892386] | Lr: 0.000100 | Loss: 0.9474 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 79.88
24-04-01 11:40:55.909 - INFO: Train epoch 319: [89600/94637 (95%)] Step: [1892486] | Lr: 0.000100 | Loss: 1.2078 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 77.39
24-04-01 11:41:27.971 - INFO: Train epoch 319: [91200/94637 (96%)] Step: [1892586] | Lr: 0.000100 | Loss: 0.6086 | MSE loss: 0.0001 | Bpp loss: 0.43 | Aux loss: 76.73
24-04-01 11:41:57.605 - INFO: Train epoch 319: [92800/94637 (98%)] Step: [1892686] | Lr: 0.000100 | Loss: 1.5758 | MSE loss: 0.0003 | Bpp loss: 1.02 | Aux loss: 78.04
24-04-01 11:42:27.981 - INFO: Train epoch 319: [94400/94637 (100%)] Step: [1892786] | Lr: 0.000100 | Loss: 1.3676 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 77.90
24-04-01 11:42:43.503 - INFO: Learning rate: 0.0001
24-04-01 11:42:45.063 - INFO: Train epoch 320: [    0/94637 (0%)] Step: [1892801] | Lr: 0.000100 | Loss: 0.9101 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 74.45
24-04-01 11:43:14.957 - INFO: Train epoch 320: [ 1600/94637 (2%)] Step: [1892901] | Lr: 0.000100 | Loss: 0.9579 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 79.57
24-04-01 11:43:45.580 - INFO: Train epoch 320: [ 3200/94637 (3%)] Step: [1893001] | Lr: 0.000100 | Loss: 0.8031 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 77.50
24-04-01 11:44:15.626 - INFO: Train epoch 320: [ 4800/94637 (5%)] Step: [1893101] | Lr: 0.000100 | Loss: 1.5637 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 79.21
24-04-01 11:44:45.881 - INFO: Train epoch 320: [ 6400/94637 (7%)] Step: [1893201] | Lr: 0.000100 | Loss: 1.1162 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 82.75
24-04-01 11:45:15.604 - INFO: Train epoch 320: [ 8000/94637 (8%)] Step: [1893301] | Lr: 0.000100 | Loss: 1.0363 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 76.18
24-04-01 11:45:44.768 - INFO: Train epoch 320: [ 9600/94637 (10%)] Step: [1893401] | Lr: 0.000100 | Loss: 0.9443 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 81.91
24-04-01 11:46:14.585 - INFO: Train epoch 320: [11200/94637 (12%)] Step: [1893501] | Lr: 0.000100 | Loss: 0.7719 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 71.48
24-04-01 11:46:43.890 - INFO: Train epoch 320: [12800/94637 (14%)] Step: [1893601] | Lr: 0.000100 | Loss: 1.3123 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 80.11
24-04-01 11:47:13.210 - INFO: Train epoch 320: [14400/94637 (15%)] Step: [1893701] | Lr: 0.000100 | Loss: 1.0114 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 78.31
24-04-01 11:47:42.799 - INFO: Train epoch 320: [16000/94637 (17%)] Step: [1893801] | Lr: 0.000100 | Loss: 2.0013 | MSE loss: 0.0005 | Bpp loss: 1.13 | Aux loss: 73.40
24-04-01 11:48:11.804 - INFO: Train epoch 320: [17600/94637 (19%)] Step: [1893901] | Lr: 0.000100 | Loss: 1.1469 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 85.83
24-04-01 11:48:40.973 - INFO: Train epoch 320: [19200/94637 (20%)] Step: [1894001] | Lr: 0.000100 | Loss: 2.2338 | MSE loss: 0.0007 | Bpp loss: 1.11 | Aux loss: 71.28
24-04-01 11:49:09.348 - INFO: Train epoch 320: [20800/94637 (22%)] Step: [1894101] | Lr: 0.000100 | Loss: 1.5780 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 75.68
24-04-01 11:49:37.178 - INFO: Train epoch 320: [22400/94637 (24%)] Step: [1894201] | Lr: 0.000100 | Loss: 0.9078 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 74.25
24-04-01 11:50:05.138 - INFO: Train epoch 320: [24000/94637 (25%)] Step: [1894301] | Lr: 0.000100 | Loss: 1.3342 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 73.20
24-04-01 11:50:33.830 - INFO: Train epoch 320: [25600/94637 (27%)] Step: [1894401] | Lr: 0.000100 | Loss: 2.4259 | MSE loss: 0.0007 | Bpp loss: 1.30 | Aux loss: 82.42
24-04-01 11:51:02.974 - INFO: Train epoch 320: [27200/94637 (29%)] Step: [1894501] | Lr: 0.000100 | Loss: 1.2623 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 75.36
24-04-01 11:51:31.988 - INFO: Train epoch 320: [28800/94637 (30%)] Step: [1894601] | Lr: 0.000100 | Loss: 1.2515 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 77.24
24-04-01 11:52:01.283 - INFO: Train epoch 320: [30400/94637 (32%)] Step: [1894701] | Lr: 0.000100 | Loss: 1.9251 | MSE loss: 0.0005 | Bpp loss: 1.16 | Aux loss: 77.16
24-04-01 11:52:30.427 - INFO: Train epoch 320: [32000/94637 (34%)] Step: [1894801] | Lr: 0.000100 | Loss: 1.2578 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 85.75
24-04-01 11:53:00.270 - INFO: Train epoch 320: [33600/94637 (36%)] Step: [1894901] | Lr: 0.000100 | Loss: 2.4040 | MSE loss: 0.0008 | Bpp loss: 1.11 | Aux loss: 83.39
24-04-01 11:53:31.363 - INFO: Train epoch 320: [35200/94637 (37%)] Step: [1895001] | Lr: 0.000100 | Loss: 1.0757 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 78.30
24-04-01 11:54:01.147 - INFO: Train epoch 320: [36800/94637 (39%)] Step: [1895101] | Lr: 0.000100 | Loss: 0.8184 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 73.50
24-04-01 11:54:30.592 - INFO: Train epoch 320: [38400/94637 (41%)] Step: [1895201] | Lr: 0.000100 | Loss: 1.2003 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 77.65
24-04-01 11:55:00.469 - INFO: Train epoch 320: [40000/94637 (42%)] Step: [1895301] | Lr: 0.000100 | Loss: 1.6834 | MSE loss: 0.0004 | Bpp loss: 1.07 | Aux loss: 76.44
24-04-01 11:55:30.114 - INFO: Train epoch 320: [41600/94637 (44%)] Step: [1895401] | Lr: 0.000100 | Loss: 0.9065 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 73.23
24-04-01 11:55:59.259 - INFO: Train epoch 320: [43200/94637 (46%)] Step: [1895501] | Lr: 0.000100 | Loss: 1.4462 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 71.94
24-04-01 11:56:29.083 - INFO: Train epoch 320: [44800/94637 (47%)] Step: [1895601] | Lr: 0.000100 | Loss: 1.1485 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 78.93
24-04-01 11:56:58.257 - INFO: Train epoch 320: [46400/94637 (49%)] Step: [1895701] | Lr: 0.000100 | Loss: 1.2297 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 84.76
24-04-01 11:57:27.500 - INFO: Train epoch 320: [48000/94637 (51%)] Step: [1895801] | Lr: 0.000100 | Loss: 1.0326 | MSE loss: 0.0003 | Bpp loss: 0.62 | Aux loss: 84.12
24-04-01 11:57:56.528 - INFO: Train epoch 320: [49600/94637 (52%)] Step: [1895901] | Lr: 0.000100 | Loss: 1.1441 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 77.02
24-04-01 11:58:26.558 - INFO: Train epoch 320: [51200/94637 (54%)] Step: [1896001] | Lr: 0.000100 | Loss: 0.7780 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 77.80
24-04-01 11:58:55.797 - INFO: Train epoch 320: [52800/94637 (56%)] Step: [1896101] | Lr: 0.000100 | Loss: 1.1221 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 80.46
24-04-01 11:59:25.313 - INFO: Train epoch 320: [54400/94637 (57%)] Step: [1896201] | Lr: 0.000100 | Loss: 0.7646 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 81.51
24-04-01 11:59:54.898 - INFO: Train epoch 320: [56000/94637 (59%)] Step: [1896301] | Lr: 0.000100 | Loss: 0.8997 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 87.55
24-04-01 12:00:24.241 - INFO: Train epoch 320: [57600/94637 (61%)] Step: [1896401] | Lr: 0.000100 | Loss: 0.6045 | MSE loss: 0.0001 | Bpp loss: 0.41 | Aux loss: 82.67
24-04-01 12:00:54.402 - INFO: Train epoch 320: [59200/94637 (63%)] Step: [1896501] | Lr: 0.000100 | Loss: 1.2490 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 80.36
24-04-01 12:01:23.775 - INFO: Train epoch 320: [60800/94637 (64%)] Step: [1896601] | Lr: 0.000100 | Loss: 1.0263 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 83.55
24-04-01 12:01:53.265 - INFO: Train epoch 320: [62400/94637 (66%)] Step: [1896701] | Lr: 0.000100 | Loss: 1.6950 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 81.91
24-04-01 12:02:22.602 - INFO: Train epoch 320: [64000/94637 (68%)] Step: [1896801] | Lr: 0.000100 | Loss: 1.3099 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 78.49
24-04-01 12:02:52.218 - INFO: Train epoch 320: [65600/94637 (69%)] Step: [1896901] | Lr: 0.000100 | Loss: 0.7803 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 84.71
24-04-01 12:03:22.161 - INFO: Train epoch 320: [67200/94637 (71%)] Step: [1897001] | Lr: 0.000100 | Loss: 1.6522 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 80.52
24-04-01 12:03:51.253 - INFO: Train epoch 320: [68800/94637 (73%)] Step: [1897101] | Lr: 0.000100 | Loss: 1.2135 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 81.45
24-04-01 12:04:21.192 - INFO: Train epoch 320: [70400/94637 (74%)] Step: [1897201] | Lr: 0.000100 | Loss: 1.3118 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 81.99
24-04-01 12:04:50.534 - INFO: Train epoch 320: [72000/94637 (76%)] Step: [1897301] | Lr: 0.000100 | Loss: 1.3551 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 77.34
24-04-01 12:05:19.775 - INFO: Train epoch 320: [73600/94637 (78%)] Step: [1897401] | Lr: 0.000100 | Loss: 1.2381 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 76.26
24-04-01 12:05:49.690 - INFO: Train epoch 320: [75200/94637 (79%)] Step: [1897501] | Lr: 0.000100 | Loss: 1.1356 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 82.46
24-04-01 12:06:18.260 - INFO: Train epoch 320: [76800/94637 (81%)] Step: [1897601] | Lr: 0.000100 | Loss: 1.8008 | MSE loss: 0.0004 | Bpp loss: 1.09 | Aux loss: 82.01
24-04-01 12:06:47.939 - INFO: Train epoch 320: [78400/94637 (83%)] Step: [1897701] | Lr: 0.000100 | Loss: 1.2219 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 87.12
24-04-01 12:07:17.580 - INFO: Train epoch 320: [80000/94637 (85%)] Step: [1897801] | Lr: 0.000100 | Loss: 1.5631 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 84.50
24-04-01 12:07:46.893 - INFO: Train epoch 320: [81600/94637 (86%)] Step: [1897901] | Lr: 0.000100 | Loss: 1.5262 | MSE loss: 0.0003 | Bpp loss: 0.97 | Aux loss: 76.02
24-04-01 12:08:16.195 - INFO: Train epoch 320: [83200/94637 (88%)] Step: [1898001] | Lr: 0.000100 | Loss: 1.4154 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 82.16
24-04-01 12:08:46.005 - INFO: Train epoch 320: [84800/94637 (90%)] Step: [1898101] | Lr: 0.000100 | Loss: 0.7771 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 80.10
24-04-01 12:09:15.417 - INFO: Train epoch 320: [86400/94637 (91%)] Step: [1898201] | Lr: 0.000100 | Loss: 1.5263 | MSE loss: 0.0003 | Bpp loss: 0.96 | Aux loss: 76.21
24-04-01 12:09:45.073 - INFO: Train epoch 320: [88000/94637 (93%)] Step: [1898301] | Lr: 0.000100 | Loss: 1.2585 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 80.85
24-04-01 12:10:14.607 - INFO: Train epoch 320: [89600/94637 (95%)] Step: [1898401] | Lr: 0.000100 | Loss: 1.1372 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 87.71
24-04-01 12:10:44.230 - INFO: Train epoch 320: [91200/94637 (96%)] Step: [1898501] | Lr: 0.000100 | Loss: 0.6410 | MSE loss: 0.0001 | Bpp loss: 0.43 | Aux loss: 81.63
24-04-01 12:11:13.730 - INFO: Train epoch 320: [92800/94637 (98%)] Step: [1898601] | Lr: 0.000100 | Loss: 1.4541 | MSE loss: 0.0004 | Bpp loss: 0.88 | Aux loss: 76.93
24-04-01 12:11:43.453 - INFO: Train epoch 320: [94400/94637 (100%)] Step: [1898701] | Lr: 0.000100 | Loss: 1.5491 | MSE loss: 0.0003 | Bpp loss: 1.00 | Aux loss: 86.53
24-04-01 12:12:04.147 - INFO: Learning rate: 0.0001
24-04-01 12:12:04.952 - INFO: Train epoch 321: [    0/94637 (0%)] Step: [1898716] | Lr: 0.000100 | Loss: 2.3068 | MSE loss: 0.0006 | Bpp loss: 1.29 | Aux loss: 80.26
24-04-01 12:12:34.829 - INFO: Train epoch 321: [ 1600/94637 (2%)] Step: [1898816] | Lr: 0.000100 | Loss: 1.0003 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 79.83
24-04-01 12:13:04.350 - INFO: Train epoch 321: [ 3200/94637 (3%)] Step: [1898916] | Lr: 0.000100 | Loss: 1.4163 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 81.85
24-04-01 12:13:34.073 - INFO: Train epoch 321: [ 4800/94637 (5%)] Step: [1899016] | Lr: 0.000100 | Loss: 1.0615 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 82.17
24-04-01 12:14:03.109 - INFO: Train epoch 321: [ 6400/94637 (7%)] Step: [1899116] | Lr: 0.000100 | Loss: 1.1133 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 88.62
24-04-01 12:14:32.178 - INFO: Train epoch 321: [ 8000/94637 (8%)] Step: [1899216] | Lr: 0.000100 | Loss: 1.1914 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 73.56
24-04-01 12:15:00.827 - INFO: Train epoch 321: [ 9600/94637 (10%)] Step: [1899316] | Lr: 0.000100 | Loss: 1.6069 | MSE loss: 0.0004 | Bpp loss: 1.03 | Aux loss: 83.36
24-04-01 12:15:29.743 - INFO: Train epoch 321: [11200/94637 (12%)] Step: [1899416] | Lr: 0.000100 | Loss: 1.1753 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 83.43
24-04-01 12:15:58.370 - INFO: Train epoch 321: [12800/94637 (14%)] Step: [1899516] | Lr: 0.000100 | Loss: 1.3495 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 82.77
24-04-01 12:16:27.360 - INFO: Train epoch 321: [14400/94637 (15%)] Step: [1899616] | Lr: 0.000100 | Loss: 0.8545 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 77.99
24-04-01 12:16:56.307 - INFO: Train epoch 321: [16000/94637 (17%)] Step: [1899716] | Lr: 0.000100 | Loss: 1.6815 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 79.02
24-04-01 12:17:25.575 - INFO: Train epoch 321: [17600/94637 (19%)] Step: [1899816] | Lr: 0.000100 | Loss: 1.7635 | MSE loss: 0.0004 | Bpp loss: 1.06 | Aux loss: 79.85
24-04-01 12:17:54.630 - INFO: Train epoch 321: [19200/94637 (20%)] Step: [1899916] | Lr: 0.000100 | Loss: 0.8891 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 78.49
24-04-01 12:18:25.488 - INFO: Train epoch 321: [20800/94637 (22%)] Step: [1900016] | Lr: 0.000100 | Loss: 1.5477 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 76.82
24-04-01 12:18:54.466 - INFO: Train epoch 321: [22400/94637 (24%)] Step: [1900116] | Lr: 0.000100 | Loss: 1.1138 | MSE loss: 0.0003 | Bpp loss: 0.62 | Aux loss: 77.84
24-04-01 12:19:23.902 - INFO: Train epoch 321: [24000/94637 (25%)] Step: [1900216] | Lr: 0.000100 | Loss: 1.3080 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 74.71
24-04-01 12:19:53.025 - INFO: Train epoch 321: [25600/94637 (27%)] Step: [1900316] | Lr: 0.000100 | Loss: 1.0368 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 77.49
24-04-01 12:20:22.111 - INFO: Train epoch 321: [27200/94637 (29%)] Step: [1900416] | Lr: 0.000100 | Loss: 1.0581 | MSE loss: 0.0003 | Bpp loss: 0.62 | Aux loss: 76.22
24-04-01 12:20:50.876 - INFO: Train epoch 321: [28800/94637 (30%)] Step: [1900516] | Lr: 0.000100 | Loss: 1.0944 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 77.80
24-04-01 12:21:19.774 - INFO: Train epoch 321: [30400/94637 (32%)] Step: [1900616] | Lr: 0.000100 | Loss: 1.7132 | MSE loss: 0.0004 | Bpp loss: 1.06 | Aux loss: 81.50
24-04-01 12:21:48.499 - INFO: Train epoch 321: [32000/94637 (34%)] Step: [1900716] | Lr: 0.000100 | Loss: 1.6477 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 76.26
24-04-01 12:22:17.329 - INFO: Train epoch 321: [33600/94637 (36%)] Step: [1900816] | Lr: 0.000100 | Loss: 1.4255 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 80.66
24-04-01 12:22:46.346 - INFO: Train epoch 321: [35200/94637 (37%)] Step: [1900916] | Lr: 0.000100 | Loss: 1.1090 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 77.44
24-04-01 12:23:15.477 - INFO: Train epoch 321: [36800/94637 (39%)] Step: [1901016] | Lr: 0.000100 | Loss: 1.1934 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 78.07
24-04-01 12:23:44.251 - INFO: Train epoch 321: [38400/94637 (41%)] Step: [1901116] | Lr: 0.000100 | Loss: 1.2417 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 77.54
24-04-01 12:24:12.907 - INFO: Train epoch 321: [40000/94637 (42%)] Step: [1901216] | Lr: 0.000100 | Loss: 1.2747 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 75.90
24-04-01 12:24:41.486 - INFO: Train epoch 321: [41600/94637 (44%)] Step: [1901316] | Lr: 0.000100 | Loss: 1.5787 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 74.88
24-04-01 12:25:10.797 - INFO: Train epoch 321: [43200/94637 (46%)] Step: [1901416] | Lr: 0.000100 | Loss: 1.0940 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 82.81
24-04-01 12:25:40.100 - INFO: Train epoch 321: [44800/94637 (47%)] Step: [1901516] | Lr: 0.000100 | Loss: 0.9783 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 74.56
24-04-01 12:26:08.751 - INFO: Train epoch 321: [46400/94637 (49%)] Step: [1901616] | Lr: 0.000100 | Loss: 1.1331 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 74.50
24-04-01 12:26:37.786 - INFO: Train epoch 321: [48000/94637 (51%)] Step: [1901716] | Lr: 0.000100 | Loss: 1.2789 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 79.23
24-04-01 12:27:06.786 - INFO: Train epoch 321: [49600/94637 (52%)] Step: [1901816] | Lr: 0.000100 | Loss: 1.2343 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 76.03
24-04-01 12:27:36.214 - INFO: Train epoch 321: [51200/94637 (54%)] Step: [1901916] | Lr: 0.000100 | Loss: 1.2875 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 84.12
24-04-01 12:28:05.277 - INFO: Train epoch 321: [52800/94637 (56%)] Step: [1902016] | Lr: 0.000100 | Loss: 1.0819 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 76.46
24-04-01 12:28:35.101 - INFO: Train epoch 321: [54400/94637 (57%)] Step: [1902116] | Lr: 0.000100 | Loss: 1.3179 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 76.46
24-04-01 12:29:04.552 - INFO: Train epoch 321: [56000/94637 (59%)] Step: [1902216] | Lr: 0.000100 | Loss: 1.1563 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 80.40
24-04-01 12:29:34.191 - INFO: Train epoch 321: [57600/94637 (61%)] Step: [1902316] | Lr: 0.000100 | Loss: 1.4084 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 80.70
24-04-01 12:30:03.178 - INFO: Train epoch 321: [59200/94637 (63%)] Step: [1902416] | Lr: 0.000100 | Loss: 1.1285 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 77.33
24-04-01 12:30:34.212 - INFO: Train epoch 321: [60800/94637 (64%)] Step: [1902516] | Lr: 0.000100 | Loss: 0.7038 | MSE loss: 0.0002 | Bpp loss: 0.41 | Aux loss: 73.57
24-04-01 12:31:03.806 - INFO: Train epoch 321: [62400/94637 (66%)] Step: [1902616] | Lr: 0.000100 | Loss: 1.2192 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 79.63
24-04-01 12:31:32.835 - INFO: Train epoch 321: [64000/94637 (68%)] Step: [1902716] | Lr: 0.000100 | Loss: 0.8194 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 80.61
24-04-01 12:32:01.882 - INFO: Train epoch 321: [65600/94637 (69%)] Step: [1902816] | Lr: 0.000100 | Loss: 0.8900 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 76.46
24-04-01 12:32:30.899 - INFO: Train epoch 321: [67200/94637 (71%)] Step: [1902916] | Lr: 0.000100 | Loss: 1.9090 | MSE loss: 0.0004 | Bpp loss: 1.18 | Aux loss: 76.89
24-04-01 12:32:59.832 - INFO: Train epoch 321: [68800/94637 (73%)] Step: [1903016] | Lr: 0.000100 | Loss: 2.2471 | MSE loss: 0.0006 | Bpp loss: 1.23 | Aux loss: 76.97
24-04-01 12:33:28.887 - INFO: Train epoch 321: [70400/94637 (74%)] Step: [1903116] | Lr: 0.000100 | Loss: 1.3856 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 86.86
24-04-01 12:33:57.939 - INFO: Train epoch 321: [72000/94637 (76%)] Step: [1903216] | Lr: 0.000100 | Loss: 1.2604 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 79.57
24-04-01 12:34:27.006 - INFO: Train epoch 321: [73600/94637 (78%)] Step: [1903316] | Lr: 0.000100 | Loss: 1.1158 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 82.27
24-04-01 12:34:56.224 - INFO: Train epoch 321: [75200/94637 (79%)] Step: [1903416] | Lr: 0.000100 | Loss: 1.2064 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 81.48
24-04-01 12:35:25.253 - INFO: Train epoch 321: [76800/94637 (81%)] Step: [1903516] | Lr: 0.000100 | Loss: 1.7369 | MSE loss: 0.0004 | Bpp loss: 1.07 | Aux loss: 86.02
24-04-01 12:35:54.420 - INFO: Train epoch 321: [78400/94637 (83%)] Step: [1903616] | Lr: 0.000100 | Loss: 1.0291 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 81.18
24-04-01 12:36:23.665 - INFO: Train epoch 321: [80000/94637 (85%)] Step: [1903716] | Lr: 0.000100 | Loss: 1.6544 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 82.43
24-04-01 12:36:52.896 - INFO: Train epoch 321: [81600/94637 (86%)] Step: [1903816] | Lr: 0.000100 | Loss: 1.3195 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 80.87
24-04-01 12:37:22.393 - INFO: Train epoch 321: [83200/94637 (88%)] Step: [1903916] | Lr: 0.000100 | Loss: 1.1351 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 79.91
24-04-01 12:37:51.666 - INFO: Train epoch 321: [84800/94637 (90%)] Step: [1904016] | Lr: 0.000100 | Loss: 1.3249 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 83.97
24-04-01 12:38:20.505 - INFO: Train epoch 321: [86400/94637 (91%)] Step: [1904116] | Lr: 0.000100 | Loss: 1.3520 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 79.73
24-04-01 12:38:49.470 - INFO: Train epoch 321: [88000/94637 (93%)] Step: [1904216] | Lr: 0.000100 | Loss: 1.3563 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 85.40
24-04-01 12:39:18.379 - INFO: Train epoch 321: [89600/94637 (95%)] Step: [1904316] | Lr: 0.000100 | Loss: 0.7269 | MSE loss: 0.0001 | Bpp loss: 0.51 | Aux loss: 82.43
24-04-01 12:39:47.437 - INFO: Train epoch 321: [91200/94637 (96%)] Step: [1904416] | Lr: 0.000100 | Loss: 1.8470 | MSE loss: 0.0005 | Bpp loss: 1.06 | Aux loss: 76.70
24-04-01 12:40:16.065 - INFO: Train epoch 321: [92800/94637 (98%)] Step: [1904516] | Lr: 0.000100 | Loss: 1.0924 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 83.69
24-04-01 12:40:45.068 - INFO: Train epoch 321: [94400/94637 (100%)] Step: [1904616] | Lr: 0.000100 | Loss: 1.1223 | MSE loss: 0.0002 | Bpp loss: 0.73 | Aux loss: 76.31
24-04-01 12:41:00.540 - INFO: Learning rate: 0.0001
24-04-01 12:41:01.271 - INFO: Train epoch 322: [    0/94637 (0%)] Step: [1904631] | Lr: 0.000100 | Loss: 1.2764 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 81.78
24-04-01 12:41:29.916 - INFO: Train epoch 322: [ 1600/94637 (2%)] Step: [1904731] | Lr: 0.000100 | Loss: 1.4565 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 78.17
24-04-01 12:41:57.643 - INFO: Train epoch 322: [ 3200/94637 (3%)] Step: [1904831] | Lr: 0.000100 | Loss: 1.5311 | MSE loss: 0.0004 | Bpp loss: 0.81 | Aux loss: 77.90
24-04-01 12:42:26.229 - INFO: Train epoch 322: [ 4800/94637 (5%)] Step: [1904931] | Lr: 0.000100 | Loss: 1.3926 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 76.19
24-04-01 12:42:57.022 - INFO: Train epoch 322: [ 6400/94637 (7%)] Step: [1905031] | Lr: 0.000100 | Loss: 1.3213 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 84.70
24-04-01 12:43:26.217 - INFO: Train epoch 322: [ 8000/94637 (8%)] Step: [1905131] | Lr: 0.000100 | Loss: 1.2041 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 80.71
24-04-01 12:43:55.533 - INFO: Train epoch 322: [ 9600/94637 (10%)] Step: [1905231] | Lr: 0.000100 | Loss: 1.1844 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 78.49
24-04-01 12:44:24.314 - INFO: Train epoch 322: [11200/94637 (12%)] Step: [1905331] | Lr: 0.000100 | Loss: 1.4110 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 83.20
24-04-01 12:44:52.830 - INFO: Train epoch 322: [12800/94637 (14%)] Step: [1905431] | Lr: 0.000100 | Loss: 1.3459 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 79.19
24-04-01 12:45:21.704 - INFO: Train epoch 322: [14400/94637 (15%)] Step: [1905531] | Lr: 0.000100 | Loss: 0.8577 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 79.10
24-04-01 12:45:50.825 - INFO: Train epoch 322: [16000/94637 (17%)] Step: [1905631] | Lr: 0.000100 | Loss: 1.2144 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 83.38
24-04-01 12:46:19.521 - INFO: Train epoch 322: [17600/94637 (19%)] Step: [1905731] | Lr: 0.000100 | Loss: 1.7697 | MSE loss: 0.0004 | Bpp loss: 1.10 | Aux loss: 78.39
24-04-01 12:46:49.026 - INFO: Train epoch 322: [19200/94637 (20%)] Step: [1905831] | Lr: 0.000100 | Loss: 1.0677 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 81.44
24-04-01 12:47:17.861 - INFO: Train epoch 322: [20800/94637 (22%)] Step: [1905931] | Lr: 0.000100 | Loss: 1.2937 | MSE loss: 0.0004 | Bpp loss: 0.72 | Aux loss: 83.12
24-04-01 12:47:46.739 - INFO: Train epoch 322: [22400/94637 (24%)] Step: [1906031] | Lr: 0.000100 | Loss: 1.2130 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 76.51
24-04-01 12:48:15.689 - INFO: Train epoch 322: [24000/94637 (25%)] Step: [1906131] | Lr: 0.000100 | Loss: 1.1001 | MSE loss: 0.0003 | Bpp loss: 0.61 | Aux loss: 83.56
24-04-01 12:48:44.652 - INFO: Train epoch 322: [25600/94637 (27%)] Step: [1906231] | Lr: 0.000100 | Loss: 1.3528 | MSE loss: 0.0004 | Bpp loss: 0.78 | Aux loss: 76.35
24-04-01 12:49:14.296 - INFO: Train epoch 322: [27200/94637 (29%)] Step: [1906331] | Lr: 0.000100 | Loss: 1.1292 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 78.55
24-04-01 12:49:42.868 - INFO: Train epoch 322: [28800/94637 (30%)] Step: [1906431] | Lr: 0.000100 | Loss: 1.0401 | MSE loss: 0.0003 | Bpp loss: 0.62 | Aux loss: 78.25
24-04-01 12:50:12.021 - INFO: Train epoch 322: [30400/94637 (32%)] Step: [1906531] | Lr: 0.000100 | Loss: 1.1011 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 79.84
24-04-01 12:50:41.376 - INFO: Train epoch 322: [32000/94637 (34%)] Step: [1906631] | Lr: 0.000100 | Loss: 1.4366 | MSE loss: 0.0004 | Bpp loss: 0.82 | Aux loss: 80.85
24-04-01 12:51:10.960 - INFO: Train epoch 322: [33600/94637 (36%)] Step: [1906731] | Lr: 0.000100 | Loss: 1.5570 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 81.82
24-04-01 12:51:40.105 - INFO: Train epoch 322: [35200/94637 (37%)] Step: [1906831] | Lr: 0.000100 | Loss: 1.6859 | MSE loss: 0.0004 | Bpp loss: 1.06 | Aux loss: 82.86
24-04-01 12:52:09.415 - INFO: Train epoch 322: [36800/94637 (39%)] Step: [1906931] | Lr: 0.000100 | Loss: 1.0592 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 92.32
24-04-01 12:52:38.548 - INFO: Train epoch 322: [38400/94637 (41%)] Step: [1907031] | Lr: 0.000100 | Loss: 1.1493 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 84.98
24-04-01 12:53:07.442 - INFO: Train epoch 322: [40000/94637 (42%)] Step: [1907131] | Lr: 0.000100 | Loss: 1.3665 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 78.50
24-04-01 12:53:36.523 - INFO: Train epoch 322: [41600/94637 (44%)] Step: [1907231] | Lr: 0.000100 | Loss: 2.1248 | MSE loss: 0.0005 | Bpp loss: 1.24 | Aux loss: 78.88
24-04-01 12:54:05.271 - INFO: Train epoch 322: [43200/94637 (46%)] Step: [1907331] | Lr: 0.000100 | Loss: 1.1745 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 74.76
24-04-01 12:54:34.463 - INFO: Train epoch 322: [44800/94637 (47%)] Step: [1907431] | Lr: 0.000100 | Loss: 1.5237 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 75.12
24-04-01 12:55:04.802 - INFO: Train epoch 322: [46400/94637 (49%)] Step: [1907531] | Lr: 0.000100 | Loss: 0.8165 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 76.69
24-04-01 12:55:33.858 - INFO: Train epoch 322: [48000/94637 (51%)] Step: [1907631] | Lr: 0.000100 | Loss: 0.8412 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 72.45
24-04-01 12:56:02.680 - INFO: Train epoch 322: [49600/94637 (52%)] Step: [1907731] | Lr: 0.000100 | Loss: 0.9089 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 71.73
24-04-01 12:56:31.411 - INFO: Train epoch 322: [51200/94637 (54%)] Step: [1907831] | Lr: 0.000100 | Loss: 1.4291 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 76.25
24-04-01 12:57:00.671 - INFO: Train epoch 322: [52800/94637 (56%)] Step: [1907931] | Lr: 0.000100 | Loss: 0.8845 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 76.06
24-04-01 12:57:29.479 - INFO: Train epoch 322: [54400/94637 (57%)] Step: [1908031] | Lr: 0.000100 | Loss: 1.1977 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 78.76
24-04-01 12:57:58.710 - INFO: Train epoch 322: [56000/94637 (59%)] Step: [1908131] | Lr: 0.000100 | Loss: 1.4422 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 73.29
24-04-01 12:58:27.636 - INFO: Train epoch 322: [57600/94637 (61%)] Step: [1908231] | Lr: 0.000100 | Loss: 0.9826 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 78.27
24-04-01 12:58:57.395 - INFO: Train epoch 322: [59200/94637 (63%)] Step: [1908331] | Lr: 0.000100 | Loss: 0.8257 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 81.80
24-04-01 12:59:26.796 - INFO: Train epoch 322: [60800/94637 (64%)] Step: [1908431] | Lr: 0.000100 | Loss: 1.7556 | MSE loss: 0.0005 | Bpp loss: 0.98 | Aux loss: 73.31
24-04-01 12:59:55.689 - INFO: Train epoch 322: [62400/94637 (66%)] Step: [1908531] | Lr: 0.000100 | Loss: 0.9260 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 78.26
24-04-01 13:00:25.106 - INFO: Train epoch 322: [64000/94637 (68%)] Step: [1908631] | Lr: 0.000100 | Loss: 1.0479 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 78.36
24-04-01 13:00:54.038 - INFO: Train epoch 322: [65600/94637 (69%)] Step: [1908731] | Lr: 0.000100 | Loss: 1.4177 | MSE loss: 0.0004 | Bpp loss: 0.82 | Aux loss: 80.03
24-04-01 13:01:23.300 - INFO: Train epoch 322: [67200/94637 (71%)] Step: [1908831] | Lr: 0.000100 | Loss: 2.0616 | MSE loss: 0.0004 | Bpp loss: 1.33 | Aux loss: 68.88
24-04-01 13:01:52.148 - INFO: Train epoch 322: [68800/94637 (73%)] Step: [1908931] | Lr: 0.000100 | Loss: 1.5856 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 81.99
24-04-01 13:02:21.671 - INFO: Train epoch 322: [70400/94637 (74%)] Step: [1909031] | Lr: 0.000100 | Loss: 1.3771 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 77.23
24-04-01 13:02:50.623 - INFO: Train epoch 322: [72000/94637 (76%)] Step: [1909131] | Lr: 0.000100 | Loss: 1.4256 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 73.14
24-04-01 13:03:19.770 - INFO: Train epoch 322: [73600/94637 (78%)] Step: [1909231] | Lr: 0.000100 | Loss: 0.7436 | MSE loss: 0.0002 | Bpp loss: 0.45 | Aux loss: 79.10
24-04-01 13:03:48.750 - INFO: Train epoch 322: [75200/94637 (79%)] Step: [1909331] | Lr: 0.000100 | Loss: 0.9541 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 87.20
24-04-01 13:04:17.529 - INFO: Train epoch 322: [76800/94637 (81%)] Step: [1909431] | Lr: 0.000100 | Loss: 0.8136 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 82.30
24-04-01 13:04:46.811 - INFO: Train epoch 322: [78400/94637 (83%)] Step: [1909531] | Lr: 0.000100 | Loss: 1.3432 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 76.80
24-04-01 13:05:15.934 - INFO: Train epoch 322: [80000/94637 (85%)] Step: [1909631] | Lr: 0.000100 | Loss: 1.5132 | MSE loss: 0.0004 | Bpp loss: 0.84 | Aux loss: 83.77
24-04-01 13:05:45.303 - INFO: Train epoch 322: [81600/94637 (86%)] Step: [1909731] | Lr: 0.000100 | Loss: 0.8154 | MSE loss: 0.0002 | Bpp loss: 0.48 | Aux loss: 75.08
24-04-01 13:06:14.771 - INFO: Train epoch 322: [83200/94637 (88%)] Step: [1909831] | Lr: 0.000100 | Loss: 1.0627 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 80.09
24-04-01 13:06:44.507 - INFO: Train epoch 322: [84800/94637 (90%)] Step: [1909931] | Lr: 0.000100 | Loss: 0.9024 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 81.51
24-04-01 13:07:15.522 - INFO: Train epoch 322: [86400/94637 (91%)] Step: [1910031] | Lr: 0.000100 | Loss: 1.4969 | MSE loss: 0.0004 | Bpp loss: 0.84 | Aux loss: 80.77
24-04-01 13:07:44.866 - INFO: Train epoch 322: [88000/94637 (93%)] Step: [1910131] | Lr: 0.000100 | Loss: 0.9785 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 80.90
24-04-01 13:08:14.555 - INFO: Train epoch 322: [89600/94637 (95%)] Step: [1910231] | Lr: 0.000100 | Loss: 1.1099 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 80.21
24-04-01 13:08:43.625 - INFO: Train epoch 322: [91200/94637 (96%)] Step: [1910331] | Lr: 0.000100 | Loss: 1.1458 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 81.22
24-04-01 13:09:12.818 - INFO: Train epoch 322: [92800/94637 (98%)] Step: [1910431] | Lr: 0.000100 | Loss: 1.6902 | MSE loss: 0.0004 | Bpp loss: 1.05 | Aux loss: 80.02
24-04-01 13:09:42.406 - INFO: Train epoch 322: [94400/94637 (100%)] Step: [1910531] | Lr: 0.000100 | Loss: 1.0428 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 79.94
24-04-01 13:09:58.078 - INFO: Learning rate: 0.0001
24-04-01 13:09:58.905 - INFO: Train epoch 323: [    0/94637 (0%)] Step: [1910546] | Lr: 0.000100 | Loss: 1.6121 | MSE loss: 0.0004 | Bpp loss: 0.99 | Aux loss: 82.68
24-04-01 13:10:27.922 - INFO: Train epoch 323: [ 1600/94637 (2%)] Step: [1910646] | Lr: 0.000100 | Loss: 0.8299 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 78.99
24-04-01 13:10:56.459 - INFO: Train epoch 323: [ 3200/94637 (3%)] Step: [1910746] | Lr: 0.000100 | Loss: 1.2936 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 76.45
24-04-01 13:11:25.007 - INFO: Train epoch 323: [ 4800/94637 (5%)] Step: [1910846] | Lr: 0.000100 | Loss: 1.6455 | MSE loss: 0.0004 | Bpp loss: 0.99 | Aux loss: 77.51
24-04-01 13:11:53.290 - INFO: Train epoch 323: [ 6400/94637 (7%)] Step: [1910946] | Lr: 0.000100 | Loss: 1.1015 | MSE loss: 0.0003 | Bpp loss: 0.62 | Aux loss: 77.18
24-04-01 13:12:21.614 - INFO: Train epoch 323: [ 8000/94637 (8%)] Step: [1911046] | Lr: 0.000100 | Loss: 0.9153 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 76.29
24-04-01 13:12:49.859 - INFO: Train epoch 323: [ 9600/94637 (10%)] Step: [1911146] | Lr: 0.000100 | Loss: 0.8907 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 74.30
24-04-01 13:13:18.805 - INFO: Train epoch 323: [11200/94637 (12%)] Step: [1911246] | Lr: 0.000100 | Loss: 1.1868 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 73.05
24-04-01 13:13:47.785 - INFO: Train epoch 323: [12800/94637 (14%)] Step: [1911346] | Lr: 0.000100 | Loss: 1.0796 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 78.25
24-04-01 13:14:16.793 - INFO: Train epoch 323: [14400/94637 (15%)] Step: [1911446] | Lr: 0.000100 | Loss: 1.0539 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 77.88
24-04-01 13:14:45.844 - INFO: Train epoch 323: [16000/94637 (17%)] Step: [1911546] | Lr: 0.000100 | Loss: 1.1344 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 76.20
24-04-01 13:15:14.932 - INFO: Train epoch 323: [17600/94637 (19%)] Step: [1911646] | Lr: 0.000100 | Loss: 1.1727 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 73.44
24-04-01 13:15:44.475 - INFO: Train epoch 323: [19200/94637 (20%)] Step: [1911746] | Lr: 0.000100 | Loss: 0.9469 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 71.64
24-04-01 13:16:13.348 - INFO: Train epoch 323: [20800/94637 (22%)] Step: [1911846] | Lr: 0.000100 | Loss: 1.4636 | MSE loss: 0.0004 | Bpp loss: 0.84 | Aux loss: 74.85
24-04-01 13:16:42.789 - INFO: Train epoch 323: [22400/94637 (24%)] Step: [1911946] | Lr: 0.000100 | Loss: 1.5765 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 80.36
24-04-01 13:17:11.867 - INFO: Train epoch 323: [24000/94637 (25%)] Step: [1912046] | Lr: 0.000100 | Loss: 1.6032 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 76.25
24-04-01 13:17:40.866 - INFO: Train epoch 323: [25600/94637 (27%)] Step: [1912146] | Lr: 0.000100 | Loss: 1.6381 | MSE loss: 0.0004 | Bpp loss: 0.99 | Aux loss: 78.58
24-04-01 13:18:10.104 - INFO: Train epoch 323: [27200/94637 (29%)] Step: [1912246] | Lr: 0.000100 | Loss: 1.1810 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 72.23
24-04-01 13:18:39.772 - INFO: Train epoch 323: [28800/94637 (30%)] Step: [1912346] | Lr: 0.000100 | Loss: 1.5118 | MSE loss: 0.0003 | Bpp loss: 0.98 | Aux loss: 80.35
24-04-01 13:19:08.753 - INFO: Train epoch 323: [30400/94637 (32%)] Step: [1912446] | Lr: 0.000100 | Loss: 0.9636 | MSE loss: 0.0003 | Bpp loss: 0.55 | Aux loss: 78.56
24-04-01 13:19:38.804 - INFO: Train epoch 323: [32000/94637 (34%)] Step: [1912546] | Lr: 0.000100 | Loss: 0.7519 | MSE loss: 0.0001 | Bpp loss: 0.52 | Aux loss: 79.12
24-04-01 13:20:07.064 - INFO: Train epoch 323: [33600/94637 (36%)] Step: [1912646] | Lr: 0.000100 | Loss: 1.3303 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 77.22
24-04-01 13:20:35.371 - INFO: Train epoch 323: [35200/94637 (37%)] Step: [1912746] | Lr: 0.000100 | Loss: 1.2761 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 81.99
24-04-01 13:21:03.441 - INFO: Train epoch 323: [36800/94637 (39%)] Step: [1912846] | Lr: 0.000100 | Loss: 0.7654 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 78.52
24-04-01 13:21:31.663 - INFO: Train epoch 323: [38400/94637 (41%)] Step: [1912946] | Lr: 0.000100 | Loss: 1.4929 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 83.38
24-04-01 13:21:59.675 - INFO: Train epoch 323: [40000/94637 (42%)] Step: [1913046] | Lr: 0.000100 | Loss: 1.1102 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 79.79
24-04-01 13:22:27.821 - INFO: Train epoch 323: [41600/94637 (44%)] Step: [1913146] | Lr: 0.000100 | Loss: 2.8498 | MSE loss: 0.0010 | Bpp loss: 1.26 | Aux loss: 85.22
24-04-01 13:22:55.594 - INFO: Train epoch 323: [43200/94637 (46%)] Step: [1913246] | Lr: 0.000100 | Loss: 1.1795 | MSE loss: 0.0002 | Bpp loss: 0.78 | Aux loss: 71.70
24-04-01 13:23:23.794 - INFO: Train epoch 323: [44800/94637 (47%)] Step: [1913346] | Lr: 0.000100 | Loss: 1.5344 | MSE loss: 0.0003 | Bpp loss: 0.97 | Aux loss: 79.62
24-04-01 13:23:51.575 - INFO: Train epoch 323: [46400/94637 (49%)] Step: [1913446] | Lr: 0.000100 | Loss: 1.0767 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 76.53
24-04-01 13:24:19.706 - INFO: Train epoch 323: [48000/94637 (51%)] Step: [1913546] | Lr: 0.000100 | Loss: 1.3897 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 83.67
24-04-01 13:24:48.313 - INFO: Train epoch 323: [49600/94637 (52%)] Step: [1913646] | Lr: 0.000100 | Loss: 0.9720 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 82.42
24-04-01 13:25:17.242 - INFO: Train epoch 323: [51200/94637 (54%)] Step: [1913746] | Lr: 0.000100 | Loss: 1.1711 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 77.97
24-04-01 13:25:46.581 - INFO: Train epoch 323: [52800/94637 (56%)] Step: [1913846] | Lr: 0.000100 | Loss: 1.6188 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 84.21
24-04-01 13:26:15.675 - INFO: Train epoch 323: [54400/94637 (57%)] Step: [1913946] | Lr: 0.000100 | Loss: 1.1322 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 83.54
24-04-01 13:26:44.904 - INFO: Train epoch 323: [56000/94637 (59%)] Step: [1914046] | Lr: 0.000100 | Loss: 2.2976 | MSE loss: 0.0006 | Bpp loss: 1.34 | Aux loss: 84.25
24-04-01 13:27:13.872 - INFO: Train epoch 323: [57600/94637 (61%)] Step: [1914146] | Lr: 0.000100 | Loss: 1.4543 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 80.13
24-04-01 13:27:42.666 - INFO: Train epoch 323: [59200/94637 (63%)] Step: [1914246] | Lr: 0.000100 | Loss: 1.8527 | MSE loss: 0.0005 | Bpp loss: 1.11 | Aux loss: 82.13
24-04-01 13:28:11.744 - INFO: Train epoch 323: [60800/94637 (64%)] Step: [1914346] | Lr: 0.000100 | Loss: 1.1149 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 79.03
24-04-01 13:28:40.517 - INFO: Train epoch 323: [62400/94637 (66%)] Step: [1914446] | Lr: 0.000100 | Loss: 1.4557 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 83.87
24-04-01 13:29:09.932 - INFO: Train epoch 323: [64000/94637 (68%)] Step: [1914546] | Lr: 0.000100 | Loss: 1.0672 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 77.99
24-04-01 13:29:39.030 - INFO: Train epoch 323: [65600/94637 (69%)] Step: [1914646] | Lr: 0.000100 | Loss: 1.7522 | MSE loss: 0.0004 | Bpp loss: 1.08 | Aux loss: 80.71
24-04-01 13:30:08.250 - INFO: Train epoch 323: [67200/94637 (71%)] Step: [1914746] | Lr: 0.000100 | Loss: 1.4127 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 72.31
24-04-01 13:30:37.308 - INFO: Train epoch 323: [68800/94637 (73%)] Step: [1914846] | Lr: 0.000100 | Loss: 1.1716 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 75.38
24-04-01 13:31:06.394 - INFO: Train epoch 323: [70400/94637 (74%)] Step: [1914946] | Lr: 0.000100 | Loss: 1.0362 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 77.67
24-04-01 13:31:37.356 - INFO: Train epoch 323: [72000/94637 (76%)] Step: [1915046] | Lr: 0.000100 | Loss: 1.1062 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 80.46
24-04-01 13:32:06.461 - INFO: Train epoch 323: [73600/94637 (78%)] Step: [1915146] | Lr: 0.000100 | Loss: 1.2298 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 81.78
24-04-01 13:32:35.395 - INFO: Train epoch 323: [75200/94637 (79%)] Step: [1915246] | Lr: 0.000100 | Loss: 1.6245 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 101.97
24-04-01 13:33:04.350 - INFO: Train epoch 323: [76800/94637 (81%)] Step: [1915346] | Lr: 0.000100 | Loss: 1.3706 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 75.29
24-04-01 13:33:33.015 - INFO: Train epoch 323: [78400/94637 (83%)] Step: [1915446] | Lr: 0.000100 | Loss: 1.6244 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 76.84
24-04-01 13:34:01.507 - INFO: Train epoch 323: [80000/94637 (85%)] Step: [1915546] | Lr: 0.000100 | Loss: 1.2593 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 73.10
24-04-01 13:34:29.706 - INFO: Train epoch 323: [81600/94637 (86%)] Step: [1915646] | Lr: 0.000100 | Loss: 1.3188 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 76.17
24-04-01 13:34:58.393 - INFO: Train epoch 323: [83200/94637 (88%)] Step: [1915746] | Lr: 0.000100 | Loss: 1.1994 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 77.55
24-04-01 13:35:28.148 - INFO: Train epoch 323: [84800/94637 (90%)] Step: [1915846] | Lr: 0.000100 | Loss: 1.5501 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 75.14
24-04-01 13:35:57.105 - INFO: Train epoch 323: [86400/94637 (91%)] Step: [1915946] | Lr: 0.000100 | Loss: 1.1491 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 76.75
24-04-01 13:36:26.351 - INFO: Train epoch 323: [88000/94637 (93%)] Step: [1916046] | Lr: 0.000100 | Loss: 1.1491 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 76.20
24-04-01 13:36:55.917 - INFO: Train epoch 323: [89600/94637 (95%)] Step: [1916146] | Lr: 0.000100 | Loss: 1.8155 | MSE loss: 0.0005 | Bpp loss: 1.06 | Aux loss: 71.83
24-04-01 13:37:25.205 - INFO: Train epoch 323: [91200/94637 (96%)] Step: [1916246] | Lr: 0.000100 | Loss: 1.9317 | MSE loss: 0.0006 | Bpp loss: 1.00 | Aux loss: 74.31
24-04-01 13:37:54.744 - INFO: Train epoch 323: [92800/94637 (98%)] Step: [1916346] | Lr: 0.000100 | Loss: 1.4774 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 78.76
24-04-01 13:38:24.145 - INFO: Train epoch 323: [94400/94637 (100%)] Step: [1916446] | Lr: 0.000100 | Loss: 1.2259 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 78.88
24-04-01 13:38:44.845 - INFO: Learning rate: 0.0001
24-04-01 13:38:45.735 - INFO: Train epoch 324: [    0/94637 (0%)] Step: [1916461] | Lr: 0.000100 | Loss: 1.0098 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 74.67
24-04-01 13:39:14.384 - INFO: Train epoch 324: [ 1600/94637 (2%)] Step: [1916561] | Lr: 0.000100 | Loss: 1.0332 | MSE loss: 0.0003 | Bpp loss: 0.59 | Aux loss: 73.39
24-04-01 13:39:42.769 - INFO: Train epoch 324: [ 3200/94637 (3%)] Step: [1916661] | Lr: 0.000100 | Loss: 0.9058 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 77.34
24-04-01 13:40:11.950 - INFO: Train epoch 324: [ 4800/94637 (5%)] Step: [1916761] | Lr: 0.000100 | Loss: 1.2462 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 74.88
24-04-01 13:40:40.285 - INFO: Train epoch 324: [ 6400/94637 (7%)] Step: [1916861] | Lr: 0.000100 | Loss: 0.7848 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 81.32
24-04-01 13:41:08.887 - INFO: Train epoch 324: [ 8000/94637 (8%)] Step: [1916961] | Lr: 0.000100 | Loss: 1.3398 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 79.88
24-04-01 13:41:37.566 - INFO: Train epoch 324: [ 9600/94637 (10%)] Step: [1917061] | Lr: 0.000100 | Loss: 1.2186 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 75.10
24-04-01 13:42:06.064 - INFO: Train epoch 324: [11200/94637 (12%)] Step: [1917161] | Lr: 0.000100 | Loss: 1.2361 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 81.99
24-04-01 13:42:34.740 - INFO: Train epoch 324: [12800/94637 (14%)] Step: [1917261] | Lr: 0.000100 | Loss: 1.4316 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 80.45
24-04-01 13:43:03.297 - INFO: Train epoch 324: [14400/94637 (15%)] Step: [1917361] | Lr: 0.000100 | Loss: 2.0082 | MSE loss: 0.0005 | Bpp loss: 1.12 | Aux loss: 73.18
24-04-01 13:43:31.750 - INFO: Train epoch 324: [16000/94637 (17%)] Step: [1917461] | Lr: 0.000100 | Loss: 1.2902 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 77.09
24-04-01 13:44:01.670 - INFO: Train epoch 324: [17600/94637 (19%)] Step: [1917561] | Lr: 0.000100 | Loss: 0.8554 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 81.96
24-04-01 13:44:29.907 - INFO: Train epoch 324: [19200/94637 (20%)] Step: [1917661] | Lr: 0.000100 | Loss: 1.4712 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 74.68
24-04-01 13:44:58.694 - INFO: Train epoch 324: [20800/94637 (22%)] Step: [1917761] | Lr: 0.000100 | Loss: 1.5323 | MSE loss: 0.0005 | Bpp loss: 0.69 | Aux loss: 86.05
24-04-01 13:45:27.124 - INFO: Train epoch 324: [22400/94637 (24%)] Step: [1917861] | Lr: 0.000100 | Loss: 0.8440 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 80.87
24-04-01 13:45:56.215 - INFO: Train epoch 324: [24000/94637 (25%)] Step: [1917961] | Lr: 0.000100 | Loss: 1.3395 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 83.10
24-04-01 13:46:25.041 - INFO: Train epoch 324: [25600/94637 (27%)] Step: [1918061] | Lr: 0.000100 | Loss: 1.5489 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 77.47
24-04-01 13:46:53.583 - INFO: Train epoch 324: [27200/94637 (29%)] Step: [1918161] | Lr: 0.000100 | Loss: 1.7181 | MSE loss: 0.0004 | Bpp loss: 1.05 | Aux loss: 80.00
24-04-01 13:47:22.952 - INFO: Train epoch 324: [28800/94637 (30%)] Step: [1918261] | Lr: 0.000100 | Loss: 1.9990 | MSE loss: 0.0005 | Bpp loss: 1.18 | Aux loss: 78.67
24-04-01 13:47:51.940 - INFO: Train epoch 324: [30400/94637 (32%)] Step: [1918361] | Lr: 0.000100 | Loss: 1.3324 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 77.40
24-04-01 13:48:20.819 - INFO: Train epoch 324: [32000/94637 (34%)] Step: [1918461] | Lr: 0.000100 | Loss: 1.7263 | MSE loss: 0.0004 | Bpp loss: 1.11 | Aux loss: 74.31
24-04-01 13:48:50.335 - INFO: Train epoch 324: [33600/94637 (36%)] Step: [1918561] | Lr: 0.000100 | Loss: 1.2715 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 81.66
24-04-01 13:49:18.552 - INFO: Train epoch 324: [35200/94637 (37%)] Step: [1918661] | Lr: 0.000100 | Loss: 0.9029 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 77.87
24-04-01 13:49:47.204 - INFO: Train epoch 324: [36800/94637 (39%)] Step: [1918761] | Lr: 0.000100 | Loss: 1.0763 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 82.81
24-04-01 13:50:15.305 - INFO: Train epoch 324: [38400/94637 (41%)] Step: [1918861] | Lr: 0.000100 | Loss: 1.0788 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 72.30
24-04-01 13:50:43.515 - INFO: Train epoch 324: [40000/94637 (42%)] Step: [1918961] | Lr: 0.000100 | Loss: 1.3553 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 80.32
24-04-01 13:51:12.422 - INFO: Train epoch 324: [41600/94637 (44%)] Step: [1919061] | Lr: 0.000100 | Loss: 0.7839 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 77.38
24-04-01 13:51:40.792 - INFO: Train epoch 324: [43200/94637 (46%)] Step: [1919161] | Lr: 0.000100 | Loss: 1.4350 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 76.14
24-04-01 13:52:09.226 - INFO: Train epoch 324: [44800/94637 (47%)] Step: [1919261] | Lr: 0.000100 | Loss: 1.0199 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 78.30
24-04-01 13:52:37.367 - INFO: Train epoch 324: [46400/94637 (49%)] Step: [1919361] | Lr: 0.000100 | Loss: 0.9496 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 84.14
24-04-01 13:53:05.785 - INFO: Train epoch 324: [48000/94637 (51%)] Step: [1919461] | Lr: 0.000100 | Loss: 1.0065 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 78.83
24-04-01 13:53:33.984 - INFO: Train epoch 324: [49600/94637 (52%)] Step: [1919561] | Lr: 0.000100 | Loss: 1.7279 | MSE loss: 0.0005 | Bpp loss: 0.92 | Aux loss: 85.74
24-04-01 13:54:02.322 - INFO: Train epoch 324: [51200/94637 (54%)] Step: [1919661] | Lr: 0.000100 | Loss: 1.1999 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 78.89
24-04-01 13:54:30.966 - INFO: Train epoch 324: [52800/94637 (56%)] Step: [1919761] | Lr: 0.000100 | Loss: 0.9258 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 81.03
24-04-01 13:54:59.745 - INFO: Train epoch 324: [54400/94637 (57%)] Step: [1919861] | Lr: 0.000100 | Loss: 1.2269 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 92.01
24-04-01 13:55:28.715 - INFO: Train epoch 324: [56000/94637 (59%)] Step: [1919961] | Lr: 0.000100 | Loss: 1.2511 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 81.04
24-04-01 13:55:59.600 - INFO: Train epoch 324: [57600/94637 (61%)] Step: [1920061] | Lr: 0.000100 | Loss: 1.3196 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 75.08
24-04-01 13:56:28.742 - INFO: Train epoch 324: [59200/94637 (63%)] Step: [1920161] | Lr: 0.000100 | Loss: 1.3109 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 72.75
24-04-01 13:56:57.473 - INFO: Train epoch 324: [60800/94637 (64%)] Step: [1920261] | Lr: 0.000100 | Loss: 0.9756 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 77.26
24-04-01 13:57:26.081 - INFO: Train epoch 324: [62400/94637 (66%)] Step: [1920361] | Lr: 0.000100 | Loss: 1.1965 | MSE loss: 0.0002 | Bpp loss: 0.79 | Aux loss: 73.70
24-04-01 13:57:54.404 - INFO: Train epoch 324: [64000/94637 (68%)] Step: [1920461] | Lr: 0.000100 | Loss: 0.9407 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 80.04
24-04-01 13:58:22.656 - INFO: Train epoch 324: [65600/94637 (69%)] Step: [1920561] | Lr: 0.000100 | Loss: 1.7555 | MSE loss: 0.0004 | Bpp loss: 1.09 | Aux loss: 80.16
24-04-01 13:58:51.179 - INFO: Train epoch 324: [67200/94637 (71%)] Step: [1920661] | Lr: 0.000100 | Loss: 1.0953 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 74.66
24-04-01 13:59:20.206 - INFO: Train epoch 324: [68800/94637 (73%)] Step: [1920761] | Lr: 0.000100 | Loss: 1.3998 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 75.83
24-04-01 13:59:48.507 - INFO: Train epoch 324: [70400/94637 (74%)] Step: [1920861] | Lr: 0.000100 | Loss: 0.7631 | MSE loss: 0.0002 | Bpp loss: 0.47 | Aux loss: 80.27
24-04-01 14:00:16.825 - INFO: Train epoch 324: [72000/94637 (76%)] Step: [1920961] | Lr: 0.000100 | Loss: 1.0959 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 74.11
24-04-01 14:00:44.966 - INFO: Train epoch 324: [73600/94637 (78%)] Step: [1921061] | Lr: 0.000100 | Loss: 1.2595 | MSE loss: 0.0004 | Bpp loss: 0.63 | Aux loss: 70.96
24-04-01 14:01:13.347 - INFO: Train epoch 324: [75200/94637 (79%)] Step: [1921161] | Lr: 0.000100 | Loss: 1.3383 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 76.28
24-04-01 14:01:41.631 - INFO: Train epoch 324: [76800/94637 (81%)] Step: [1921261] | Lr: 0.000100 | Loss: 2.1595 | MSE loss: 0.0005 | Bpp loss: 1.40 | Aux loss: 73.52
24-04-01 14:02:09.723 - INFO: Train epoch 324: [78400/94637 (83%)] Step: [1921361] | Lr: 0.000100 | Loss: 0.8049 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 74.76
24-04-01 14:02:38.252 - INFO: Train epoch 324: [80000/94637 (85%)] Step: [1921461] | Lr: 0.000100 | Loss: 1.4968 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 76.85
24-04-01 14:03:06.646 - INFO: Train epoch 324: [81600/94637 (86%)] Step: [1921561] | Lr: 0.000100 | Loss: 1.4050 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 76.50
24-04-01 14:03:35.337 - INFO: Train epoch 324: [83200/94637 (88%)] Step: [1921661] | Lr: 0.000100 | Loss: 1.0240 | MSE loss: 0.0003 | Bpp loss: 0.61 | Aux loss: 80.43
24-04-01 14:04:04.272 - INFO: Train epoch 324: [84800/94637 (90%)] Step: [1921761] | Lr: 0.000100 | Loss: 1.4272 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 82.55
24-04-01 14:04:32.760 - INFO: Train epoch 324: [86400/94637 (91%)] Step: [1921861] | Lr: 0.000100 | Loss: 1.4486 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 76.50
24-04-01 14:05:01.436 - INFO: Train epoch 324: [88000/94637 (93%)] Step: [1921961] | Lr: 0.000100 | Loss: 1.1122 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 76.78
24-04-01 14:05:29.907 - INFO: Train epoch 324: [89600/94637 (95%)] Step: [1922061] | Lr: 0.000100 | Loss: 2.3725 | MSE loss: 0.0006 | Bpp loss: 1.39 | Aux loss: 79.37
24-04-01 14:05:58.690 - INFO: Train epoch 324: [91200/94637 (96%)] Step: [1922161] | Lr: 0.000100 | Loss: 1.2637 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 78.08
24-04-01 14:06:28.073 - INFO: Train epoch 324: [92800/94637 (98%)] Step: [1922261] | Lr: 0.000100 | Loss: 0.9209 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 77.20
24-04-01 14:06:57.143 - INFO: Train epoch 324: [94400/94637 (100%)] Step: [1922361] | Lr: 0.000100 | Loss: 0.8641 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 79.44
24-04-01 14:07:18.108 - INFO: Learning rate: 0.0001
24-04-01 14:07:18.862 - INFO: Train epoch 325: [    0/94637 (0%)] Step: [1922376] | Lr: 0.000100 | Loss: 1.5668 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 74.91
24-04-01 14:07:48.539 - INFO: Train epoch 325: [ 1600/94637 (2%)] Step: [1922476] | Lr: 0.000100 | Loss: 1.2507 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 81.81
24-04-01 14:08:20.302 - INFO: Train epoch 325: [ 3200/94637 (3%)] Step: [1922576] | Lr: 0.000100 | Loss: 1.7157 | MSE loss: 0.0004 | Bpp loss: 1.07 | Aux loss: 75.02
24-04-01 14:08:49.230 - INFO: Train epoch 325: [ 4800/94637 (5%)] Step: [1922676] | Lr: 0.000100 | Loss: 1.2100 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 79.11
24-04-01 14:09:18.878 - INFO: Train epoch 325: [ 6400/94637 (7%)] Step: [1922776] | Lr: 0.000100 | Loss: 0.8345 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 82.96
24-04-01 14:09:47.903 - INFO: Train epoch 325: [ 8000/94637 (8%)] Step: [1922876] | Lr: 0.000100 | Loss: 1.9020 | MSE loss: 0.0005 | Bpp loss: 1.16 | Aux loss: 80.09
24-04-01 14:10:16.986 - INFO: Train epoch 325: [ 9600/94637 (10%)] Step: [1922976] | Lr: 0.000100 | Loss: 0.8440 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 84.91
24-04-01 14:10:45.991 - INFO: Train epoch 325: [11200/94637 (12%)] Step: [1923076] | Lr: 0.000100 | Loss: 1.1393 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 78.18
24-04-01 14:11:15.205 - INFO: Train epoch 325: [12800/94637 (14%)] Step: [1923176] | Lr: 0.000100 | Loss: 1.6915 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 77.15
24-04-01 14:11:45.040 - INFO: Train epoch 325: [14400/94637 (15%)] Step: [1923276] | Lr: 0.000100 | Loss: 1.4348 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 83.42
24-04-01 14:12:14.452 - INFO: Train epoch 325: [16000/94637 (17%)] Step: [1923376] | Lr: 0.000100 | Loss: 1.6164 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 72.67
24-04-01 14:12:43.664 - INFO: Train epoch 325: [17600/94637 (19%)] Step: [1923476] | Lr: 0.000100 | Loss: 1.1414 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 78.86
24-04-01 14:13:13.431 - INFO: Train epoch 325: [19200/94637 (20%)] Step: [1923576] | Lr: 0.000100 | Loss: 1.4004 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 81.78
24-04-01 14:13:42.832 - INFO: Train epoch 325: [20800/94637 (22%)] Step: [1923676] | Lr: 0.000100 | Loss: 1.2494 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 80.76
24-04-01 14:14:12.281 - INFO: Train epoch 325: [22400/94637 (24%)] Step: [1923776] | Lr: 0.000100 | Loss: 1.1230 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 80.79
24-04-01 14:14:41.495 - INFO: Train epoch 325: [24000/94637 (25%)] Step: [1923876] | Lr: 0.000100 | Loss: 1.4538 | MSE loss: 0.0004 | Bpp loss: 0.82 | Aux loss: 84.43
24-04-01 14:15:11.080 - INFO: Train epoch 325: [25600/94637 (27%)] Step: [1923976] | Lr: 0.000100 | Loss: 1.3333 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 76.97
24-04-01 14:15:40.397 - INFO: Train epoch 325: [27200/94637 (29%)] Step: [1924076] | Lr: 0.000100 | Loss: 1.2523 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 79.34
24-04-01 14:16:09.903 - INFO: Train epoch 325: [28800/94637 (30%)] Step: [1924176] | Lr: 0.000100 | Loss: 0.8202 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 80.33
24-04-01 14:16:39.393 - INFO: Train epoch 325: [30400/94637 (32%)] Step: [1924276] | Lr: 0.000100 | Loss: 1.0947 | MSE loss: 0.0003 | Bpp loss: 0.62 | Aux loss: 74.76
24-04-01 14:17:08.644 - INFO: Train epoch 325: [32000/94637 (34%)] Step: [1924376] | Lr: 0.000100 | Loss: 1.3621 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 74.88
24-04-01 14:17:37.885 - INFO: Train epoch 325: [33600/94637 (36%)] Step: [1924476] | Lr: 0.000100 | Loss: 1.4665 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 79.02
24-04-01 14:18:07.146 - INFO: Train epoch 325: [35200/94637 (37%)] Step: [1924576] | Lr: 0.000100 | Loss: 1.2887 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 84.77
24-04-01 14:18:36.192 - INFO: Train epoch 325: [36800/94637 (39%)] Step: [1924676] | Lr: 0.000100 | Loss: 0.8714 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 85.15
24-04-01 14:19:05.317 - INFO: Train epoch 325: [38400/94637 (41%)] Step: [1924776] | Lr: 0.000100 | Loss: 1.0392 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 79.90
24-04-01 14:19:34.977 - INFO: Train epoch 325: [40000/94637 (42%)] Step: [1924876] | Lr: 0.000100 | Loss: 1.1767 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 82.53
24-04-01 14:20:04.053 - INFO: Train epoch 325: [41600/94637 (44%)] Step: [1924976] | Lr: 0.000100 | Loss: 1.4519 | MSE loss: 0.0004 | Bpp loss: 0.88 | Aux loss: 83.20
24-04-01 14:20:34.077 - INFO: Train epoch 325: [43200/94637 (46%)] Step: [1925076] | Lr: 0.000100 | Loss: 1.6103 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 82.27
24-04-01 14:21:02.896 - INFO: Train epoch 325: [44800/94637 (47%)] Step: [1925176] | Lr: 0.000100 | Loss: 1.0624 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 83.65
24-04-01 14:21:32.024 - INFO: Train epoch 325: [46400/94637 (49%)] Step: [1925276] | Lr: 0.000100 | Loss: 1.1220 | MSE loss: 0.0003 | Bpp loss: 0.62 | Aux loss: 81.43
24-04-01 14:22:00.505 - INFO: Train epoch 325: [48000/94637 (51%)] Step: [1925376] | Lr: 0.000100 | Loss: 1.4361 | MSE loss: 0.0004 | Bpp loss: 0.79 | Aux loss: 80.28
24-04-01 14:22:29.675 - INFO: Train epoch 325: [49600/94637 (52%)] Step: [1925476] | Lr: 0.000100 | Loss: 1.1581 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 79.96
24-04-01 14:22:58.730 - INFO: Train epoch 325: [51200/94637 (54%)] Step: [1925576] | Lr: 0.000100 | Loss: 0.9954 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 81.89
24-04-01 14:23:28.147 - INFO: Train epoch 325: [52800/94637 (56%)] Step: [1925676] | Lr: 0.000100 | Loss: 1.2305 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 82.13
24-04-01 14:23:58.078 - INFO: Train epoch 325: [54400/94637 (57%)] Step: [1925776] | Lr: 0.000100 | Loss: 1.2654 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 83.16
24-04-01 14:24:27.537 - INFO: Train epoch 325: [56000/94637 (59%)] Step: [1925876] | Lr: 0.000100 | Loss: 1.4125 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 78.45
24-04-01 14:24:56.374 - INFO: Train epoch 325: [57600/94637 (61%)] Step: [1925976] | Lr: 0.000100 | Loss: 0.9851 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 82.41
24-04-01 14:25:25.765 - INFO: Train epoch 325: [59200/94637 (63%)] Step: [1926076] | Lr: 0.000100 | Loss: 1.6009 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 79.90
24-04-01 14:25:55.427 - INFO: Train epoch 325: [60800/94637 (64%)] Step: [1926176] | Lr: 0.000100 | Loss: 1.3008 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 79.92
24-04-01 14:26:24.788 - INFO: Train epoch 325: [62400/94637 (66%)] Step: [1926276] | Lr: 0.000100 | Loss: 1.6715 | MSE loss: 0.0004 | Bpp loss: 1.03 | Aux loss: 80.45
24-04-01 14:26:54.580 - INFO: Train epoch 325: [64000/94637 (68%)] Step: [1926376] | Lr: 0.000100 | Loss: 1.5397 | MSE loss: 0.0003 | Bpp loss: 0.99 | Aux loss: 85.02
24-04-01 14:27:24.369 - INFO: Train epoch 325: [65600/94637 (69%)] Step: [1926476] | Lr: 0.000100 | Loss: 1.4427 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 85.55
24-04-01 14:27:54.143 - INFO: Train epoch 325: [67200/94637 (71%)] Step: [1926576] | Lr: 0.000100 | Loss: 1.0105 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 86.24
24-04-01 14:28:23.719 - INFO: Train epoch 325: [68800/94637 (73%)] Step: [1926676] | Lr: 0.000100 | Loss: 0.7996 | MSE loss: 0.0002 | Bpp loss: 0.48 | Aux loss: 75.47
24-04-01 14:28:53.750 - INFO: Train epoch 325: [70400/94637 (74%)] Step: [1926776] | Lr: 0.000100 | Loss: 1.9599 | MSE loss: 0.0005 | Bpp loss: 1.22 | Aux loss: 78.82
24-04-01 14:29:23.049 - INFO: Train epoch 325: [72000/94637 (76%)] Step: [1926876] | Lr: 0.000100 | Loss: 1.5396 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 79.25
24-04-01 14:29:53.222 - INFO: Train epoch 325: [73600/94637 (78%)] Step: [1926976] | Lr: 0.000100 | Loss: 0.9473 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 72.69
24-04-01 14:30:23.190 - INFO: Train epoch 325: [75200/94637 (79%)] Step: [1927076] | Lr: 0.000100 | Loss: 0.7695 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 77.21
24-04-01 14:30:52.847 - INFO: Train epoch 325: [76800/94637 (81%)] Step: [1927176] | Lr: 0.000100 | Loss: 1.5109 | MSE loss: 0.0004 | Bpp loss: 0.93 | Aux loss: 80.23
24-04-01 14:31:22.060 - INFO: Train epoch 325: [78400/94637 (83%)] Step: [1927276] | Lr: 0.000100 | Loss: 1.4232 | MSE loss: 0.0004 | Bpp loss: 0.82 | Aux loss: 75.97
24-04-01 14:31:51.339 - INFO: Train epoch 325: [80000/94637 (85%)] Step: [1927376] | Lr: 0.000100 | Loss: 1.5452 | MSE loss: 0.0003 | Bpp loss: 0.99 | Aux loss: 75.84
24-04-01 14:32:20.194 - INFO: Train epoch 325: [81600/94637 (86%)] Step: [1927476] | Lr: 0.000100 | Loss: 1.2496 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 79.39
24-04-01 14:32:50.916 - INFO: Train epoch 325: [83200/94637 (88%)] Step: [1927576] | Lr: 0.000100 | Loss: 1.0374 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 76.86
24-04-01 14:33:19.944 - INFO: Train epoch 325: [84800/94637 (90%)] Step: [1927676] | Lr: 0.000100 | Loss: 1.1761 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 80.60
24-04-01 14:33:49.381 - INFO: Train epoch 325: [86400/94637 (91%)] Step: [1927776] | Lr: 0.000100 | Loss: 1.4647 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 77.84
24-04-01 14:34:18.293 - INFO: Train epoch 325: [88000/94637 (93%)] Step: [1927876] | Lr: 0.000100 | Loss: 1.0352 | MSE loss: 0.0003 | Bpp loss: 0.57 | Aux loss: 77.71
24-04-01 14:34:47.079 - INFO: Train epoch 325: [89600/94637 (95%)] Step: [1927976] | Lr: 0.000100 | Loss: 0.7333 | MSE loss: 0.0002 | Bpp loss: 0.45 | Aux loss: 77.72
24-04-01 14:35:15.888 - INFO: Train epoch 325: [91200/94637 (96%)] Step: [1928076] | Lr: 0.000100 | Loss: 1.7174 | MSE loss: 0.0004 | Bpp loss: 1.05 | Aux loss: 75.73
24-04-01 14:35:44.949 - INFO: Train epoch 325: [92800/94637 (98%)] Step: [1928176] | Lr: 0.000100 | Loss: 1.3967 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 81.31
24-04-01 14:36:14.236 - INFO: Train epoch 325: [94400/94637 (100%)] Step: [1928276] | Lr: 0.000100 | Loss: 0.9084 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 76.75
24-04-01 14:36:29.872 - INFO: Learning rate: 0.0001
24-04-01 14:36:30.645 - INFO: Train epoch 326: [    0/94637 (0%)] Step: [1928291] | Lr: 0.000100 | Loss: 1.3227 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 78.84
24-04-01 14:36:59.491 - INFO: Train epoch 326: [ 1600/94637 (2%)] Step: [1928391] | Lr: 0.000100 | Loss: 1.5546 | MSE loss: 0.0003 | Bpp loss: 1.01 | Aux loss: 81.26
24-04-01 14:37:28.516 - INFO: Train epoch 326: [ 3200/94637 (3%)] Step: [1928491] | Lr: 0.000100 | Loss: 1.4387 | MSE loss: 0.0004 | Bpp loss: 0.85 | Aux loss: 78.47
24-04-01 14:37:56.923 - INFO: Train epoch 326: [ 4800/94637 (5%)] Step: [1928591] | Lr: 0.000100 | Loss: 1.0404 | MSE loss: 0.0003 | Bpp loss: 0.62 | Aux loss: 83.42
24-04-01 14:38:25.410 - INFO: Train epoch 326: [ 6400/94637 (7%)] Step: [1928691] | Lr: 0.000100 | Loss: 1.2572 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 79.84
24-04-01 14:38:54.166 - INFO: Train epoch 326: [ 8000/94637 (8%)] Step: [1928791] | Lr: 0.000100 | Loss: 1.3074 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 79.89
24-04-01 14:39:22.765 - INFO: Train epoch 326: [ 9600/94637 (10%)] Step: [1928891] | Lr: 0.000100 | Loss: 0.8138 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 81.46
24-04-01 14:39:51.279 - INFO: Train epoch 326: [11200/94637 (12%)] Step: [1928991] | Lr: 0.000100 | Loss: 1.2384 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 79.89
24-04-01 14:40:20.224 - INFO: Train epoch 326: [12800/94637 (14%)] Step: [1929091] | Lr: 0.000100 | Loss: 0.9191 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 79.11
24-04-01 14:40:48.821 - INFO: Train epoch 326: [14400/94637 (15%)] Step: [1929191] | Lr: 0.000100 | Loss: 1.5732 | MSE loss: 0.0004 | Bpp loss: 0.99 | Aux loss: 86.63
24-04-01 14:41:17.317 - INFO: Train epoch 326: [16000/94637 (17%)] Step: [1929291] | Lr: 0.000100 | Loss: 1.4565 | MSE loss: 0.0004 | Bpp loss: 0.77 | Aux loss: 81.38
24-04-01 14:41:46.262 - INFO: Train epoch 326: [17600/94637 (19%)] Step: [1929391] | Lr: 0.000100 | Loss: 1.5287 | MSE loss: 0.0004 | Bpp loss: 0.93 | Aux loss: 78.34
24-04-01 14:42:15.234 - INFO: Train epoch 326: [19200/94637 (20%)] Step: [1929491] | Lr: 0.000100 | Loss: 0.9409 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 81.68
24-04-01 14:42:44.186 - INFO: Train epoch 326: [20800/94637 (22%)] Step: [1929591] | Lr: 0.000100 | Loss: 0.6636 | MSE loss: 0.0001 | Bpp loss: 0.45 | Aux loss: 76.47
24-04-01 14:43:12.967 - INFO: Train epoch 326: [22400/94637 (24%)] Step: [1929691] | Lr: 0.000100 | Loss: 0.9333 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 78.14
24-04-01 14:43:41.502 - INFO: Train epoch 326: [24000/94637 (25%)] Step: [1929791] | Lr: 0.000100 | Loss: 1.2665 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 81.32
24-04-01 14:44:10.392 - INFO: Train epoch 326: [25600/94637 (27%)] Step: [1929891] | Lr: 0.000100 | Loss: 1.1215 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 82.23
24-04-01 14:44:39.139 - INFO: Train epoch 326: [27200/94637 (29%)] Step: [1929991] | Lr: 0.000100 | Loss: 1.3951 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 82.34
24-04-01 14:45:10.947 - INFO: Train epoch 326: [28800/94637 (30%)] Step: [1930091] | Lr: 0.000100 | Loss: 1.4415 | MSE loss: 0.0003 | Bpp loss: 0.97 | Aux loss: 80.64
24-04-01 14:45:40.688 - INFO: Train epoch 326: [30400/94637 (32%)] Step: [1930191] | Lr: 0.000100 | Loss: 1.4800 | MSE loss: 0.0004 | Bpp loss: 0.88 | Aux loss: 78.85
24-04-01 14:46:10.472 - INFO: Train epoch 326: [32000/94637 (34%)] Step: [1930291] | Lr: 0.000100 | Loss: 1.3110 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 83.74
24-04-01 14:46:39.881 - INFO: Train epoch 326: [33600/94637 (36%)] Step: [1930391] | Lr: 0.000100 | Loss: 0.8433 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 80.22
24-04-01 14:47:09.690 - INFO: Train epoch 326: [35200/94637 (37%)] Step: [1930491] | Lr: 0.000100 | Loss: 1.2196 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 85.69
24-04-01 14:47:38.907 - INFO: Train epoch 326: [36800/94637 (39%)] Step: [1930591] | Lr: 0.000100 | Loss: 0.7049 | MSE loss: 0.0002 | Bpp loss: 0.44 | Aux loss: 80.86
24-04-01 14:48:07.740 - INFO: Train epoch 326: [38400/94637 (41%)] Step: [1930691] | Lr: 0.000100 | Loss: 1.4156 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 79.69
24-04-01 14:48:37.207 - INFO: Train epoch 326: [40000/94637 (42%)] Step: [1930791] | Lr: 0.000100 | Loss: 0.7252 | MSE loss: 0.0002 | Bpp loss: 0.47 | Aux loss: 72.44
24-04-01 14:49:06.184 - INFO: Train epoch 326: [41600/94637 (44%)] Step: [1930891] | Lr: 0.000100 | Loss: 0.9894 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 83.59
24-04-01 14:49:34.940 - INFO: Train epoch 326: [43200/94637 (46%)] Step: [1930991] | Lr: 0.000100 | Loss: 1.1757 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 86.24
24-04-01 14:50:03.677 - INFO: Train epoch 326: [44800/94637 (47%)] Step: [1931091] | Lr: 0.000100 | Loss: 0.7804 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 81.21
24-04-01 14:50:32.656 - INFO: Train epoch 326: [46400/94637 (49%)] Step: [1931191] | Lr: 0.000100 | Loss: 1.4064 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 81.86
24-04-01 14:51:01.677 - INFO: Train epoch 326: [48000/94637 (51%)] Step: [1931291] | Lr: 0.000100 | Loss: 1.4102 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 84.14
24-04-01 14:51:30.231 - INFO: Train epoch 326: [49600/94637 (52%)] Step: [1931391] | Lr: 0.000100 | Loss: 1.2027 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 82.01
24-04-01 14:51:58.972 - INFO: Train epoch 326: [51200/94637 (54%)] Step: [1931491] | Lr: 0.000100 | Loss: 1.4002 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 79.83
24-04-01 14:52:27.690 - INFO: Train epoch 326: [52800/94637 (56%)] Step: [1931591] | Lr: 0.000100 | Loss: 1.3751 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 82.81
24-04-01 14:52:56.823 - INFO: Train epoch 326: [54400/94637 (57%)] Step: [1931691] | Lr: 0.000100 | Loss: 1.9667 | MSE loss: 0.0005 | Bpp loss: 1.12 | Aux loss: 81.28
24-04-01 14:53:26.235 - INFO: Train epoch 326: [56000/94637 (59%)] Step: [1931791] | Lr: 0.000100 | Loss: 1.6662 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 82.47
24-04-01 14:53:55.438 - INFO: Train epoch 326: [57600/94637 (61%)] Step: [1931891] | Lr: 0.000100 | Loss: 1.1267 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 84.37
24-04-01 14:54:24.402 - INFO: Train epoch 326: [59200/94637 (63%)] Step: [1931991] | Lr: 0.000100 | Loss: 1.1597 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 86.86
24-04-01 14:54:53.616 - INFO: Train epoch 326: [60800/94637 (64%)] Step: [1932091] | Lr: 0.000100 | Loss: 1.7796 | MSE loss: 0.0004 | Bpp loss: 1.06 | Aux loss: 85.28
24-04-01 14:55:22.960 - INFO: Train epoch 326: [62400/94637 (66%)] Step: [1932191] | Lr: 0.000100 | Loss: 1.3326 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 90.09
24-04-01 14:55:51.677 - INFO: Train epoch 326: [64000/94637 (68%)] Step: [1932291] | Lr: 0.000100 | Loss: 1.1653 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 80.93
24-04-01 14:56:20.989 - INFO: Train epoch 326: [65600/94637 (69%)] Step: [1932391] | Lr: 0.000100 | Loss: 1.9115 | MSE loss: 0.0005 | Bpp loss: 1.16 | Aux loss: 78.27
24-04-01 14:56:49.808 - INFO: Train epoch 326: [67200/94637 (71%)] Step: [1932491] | Lr: 0.000100 | Loss: 0.8398 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 78.32
24-04-01 14:57:20.549 - INFO: Train epoch 326: [68800/94637 (73%)] Step: [1932591] | Lr: 0.000100 | Loss: 1.2246 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 78.79
24-04-01 14:57:49.628 - INFO: Train epoch 326: [70400/94637 (74%)] Step: [1932691] | Lr: 0.000100 | Loss: 1.1542 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 80.27
24-04-01 14:58:19.175 - INFO: Train epoch 326: [72000/94637 (76%)] Step: [1932791] | Lr: 0.000100 | Loss: 1.6484 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 78.21
24-04-01 14:58:48.955 - INFO: Train epoch 326: [73600/94637 (78%)] Step: [1932891] | Lr: 0.000100 | Loss: 1.6180 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 80.98
24-04-01 14:59:17.860 - INFO: Train epoch 326: [75200/94637 (79%)] Step: [1932991] | Lr: 0.000100 | Loss: 1.4722 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 80.66
24-04-01 14:59:46.680 - INFO: Train epoch 326: [76800/94637 (81%)] Step: [1933091] | Lr: 0.000100 | Loss: 1.3775 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 71.19
24-04-01 15:00:16.076 - INFO: Train epoch 326: [78400/94637 (83%)] Step: [1933191] | Lr: 0.000100 | Loss: 1.1740 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 81.62
24-04-01 15:00:46.167 - INFO: Train epoch 326: [80000/94637 (85%)] Step: [1933291] | Lr: 0.000100 | Loss: 0.7617 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 81.60
24-04-01 15:01:15.868 - INFO: Train epoch 326: [81600/94637 (86%)] Step: [1933391] | Lr: 0.000100 | Loss: 1.1878 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 76.98
24-04-01 15:01:45.577 - INFO: Train epoch 326: [83200/94637 (88%)] Step: [1933491] | Lr: 0.000100 | Loss: 1.1629 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 73.70
24-04-01 15:02:14.833 - INFO: Train epoch 326: [84800/94637 (90%)] Step: [1933591] | Lr: 0.000100 | Loss: 1.3335 | MSE loss: 0.0004 | Bpp loss: 0.75 | Aux loss: 77.60
24-04-01 15:02:43.950 - INFO: Train epoch 326: [86400/94637 (91%)] Step: [1933691] | Lr: 0.000100 | Loss: 1.5909 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 77.88
24-04-01 15:03:13.021 - INFO: Train epoch 326: [88000/94637 (93%)] Step: [1933791] | Lr: 0.000100 | Loss: 1.6180 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 81.85
24-04-01 15:03:42.625 - INFO: Train epoch 326: [89600/94637 (95%)] Step: [1933891] | Lr: 0.000100 | Loss: 1.4204 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 83.55
24-04-01 15:04:12.196 - INFO: Train epoch 326: [91200/94637 (96%)] Step: [1933991] | Lr: 0.000100 | Loss: 1.2694 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 78.87
24-04-01 15:04:41.379 - INFO: Train epoch 326: [92800/94637 (98%)] Step: [1934091] | Lr: 0.000100 | Loss: 1.2814 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 77.22
24-04-01 15:05:10.227 - INFO: Train epoch 326: [94400/94637 (100%)] Step: [1934191] | Lr: 0.000100 | Loss: 1.1106 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 82.98
24-04-01 15:05:25.543 - INFO: Learning rate: 0.0001
24-04-01 15:05:26.361 - INFO: Train epoch 327: [    0/94637 (0%)] Step: [1934206] | Lr: 0.000100 | Loss: 1.9089 | MSE loss: 0.0005 | Bpp loss: 1.07 | Aux loss: 80.01
24-04-01 15:05:54.913 - INFO: Train epoch 327: [ 1600/94637 (2%)] Step: [1934306] | Lr: 0.000100 | Loss: 2.1140 | MSE loss: 0.0005 | Bpp loss: 1.37 | Aux loss: 80.24
24-04-01 15:06:23.024 - INFO: Train epoch 327: [ 3200/94637 (3%)] Step: [1934406] | Lr: 0.000100 | Loss: 0.6713 | MSE loss: 0.0001 | Bpp loss: 0.43 | Aux loss: 84.54
24-04-01 15:06:51.636 - INFO: Train epoch 327: [ 4800/94637 (5%)] Step: [1934506] | Lr: 0.000100 | Loss: 1.0213 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 83.62
24-04-01 15:07:19.576 - INFO: Train epoch 327: [ 6400/94637 (7%)] Step: [1934606] | Lr: 0.000100 | Loss: 1.2260 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 79.27
24-04-01 15:07:47.743 - INFO: Train epoch 327: [ 8000/94637 (8%)] Step: [1934706] | Lr: 0.000100 | Loss: 1.4972 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 85.13
24-04-01 15:08:16.207 - INFO: Train epoch 327: [ 9600/94637 (10%)] Step: [1934806] | Lr: 0.000100 | Loss: 1.8743 | MSE loss: 0.0005 | Bpp loss: 1.08 | Aux loss: 90.36
24-04-01 15:08:45.107 - INFO: Train epoch 327: [11200/94637 (12%)] Step: [1934906] | Lr: 0.000100 | Loss: 0.8845 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 80.51
24-04-01 15:09:15.312 - INFO: Train epoch 327: [12800/94637 (14%)] Step: [1935006] | Lr: 0.000100 | Loss: 1.0401 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 79.58
24-04-01 15:09:43.902 - INFO: Train epoch 327: [14400/94637 (15%)] Step: [1935106] | Lr: 0.000100 | Loss: 1.2768 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 77.42
24-04-01 15:10:12.153 - INFO: Train epoch 327: [16000/94637 (17%)] Step: [1935206] | Lr: 0.000100 | Loss: 1.5663 | MSE loss: 0.0003 | Bpp loss: 1.00 | Aux loss: 79.20
24-04-01 15:10:40.957 - INFO: Train epoch 327: [17600/94637 (19%)] Step: [1935306] | Lr: 0.000100 | Loss: 1.9295 | MSE loss: 0.0004 | Bpp loss: 1.22 | Aux loss: 78.02
24-04-01 15:11:09.285 - INFO: Train epoch 327: [19200/94637 (20%)] Step: [1935406] | Lr: 0.000100 | Loss: 1.3430 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 79.61
24-04-01 15:11:38.037 - INFO: Train epoch 327: [20800/94637 (22%)] Step: [1935506] | Lr: 0.000100 | Loss: 1.4201 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 76.99
24-04-01 15:12:06.656 - INFO: Train epoch 327: [22400/94637 (24%)] Step: [1935606] | Lr: 0.000100 | Loss: 1.3409 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 82.98
24-04-01 15:12:34.958 - INFO: Train epoch 327: [24000/94637 (25%)] Step: [1935706] | Lr: 0.000100 | Loss: 0.8424 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 77.36
24-04-01 15:13:04.189 - INFO: Train epoch 327: [25600/94637 (27%)] Step: [1935806] | Lr: 0.000100 | Loss: 1.2276 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 78.54
24-04-01 15:13:33.592 - INFO: Train epoch 327: [27200/94637 (29%)] Step: [1935906] | Lr: 0.000100 | Loss: 0.8685 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 84.59
24-04-01 15:14:02.490 - INFO: Train epoch 327: [28800/94637 (30%)] Step: [1936006] | Lr: 0.000100 | Loss: 1.6692 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 87.39
24-04-01 15:14:30.860 - INFO: Train epoch 327: [30400/94637 (32%)] Step: [1936106] | Lr: 0.000100 | Loss: 1.0829 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 79.99
24-04-01 15:14:59.218 - INFO: Train epoch 327: [32000/94637 (34%)] Step: [1936206] | Lr: 0.000100 | Loss: 0.8756 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 80.83
24-04-01 15:15:27.460 - INFO: Train epoch 327: [33600/94637 (36%)] Step: [1936306] | Lr: 0.000100 | Loss: 1.0780 | MSE loss: 0.0003 | Bpp loss: 0.61 | Aux loss: 81.17
24-04-01 15:15:56.555 - INFO: Train epoch 327: [35200/94637 (37%)] Step: [1936406] | Lr: 0.000100 | Loss: 1.4285 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 79.42
24-04-01 15:16:25.291 - INFO: Train epoch 327: [36800/94637 (39%)] Step: [1936506] | Lr: 0.000100 | Loss: 0.9903 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 75.96
24-04-01 15:16:54.346 - INFO: Train epoch 327: [38400/94637 (41%)] Step: [1936606] | Lr: 0.000100 | Loss: 0.9969 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 76.77
24-04-01 15:17:23.309 - INFO: Train epoch 327: [40000/94637 (42%)] Step: [1936706] | Lr: 0.000100 | Loss: 1.0314 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 82.32
24-04-01 15:17:52.070 - INFO: Train epoch 327: [41600/94637 (44%)] Step: [1936806] | Lr: 0.000100 | Loss: 0.7895 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 87.28
24-04-01 15:18:21.476 - INFO: Train epoch 327: [43200/94637 (46%)] Step: [1936906] | Lr: 0.000100 | Loss: 1.0369 | MSE loss: 0.0003 | Bpp loss: 0.57 | Aux loss: 84.91
24-04-01 15:18:50.065 - INFO: Train epoch 327: [44800/94637 (47%)] Step: [1937006] | Lr: 0.000100 | Loss: 0.9445 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 84.05
24-04-01 15:19:18.916 - INFO: Train epoch 327: [46400/94637 (49%)] Step: [1937106] | Lr: 0.000100 | Loss: 1.3200 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 83.12
24-04-01 15:19:47.228 - INFO: Train epoch 327: [48000/94637 (51%)] Step: [1937206] | Lr: 0.000100 | Loss: 1.2968 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 84.25
24-04-01 15:20:16.299 - INFO: Train epoch 327: [49600/94637 (52%)] Step: [1937306] | Lr: 0.000100 | Loss: 0.7124 | MSE loss: 0.0001 | Bpp loss: 0.48 | Aux loss: 84.75
24-04-01 15:20:45.686 - INFO: Train epoch 327: [51200/94637 (54%)] Step: [1937406] | Lr: 0.000100 | Loss: 2.2891 | MSE loss: 0.0005 | Bpp loss: 1.41 | Aux loss: 87.87
24-04-01 15:21:16.029 - INFO: Train epoch 327: [52800/94637 (56%)] Step: [1937506] | Lr: 0.000100 | Loss: 1.1320 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 84.23
24-04-01 15:21:45.352 - INFO: Train epoch 327: [54400/94637 (57%)] Step: [1937606] | Lr: 0.000100 | Loss: 1.1677 | MSE loss: 0.0002 | Bpp loss: 0.76 | Aux loss: 81.03
24-04-01 15:22:14.973 - INFO: Train epoch 327: [56000/94637 (59%)] Step: [1937706] | Lr: 0.000100 | Loss: 1.1375 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 80.99
24-04-01 15:22:44.330 - INFO: Train epoch 327: [57600/94637 (61%)] Step: [1937806] | Lr: 0.000100 | Loss: 1.1198 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 79.96
24-04-01 15:23:13.506 - INFO: Train epoch 327: [59200/94637 (63%)] Step: [1937906] | Lr: 0.000100 | Loss: 0.8766 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 81.28
24-04-01 15:23:43.130 - INFO: Train epoch 327: [60800/94637 (64%)] Step: [1938006] | Lr: 0.000100 | Loss: 2.0723 | MSE loss: 0.0005 | Bpp loss: 1.26 | Aux loss: 77.52
24-04-01 15:24:11.992 - INFO: Train epoch 327: [62400/94637 (66%)] Step: [1938106] | Lr: 0.000100 | Loss: 1.1071 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 84.66
24-04-01 15:24:40.976 - INFO: Train epoch 327: [64000/94637 (68%)] Step: [1938206] | Lr: 0.000100 | Loss: 1.0573 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 80.50
24-04-01 15:25:09.821 - INFO: Train epoch 327: [65600/94637 (69%)] Step: [1938306] | Lr: 0.000100 | Loss: 0.9299 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 81.16
24-04-01 15:25:38.754 - INFO: Train epoch 327: [67200/94637 (71%)] Step: [1938406] | Lr: 0.000100 | Loss: 0.8632 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 78.60
24-04-01 15:26:08.022 - INFO: Train epoch 327: [68800/94637 (73%)] Step: [1938506] | Lr: 0.000100 | Loss: 1.0960 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 83.17
24-04-01 15:26:36.673 - INFO: Train epoch 327: [70400/94637 (74%)] Step: [1938606] | Lr: 0.000100 | Loss: 0.8549 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 84.97
24-04-01 15:27:05.787 - INFO: Train epoch 327: [72000/94637 (76%)] Step: [1938706] | Lr: 0.000100 | Loss: 1.8003 | MSE loss: 0.0005 | Bpp loss: 1.06 | Aux loss: 74.07
24-04-01 15:27:34.794 - INFO: Train epoch 327: [73600/94637 (78%)] Step: [1938806] | Lr: 0.000100 | Loss: 2.0994 | MSE loss: 0.0005 | Bpp loss: 1.22 | Aux loss: 84.29
24-04-01 15:28:04.117 - INFO: Train epoch 327: [75200/94637 (79%)] Step: [1938906] | Lr: 0.000100 | Loss: 0.9962 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 79.55
24-04-01 15:28:33.237 - INFO: Train epoch 327: [76800/94637 (81%)] Step: [1939006] | Lr: 0.000100 | Loss: 1.4296 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 79.18
24-04-01 15:29:02.190 - INFO: Train epoch 327: [78400/94637 (83%)] Step: [1939106] | Lr: 0.000100 | Loss: 1.4840 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 82.17
24-04-01 15:29:31.787 - INFO: Train epoch 327: [80000/94637 (85%)] Step: [1939206] | Lr: 0.000100 | Loss: 1.5727 | MSE loss: 0.0003 | Bpp loss: 1.03 | Aux loss: 84.52
24-04-01 15:30:00.334 - INFO: Train epoch 327: [81600/94637 (86%)] Step: [1939306] | Lr: 0.000100 | Loss: 1.8210 | MSE loss: 0.0004 | Bpp loss: 1.11 | Aux loss: 80.83
24-04-01 15:30:29.094 - INFO: Train epoch 327: [83200/94637 (88%)] Step: [1939406] | Lr: 0.000100 | Loss: 0.9921 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 81.56
24-04-01 15:30:57.885 - INFO: Train epoch 327: [84800/94637 (90%)] Step: [1939506] | Lr: 0.000100 | Loss: 1.3740 | MSE loss: 0.0004 | Bpp loss: 0.77 | Aux loss: 80.04
24-04-01 15:31:26.402 - INFO: Train epoch 327: [86400/94637 (91%)] Step: [1939606] | Lr: 0.000100 | Loss: 1.4493 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 80.27
24-04-01 15:31:55.890 - INFO: Train epoch 327: [88000/94637 (93%)] Step: [1939706] | Lr: 0.000100 | Loss: 1.1305 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 86.12
24-04-01 15:32:24.660 - INFO: Train epoch 327: [89600/94637 (95%)] Step: [1939806] | Lr: 0.000100 | Loss: 1.2102 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 79.08
24-04-01 15:32:53.800 - INFO: Train epoch 327: [91200/94637 (96%)] Step: [1939906] | Lr: 0.000100 | Loss: 1.1817 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 83.34
24-04-01 15:33:24.641 - INFO: Train epoch 327: [92800/94637 (98%)] Step: [1940006] | Lr: 0.000100 | Loss: 0.7150 | MSE loss: 0.0002 | Bpp loss: 0.43 | Aux loss: 77.11
24-04-01 15:33:53.891 - INFO: Train epoch 327: [94400/94637 (100%)] Step: [1940106] | Lr: 0.000100 | Loss: 1.3325 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 83.12
24-04-01 15:34:09.537 - INFO: Learning rate: 0.0001
24-04-01 15:34:10.291 - INFO: Train epoch 328: [    0/94637 (0%)] Step: [1940121] | Lr: 0.000100 | Loss: 1.1785 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 82.55
24-04-01 15:34:38.992 - INFO: Train epoch 328: [ 1600/94637 (2%)] Step: [1940221] | Lr: 0.000100 | Loss: 1.4076 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 82.06
24-04-01 15:35:07.926 - INFO: Train epoch 328: [ 3200/94637 (3%)] Step: [1940321] | Lr: 0.000100 | Loss: 1.3891 | MSE loss: 0.0004 | Bpp loss: 0.78 | Aux loss: 79.39
24-04-01 15:35:36.304 - INFO: Train epoch 328: [ 4800/94637 (5%)] Step: [1940421] | Lr: 0.000100 | Loss: 1.3934 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 85.50
24-04-01 15:36:05.399 - INFO: Train epoch 328: [ 6400/94637 (7%)] Step: [1940521] | Lr: 0.000100 | Loss: 1.2012 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 83.01
24-04-01 15:36:33.794 - INFO: Train epoch 328: [ 8000/94637 (8%)] Step: [1940621] | Lr: 0.000100 | Loss: 1.0225 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 90.32
24-04-01 15:37:02.657 - INFO: Train epoch 328: [ 9600/94637 (10%)] Step: [1940721] | Lr: 0.000100 | Loss: 1.5156 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 80.55
24-04-01 15:37:31.409 - INFO: Train epoch 328: [11200/94637 (12%)] Step: [1940821] | Lr: 0.000100 | Loss: 3.0056 | MSE loss: 0.0009 | Bpp loss: 1.54 | Aux loss: 72.74
24-04-01 15:38:00.366 - INFO: Train epoch 328: [12800/94637 (14%)] Step: [1940921] | Lr: 0.000100 | Loss: 1.2408 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 74.63
24-04-01 15:38:29.423 - INFO: Train epoch 328: [14400/94637 (15%)] Step: [1941021] | Lr: 0.000100 | Loss: 1.3943 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 75.37
24-04-01 15:38:58.308 - INFO: Train epoch 328: [16000/94637 (17%)] Step: [1941121] | Lr: 0.000100 | Loss: 0.9200 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 77.71
24-04-01 15:39:27.786 - INFO: Train epoch 328: [17600/94637 (19%)] Step: [1941221] | Lr: 0.000100 | Loss: 1.2084 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 75.01
24-04-01 15:39:56.610 - INFO: Train epoch 328: [19200/94637 (20%)] Step: [1941321] | Lr: 0.000100 | Loss: 1.2426 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 74.43
24-04-01 15:40:25.265 - INFO: Train epoch 328: [20800/94637 (22%)] Step: [1941421] | Lr: 0.000100 | Loss: 1.7991 | MSE loss: 0.0005 | Bpp loss: 1.05 | Aux loss: 76.21
24-04-01 15:40:53.959 - INFO: Train epoch 328: [22400/94637 (24%)] Step: [1941521] | Lr: 0.000100 | Loss: 1.6003 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 75.63
24-04-01 15:41:22.976 - INFO: Train epoch 328: [24000/94637 (25%)] Step: [1941621] | Lr: 0.000100 | Loss: 1.6758 | MSE loss: 0.0004 | Bpp loss: 1.05 | Aux loss: 76.39
24-04-01 15:41:52.451 - INFO: Train epoch 328: [25600/94637 (27%)] Step: [1941721] | Lr: 0.000100 | Loss: 1.7863 | MSE loss: 0.0004 | Bpp loss: 1.12 | Aux loss: 79.85
24-04-01 15:42:21.848 - INFO: Train epoch 328: [27200/94637 (29%)] Step: [1941821] | Lr: 0.000100 | Loss: 1.5284 | MSE loss: 0.0004 | Bpp loss: 0.88 | Aux loss: 75.16
24-04-01 15:42:51.135 - INFO: Train epoch 328: [28800/94637 (30%)] Step: [1941921] | Lr: 0.000100 | Loss: 1.1124 | MSE loss: 0.0003 | Bpp loss: 0.61 | Aux loss: 83.12
24-04-01 15:43:19.969 - INFO: Train epoch 328: [30400/94637 (32%)] Step: [1942021] | Lr: 0.000100 | Loss: 0.7941 | MSE loss: 0.0002 | Bpp loss: 0.48 | Aux loss: 79.71
24-04-01 15:43:49.120 - INFO: Train epoch 328: [32000/94637 (34%)] Step: [1942121] | Lr: 0.000100 | Loss: 0.9538 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 77.19
24-04-01 15:44:18.515 - INFO: Train epoch 328: [33600/94637 (36%)] Step: [1942221] | Lr: 0.000100 | Loss: 1.0889 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 77.81
24-04-01 15:44:47.477 - INFO: Train epoch 328: [35200/94637 (37%)] Step: [1942321] | Lr: 0.000100 | Loss: 1.2594 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 74.35
24-04-01 15:45:16.525 - INFO: Train epoch 328: [36800/94637 (39%)] Step: [1942421] | Lr: 0.000100 | Loss: 1.1477 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 81.74
24-04-01 15:45:47.695 - INFO: Train epoch 328: [38400/94637 (41%)] Step: [1942521] | Lr: 0.000100 | Loss: 0.7928 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 83.32
24-04-01 15:46:16.974 - INFO: Train epoch 328: [40000/94637 (42%)] Step: [1942621] | Lr: 0.000100 | Loss: 1.1819 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 78.54
24-04-01 15:46:46.184 - INFO: Train epoch 328: [41600/94637 (44%)] Step: [1942721] | Lr: 0.000100 | Loss: 1.5604 | MSE loss: 0.0004 | Bpp loss: 0.93 | Aux loss: 75.00
24-04-01 15:47:15.733 - INFO: Train epoch 328: [43200/94637 (46%)] Step: [1942821] | Lr: 0.000100 | Loss: 1.3187 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 83.59
24-04-01 15:47:45.358 - INFO: Train epoch 328: [44800/94637 (47%)] Step: [1942921] | Lr: 0.000100 | Loss: 1.3970 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 78.94
24-04-01 15:48:15.061 - INFO: Train epoch 328: [46400/94637 (49%)] Step: [1943021] | Lr: 0.000100 | Loss: 1.3555 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 81.85
24-04-01 15:48:44.574 - INFO: Train epoch 328: [48000/94637 (51%)] Step: [1943121] | Lr: 0.000100 | Loss: 1.3736 | MSE loss: 0.0004 | Bpp loss: 0.80 | Aux loss: 78.81
24-04-01 15:49:13.716 - INFO: Train epoch 328: [49600/94637 (52%)] Step: [1943221] | Lr: 0.000100 | Loss: 0.8443 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 80.56
24-04-01 15:49:43.702 - INFO: Train epoch 328: [51200/94637 (54%)] Step: [1943321] | Lr: 0.000100 | Loss: 1.3087 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 76.43
24-04-01 15:50:12.846 - INFO: Train epoch 328: [52800/94637 (56%)] Step: [1943421] | Lr: 0.000100 | Loss: 0.8870 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 83.93
24-04-01 15:50:42.422 - INFO: Train epoch 328: [54400/94637 (57%)] Step: [1943521] | Lr: 0.000100 | Loss: 1.3419 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 82.39
24-04-01 15:51:11.107 - INFO: Train epoch 328: [56000/94637 (59%)] Step: [1943621] | Lr: 0.000100 | Loss: 1.2878 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 80.65
24-04-01 15:51:40.422 - INFO: Train epoch 328: [57600/94637 (61%)] Step: [1943721] | Lr: 0.000100 | Loss: 1.5476 | MSE loss: 0.0003 | Bpp loss: 0.99 | Aux loss: 86.17
24-04-01 15:52:09.351 - INFO: Train epoch 328: [59200/94637 (63%)] Step: [1943821] | Lr: 0.000100 | Loss: 1.5275 | MSE loss: 0.0003 | Bpp loss: 0.97 | Aux loss: 83.12
24-04-01 15:52:38.331 - INFO: Train epoch 328: [60800/94637 (64%)] Step: [1943921] | Lr: 0.000100 | Loss: 0.8586 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 85.76
24-04-01 15:53:07.181 - INFO: Train epoch 328: [62400/94637 (66%)] Step: [1944021] | Lr: 0.000100 | Loss: 0.8825 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 81.29
24-04-01 15:53:36.212 - INFO: Train epoch 328: [64000/94637 (68%)] Step: [1944121] | Lr: 0.000100 | Loss: 0.9006 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 80.22
24-04-01 15:54:05.593 - INFO: Train epoch 328: [65600/94637 (69%)] Step: [1944221] | Lr: 0.000100 | Loss: 0.6180 | MSE loss: 0.0001 | Bpp loss: 0.38 | Aux loss: 77.63
24-04-01 15:54:34.486 - INFO: Train epoch 328: [67200/94637 (71%)] Step: [1944321] | Lr: 0.000100 | Loss: 1.5535 | MSE loss: 0.0003 | Bpp loss: 1.03 | Aux loss: 80.78
24-04-01 15:55:03.728 - INFO: Train epoch 328: [68800/94637 (73%)] Step: [1944421] | Lr: 0.000100 | Loss: 1.0853 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 78.52
24-04-01 15:55:32.403 - INFO: Train epoch 328: [70400/94637 (74%)] Step: [1944521] | Lr: 0.000100 | Loss: 1.3842 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 81.50
24-04-01 15:56:01.769 - INFO: Train epoch 328: [72000/94637 (76%)] Step: [1944621] | Lr: 0.000100 | Loss: 1.4889 | MSE loss: 0.0004 | Bpp loss: 0.82 | Aux loss: 82.45
24-04-01 15:56:30.920 - INFO: Train epoch 328: [73600/94637 (78%)] Step: [1944721] | Lr: 0.000100 | Loss: 1.5225 | MSE loss: 0.0003 | Bpp loss: 0.99 | Aux loss: 85.13
24-04-01 15:56:59.797 - INFO: Train epoch 328: [75200/94637 (79%)] Step: [1944821] | Lr: 0.000100 | Loss: 1.2021 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 81.20
24-04-01 15:57:29.664 - INFO: Train epoch 328: [76800/94637 (81%)] Step: [1944921] | Lr: 0.000100 | Loss: 2.0187 | MSE loss: 0.0005 | Bpp loss: 1.25 | Aux loss: 83.22
24-04-01 15:58:00.274 - INFO: Train epoch 328: [78400/94637 (83%)] Step: [1945021] | Lr: 0.000100 | Loss: 1.2355 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 80.03
24-04-01 15:58:29.461 - INFO: Train epoch 328: [80000/94637 (85%)] Step: [1945121] | Lr: 0.000100 | Loss: 0.9605 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 84.89
24-04-01 15:58:58.439 - INFO: Train epoch 328: [81600/94637 (86%)] Step: [1945221] | Lr: 0.000100 | Loss: 1.7123 | MSE loss: 0.0004 | Bpp loss: 1.08 | Aux loss: 87.90
24-04-01 15:59:27.364 - INFO: Train epoch 328: [83200/94637 (88%)] Step: [1945321] | Lr: 0.000100 | Loss: 1.2659 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 83.33
24-04-01 15:59:56.813 - INFO: Train epoch 328: [84800/94637 (90%)] Step: [1945421] | Lr: 0.000100 | Loss: 0.6585 | MSE loss: 0.0001 | Bpp loss: 0.44 | Aux loss: 83.82
24-04-01 16:00:26.106 - INFO: Train epoch 328: [86400/94637 (91%)] Step: [1945521] | Lr: 0.000100 | Loss: 1.1271 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 79.59
24-04-01 16:00:55.708 - INFO: Train epoch 328: [88000/94637 (93%)] Step: [1945621] | Lr: 0.000100 | Loss: 1.0638 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 77.61
24-04-01 16:01:25.244 - INFO: Train epoch 328: [89600/94637 (95%)] Step: [1945721] | Lr: 0.000100 | Loss: 1.3012 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 79.09
24-04-01 16:01:54.398 - INFO: Train epoch 328: [91200/94637 (96%)] Step: [1945821] | Lr: 0.000100 | Loss: 1.8471 | MSE loss: 0.0004 | Bpp loss: 1.12 | Aux loss: 82.19
24-04-01 16:02:23.590 - INFO: Train epoch 328: [92800/94637 (98%)] Step: [1945921] | Lr: 0.000100 | Loss: 0.7500 | MSE loss: 0.0002 | Bpp loss: 0.47 | Aux loss: 75.11
24-04-01 16:02:52.558 - INFO: Train epoch 328: [94400/94637 (100%)] Step: [1946021] | Lr: 0.000100 | Loss: 1.4687 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 84.26
24-04-01 16:03:08.136 - INFO: Learning rate: 0.0001
24-04-01 16:03:09.337 - INFO: Train epoch 329: [    0/94637 (0%)] Step: [1946036] | Lr: 0.000100 | Loss: 0.9162 | MSE loss: 0.0003 | Bpp loss: 0.50 | Aux loss: 80.02
24-04-01 16:03:37.963 - INFO: Train epoch 329: [ 1600/94637 (2%)] Step: [1946136] | Lr: 0.000100 | Loss: 1.1691 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 79.21
24-04-01 16:04:07.396 - INFO: Train epoch 329: [ 3200/94637 (3%)] Step: [1946236] | Lr: 0.000100 | Loss: 0.8788 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 80.99
24-04-01 16:04:35.933 - INFO: Train epoch 329: [ 4800/94637 (5%)] Step: [1946336] | Lr: 0.000100 | Loss: 1.2097 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 83.90
24-04-01 16:05:04.809 - INFO: Train epoch 329: [ 6400/94637 (7%)] Step: [1946436] | Lr: 0.000100 | Loss: 1.1004 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 81.74
24-04-01 16:05:33.576 - INFO: Train epoch 329: [ 8000/94637 (8%)] Step: [1946536] | Lr: 0.000100 | Loss: 1.3106 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 79.65
24-04-01 16:06:02.242 - INFO: Train epoch 329: [ 9600/94637 (10%)] Step: [1946636] | Lr: 0.000100 | Loss: 1.0559 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 81.19
24-04-01 16:06:31.107 - INFO: Train epoch 329: [11200/94637 (12%)] Step: [1946736] | Lr: 0.000100 | Loss: 1.6654 | MSE loss: 0.0004 | Bpp loss: 1.06 | Aux loss: 78.79
24-04-01 16:06:59.692 - INFO: Train epoch 329: [12800/94637 (14%)] Step: [1946836] | Lr: 0.000100 | Loss: 0.9548 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 77.30
24-04-01 16:07:28.745 - INFO: Train epoch 329: [14400/94637 (15%)] Step: [1946936] | Lr: 0.000100 | Loss: 1.4008 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 83.82
24-04-01 16:07:57.855 - INFO: Train epoch 329: [16000/94637 (17%)] Step: [1947036] | Lr: 0.000100 | Loss: 1.0459 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 81.67
24-04-01 16:08:26.880 - INFO: Train epoch 329: [17600/94637 (19%)] Step: [1947136] | Lr: 0.000100 | Loss: 1.6794 | MSE loss: 0.0004 | Bpp loss: 1.11 | Aux loss: 79.26
24-04-01 16:08:55.726 - INFO: Train epoch 329: [19200/94637 (20%)] Step: [1947236] | Lr: 0.000100 | Loss: 0.7919 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 83.35
24-04-01 16:09:24.513 - INFO: Train epoch 329: [20800/94637 (22%)] Step: [1947336] | Lr: 0.000100 | Loss: 1.2859 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 81.85
24-04-01 16:09:53.771 - INFO: Train epoch 329: [22400/94637 (24%)] Step: [1947436] | Lr: 0.000100 | Loss: 1.3954 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 77.68
24-04-01 16:10:24.523 - INFO: Train epoch 329: [24000/94637 (25%)] Step: [1947536] | Lr: 0.000100 | Loss: 1.1470 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 83.87
24-04-01 16:10:53.429 - INFO: Train epoch 329: [25600/94637 (27%)] Step: [1947636] | Lr: 0.000100 | Loss: 1.4529 | MSE loss: 0.0004 | Bpp loss: 0.85 | Aux loss: 80.93
24-04-01 16:11:22.675 - INFO: Train epoch 329: [27200/94637 (29%)] Step: [1947736] | Lr: 0.000100 | Loss: 1.3934 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 77.64
24-04-01 16:11:51.244 - INFO: Train epoch 329: [28800/94637 (30%)] Step: [1947836] | Lr: 0.000100 | Loss: 1.1434 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 86.37
24-04-01 16:12:20.929 - INFO: Train epoch 329: [30400/94637 (32%)] Step: [1947936] | Lr: 0.000100 | Loss: 1.8479 | MSE loss: 0.0005 | Bpp loss: 1.07 | Aux loss: 74.49
24-04-01 16:12:50.314 - INFO: Train epoch 329: [32000/94637 (34%)] Step: [1948036] | Lr: 0.000100 | Loss: 1.6926 | MSE loss: 0.0006 | Bpp loss: 0.78 | Aux loss: 83.21
24-04-01 16:13:19.471 - INFO: Train epoch 329: [33600/94637 (36%)] Step: [1948136] | Lr: 0.000100 | Loss: 1.5938 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 75.02
24-04-01 16:13:48.357 - INFO: Train epoch 329: [35200/94637 (37%)] Step: [1948236] | Lr: 0.000100 | Loss: 1.9341 | MSE loss: 0.0005 | Bpp loss: 1.12 | Aux loss: 81.13
24-04-01 16:14:17.552 - INFO: Train epoch 329: [36800/94637 (39%)] Step: [1948336] | Lr: 0.000100 | Loss: 2.0383 | MSE loss: 0.0005 | Bpp loss: 1.30 | Aux loss: 78.69
24-04-01 16:14:46.328 - INFO: Train epoch 329: [38400/94637 (41%)] Step: [1948436] | Lr: 0.000100 | Loss: 1.3235 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 79.63
24-04-01 16:15:16.185 - INFO: Train epoch 329: [40000/94637 (42%)] Step: [1948536] | Lr: 0.000100 | Loss: 1.1751 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 76.73
24-04-01 16:15:44.718 - INFO: Train epoch 329: [41600/94637 (44%)] Step: [1948636] | Lr: 0.000100 | Loss: 1.7205 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 77.55
24-04-01 16:16:14.097 - INFO: Train epoch 329: [43200/94637 (46%)] Step: [1948736] | Lr: 0.000100 | Loss: 1.0887 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 71.80
24-04-01 16:16:43.650 - INFO: Train epoch 329: [44800/94637 (47%)] Step: [1948836] | Lr: 0.000100 | Loss: 1.8586 | MSE loss: 0.0004 | Bpp loss: 1.16 | Aux loss: 77.79
24-04-01 16:17:12.853 - INFO: Train epoch 329: [46400/94637 (49%)] Step: [1948936] | Lr: 0.000100 | Loss: 1.2507 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 81.24
24-04-01 16:17:42.166 - INFO: Train epoch 329: [48000/94637 (51%)] Step: [1949036] | Lr: 0.000100 | Loss: 1.0361 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 81.17
24-04-01 16:18:11.088 - INFO: Train epoch 329: [49600/94637 (52%)] Step: [1949136] | Lr: 0.000100 | Loss: 1.0750 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 80.80
24-04-01 16:18:40.339 - INFO: Train epoch 329: [51200/94637 (54%)] Step: [1949236] | Lr: 0.000100 | Loss: 1.2352 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 80.72
24-04-01 16:19:09.088 - INFO: Train epoch 329: [52800/94637 (56%)] Step: [1949336] | Lr: 0.000100 | Loss: 0.7772 | MSE loss: 0.0002 | Bpp loss: 0.48 | Aux loss: 84.66
24-04-01 16:19:37.743 - INFO: Train epoch 329: [54400/94637 (57%)] Step: [1949436] | Lr: 0.000100 | Loss: 1.0723 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 78.50
24-04-01 16:20:06.942 - INFO: Train epoch 329: [56000/94637 (59%)] Step: [1949536] | Lr: 0.000100 | Loss: 0.9099 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 78.20
24-04-01 16:20:35.682 - INFO: Train epoch 329: [57600/94637 (61%)] Step: [1949636] | Lr: 0.000100 | Loss: 0.8993 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 80.49
24-04-01 16:21:04.522 - INFO: Train epoch 329: [59200/94637 (63%)] Step: [1949736] | Lr: 0.000100 | Loss: 1.3895 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 74.52
24-04-01 16:21:33.183 - INFO: Train epoch 329: [60800/94637 (64%)] Step: [1949836] | Lr: 0.000100 | Loss: 1.1326 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 80.87
24-04-01 16:22:02.998 - INFO: Train epoch 329: [62400/94637 (66%)] Step: [1949936] | Lr: 0.000100 | Loss: 1.1214 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 77.30
24-04-01 16:22:33.565 - INFO: Train epoch 329: [64000/94637 (68%)] Step: [1950036] | Lr: 0.000100 | Loss: 0.8895 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 77.27
24-04-01 16:23:02.593 - INFO: Train epoch 329: [65600/94637 (69%)] Step: [1950136] | Lr: 0.000100 | Loss: 1.5479 | MSE loss: 0.0003 | Bpp loss: 0.99 | Aux loss: 85.43
24-04-01 16:23:31.703 - INFO: Train epoch 329: [67200/94637 (71%)] Step: [1950236] | Lr: 0.000100 | Loss: 1.3870 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 81.37
24-04-01 16:24:00.777 - INFO: Train epoch 329: [68800/94637 (73%)] Step: [1950336] | Lr: 0.000100 | Loss: 1.2371 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 80.68
24-04-01 16:24:30.298 - INFO: Train epoch 329: [70400/94637 (74%)] Step: [1950436] | Lr: 0.000100 | Loss: 0.9887 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 83.07
24-04-01 16:24:59.677 - INFO: Train epoch 329: [72000/94637 (76%)] Step: [1950536] | Lr: 0.000100 | Loss: 1.0781 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 81.77
24-04-01 16:25:30.061 - INFO: Train epoch 329: [73600/94637 (78%)] Step: [1950636] | Lr: 0.000100 | Loss: 1.5347 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 85.38
24-04-01 16:25:58.975 - INFO: Train epoch 329: [75200/94637 (79%)] Step: [1950736] | Lr: 0.000100 | Loss: 1.2402 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 80.15
24-04-01 16:26:28.466 - INFO: Train epoch 329: [76800/94637 (81%)] Step: [1950836] | Lr: 0.000100 | Loss: 1.4254 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 85.00
24-04-01 16:26:57.634 - INFO: Train epoch 329: [78400/94637 (83%)] Step: [1950936] | Lr: 0.000100 | Loss: 1.7033 | MSE loss: 0.0004 | Bpp loss: 1.10 | Aux loss: 79.67
24-04-01 16:27:26.541 - INFO: Train epoch 329: [80000/94637 (85%)] Step: [1951036] | Lr: 0.000100 | Loss: 0.8441 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 79.49
24-04-01 16:27:55.959 - INFO: Train epoch 329: [81600/94637 (86%)] Step: [1951136] | Lr: 0.000100 | Loss: 1.3418 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 78.82
24-04-01 16:28:25.049 - INFO: Train epoch 329: [83200/94637 (88%)] Step: [1951236] | Lr: 0.000100 | Loss: 1.4793 | MSE loss: 0.0003 | Bpp loss: 0.98 | Aux loss: 81.18
24-04-01 16:28:54.345 - INFO: Train epoch 329: [84800/94637 (90%)] Step: [1951336] | Lr: 0.000100 | Loss: 1.7416 | MSE loss: 0.0004 | Bpp loss: 1.11 | Aux loss: 82.00
24-04-01 16:29:23.487 - INFO: Train epoch 329: [86400/94637 (91%)] Step: [1951436] | Lr: 0.000100 | Loss: 1.2200 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 83.74
24-04-01 16:29:53.115 - INFO: Train epoch 329: [88000/94637 (93%)] Step: [1951536] | Lr: 0.000100 | Loss: 1.5994 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 80.45
24-04-01 16:30:22.393 - INFO: Train epoch 329: [89600/94637 (95%)] Step: [1951636] | Lr: 0.000100 | Loss: 1.1694 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 81.56
24-04-01 16:30:51.496 - INFO: Train epoch 329: [91200/94637 (96%)] Step: [1951736] | Lr: 0.000100 | Loss: 0.8807 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 83.91
24-04-01 16:31:20.750 - INFO: Train epoch 329: [92800/94637 (98%)] Step: [1951836] | Lr: 0.000100 | Loss: 0.9773 | MSE loss: 0.0003 | Bpp loss: 0.56 | Aux loss: 83.64
24-04-01 16:31:49.957 - INFO: Train epoch 329: [94400/94637 (100%)] Step: [1951936] | Lr: 0.000100 | Loss: 2.0941 | MSE loss: 0.0005 | Bpp loss: 1.33 | Aux loss: 76.81
24-04-01 16:32:05.629 - INFO: Learning rate: 0.0001
24-04-01 16:32:06.370 - INFO: Train epoch 330: [    0/94637 (0%)] Step: [1951951] | Lr: 0.000100 | Loss: 1.3768 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 79.52
24-04-01 16:32:34.990 - INFO: Train epoch 330: [ 1600/94637 (2%)] Step: [1952051] | Lr: 0.000100 | Loss: 0.4540 | MSE loss: 0.0001 | Bpp loss: 0.32 | Aux loss: 79.57
24-04-01 16:33:03.231 - INFO: Train epoch 330: [ 3200/94637 (3%)] Step: [1952151] | Lr: 0.000100 | Loss: 1.9194 | MSE loss: 0.0005 | Bpp loss: 1.11 | Aux loss: 84.80
24-04-01 16:33:32.184 - INFO: Train epoch 330: [ 4800/94637 (5%)] Step: [1952251] | Lr: 0.000100 | Loss: 1.8977 | MSE loss: 0.0005 | Bpp loss: 1.16 | Aux loss: 80.77
24-04-01 16:34:00.997 - INFO: Train epoch 330: [ 6400/94637 (7%)] Step: [1952351] | Lr: 0.000100 | Loss: 1.0949 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 74.22
24-04-01 16:34:30.603 - INFO: Train epoch 330: [ 8000/94637 (8%)] Step: [1952451] | Lr: 0.000100 | Loss: 1.1940 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 80.83
24-04-01 16:35:01.190 - INFO: Train epoch 330: [ 9600/94637 (10%)] Step: [1952551] | Lr: 0.000100 | Loss: 2.0166 | MSE loss: 0.0005 | Bpp loss: 1.14 | Aux loss: 77.96
24-04-01 16:35:29.930 - INFO: Train epoch 330: [11200/94637 (12%)] Step: [1952651] | Lr: 0.000100 | Loss: 1.7803 | MSE loss: 0.0004 | Bpp loss: 1.08 | Aux loss: 85.71
24-04-01 16:35:58.666 - INFO: Train epoch 330: [12800/94637 (14%)] Step: [1952751] | Lr: 0.000100 | Loss: 1.1798 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 79.87
24-04-01 16:36:27.772 - INFO: Train epoch 330: [14400/94637 (15%)] Step: [1952851] | Lr: 0.000100 | Loss: 1.7530 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 82.85
24-04-01 16:36:56.409 - INFO: Train epoch 330: [16000/94637 (17%)] Step: [1952951] | Lr: 0.000100 | Loss: 0.8418 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 78.18
24-04-01 16:37:25.076 - INFO: Train epoch 330: [17600/94637 (19%)] Step: [1953051] | Lr: 0.000100 | Loss: 1.7980 | MSE loss: 0.0004 | Bpp loss: 1.13 | Aux loss: 83.19
24-04-01 16:37:53.846 - INFO: Train epoch 330: [19200/94637 (20%)] Step: [1953151] | Lr: 0.000100 | Loss: 1.5349 | MSE loss: 0.0004 | Bpp loss: 0.81 | Aux loss: 78.97
24-04-01 16:38:22.858 - INFO: Train epoch 330: [20800/94637 (22%)] Step: [1953251] | Lr: 0.000100 | Loss: 1.0612 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 80.24
24-04-01 16:38:51.487 - INFO: Train epoch 330: [22400/94637 (24%)] Step: [1953351] | Lr: 0.000100 | Loss: 1.0411 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 82.95
24-04-01 16:39:20.235 - INFO: Train epoch 330: [24000/94637 (25%)] Step: [1953451] | Lr: 0.000100 | Loss: 1.4427 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 78.74
24-04-01 16:39:49.343 - INFO: Train epoch 330: [25600/94637 (27%)] Step: [1953551] | Lr: 0.000100 | Loss: 0.9801 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 83.80
24-04-01 16:40:18.629 - INFO: Train epoch 330: [27200/94637 (29%)] Step: [1953651] | Lr: 0.000100 | Loss: 1.4725 | MSE loss: 0.0003 | Bpp loss: 0.97 | Aux loss: 79.91
24-04-01 16:40:47.810 - INFO: Train epoch 330: [28800/94637 (30%)] Step: [1953751] | Lr: 0.000100 | Loss: 1.1851 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 82.27
24-04-01 16:41:16.976 - INFO: Train epoch 330: [30400/94637 (32%)] Step: [1953851] | Lr: 0.000100 | Loss: 0.9766 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 80.90
24-04-01 16:41:46.119 - INFO: Train epoch 330: [32000/94637 (34%)] Step: [1953951] | Lr: 0.000100 | Loss: 1.2505 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 78.80
24-04-01 16:42:15.235 - INFO: Train epoch 330: [33600/94637 (36%)] Step: [1954051] | Lr: 0.000100 | Loss: 1.2529 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 80.13
24-04-01 16:42:44.477 - INFO: Train epoch 330: [35200/94637 (37%)] Step: [1954151] | Lr: 0.000100 | Loss: 1.5938 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 78.56
24-04-01 16:43:13.378 - INFO: Train epoch 330: [36800/94637 (39%)] Step: [1954251] | Lr: 0.000100 | Loss: 0.7884 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 82.50
24-04-01 16:43:42.203 - INFO: Train epoch 330: [38400/94637 (41%)] Step: [1954351] | Lr: 0.000100 | Loss: 1.2166 | MSE loss: 0.0004 | Bpp loss: 0.64 | Aux loss: 86.23
24-04-01 16:44:10.993 - INFO: Train epoch 330: [40000/94637 (42%)] Step: [1954451] | Lr: 0.000100 | Loss: 1.2414 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 76.54
24-04-01 16:44:39.803 - INFO: Train epoch 330: [41600/94637 (44%)] Step: [1954551] | Lr: 0.000100 | Loss: 1.3958 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 82.31
24-04-01 16:45:08.479 - INFO: Train epoch 330: [43200/94637 (46%)] Step: [1954651] | Lr: 0.000100 | Loss: 1.1994 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 75.65
24-04-01 16:45:37.050 - INFO: Train epoch 330: [44800/94637 (47%)] Step: [1954751] | Lr: 0.000100 | Loss: 1.0186 | MSE loss: 0.0003 | Bpp loss: 0.60 | Aux loss: 74.44
24-04-01 16:46:05.884 - INFO: Train epoch 330: [46400/94637 (49%)] Step: [1954851] | Lr: 0.000100 | Loss: 1.0514 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 74.98
24-04-01 16:46:35.388 - INFO: Train epoch 330: [48000/94637 (51%)] Step: [1954951] | Lr: 0.000100 | Loss: 0.7020 | MSE loss: 0.0002 | Bpp loss: 0.43 | Aux loss: 83.00
24-04-01 16:47:07.417 - INFO: Train epoch 330: [49600/94637 (52%)] Step: [1955051] | Lr: 0.000100 | Loss: 1.7520 | MSE loss: 0.0004 | Bpp loss: 1.06 | Aux loss: 82.38
24-04-01 16:47:37.322 - INFO: Train epoch 330: [51200/94637 (54%)] Step: [1955151] | Lr: 0.000100 | Loss: 1.9296 | MSE loss: 0.0004 | Bpp loss: 1.21 | Aux loss: 81.22
24-04-01 16:48:06.422 - INFO: Train epoch 330: [52800/94637 (56%)] Step: [1955251] | Lr: 0.000100 | Loss: 1.2298 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 82.87
24-04-01 16:48:35.768 - INFO: Train epoch 330: [54400/94637 (57%)] Step: [1955351] | Lr: 0.000100 | Loss: 1.1684 | MSE loss: 0.0002 | Bpp loss: 0.77 | Aux loss: 75.57
24-04-01 16:49:04.884 - INFO: Train epoch 330: [56000/94637 (59%)] Step: [1955451] | Lr: 0.000100 | Loss: 1.3675 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 84.07
24-04-01 16:49:34.007 - INFO: Train epoch 330: [57600/94637 (61%)] Step: [1955551] | Lr: 0.000100 | Loss: 0.7275 | MSE loss: 0.0002 | Bpp loss: 0.47 | Aux loss: 83.76
24-04-01 16:50:03.298 - INFO: Train epoch 330: [59200/94637 (63%)] Step: [1955651] | Lr: 0.000100 | Loss: 1.2189 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 82.26
24-04-01 16:50:32.879 - INFO: Train epoch 330: [60800/94637 (64%)] Step: [1955751] | Lr: 0.000100 | Loss: 1.0602 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 84.87
24-04-01 16:51:02.147 - INFO: Train epoch 330: [62400/94637 (66%)] Step: [1955851] | Lr: 0.000100 | Loss: 0.9703 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 81.81
24-04-01 16:51:31.536 - INFO: Train epoch 330: [64000/94637 (68%)] Step: [1955951] | Lr: 0.000100 | Loss: 1.5346 | MSE loss: 0.0003 | Bpp loss: 0.97 | Aux loss: 81.06
24-04-01 16:52:00.793 - INFO: Train epoch 330: [65600/94637 (69%)] Step: [1956051] | Lr: 0.000100 | Loss: 0.9644 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 85.20
24-04-01 16:52:30.091 - INFO: Train epoch 330: [67200/94637 (71%)] Step: [1956151] | Lr: 0.000100 | Loss: 1.0593 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 81.75
24-04-01 16:52:59.535 - INFO: Train epoch 330: [68800/94637 (73%)] Step: [1956251] | Lr: 0.000100 | Loss: 1.2147 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 82.57
24-04-01 16:53:28.664 - INFO: Train epoch 330: [70400/94637 (74%)] Step: [1956351] | Lr: 0.000100 | Loss: 0.9960 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 82.04
24-04-01 16:53:58.097 - INFO: Train epoch 330: [72000/94637 (76%)] Step: [1956451] | Lr: 0.000100 | Loss: 1.8539 | MSE loss: 0.0005 | Bpp loss: 1.04 | Aux loss: 82.98
24-04-01 16:54:27.317 - INFO: Train epoch 330: [73600/94637 (78%)] Step: [1956551] | Lr: 0.000100 | Loss: 0.7877 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 84.67
24-04-01 16:54:56.416 - INFO: Train epoch 330: [75200/94637 (79%)] Step: [1956651] | Lr: 0.000100 | Loss: 1.1329 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 81.22
24-04-01 16:55:25.837 - INFO: Train epoch 330: [76800/94637 (81%)] Step: [1956751] | Lr: 0.000100 | Loss: 1.1189 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 78.82
24-04-01 16:55:55.778 - INFO: Train epoch 330: [78400/94637 (83%)] Step: [1956851] | Lr: 0.000100 | Loss: 0.9765 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 83.31
24-04-01 16:56:25.869 - INFO: Train epoch 330: [80000/94637 (85%)] Step: [1956951] | Lr: 0.000100 | Loss: 1.6799 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 79.53
24-04-01 16:56:55.919 - INFO: Train epoch 330: [81600/94637 (86%)] Step: [1957051] | Lr: 0.000100 | Loss: 0.7658 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 82.17
24-04-01 16:57:26.047 - INFO: Train epoch 330: [83200/94637 (88%)] Step: [1957151] | Lr: 0.000100 | Loss: 1.2855 | MSE loss: 0.0004 | Bpp loss: 0.69 | Aux loss: 78.21
24-04-01 16:57:56.074 - INFO: Train epoch 330: [84800/94637 (90%)] Step: [1957251] | Lr: 0.000100 | Loss: 1.3286 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 89.37
24-04-01 16:58:26.256 - INFO: Train epoch 330: [86400/94637 (91%)] Step: [1957351] | Lr: 0.000100 | Loss: 1.4275 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 80.26
24-04-01 16:58:56.031 - INFO: Train epoch 330: [88000/94637 (93%)] Step: [1957451] | Lr: 0.000100 | Loss: 0.7397 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 80.01
24-04-01 16:59:27.688 - INFO: Train epoch 330: [89600/94637 (95%)] Step: [1957551] | Lr: 0.000100 | Loss: 1.5107 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 77.45
24-04-01 16:59:57.634 - INFO: Train epoch 330: [91200/94637 (96%)] Step: [1957651] | Lr: 0.000100 | Loss: 2.0594 | MSE loss: 0.0005 | Bpp loss: 1.29 | Aux loss: 78.66
24-04-01 17:00:27.204 - INFO: Train epoch 330: [92800/94637 (98%)] Step: [1957751] | Lr: 0.000100 | Loss: 0.6031 | MSE loss: 0.0001 | Bpp loss: 0.42 | Aux loss: 83.37
24-04-01 17:00:56.715 - INFO: Train epoch 330: [94400/94637 (100%)] Step: [1957851] | Lr: 0.000100 | Loss: 0.7454 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 76.50
24-04-01 17:01:11.779 - INFO: Learning rate: 0.0001
24-04-01 17:01:12.719 - INFO: Train epoch 331: [    0/94637 (0%)] Step: [1957866] | Lr: 0.000100 | Loss: 1.5137 | MSE loss: 0.0004 | Bpp loss: 0.90 | Aux loss: 85.50
24-04-01 17:01:41.221 - INFO: Train epoch 331: [ 1600/94637 (2%)] Step: [1957966] | Lr: 0.000100 | Loss: 1.3033 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 81.81
24-04-01 17:02:09.965 - INFO: Train epoch 331: [ 3200/94637 (3%)] Step: [1958066] | Lr: 0.000100 | Loss: 1.0034 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 80.74
24-04-01 17:02:38.420 - INFO: Train epoch 331: [ 4800/94637 (5%)] Step: [1958166] | Lr: 0.000100 | Loss: 1.5557 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 79.76
24-04-01 17:03:07.053 - INFO: Train epoch 331: [ 6400/94637 (7%)] Step: [1958266] | Lr: 0.000100 | Loss: 1.4901 | MSE loss: 0.0003 | Bpp loss: 0.96 | Aux loss: 75.77
24-04-01 17:03:35.247 - INFO: Train epoch 331: [ 8000/94637 (8%)] Step: [1958366] | Lr: 0.000100 | Loss: 1.0648 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 86.92
24-04-01 17:04:04.023 - INFO: Train epoch 331: [ 9600/94637 (10%)] Step: [1958466] | Lr: 0.000100 | Loss: 1.3607 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 76.24
24-04-01 17:04:32.741 - INFO: Train epoch 331: [11200/94637 (12%)] Step: [1958566] | Lr: 0.000100 | Loss: 2.0218 | MSE loss: 0.0006 | Bpp loss: 1.12 | Aux loss: 85.65
24-04-01 17:05:00.889 - INFO: Train epoch 331: [12800/94637 (14%)] Step: [1958666] | Lr: 0.000100 | Loss: 0.8665 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 82.44
24-04-01 17:05:29.296 - INFO: Train epoch 331: [14400/94637 (15%)] Step: [1958766] | Lr: 0.000100 | Loss: 1.3429 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 83.78
24-04-01 17:05:57.821 - INFO: Train epoch 331: [16000/94637 (17%)] Step: [1958866] | Lr: 0.000100 | Loss: 1.4490 | MSE loss: 0.0004 | Bpp loss: 0.85 | Aux loss: 85.46
24-04-01 17:06:26.188 - INFO: Train epoch 331: [17600/94637 (19%)] Step: [1958966] | Lr: 0.000100 | Loss: 1.5975 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 84.64
24-04-01 17:06:54.869 - INFO: Train epoch 331: [19200/94637 (20%)] Step: [1959066] | Lr: 0.000100 | Loss: 1.0512 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 85.30
24-04-01 17:07:23.613 - INFO: Train epoch 331: [20800/94637 (22%)] Step: [1959166] | Lr: 0.000100 | Loss: 1.3802 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 81.77
24-04-01 17:07:52.190 - INFO: Train epoch 331: [22400/94637 (24%)] Step: [1959266] | Lr: 0.000100 | Loss: 1.1195 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 81.56
24-04-01 17:08:20.854 - INFO: Train epoch 331: [24000/94637 (25%)] Step: [1959366] | Lr: 0.000100 | Loss: 0.9137 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 74.78
24-04-01 17:08:49.663 - INFO: Train epoch 331: [25600/94637 (27%)] Step: [1959466] | Lr: 0.000100 | Loss: 1.4504 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 82.52
24-04-01 17:09:18.506 - INFO: Train epoch 331: [27200/94637 (29%)] Step: [1959566] | Lr: 0.000100 | Loss: 1.2643 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 88.23
24-04-01 17:09:47.834 - INFO: Train epoch 331: [28800/94637 (30%)] Step: [1959666] | Lr: 0.000100 | Loss: 1.4354 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 83.76
24-04-01 17:10:16.482 - INFO: Train epoch 331: [30400/94637 (32%)] Step: [1959766] | Lr: 0.000100 | Loss: 1.2452 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 82.07
24-04-01 17:10:45.366 - INFO: Train epoch 331: [32000/94637 (34%)] Step: [1959866] | Lr: 0.000100 | Loss: 1.4323 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 78.53
24-04-01 17:11:13.881 - INFO: Train epoch 331: [33600/94637 (36%)] Step: [1959966] | Lr: 0.000100 | Loss: 1.0710 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 77.47
24-04-01 17:11:44.583 - INFO: Train epoch 331: [35200/94637 (37%)] Step: [1960066] | Lr: 0.000100 | Loss: 0.9494 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 84.03
24-04-01 17:12:13.272 - INFO: Train epoch 331: [36800/94637 (39%)] Step: [1960166] | Lr: 0.000100 | Loss: 1.6383 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 77.85
24-04-01 17:12:41.770 - INFO: Train epoch 331: [38400/94637 (41%)] Step: [1960266] | Lr: 0.000100 | Loss: 1.3292 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 80.37
24-04-01 17:13:10.878 - INFO: Train epoch 331: [40000/94637 (42%)] Step: [1960366] | Lr: 0.000100 | Loss: 1.5741 | MSE loss: 0.0005 | Bpp loss: 0.71 | Aux loss: 78.11
24-04-01 17:13:38.874 - INFO: Train epoch 331: [41600/94637 (44%)] Step: [1960466] | Lr: 0.000100 | Loss: 1.9915 | MSE loss: 0.0005 | Bpp loss: 1.17 | Aux loss: 84.63
24-04-01 17:14:07.540 - INFO: Train epoch 331: [43200/94637 (46%)] Step: [1960566] | Lr: 0.000100 | Loss: 1.6674 | MSE loss: 0.0004 | Bpp loss: 1.06 | Aux loss: 83.43
24-04-01 17:14:35.868 - INFO: Train epoch 331: [44800/94637 (47%)] Step: [1960666] | Lr: 0.000100 | Loss: 1.3816 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 84.74
24-04-01 17:15:04.073 - INFO: Train epoch 331: [46400/94637 (49%)] Step: [1960766] | Lr: 0.000100 | Loss: 0.7444 | MSE loss: 0.0001 | Bpp loss: 0.51 | Aux loss: 79.77
24-04-01 17:15:32.690 - INFO: Train epoch 331: [48000/94637 (51%)] Step: [1960866] | Lr: 0.000100 | Loss: 1.5276 | MSE loss: 0.0003 | Bpp loss: 0.97 | Aux loss: 80.51
24-04-01 17:16:00.728 - INFO: Train epoch 331: [49600/94637 (52%)] Step: [1960966] | Lr: 0.000100 | Loss: 0.8584 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 80.67
24-04-01 17:16:29.191 - INFO: Train epoch 331: [51200/94637 (54%)] Step: [1961066] | Lr: 0.000100 | Loss: 2.0446 | MSE loss: 0.0006 | Bpp loss: 1.12 | Aux loss: 81.54
24-04-01 17:16:57.406 - INFO: Train epoch 331: [52800/94637 (56%)] Step: [1961166] | Lr: 0.000100 | Loss: 1.1497 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 85.78
24-04-01 17:17:26.164 - INFO: Train epoch 331: [54400/94637 (57%)] Step: [1961266] | Lr: 0.000100 | Loss: 1.7356 | MSE loss: 0.0004 | Bpp loss: 1.06 | Aux loss: 82.78
24-04-01 17:17:54.522 - INFO: Train epoch 331: [56000/94637 (59%)] Step: [1961366] | Lr: 0.000100 | Loss: 1.3376 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 86.58
24-04-01 17:18:22.847 - INFO: Train epoch 331: [57600/94637 (61%)] Step: [1961466] | Lr: 0.000100 | Loss: 1.5858 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 83.34
24-04-01 17:18:51.012 - INFO: Train epoch 331: [59200/94637 (63%)] Step: [1961566] | Lr: 0.000100 | Loss: 2.0962 | MSE loss: 0.0005 | Bpp loss: 1.23 | Aux loss: 81.40
24-04-01 17:19:19.083 - INFO: Train epoch 331: [60800/94637 (64%)] Step: [1961666] | Lr: 0.000100 | Loss: 1.7925 | MSE loss: 0.0004 | Bpp loss: 1.12 | Aux loss: 83.24
24-04-01 17:19:47.497 - INFO: Train epoch 331: [62400/94637 (66%)] Step: [1961766] | Lr: 0.000100 | Loss: 1.0193 | MSE loss: 0.0003 | Bpp loss: 0.58 | Aux loss: 81.04
24-04-01 17:20:15.503 - INFO: Train epoch 331: [64000/94637 (68%)] Step: [1961866] | Lr: 0.000100 | Loss: 1.5945 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 84.58
24-04-01 17:20:43.732 - INFO: Train epoch 331: [65600/94637 (69%)] Step: [1961966] | Lr: 0.000100 | Loss: 1.4815 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 81.58
24-04-01 17:21:11.926 - INFO: Train epoch 331: [67200/94637 (71%)] Step: [1962066] | Lr: 0.000100 | Loss: 0.7923 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 79.89
24-04-01 17:21:40.384 - INFO: Train epoch 331: [68800/94637 (73%)] Step: [1962166] | Lr: 0.000100 | Loss: 2.9834 | MSE loss: 0.0010 | Bpp loss: 1.37 | Aux loss: 81.31
24-04-01 17:22:09.909 - INFO: Train epoch 331: [70400/94637 (74%)] Step: [1962266] | Lr: 0.000100 | Loss: 1.3091 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 85.56
24-04-01 17:22:38.872 - INFO: Train epoch 331: [72000/94637 (76%)] Step: [1962366] | Lr: 0.000100 | Loss: 1.8400 | MSE loss: 0.0005 | Bpp loss: 1.04 | Aux loss: 82.11
24-04-01 17:23:08.379 - INFO: Train epoch 331: [73600/94637 (78%)] Step: [1962466] | Lr: 0.000100 | Loss: 1.5409 | MSE loss: 0.0003 | Bpp loss: 0.98 | Aux loss: 82.53
24-04-01 17:23:39.292 - INFO: Train epoch 331: [75200/94637 (79%)] Step: [1962566] | Lr: 0.000100 | Loss: 2.0356 | MSE loss: 0.0005 | Bpp loss: 1.23 | Aux loss: 83.75
24-04-01 17:24:08.484 - INFO: Train epoch 331: [76800/94637 (81%)] Step: [1962666] | Lr: 0.000100 | Loss: 1.3298 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 86.10
24-04-01 17:24:37.328 - INFO: Train epoch 331: [78400/94637 (83%)] Step: [1962766] | Lr: 0.000100 | Loss: 1.0158 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 83.04
24-04-01 17:25:06.807 - INFO: Train epoch 331: [80000/94637 (85%)] Step: [1962866] | Lr: 0.000100 | Loss: 1.1638 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 82.09
24-04-01 17:25:35.895 - INFO: Train epoch 331: [81600/94637 (86%)] Step: [1962966] | Lr: 0.000100 | Loss: 0.9958 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 92.14
24-04-01 17:26:05.788 - INFO: Train epoch 331: [83200/94637 (88%)] Step: [1963066] | Lr: 0.000100 | Loss: 1.5455 | MSE loss: 0.0004 | Bpp loss: 0.93 | Aux loss: 84.44
24-04-01 17:26:35.228 - INFO: Train epoch 331: [84800/94637 (90%)] Step: [1963166] | Lr: 0.000100 | Loss: 1.1842 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 84.53
24-04-01 17:27:04.897 - INFO: Train epoch 331: [86400/94637 (91%)] Step: [1963266] | Lr: 0.000100 | Loss: 1.2047 | MSE loss: 0.0002 | Bpp loss: 0.80 | Aux loss: 83.30
24-04-01 17:27:34.802 - INFO: Train epoch 331: [88000/94637 (93%)] Step: [1963366] | Lr: 0.000100 | Loss: 1.2133 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 88.80
24-04-01 17:28:04.881 - INFO: Train epoch 331: [89600/94637 (95%)] Step: [1963466] | Lr: 0.000100 | Loss: 1.3546 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 79.79
24-04-01 17:28:34.558 - INFO: Train epoch 331: [91200/94637 (96%)] Step: [1963566] | Lr: 0.000100 | Loss: 1.2973 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 85.35
24-04-01 17:29:03.798 - INFO: Train epoch 331: [92800/94637 (98%)] Step: [1963666] | Lr: 0.000100 | Loss: 1.1010 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 84.43
24-04-01 17:29:33.464 - INFO: Train epoch 331: [94400/94637 (100%)] Step: [1963766] | Lr: 0.000100 | Loss: 0.9322 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 79.25
24-04-01 17:29:48.710 - INFO: Learning rate: 0.0001
24-04-01 17:29:49.447 - INFO: Train epoch 332: [    0/94637 (0%)] Step: [1963781] | Lr: 0.000100 | Loss: 1.1859 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 76.77
24-04-01 17:30:18.846 - INFO: Train epoch 332: [ 1600/94637 (2%)] Step: [1963881] | Lr: 0.000100 | Loss: 2.0217 | MSE loss: 0.0005 | Bpp loss: 1.16 | Aux loss: 85.95
24-04-01 17:30:47.774 - INFO: Train epoch 332: [ 3200/94637 (3%)] Step: [1963981] | Lr: 0.000100 | Loss: 1.6955 | MSE loss: 0.0004 | Bpp loss: 1.03 | Aux loss: 86.14
24-04-01 17:31:16.844 - INFO: Train epoch 332: [ 4800/94637 (5%)] Step: [1964081] | Lr: 0.000100 | Loss: 1.0013 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 84.53
24-04-01 17:31:45.444 - INFO: Train epoch 332: [ 6400/94637 (7%)] Step: [1964181] | Lr: 0.000100 | Loss: 1.3146 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 83.78
24-04-01 17:32:14.038 - INFO: Train epoch 332: [ 8000/94637 (8%)] Step: [1964281] | Lr: 0.000100 | Loss: 1.6511 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 88.99
24-04-01 17:32:42.512 - INFO: Train epoch 332: [ 9600/94637 (10%)] Step: [1964381] | Lr: 0.000100 | Loss: 1.2661 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 84.32
24-04-01 17:33:10.857 - INFO: Train epoch 332: [11200/94637 (12%)] Step: [1964481] | Lr: 0.000100 | Loss: 1.0128 | MSE loss: 0.0002 | Bpp loss: 0.63 | Aux loss: 81.48
24-04-01 17:33:39.487 - INFO: Train epoch 332: [12800/94637 (14%)] Step: [1964581] | Lr: 0.000100 | Loss: 0.9870 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 84.22
24-04-01 17:34:08.449 - INFO: Train epoch 332: [14400/94637 (15%)] Step: [1964681] | Lr: 0.000100 | Loss: 1.1554 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 83.45
24-04-01 17:34:37.228 - INFO: Train epoch 332: [16000/94637 (17%)] Step: [1964781] | Lr: 0.000100 | Loss: 1.7000 | MSE loss: 0.0004 | Bpp loss: 1.04 | Aux loss: 84.31
24-04-01 17:35:06.134 - INFO: Train epoch 332: [17600/94637 (19%)] Step: [1964881] | Lr: 0.000100 | Loss: 0.8712 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 81.85
24-04-01 17:35:35.649 - INFO: Train epoch 332: [19200/94637 (20%)] Step: [1964981] | Lr: 0.000100 | Loss: 0.7833 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 84.34
24-04-01 17:36:06.873 - INFO: Train epoch 332: [20800/94637 (22%)] Step: [1965081] | Lr: 0.000100 | Loss: 1.1454 | MSE loss: 0.0002 | Bpp loss: 0.77 | Aux loss: 86.93
24-04-01 17:36:35.499 - INFO: Train epoch 332: [22400/94637 (24%)] Step: [1965181] | Lr: 0.000100 | Loss: 0.9003 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 81.59
24-04-01 17:37:03.913 - INFO: Train epoch 332: [24000/94637 (25%)] Step: [1965281] | Lr: 0.000100 | Loss: 1.1375 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 82.64
24-04-01 17:37:32.635 - INFO: Train epoch 332: [25600/94637 (27%)] Step: [1965381] | Lr: 0.000100 | Loss: 1.2986 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 81.48
24-04-01 17:38:01.392 - INFO: Train epoch 332: [27200/94637 (29%)] Step: [1965481] | Lr: 0.000100 | Loss: 0.9871 | MSE loss: 0.0003 | Bpp loss: 0.56 | Aux loss: 84.06
24-04-01 17:38:30.022 - INFO: Train epoch 332: [28800/94637 (30%)] Step: [1965581] | Lr: 0.000100 | Loss: 1.2134 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 80.51
24-04-01 17:38:58.578 - INFO: Train epoch 332: [30400/94637 (32%)] Step: [1965681] | Lr: 0.000100 | Loss: 1.5634 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 82.34
24-04-01 17:39:27.391 - INFO: Train epoch 332: [32000/94637 (34%)] Step: [1965781] | Lr: 0.000100 | Loss: 1.2371 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 79.94
24-04-01 17:39:56.202 - INFO: Train epoch 332: [33600/94637 (36%)] Step: [1965881] | Lr: 0.000100 | Loss: 1.3516 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 81.59
24-04-01 17:40:24.925 - INFO: Train epoch 332: [35200/94637 (37%)] Step: [1965981] | Lr: 0.000100 | Loss: 1.4497 | MSE loss: 0.0004 | Bpp loss: 0.88 | Aux loss: 79.10
24-04-01 17:40:53.390 - INFO: Train epoch 332: [36800/94637 (39%)] Step: [1966081] | Lr: 0.000100 | Loss: 1.5739 | MSE loss: 0.0004 | Bpp loss: 0.97 | Aux loss: 84.97
24-04-01 17:41:22.387 - INFO: Train epoch 332: [38400/94637 (41%)] Step: [1966181] | Lr: 0.000100 | Loss: 0.9026 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 81.09
24-04-01 17:41:51.028 - INFO: Train epoch 332: [40000/94637 (42%)] Step: [1966281] | Lr: 0.000100 | Loss: 1.2271 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 82.85
24-04-01 17:42:19.680 - INFO: Train epoch 332: [41600/94637 (44%)] Step: [1966381] | Lr: 0.000100 | Loss: 1.0345 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 82.88
24-04-01 17:42:48.257 - INFO: Train epoch 332: [43200/94637 (46%)] Step: [1966481] | Lr: 0.000100 | Loss: 1.0967 | MSE loss: 0.0003 | Bpp loss: 0.67 | Aux loss: 82.81
24-04-01 17:43:16.771 - INFO: Train epoch 332: [44800/94637 (47%)] Step: [1966581] | Lr: 0.000100 | Loss: 1.6793 | MSE loss: 0.0004 | Bpp loss: 1.06 | Aux loss: 88.08
24-04-01 17:43:45.613 - INFO: Train epoch 332: [46400/94637 (49%)] Step: [1966681] | Lr: 0.000100 | Loss: 1.4895 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 83.31
24-04-01 17:44:14.899 - INFO: Train epoch 332: [48000/94637 (51%)] Step: [1966781] | Lr: 0.000100 | Loss: 2.4976 | MSE loss: 0.0008 | Bpp loss: 1.23 | Aux loss: 78.27
24-04-01 17:44:43.754 - INFO: Train epoch 332: [49600/94637 (52%)] Step: [1966881] | Lr: 0.000100 | Loss: 1.0401 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 83.21
24-04-01 17:45:12.761 - INFO: Train epoch 332: [51200/94637 (54%)] Step: [1966981] | Lr: 0.000100 | Loss: 1.9544 | MSE loss: 0.0005 | Bpp loss: 1.10 | Aux loss: 81.64
24-04-01 17:45:41.804 - INFO: Train epoch 332: [52800/94637 (56%)] Step: [1967081] | Lr: 0.000100 | Loss: 1.9357 | MSE loss: 0.0005 | Bpp loss: 1.06 | Aux loss: 84.95
24-04-01 17:46:10.403 - INFO: Train epoch 332: [54400/94637 (57%)] Step: [1967181] | Lr: 0.000100 | Loss: 1.2196 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 82.94
24-04-01 17:46:39.397 - INFO: Train epoch 332: [56000/94637 (59%)] Step: [1967281] | Lr: 0.000100 | Loss: 0.8906 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 81.72
24-04-01 17:47:08.299 - INFO: Train epoch 332: [57600/94637 (61%)] Step: [1967381] | Lr: 0.000100 | Loss: 1.8411 | MSE loss: 0.0004 | Bpp loss: 1.13 | Aux loss: 82.75
24-04-01 17:47:37.569 - INFO: Train epoch 332: [59200/94637 (63%)] Step: [1967481] | Lr: 0.000100 | Loss: 0.5483 | MSE loss: 0.0001 | Bpp loss: 0.36 | Aux loss: 83.33
24-04-01 17:48:08.285 - INFO: Train epoch 332: [60800/94637 (64%)] Step: [1967581] | Lr: 0.000100 | Loss: 1.6267 | MSE loss: 0.0005 | Bpp loss: 0.85 | Aux loss: 83.47
24-04-01 17:48:36.884 - INFO: Train epoch 332: [62400/94637 (66%)] Step: [1967681] | Lr: 0.000100 | Loss: 0.6433 | MSE loss: 0.0001 | Bpp loss: 0.41 | Aux loss: 85.65
24-04-01 17:49:05.975 - INFO: Train epoch 332: [64000/94637 (68%)] Step: [1967781] | Lr: 0.000100 | Loss: 1.1986 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 84.37
24-04-01 17:49:35.062 - INFO: Train epoch 332: [65600/94637 (69%)] Step: [1967881] | Lr: 0.000100 | Loss: 1.1184 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 85.28
24-04-01 17:50:04.101 - INFO: Train epoch 332: [67200/94637 (71%)] Step: [1967981] | Lr: 0.000100 | Loss: 1.3007 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 77.67
24-04-01 17:50:33.475 - INFO: Train epoch 332: [68800/94637 (73%)] Step: [1968081] | Lr: 0.000100 | Loss: 1.5295 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 80.50
24-04-01 17:51:02.136 - INFO: Train epoch 332: [70400/94637 (74%)] Step: [1968181] | Lr: 0.000100 | Loss: 1.6815 | MSE loss: 0.0004 | Bpp loss: 1.07 | Aux loss: 80.53
24-04-01 17:51:30.791 - INFO: Train epoch 332: [72000/94637 (76%)] Step: [1968281] | Lr: 0.000100 | Loss: 0.9582 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 82.38
24-04-01 17:51:59.962 - INFO: Train epoch 332: [73600/94637 (78%)] Step: [1968381] | Lr: 0.000100 | Loss: 1.2651 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 79.88
24-04-01 17:52:28.629 - INFO: Train epoch 332: [75200/94637 (79%)] Step: [1968481] | Lr: 0.000100 | Loss: 1.4108 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 82.38
24-04-01 17:52:57.652 - INFO: Train epoch 332: [76800/94637 (81%)] Step: [1968581] | Lr: 0.000100 | Loss: 1.6288 | MSE loss: 0.0003 | Bpp loss: 1.07 | Aux loss: 76.72
24-04-01 17:53:26.538 - INFO: Train epoch 332: [78400/94637 (83%)] Step: [1968681] | Lr: 0.000100 | Loss: 1.4921 | MSE loss: 0.0003 | Bpp loss: 0.97 | Aux loss: 79.19
24-04-01 17:53:55.889 - INFO: Train epoch 332: [80000/94637 (85%)] Step: [1968781] | Lr: 0.000100 | Loss: 1.4012 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 91.37
24-04-01 17:54:25.810 - INFO: Train epoch 332: [81600/94637 (86%)] Step: [1968881] | Lr: 0.000100 | Loss: 1.2977 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 87.15
24-04-01 17:54:54.620 - INFO: Train epoch 332: [83200/94637 (88%)] Step: [1968981] | Lr: 0.000100 | Loss: 1.8764 | MSE loss: 0.0005 | Bpp loss: 1.06 | Aux loss: 88.75
24-04-01 17:55:23.386 - INFO: Train epoch 332: [84800/94637 (90%)] Step: [1969081] | Lr: 0.000100 | Loss: 1.1098 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 87.86
24-04-01 17:55:52.021 - INFO: Train epoch 332: [86400/94637 (91%)] Step: [1969181] | Lr: 0.000100 | Loss: 1.5788 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 84.13
24-04-01 17:56:20.944 - INFO: Train epoch 332: [88000/94637 (93%)] Step: [1969281] | Lr: 0.000100 | Loss: 0.7090 | MSE loss: 0.0002 | Bpp loss: 0.45 | Aux loss: 85.55
24-04-01 17:56:49.727 - INFO: Train epoch 332: [89600/94637 (95%)] Step: [1969381] | Lr: 0.000100 | Loss: 1.9708 | MSE loss: 0.0005 | Bpp loss: 1.22 | Aux loss: 81.66
24-04-01 17:57:19.026 - INFO: Train epoch 332: [91200/94637 (96%)] Step: [1969481] | Lr: 0.000100 | Loss: 1.2247 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 76.24
24-04-01 17:57:48.009 - INFO: Train epoch 332: [92800/94637 (98%)] Step: [1969581] | Lr: 0.000100 | Loss: 1.1408 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 89.74
24-04-01 17:58:17.012 - INFO: Train epoch 332: [94400/94637 (100%)] Step: [1969681] | Lr: 0.000100 | Loss: 1.9539 | MSE loss: 0.0004 | Bpp loss: 1.27 | Aux loss: 82.58
24-04-01 17:58:32.389 - INFO: Learning rate: 0.0001
24-04-01 17:58:33.134 - INFO: Train epoch 333: [    0/94637 (0%)] Step: [1969696] | Lr: 0.000100 | Loss: 2.0872 | MSE loss: 0.0005 | Bpp loss: 1.21 | Aux loss: 83.30
24-04-01 17:59:01.941 - INFO: Train epoch 333: [ 1600/94637 (2%)] Step: [1969796] | Lr: 0.000100 | Loss: 1.5056 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 81.77
24-04-01 17:59:30.138 - INFO: Train epoch 333: [ 3200/94637 (3%)] Step: [1969896] | Lr: 0.000100 | Loss: 1.8140 | MSE loss: 0.0005 | Bpp loss: 1.02 | Aux loss: 83.20
24-04-01 17:59:58.909 - INFO: Train epoch 333: [ 4800/94637 (5%)] Step: [1969996] | Lr: 0.000100 | Loss: 1.0997 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 77.51
24-04-01 18:00:29.445 - INFO: Train epoch 333: [ 6400/94637 (7%)] Step: [1970096] | Lr: 0.000100 | Loss: 1.0499 | MSE loss: 0.0003 | Bpp loss: 0.63 | Aux loss: 84.20
24-04-01 18:00:58.189 - INFO: Train epoch 333: [ 8000/94637 (8%)] Step: [1970196] | Lr: 0.000100 | Loss: 1.3917 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 84.96
24-04-01 18:01:26.725 - INFO: Train epoch 333: [ 9600/94637 (10%)] Step: [1970296] | Lr: 0.000100 | Loss: 0.7337 | MSE loss: 0.0002 | Bpp loss: 0.46 | Aux loss: 80.35
24-04-01 18:01:55.482 - INFO: Train epoch 333: [11200/94637 (12%)] Step: [1970396] | Lr: 0.000100 | Loss: 1.6342 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 82.37
24-04-01 18:02:24.476 - INFO: Train epoch 333: [12800/94637 (14%)] Step: [1970496] | Lr: 0.000100 | Loss: 1.2205 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 80.47
24-04-01 18:02:53.161 - INFO: Train epoch 333: [14400/94637 (15%)] Step: [1970596] | Lr: 0.000100 | Loss: 0.7337 | MSE loss: 0.0001 | Bpp loss: 0.50 | Aux loss: 85.23
24-04-01 18:03:22.831 - INFO: Train epoch 333: [16000/94637 (17%)] Step: [1970696] | Lr: 0.000100 | Loss: 2.2505 | MSE loss: 0.0005 | Bpp loss: 1.38 | Aux loss: 81.03
24-04-01 18:03:52.176 - INFO: Train epoch 333: [17600/94637 (19%)] Step: [1970796] | Lr: 0.000100 | Loss: 1.1188 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 87.12
24-04-01 18:04:21.620 - INFO: Train epoch 333: [19200/94637 (20%)] Step: [1970896] | Lr: 0.000100 | Loss: 1.6199 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 84.89
24-04-01 18:04:51.232 - INFO: Train epoch 333: [20800/94637 (22%)] Step: [1970996] | Lr: 0.000100 | Loss: 1.3005 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 83.20
24-04-01 18:05:20.698 - INFO: Train epoch 333: [22400/94637 (24%)] Step: [1971096] | Lr: 0.000100 | Loss: 1.1909 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 80.86
24-04-01 18:05:49.818 - INFO: Train epoch 333: [24000/94637 (25%)] Step: [1971196] | Lr: 0.000100 | Loss: 1.2295 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 80.07
24-04-01 18:06:18.866 - INFO: Train epoch 333: [25600/94637 (27%)] Step: [1971296] | Lr: 0.000100 | Loss: 0.9838 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 82.08
24-04-01 18:06:47.724 - INFO: Train epoch 333: [27200/94637 (29%)] Step: [1971396] | Lr: 0.000100 | Loss: 0.7826 | MSE loss: 0.0002 | Bpp loss: 0.44 | Aux loss: 85.72
24-04-01 18:07:16.268 - INFO: Train epoch 333: [28800/94637 (30%)] Step: [1971496] | Lr: 0.000100 | Loss: 0.8342 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 79.32
24-04-01 18:07:45.393 - INFO: Train epoch 333: [30400/94637 (32%)] Step: [1971596] | Lr: 0.000100 | Loss: 1.8121 | MSE loss: 0.0004 | Bpp loss: 1.11 | Aux loss: 85.15
24-04-01 18:08:14.156 - INFO: Train epoch 333: [32000/94637 (34%)] Step: [1971696] | Lr: 0.000100 | Loss: 1.3969 | MSE loss: 0.0003 | Bpp loss: 0.88 | Aux loss: 80.48
24-04-01 18:08:42.911 - INFO: Train epoch 333: [33600/94637 (36%)] Step: [1971796] | Lr: 0.000100 | Loss: 1.4877 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 83.89
24-04-01 18:09:12.237 - INFO: Train epoch 333: [35200/94637 (37%)] Step: [1971896] | Lr: 0.000100 | Loss: 1.1552 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 79.36
24-04-01 18:09:41.454 - INFO: Train epoch 333: [36800/94637 (39%)] Step: [1971996] | Lr: 0.000100 | Loss: 1.3130 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 83.44
24-04-01 18:10:10.443 - INFO: Train epoch 333: [38400/94637 (41%)] Step: [1972096] | Lr: 0.000100 | Loss: 1.0254 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 83.69
24-04-01 18:10:39.223 - INFO: Train epoch 333: [40000/94637 (42%)] Step: [1972196] | Lr: 0.000100 | Loss: 1.5947 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 79.86
24-04-01 18:11:08.869 - INFO: Train epoch 333: [41600/94637 (44%)] Step: [1972296] | Lr: 0.000100 | Loss: 1.2022 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 86.85
24-04-01 18:11:38.277 - INFO: Train epoch 333: [43200/94637 (46%)] Step: [1972396] | Lr: 0.000100 | Loss: 2.0503 | MSE loss: 0.0005 | Bpp loss: 1.24 | Aux loss: 85.79
24-04-01 18:12:07.461 - INFO: Train epoch 333: [44800/94637 (47%)] Step: [1972496] | Lr: 0.000100 | Loss: 1.4872 | MSE loss: 0.0004 | Bpp loss: 0.86 | Aux loss: 86.07
24-04-01 18:12:38.750 - INFO: Train epoch 333: [46400/94637 (49%)] Step: [1972596] | Lr: 0.000100 | Loss: 1.6538 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 77.94
24-04-01 18:13:07.630 - INFO: Train epoch 333: [48000/94637 (51%)] Step: [1972696] | Lr: 0.000100 | Loss: 1.5370 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 88.60
24-04-01 18:13:36.963 - INFO: Train epoch 333: [49600/94637 (52%)] Step: [1972796] | Lr: 0.000100 | Loss: 0.9627 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 83.57
24-04-01 18:14:05.316 - INFO: Train epoch 333: [51200/94637 (54%)] Step: [1972896] | Lr: 0.000100 | Loss: 1.2914 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 82.89
24-04-01 18:14:33.853 - INFO: Train epoch 333: [52800/94637 (56%)] Step: [1972996] | Lr: 0.000100 | Loss: 1.5532 | MSE loss: 0.0003 | Bpp loss: 0.99 | Aux loss: 86.16
24-04-01 18:15:02.972 - INFO: Train epoch 333: [54400/94637 (57%)] Step: [1973096] | Lr: 0.000100 | Loss: 1.3349 | MSE loss: 0.0004 | Bpp loss: 0.74 | Aux loss: 85.78
24-04-01 18:15:32.066 - INFO: Train epoch 333: [56000/94637 (59%)] Step: [1973196] | Lr: 0.000100 | Loss: 1.6209 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 86.68
24-04-01 18:16:00.570 - INFO: Train epoch 333: [57600/94637 (61%)] Step: [1973296] | Lr: 0.000100 | Loss: 1.2356 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 79.14
24-04-01 18:16:29.267 - INFO: Train epoch 333: [59200/94637 (63%)] Step: [1973396] | Lr: 0.000100 | Loss: 1.0566 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 83.23
24-04-01 18:16:58.294 - INFO: Train epoch 333: [60800/94637 (64%)] Step: [1973496] | Lr: 0.000100 | Loss: 1.3820 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 82.52
24-04-01 18:17:27.621 - INFO: Train epoch 333: [62400/94637 (66%)] Step: [1973596] | Lr: 0.000100 | Loss: 1.4501 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 84.76
24-04-01 18:17:57.113 - INFO: Train epoch 333: [64000/94637 (68%)] Step: [1973696] | Lr: 0.000100 | Loss: 1.7182 | MSE loss: 0.0004 | Bpp loss: 1.11 | Aux loss: 78.54
24-04-01 18:18:26.076 - INFO: Train epoch 333: [65600/94637 (69%)] Step: [1973796] | Lr: 0.000100 | Loss: 0.9089 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 80.60
24-04-01 18:18:55.206 - INFO: Train epoch 333: [67200/94637 (71%)] Step: [1973896] | Lr: 0.000100 | Loss: 1.5733 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 82.15
24-04-01 18:19:24.035 - INFO: Train epoch 333: [68800/94637 (73%)] Step: [1973996] | Lr: 0.000100 | Loss: 1.5032 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 86.77
24-04-01 18:19:53.312 - INFO: Train epoch 333: [70400/94637 (74%)] Step: [1974096] | Lr: 0.000100 | Loss: 1.0868 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 84.25
24-04-01 18:20:22.657 - INFO: Train epoch 333: [72000/94637 (76%)] Step: [1974196] | Lr: 0.000100 | Loss: 1.1092 | MSE loss: 0.0002 | Bpp loss: 0.72 | Aux loss: 83.09
24-04-01 18:20:51.435 - INFO: Train epoch 333: [73600/94637 (78%)] Step: [1974296] | Lr: 0.000100 | Loss: 0.8646 | MSE loss: 0.0002 | Bpp loss: 0.52 | Aux loss: 90.78
24-04-01 18:21:20.835 - INFO: Train epoch 333: [75200/94637 (79%)] Step: [1974396] | Lr: 0.000100 | Loss: 1.0893 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 88.93
24-04-01 18:21:50.233 - INFO: Train epoch 333: [76800/94637 (81%)] Step: [1974496] | Lr: 0.000100 | Loss: 1.6273 | MSE loss: 0.0003 | Bpp loss: 1.08 | Aux loss: 87.36
24-04-01 18:22:19.382 - INFO: Train epoch 333: [78400/94637 (83%)] Step: [1974596] | Lr: 0.000100 | Loss: 1.7656 | MSE loss: 0.0004 | Bpp loss: 1.08 | Aux loss: 84.83
24-04-01 18:22:48.275 - INFO: Train epoch 333: [80000/94637 (85%)] Step: [1974696] | Lr: 0.000100 | Loss: 1.1083 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 81.84
24-04-01 18:23:17.587 - INFO: Train epoch 333: [81600/94637 (86%)] Step: [1974796] | Lr: 0.000100 | Loss: 1.5963 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 82.87
24-04-01 18:23:46.355 - INFO: Train epoch 333: [83200/94637 (88%)] Step: [1974896] | Lr: 0.000100 | Loss: 1.0123 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 86.50
24-04-01 18:24:14.905 - INFO: Train epoch 333: [84800/94637 (90%)] Step: [1974996] | Lr: 0.000100 | Loss: 2.3583 | MSE loss: 0.0007 | Bpp loss: 1.28 | Aux loss: 82.97
24-04-01 18:24:49.369 - INFO: Train epoch 333: [86400/94637 (91%)] Step: [1975096] | Lr: 0.000100 | Loss: 1.1534 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 83.97
24-04-01 18:25:17.960 - INFO: Train epoch 333: [88000/94637 (93%)] Step: [1975196] | Lr: 0.000100 | Loss: 0.8067 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 77.71
24-04-01 18:25:47.473 - INFO: Train epoch 333: [89600/94637 (95%)] Step: [1975296] | Lr: 0.000100 | Loss: 0.8016 | MSE loss: 0.0002 | Bpp loss: 0.47 | Aux loss: 82.50
24-04-01 18:26:16.722 - INFO: Train epoch 333: [91200/94637 (96%)] Step: [1975396] | Lr: 0.000100 | Loss: 0.6270 | MSE loss: 0.0001 | Bpp loss: 0.43 | Aux loss: 80.45
24-04-01 18:26:45.945 - INFO: Train epoch 333: [92800/94637 (98%)] Step: [1975496] | Lr: 0.000100 | Loss: 1.4722 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 81.72
24-04-01 18:27:15.056 - INFO: Train epoch 333: [94400/94637 (100%)] Step: [1975596] | Lr: 0.000100 | Loss: 1.1589 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 77.59
24-04-01 18:27:30.664 - INFO: Learning rate: 0.0001
24-04-01 18:27:31.499 - INFO: Train epoch 334: [    0/94637 (0%)] Step: [1975611] | Lr: 0.000100 | Loss: 1.3397 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 82.88
24-04-01 18:28:00.884 - INFO: Train epoch 334: [ 1600/94637 (2%)] Step: [1975711] | Lr: 0.000100 | Loss: 1.4766 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 89.34
24-04-01 18:28:29.798 - INFO: Train epoch 334: [ 3200/94637 (3%)] Step: [1975811] | Lr: 0.000100 | Loss: 1.6587 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 81.78
24-04-01 18:28:58.475 - INFO: Train epoch 334: [ 4800/94637 (5%)] Step: [1975911] | Lr: 0.000100 | Loss: 2.0393 | MSE loss: 0.0005 | Bpp loss: 1.20 | Aux loss: 86.84
24-04-01 18:29:27.270 - INFO: Train epoch 334: [ 6400/94637 (7%)] Step: [1976011] | Lr: 0.000100 | Loss: 1.3640 | MSE loss: 0.0004 | Bpp loss: 0.75 | Aux loss: 86.76
24-04-01 18:29:55.943 - INFO: Train epoch 334: [ 8000/94637 (8%)] Step: [1976111] | Lr: 0.000100 | Loss: 1.1158 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 81.82
24-04-01 18:30:24.512 - INFO: Train epoch 334: [ 9600/94637 (10%)] Step: [1976211] | Lr: 0.000100 | Loss: 1.6225 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 79.45
24-04-01 18:30:52.712 - INFO: Train epoch 334: [11200/94637 (12%)] Step: [1976311] | Lr: 0.000100 | Loss: 1.5318 | MSE loss: 0.0003 | Bpp loss: 0.98 | Aux loss: 78.82
24-04-01 18:31:21.277 - INFO: Train epoch 334: [12800/94637 (14%)] Step: [1976411] | Lr: 0.000100 | Loss: 1.5174 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 84.58
24-04-01 18:31:49.883 - INFO: Train epoch 334: [14400/94637 (15%)] Step: [1976511] | Lr: 0.000100 | Loss: 0.7473 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 79.83
24-04-01 18:32:18.880 - INFO: Train epoch 334: [16000/94637 (17%)] Step: [1976611] | Lr: 0.000100 | Loss: 1.7402 | MSE loss: 0.0004 | Bpp loss: 1.06 | Aux loss: 82.78
24-04-01 18:32:47.566 - INFO: Train epoch 334: [17600/94637 (19%)] Step: [1976711] | Lr: 0.000100 | Loss: 1.2713 | MSE loss: 0.0003 | Bpp loss: 0.80 | Aux loss: 82.89
24-04-01 18:33:16.277 - INFO: Train epoch 334: [19200/94637 (20%)] Step: [1976811] | Lr: 0.000100 | Loss: 1.0546 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 85.09
24-04-01 18:33:45.144 - INFO: Train epoch 334: [20800/94637 (22%)] Step: [1976911] | Lr: 0.000100 | Loss: 1.1452 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 83.38
24-04-01 18:34:14.581 - INFO: Train epoch 334: [22400/94637 (24%)] Step: [1977011] | Lr: 0.000100 | Loss: 1.1942 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 85.35
24-04-01 18:34:43.776 - INFO: Train epoch 334: [24000/94637 (25%)] Step: [1977111] | Lr: 0.000100 | Loss: 1.3443 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 80.39
24-04-01 18:35:12.637 - INFO: Train epoch 334: [25600/94637 (27%)] Step: [1977211] | Lr: 0.000100 | Loss: 0.7721 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 79.82
24-04-01 18:35:42.183 - INFO: Train epoch 334: [27200/94637 (29%)] Step: [1977311] | Lr: 0.000100 | Loss: 1.5588 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 78.29
24-04-01 18:36:11.600 - INFO: Train epoch 334: [28800/94637 (30%)] Step: [1977411] | Lr: 0.000100 | Loss: 1.1522 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 83.24
24-04-01 18:36:42.376 - INFO: Train epoch 334: [30400/94637 (32%)] Step: [1977511] | Lr: 0.000100 | Loss: 1.9727 | MSE loss: 0.0005 | Bpp loss: 1.22 | Aux loss: 85.40
24-04-01 18:37:11.891 - INFO: Train epoch 334: [32000/94637 (34%)] Step: [1977611] | Lr: 0.000100 | Loss: 1.3652 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 87.02
24-04-01 18:37:40.639 - INFO: Train epoch 334: [33600/94637 (36%)] Step: [1977711] | Lr: 0.000100 | Loss: 1.1397 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 83.71
24-04-01 18:38:09.847 - INFO: Train epoch 334: [35200/94637 (37%)] Step: [1977811] | Lr: 0.000100 | Loss: 0.6278 | MSE loss: 0.0001 | Bpp loss: 0.42 | Aux loss: 79.07
24-04-01 18:38:38.475 - INFO: Train epoch 334: [36800/94637 (39%)] Step: [1977911] | Lr: 0.000100 | Loss: 1.4692 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 78.41
24-04-01 18:39:07.575 - INFO: Train epoch 334: [38400/94637 (41%)] Step: [1978011] | Lr: 0.000100 | Loss: 1.4695 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 81.84
24-04-01 18:39:37.092 - INFO: Train epoch 334: [40000/94637 (42%)] Step: [1978111] | Lr: 0.000100 | Loss: 1.3442 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 80.37
24-04-01 18:40:07.470 - INFO: Train epoch 334: [41600/94637 (44%)] Step: [1978211] | Lr: 0.000100 | Loss: 1.0968 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 93.70
24-04-01 18:40:36.846 - INFO: Train epoch 334: [43200/94637 (46%)] Step: [1978311] | Lr: 0.000100 | Loss: 1.5109 | MSE loss: 0.0003 | Bpp loss: 0.99 | Aux loss: 79.01
24-04-01 18:41:05.709 - INFO: Train epoch 334: [44800/94637 (47%)] Step: [1978411] | Lr: 0.000100 | Loss: 2.2747 | MSE loss: 0.0006 | Bpp loss: 1.33 | Aux loss: 83.99
24-04-01 18:41:34.891 - INFO: Train epoch 334: [46400/94637 (49%)] Step: [1978511] | Lr: 0.000100 | Loss: 1.4282 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 85.00
24-04-01 18:42:04.055 - INFO: Train epoch 334: [48000/94637 (51%)] Step: [1978611] | Lr: 0.000100 | Loss: 0.7786 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 83.23
24-04-01 18:42:33.352 - INFO: Train epoch 334: [49600/94637 (52%)] Step: [1978711] | Lr: 0.000100 | Loss: 1.1444 | MSE loss: 0.0003 | Bpp loss: 0.72 | Aux loss: 79.77
24-04-01 18:43:02.601 - INFO: Train epoch 334: [51200/94637 (54%)] Step: [1978811] | Lr: 0.000100 | Loss: 1.1591 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 83.89
24-04-01 18:43:32.119 - INFO: Train epoch 334: [52800/94637 (56%)] Step: [1978911] | Lr: 0.000100 | Loss: 1.3067 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 76.90
24-04-01 18:44:01.126 - INFO: Train epoch 334: [54400/94637 (57%)] Step: [1979011] | Lr: 0.000100 | Loss: 1.4736 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 86.91
24-04-01 18:44:30.324 - INFO: Train epoch 334: [56000/94637 (59%)] Step: [1979111] | Lr: 0.000100 | Loss: 1.3109 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 83.30
24-04-01 18:45:00.100 - INFO: Train epoch 334: [57600/94637 (61%)] Step: [1979211] | Lr: 0.000100 | Loss: 1.3597 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 76.90
24-04-01 18:45:29.494 - INFO: Train epoch 334: [59200/94637 (63%)] Step: [1979311] | Lr: 0.000100 | Loss: 1.3068 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 86.72
24-04-01 18:45:59.150 - INFO: Train epoch 334: [60800/94637 (64%)] Step: [1979411] | Lr: 0.000100 | Loss: 1.2917 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 86.13
24-04-01 18:46:28.251 - INFO: Train epoch 334: [62400/94637 (66%)] Step: [1979511] | Lr: 0.000100 | Loss: 1.1419 | MSE loss: 0.0002 | Bpp loss: 0.75 | Aux loss: 86.22
24-04-01 18:46:56.777 - INFO: Train epoch 334: [64000/94637 (68%)] Step: [1979611] | Lr: 0.000100 | Loss: 1.4932 | MSE loss: 0.0003 | Bpp loss: 0.96 | Aux loss: 83.72
24-04-01 18:47:25.827 - INFO: Train epoch 334: [65600/94637 (69%)] Step: [1979711] | Lr: 0.000100 | Loss: 0.8634 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 77.61
24-04-01 18:47:54.831 - INFO: Train epoch 334: [67200/94637 (71%)] Step: [1979811] | Lr: 0.000100 | Loss: 1.0230 | MSE loss: 0.0003 | Bpp loss: 0.60 | Aux loss: 81.58
24-04-01 18:48:23.821 - INFO: Train epoch 334: [68800/94637 (73%)] Step: [1979911] | Lr: 0.000100 | Loss: 0.6556 | MSE loss: 0.0002 | Bpp loss: 0.38 | Aux loss: 85.68
24-04-01 18:48:54.507 - INFO: Train epoch 334: [70400/94637 (74%)] Step: [1980011] | Lr: 0.000100 | Loss: 1.7362 | MSE loss: 0.0004 | Bpp loss: 1.07 | Aux loss: 83.14
24-04-01 18:49:24.195 - INFO: Train epoch 334: [72000/94637 (76%)] Step: [1980111] | Lr: 0.000100 | Loss: 1.6370 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 84.05
24-04-01 18:49:53.159 - INFO: Train epoch 334: [73600/94637 (78%)] Step: [1980211] | Lr: 0.000100 | Loss: 1.3059 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 80.40
24-04-01 18:50:22.868 - INFO: Train epoch 334: [75200/94637 (79%)] Step: [1980311] | Lr: 0.000100 | Loss: 0.8827 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 82.44
24-04-01 18:50:51.877 - INFO: Train epoch 334: [76800/94637 (81%)] Step: [1980411] | Lr: 0.000100 | Loss: 1.6496 | MSE loss: 0.0004 | Bpp loss: 1.02 | Aux loss: 82.71
24-04-01 18:51:21.553 - INFO: Train epoch 334: [78400/94637 (83%)] Step: [1980511] | Lr: 0.000100 | Loss: 0.8992 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 85.23
24-04-01 18:51:50.713 - INFO: Train epoch 334: [80000/94637 (85%)] Step: [1980611] | Lr: 0.000100 | Loss: 1.1314 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 86.07
24-04-01 18:52:20.290 - INFO: Train epoch 334: [81600/94637 (86%)] Step: [1980711] | Lr: 0.000100 | Loss: 1.8211 | MSE loss: 0.0004 | Bpp loss: 1.11 | Aux loss: 82.31
24-04-01 18:52:49.540 - INFO: Train epoch 334: [83200/94637 (88%)] Step: [1980811] | Lr: 0.000100 | Loss: 1.1380 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 102.42
24-04-01 18:53:19.969 - INFO: Train epoch 334: [84800/94637 (90%)] Step: [1980911] | Lr: 0.000100 | Loss: 1.4631 | MSE loss: 0.0003 | Bpp loss: 0.92 | Aux loss: 82.91
24-04-01 18:53:49.819 - INFO: Train epoch 334: [86400/94637 (91%)] Step: [1981011] | Lr: 0.000100 | Loss: 1.4287 | MSE loss: 0.0003 | Bpp loss: 0.94 | Aux loss: 80.67
24-04-01 18:54:18.881 - INFO: Train epoch 334: [88000/94637 (93%)] Step: [1981111] | Lr: 0.000100 | Loss: 1.7815 | MSE loss: 0.0004 | Bpp loss: 1.18 | Aux loss: 82.46
24-04-01 18:54:48.620 - INFO: Train epoch 334: [89600/94637 (95%)] Step: [1981211] | Lr: 0.000100 | Loss: 1.2334 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 74.95
24-04-01 18:55:18.046 - INFO: Train epoch 334: [91200/94637 (96%)] Step: [1981311] | Lr: 0.000100 | Loss: 1.1998 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 74.59
24-04-01 18:55:47.720 - INFO: Train epoch 334: [92800/94637 (98%)] Step: [1981411] | Lr: 0.000100 | Loss: 1.9592 | MSE loss: 0.0005 | Bpp loss: 1.08 | Aux loss: 78.15
24-04-01 18:56:18.038 - INFO: Train epoch 334: [94400/94637 (100%)] Step: [1981511] | Lr: 0.000100 | Loss: 0.8997 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 83.01
24-04-01 18:56:33.598 - INFO: Learning rate: 0.0001
24-04-01 18:56:34.391 - INFO: Train epoch 335: [    0/94637 (0%)] Step: [1981526] | Lr: 0.000100 | Loss: 1.1069 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 79.84
24-04-01 18:57:03.028 - INFO: Train epoch 335: [ 1600/94637 (2%)] Step: [1981626] | Lr: 0.000100 | Loss: 1.3733 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 81.07
24-04-01 18:57:31.586 - INFO: Train epoch 335: [ 3200/94637 (3%)] Step: [1981726] | Lr: 0.000100 | Loss: 1.5139 | MSE loss: 0.0004 | Bpp loss: 0.93 | Aux loss: 76.66
24-04-01 18:58:00.959 - INFO: Train epoch 335: [ 4800/94637 (5%)] Step: [1981826] | Lr: 0.000100 | Loss: 1.8791 | MSE loss: 0.0005 | Bpp loss: 1.05 | Aux loss: 74.16
24-04-01 18:58:29.976 - INFO: Train epoch 335: [ 6400/94637 (7%)] Step: [1981926] | Lr: 0.000100 | Loss: 1.2024 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 83.90
24-04-01 18:58:59.615 - INFO: Train epoch 335: [ 8000/94637 (8%)] Step: [1982026] | Lr: 0.000100 | Loss: 0.9743 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 74.57
24-04-01 18:59:29.019 - INFO: Train epoch 335: [ 9600/94637 (10%)] Step: [1982126] | Lr: 0.000100 | Loss: 1.4307 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 82.45
24-04-01 18:59:58.498 - INFO: Train epoch 335: [11200/94637 (12%)] Step: [1982226] | Lr: 0.000100 | Loss: 1.2332 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 73.44
24-04-01 19:00:27.971 - INFO: Train epoch 335: [12800/94637 (14%)] Step: [1982326] | Lr: 0.000100 | Loss: 1.0344 | MSE loss: 0.0003 | Bpp loss: 0.62 | Aux loss: 75.35
24-04-01 19:00:56.907 - INFO: Train epoch 335: [14400/94637 (15%)] Step: [1982426] | Lr: 0.000100 | Loss: 1.7268 | MSE loss: 0.0004 | Bpp loss: 1.06 | Aux loss: 79.61
24-04-01 19:01:27.737 - INFO: Train epoch 335: [16000/94637 (17%)] Step: [1982526] | Lr: 0.000100 | Loss: 1.1404 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 75.40
24-04-01 19:01:56.987 - INFO: Train epoch 335: [17600/94637 (19%)] Step: [1982626] | Lr: 0.000100 | Loss: 1.3688 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 83.09
24-04-01 19:02:26.051 - INFO: Train epoch 335: [19200/94637 (20%)] Step: [1982726] | Lr: 0.000100 | Loss: 1.2818 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 78.65
24-04-01 19:02:55.045 - INFO: Train epoch 335: [20800/94637 (22%)] Step: [1982826] | Lr: 0.000100 | Loss: 1.3656 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 75.48
24-04-01 19:03:25.588 - INFO: Train epoch 335: [22400/94637 (24%)] Step: [1982926] | Lr: 0.000100 | Loss: 1.1417 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 79.09
24-04-01 19:03:55.270 - INFO: Train epoch 335: [24000/94637 (25%)] Step: [1983026] | Lr: 0.000100 | Loss: 0.9774 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 78.73
24-04-01 19:04:25.021 - INFO: Train epoch 335: [25600/94637 (27%)] Step: [1983126] | Lr: 0.000100 | Loss: 1.6876 | MSE loss: 0.0004 | Bpp loss: 1.06 | Aux loss: 83.41
24-04-01 19:04:54.832 - INFO: Train epoch 335: [27200/94637 (29%)] Step: [1983226] | Lr: 0.000100 | Loss: 1.5165 | MSE loss: 0.0004 | Bpp loss: 0.91 | Aux loss: 81.76
24-04-01 19:05:23.971 - INFO: Train epoch 335: [28800/94637 (30%)] Step: [1983326] | Lr: 0.000100 | Loss: 0.6056 | MSE loss: 0.0001 | Bpp loss: 0.38 | Aux loss: 80.99
24-04-01 19:05:53.437 - INFO: Train epoch 335: [30400/94637 (32%)] Step: [1983426] | Lr: 0.000100 | Loss: 1.0073 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 84.81
24-04-01 19:06:22.735 - INFO: Train epoch 335: [32000/94637 (34%)] Step: [1983526] | Lr: 0.000100 | Loss: 1.4490 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 83.29
24-04-01 19:06:51.763 - INFO: Train epoch 335: [33600/94637 (36%)] Step: [1983626] | Lr: 0.000100 | Loss: 1.1653 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 77.70
24-04-01 19:07:20.808 - INFO: Train epoch 335: [35200/94637 (37%)] Step: [1983726] | Lr: 0.000100 | Loss: 0.9306 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 77.71
24-04-01 19:07:49.429 - INFO: Train epoch 335: [36800/94637 (39%)] Step: [1983826] | Lr: 0.000100 | Loss: 1.6523 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 85.33
24-04-01 19:08:17.943 - INFO: Train epoch 335: [38400/94637 (41%)] Step: [1983926] | Lr: 0.000100 | Loss: 1.2019 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 78.63
24-04-01 19:08:47.167 - INFO: Train epoch 335: [40000/94637 (42%)] Step: [1984026] | Lr: 0.000100 | Loss: 1.0653 | MSE loss: 0.0002 | Bpp loss: 0.69 | Aux loss: 82.42
24-04-01 19:09:17.131 - INFO: Train epoch 335: [41600/94637 (44%)] Step: [1984126] | Lr: 0.000100 | Loss: 0.9232 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 77.22
24-04-01 19:09:46.789 - INFO: Train epoch 335: [43200/94637 (46%)] Step: [1984226] | Lr: 0.000100 | Loss: 1.9310 | MSE loss: 0.0005 | Bpp loss: 1.19 | Aux loss: 81.13
24-04-01 19:10:16.466 - INFO: Train epoch 335: [44800/94637 (47%)] Step: [1984326] | Lr: 0.000100 | Loss: 1.7133 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 79.88
24-04-01 19:10:46.236 - INFO: Train epoch 335: [46400/94637 (49%)] Step: [1984426] | Lr: 0.000100 | Loss: 1.6202 | MSE loss: 0.0005 | Bpp loss: 0.73 | Aux loss: 84.41
24-04-01 19:11:16.158 - INFO: Train epoch 335: [48000/94637 (51%)] Step: [1984526] | Lr: 0.000100 | Loss: 1.1374 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 78.29
24-04-01 19:11:45.332 - INFO: Train epoch 335: [49600/94637 (52%)] Step: [1984626] | Lr: 0.000100 | Loss: 1.7861 | MSE loss: 0.0005 | Bpp loss: 1.02 | Aux loss: 85.78
24-04-01 19:12:15.140 - INFO: Train epoch 335: [51200/94637 (54%)] Step: [1984726] | Lr: 0.000100 | Loss: 0.9297 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 84.31
24-04-01 19:12:44.103 - INFO: Train epoch 335: [52800/94637 (56%)] Step: [1984826] | Lr: 0.000100 | Loss: 1.0605 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 82.92
24-04-01 19:13:13.510 - INFO: Train epoch 335: [54400/94637 (57%)] Step: [1984926] | Lr: 0.000100 | Loss: 1.0239 | MSE loss: 0.0003 | Bpp loss: 0.56 | Aux loss: 85.56
24-04-01 19:13:44.692 - INFO: Train epoch 335: [56000/94637 (59%)] Step: [1985026] | Lr: 0.000100 | Loss: 1.2049 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 83.31
24-04-01 19:14:13.848 - INFO: Train epoch 335: [57600/94637 (61%)] Step: [1985126] | Lr: 0.000100 | Loss: 1.2663 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 83.35
24-04-01 19:14:43.223 - INFO: Train epoch 335: [59200/94637 (63%)] Step: [1985226] | Lr: 0.000100 | Loss: 0.9477 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 81.77
24-04-01 19:15:12.277 - INFO: Train epoch 335: [60800/94637 (64%)] Step: [1985326] | Lr: 0.000100 | Loss: 1.5844 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 79.23
24-04-01 19:15:41.262 - INFO: Train epoch 335: [62400/94637 (66%)] Step: [1985426] | Lr: 0.000100 | Loss: 1.4143 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 86.96
24-04-01 19:16:09.773 - INFO: Train epoch 335: [64000/94637 (68%)] Step: [1985526] | Lr: 0.000100 | Loss: 1.4781 | MSE loss: 0.0004 | Bpp loss: 0.85 | Aux loss: 83.48
24-04-01 19:16:38.784 - INFO: Train epoch 335: [65600/94637 (69%)] Step: [1985626] | Lr: 0.000100 | Loss: 1.3820 | MSE loss: 0.0003 | Bpp loss: 0.89 | Aux loss: 75.68
24-04-01 19:17:07.726 - INFO: Train epoch 335: [67200/94637 (71%)] Step: [1985726] | Lr: 0.000100 | Loss: 1.5684 | MSE loss: 0.0005 | Bpp loss: 0.73 | Aux loss: 77.72
24-04-01 19:17:36.982 - INFO: Train epoch 335: [68800/94637 (73%)] Step: [1985826] | Lr: 0.000100 | Loss: 0.9391 | MSE loss: 0.0002 | Bpp loss: 0.57 | Aux loss: 79.84
24-04-01 19:18:06.398 - INFO: Train epoch 335: [70400/94637 (74%)] Step: [1985926] | Lr: 0.000100 | Loss: 1.4413 | MSE loss: 0.0004 | Bpp loss: 0.87 | Aux loss: 88.98
24-04-01 19:18:35.894 - INFO: Train epoch 335: [72000/94637 (76%)] Step: [1986026] | Lr: 0.000100 | Loss: 0.7123 | MSE loss: 0.0002 | Bpp loss: 0.38 | Aux loss: 84.88
24-04-01 19:19:04.904 - INFO: Train epoch 335: [73600/94637 (78%)] Step: [1986126] | Lr: 0.000100 | Loss: 1.3937 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 84.00
24-04-01 19:19:34.075 - INFO: Train epoch 335: [75200/94637 (79%)] Step: [1986226] | Lr: 0.000100 | Loss: 1.5146 | MSE loss: 0.0004 | Bpp loss: 0.93 | Aux loss: 80.79
24-04-01 19:20:02.851 - INFO: Train epoch 335: [76800/94637 (81%)] Step: [1986326] | Lr: 0.000100 | Loss: 1.0248 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 85.27
24-04-01 19:20:31.787 - INFO: Train epoch 335: [78400/94637 (83%)] Step: [1986426] | Lr: 0.000100 | Loss: 1.2312 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 86.93
24-04-01 19:21:01.154 - INFO: Train epoch 335: [80000/94637 (85%)] Step: [1986526] | Lr: 0.000100 | Loss: 1.3120 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 80.04
24-04-01 19:21:30.679 - INFO: Train epoch 335: [81600/94637 (86%)] Step: [1986626] | Lr: 0.000100 | Loss: 1.3684 | MSE loss: 0.0003 | Bpp loss: 0.86 | Aux loss: 85.08
24-04-01 19:22:00.150 - INFO: Train epoch 335: [83200/94637 (88%)] Step: [1986726] | Lr: 0.000100 | Loss: 1.7959 | MSE loss: 0.0004 | Bpp loss: 1.12 | Aux loss: 81.53
24-04-01 19:22:29.875 - INFO: Train epoch 335: [84800/94637 (90%)] Step: [1986826] | Lr: 0.000100 | Loss: 1.5351 | MSE loss: 0.0004 | Bpp loss: 0.89 | Aux loss: 88.72
24-04-01 19:22:59.843 - INFO: Train epoch 335: [86400/94637 (91%)] Step: [1986926] | Lr: 0.000100 | Loss: 1.2085 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 81.95
24-04-01 19:23:29.311 - INFO: Train epoch 335: [88000/94637 (93%)] Step: [1987026] | Lr: 0.000100 | Loss: 1.6678 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 84.59
24-04-01 19:23:59.230 - INFO: Train epoch 335: [89600/94637 (95%)] Step: [1987126] | Lr: 0.000100 | Loss: 1.0012 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 77.13
24-04-01 19:24:29.414 - INFO: Train epoch 335: [91200/94637 (96%)] Step: [1987226] | Lr: 0.000100 | Loss: 1.0631 | MSE loss: 0.0002 | Bpp loss: 0.67 | Aux loss: 78.09
24-04-01 19:24:59.376 - INFO: Train epoch 335: [92800/94637 (98%)] Step: [1987326] | Lr: 0.000100 | Loss: 1.1193 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 79.49
24-04-01 19:25:29.270 - INFO: Train epoch 335: [94400/94637 (100%)] Step: [1987426] | Lr: 0.000100 | Loss: 0.9746 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 78.45
24-04-01 19:25:45.018 - INFO: Learning rate: 0.0001
24-04-01 19:25:45.775 - INFO: Train epoch 336: [    0/94637 (0%)] Step: [1987441] | Lr: 0.000100 | Loss: 0.8384 | MSE loss: 0.0002 | Bpp loss: 0.49 | Aux loss: 77.15
24-04-01 19:26:17.622 - INFO: Train epoch 336: [ 1600/94637 (2%)] Step: [1987541] | Lr: 0.000100 | Loss: 1.3208 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 80.88
24-04-01 19:26:46.337 - INFO: Train epoch 336: [ 3200/94637 (3%)] Step: [1987641] | Lr: 0.000100 | Loss: 1.1445 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 85.88
24-04-01 19:27:14.916 - INFO: Train epoch 336: [ 4800/94637 (5%)] Step: [1987741] | Lr: 0.000100 | Loss: 0.9849 | MSE loss: 0.0002 | Bpp loss: 0.64 | Aux loss: 78.35
24-04-01 19:27:43.205 - INFO: Train epoch 336: [ 6400/94637 (7%)] Step: [1987841] | Lr: 0.000100 | Loss: 1.4263 | MSE loss: 0.0003 | Bpp loss: 0.91 | Aux loss: 79.44
24-04-01 19:28:12.242 - INFO: Train epoch 336: [ 8000/94637 (8%)] Step: [1987941] | Lr: 0.000100 | Loss: 1.5019 | MSE loss: 0.0004 | Bpp loss: 0.93 | Aux loss: 81.78
24-04-01 19:28:40.673 - INFO: Train epoch 336: [ 9600/94637 (10%)] Step: [1988041] | Lr: 0.000100 | Loss: 1.2215 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 77.79
24-04-01 19:29:09.255 - INFO: Train epoch 336: [11200/94637 (12%)] Step: [1988141] | Lr: 0.000100 | Loss: 1.4626 | MSE loss: 0.0004 | Bpp loss: 0.88 | Aux loss: 78.70
24-04-01 19:29:38.006 - INFO: Train epoch 336: [12800/94637 (14%)] Step: [1988241] | Lr: 0.000100 | Loss: 1.0415 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 78.05
24-04-01 19:30:06.502 - INFO: Train epoch 336: [14400/94637 (15%)] Step: [1988341] | Lr: 0.000100 | Loss: 1.2841 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 78.08
24-04-01 19:30:35.587 - INFO: Train epoch 336: [16000/94637 (17%)] Step: [1988441] | Lr: 0.000100 | Loss: 1.6354 | MSE loss: 0.0004 | Bpp loss: 1.03 | Aux loss: 75.88
24-04-01 19:31:04.770 - INFO: Train epoch 336: [17600/94637 (19%)] Step: [1988541] | Lr: 0.000100 | Loss: 1.3520 | MSE loss: 0.0004 | Bpp loss: 0.74 | Aux loss: 79.72
24-04-01 19:31:33.490 - INFO: Train epoch 336: [19200/94637 (20%)] Step: [1988641] | Lr: 0.000100 | Loss: 2.3744 | MSE loss: 0.0006 | Bpp loss: 1.34 | Aux loss: 79.73
24-04-01 19:32:02.806 - INFO: Train epoch 336: [20800/94637 (22%)] Step: [1988741] | Lr: 0.000100 | Loss: 1.6628 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 79.24
24-04-01 19:32:32.186 - INFO: Train epoch 336: [22400/94637 (24%)] Step: [1988841] | Lr: 0.000100 | Loss: 1.1417 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 83.24
24-04-01 19:33:01.291 - INFO: Train epoch 336: [24000/94637 (25%)] Step: [1988941] | Lr: 0.000100 | Loss: 1.5915 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 78.70
24-04-01 19:33:30.447 - INFO: Train epoch 336: [25600/94637 (27%)] Step: [1989041] | Lr: 0.000100 | Loss: 1.3775 | MSE loss: 0.0004 | Bpp loss: 0.77 | Aux loss: 77.92
24-04-01 19:33:59.332 - INFO: Train epoch 336: [27200/94637 (29%)] Step: [1989141] | Lr: 0.000100 | Loss: 1.2807 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 80.35
24-04-01 19:34:28.480 - INFO: Train epoch 336: [28800/94637 (30%)] Step: [1989241] | Lr: 0.000100 | Loss: 1.5340 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 79.88
24-04-01 19:34:57.230 - INFO: Train epoch 336: [30400/94637 (32%)] Step: [1989341] | Lr: 0.000100 | Loss: 0.9560 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 79.41
24-04-01 19:35:26.242 - INFO: Train epoch 336: [32000/94637 (34%)] Step: [1989441] | Lr: 0.000100 | Loss: 1.0343 | MSE loss: 0.0003 | Bpp loss: 0.62 | Aux loss: 75.14
24-04-01 19:35:54.759 - INFO: Train epoch 336: [33600/94637 (36%)] Step: [1989541] | Lr: 0.000100 | Loss: 1.3181 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 74.75
24-04-01 19:36:22.984 - INFO: Train epoch 336: [35200/94637 (37%)] Step: [1989641] | Lr: 0.000100 | Loss: 3.2412 | MSE loss: 0.0010 | Bpp loss: 1.61 | Aux loss: 80.10
24-04-01 19:36:51.616 - INFO: Train epoch 336: [36800/94637 (39%)] Step: [1989741] | Lr: 0.000100 | Loss: 0.8382 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 81.10
24-04-01 19:37:20.220 - INFO: Train epoch 336: [38400/94637 (41%)] Step: [1989841] | Lr: 0.000100 | Loss: 1.2367 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 79.11
24-04-01 19:37:48.415 - INFO: Train epoch 336: [40000/94637 (42%)] Step: [1989941] | Lr: 0.000100 | Loss: 1.1858 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 81.29
24-04-01 19:38:19.023 - INFO: Train epoch 336: [41600/94637 (44%)] Step: [1990041] | Lr: 0.000100 | Loss: 2.3948 | MSE loss: 0.0008 | Bpp loss: 1.06 | Aux loss: 83.60
24-04-01 19:38:47.409 - INFO: Train epoch 336: [43200/94637 (46%)] Step: [1990141] | Lr: 0.000100 | Loss: 0.9927 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 83.32
24-04-01 19:39:15.974 - INFO: Train epoch 336: [44800/94637 (47%)] Step: [1990241] | Lr: 0.000100 | Loss: 1.5227 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 79.26
24-04-01 19:39:44.610 - INFO: Train epoch 336: [46400/94637 (49%)] Step: [1990341] | Lr: 0.000100 | Loss: 1.8244 | MSE loss: 0.0005 | Bpp loss: 1.09 | Aux loss: 77.52
24-04-01 19:40:12.987 - INFO: Train epoch 336: [48000/94637 (51%)] Step: [1990441] | Lr: 0.000100 | Loss: 1.6126 | MSE loss: 0.0004 | Bpp loss: 0.95 | Aux loss: 77.86
24-04-01 19:40:40.969 - INFO: Train epoch 336: [49600/94637 (52%)] Step: [1990541] | Lr: 0.000100 | Loss: 1.2173 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 79.80
24-04-01 19:41:09.352 - INFO: Train epoch 336: [51200/94637 (54%)] Step: [1990641] | Lr: 0.000100 | Loss: 0.9466 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 78.32
24-04-01 19:41:38.886 - INFO: Train epoch 336: [52800/94637 (56%)] Step: [1990741] | Lr: 0.000100 | Loss: 1.1782 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 77.08
24-04-01 19:42:06.999 - INFO: Train epoch 336: [54400/94637 (57%)] Step: [1990841] | Lr: 0.000100 | Loss: 0.9322 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 78.64
24-04-01 19:42:35.033 - INFO: Train epoch 336: [56000/94637 (59%)] Step: [1990941] | Lr: 0.000100 | Loss: 0.5516 | MSE loss: 0.0001 | Bpp loss: 0.37 | Aux loss: 80.88
24-04-01 19:43:03.189 - INFO: Train epoch 336: [57600/94637 (61%)] Step: [1991041] | Lr: 0.000100 | Loss: 1.1409 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 79.89
24-04-01 19:43:31.475 - INFO: Train epoch 336: [59200/94637 (63%)] Step: [1991141] | Lr: 0.000100 | Loss: 1.5957 | MSE loss: 0.0003 | Bpp loss: 1.03 | Aux loss: 85.71
24-04-01 19:43:59.219 - INFO: Train epoch 336: [60800/94637 (64%)] Step: [1991241] | Lr: 0.000100 | Loss: 1.2532 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 84.44
24-04-01 19:44:27.552 - INFO: Train epoch 336: [62400/94637 (66%)] Step: [1991341] | Lr: 0.000100 | Loss: 1.1172 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 79.74
24-04-01 19:44:55.960 - INFO: Train epoch 336: [64000/94637 (68%)] Step: [1991441] | Lr: 0.000100 | Loss: 0.9138 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 85.54
24-04-01 19:45:24.663 - INFO: Train epoch 336: [65600/94637 (69%)] Step: [1991541] | Lr: 0.000100 | Loss: 1.0366 | MSE loss: 0.0003 | Bpp loss: 0.58 | Aux loss: 84.78
24-04-01 19:45:53.027 - INFO: Train epoch 336: [67200/94637 (71%)] Step: [1991641] | Lr: 0.000100 | Loss: 1.0975 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 80.37
24-04-01 19:46:21.526 - INFO: Train epoch 336: [68800/94637 (73%)] Step: [1991741] | Lr: 0.000100 | Loss: 1.2545 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 80.87
24-04-01 19:46:50.173 - INFO: Train epoch 336: [70400/94637 (74%)] Step: [1991841] | Lr: 0.000100 | Loss: 1.1455 | MSE loss: 0.0002 | Bpp loss: 0.77 | Aux loss: 86.65
24-04-01 19:47:19.791 - INFO: Train epoch 336: [72000/94637 (76%)] Step: [1991941] | Lr: 0.000100 | Loss: 1.3531 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 85.40
24-04-01 19:47:49.559 - INFO: Train epoch 336: [73600/94637 (78%)] Step: [1992041] | Lr: 0.000100 | Loss: 0.8293 | MSE loss: 0.0002 | Bpp loss: 0.50 | Aux loss: 77.43
24-04-01 19:48:18.957 - INFO: Train epoch 336: [75200/94637 (79%)] Step: [1992141] | Lr: 0.000100 | Loss: 1.2028 | MSE loss: 0.0003 | Bpp loss: 0.76 | Aux loss: 82.00
24-04-01 19:48:47.336 - INFO: Train epoch 336: [76800/94637 (81%)] Step: [1992241] | Lr: 0.000100 | Loss: 1.6022 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 85.80
24-04-01 19:49:15.690 - INFO: Train epoch 336: [78400/94637 (83%)] Step: [1992341] | Lr: 0.000100 | Loss: 1.2679 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 76.76
24-04-01 19:49:44.097 - INFO: Train epoch 336: [80000/94637 (85%)] Step: [1992441] | Lr: 0.000100 | Loss: 1.7784 | MSE loss: 0.0005 | Bpp loss: 1.04 | Aux loss: 83.08
24-04-01 19:50:14.090 - INFO: Train epoch 336: [81600/94637 (86%)] Step: [1992541] | Lr: 0.000100 | Loss: 1.8255 | MSE loss: 0.0006 | Bpp loss: 0.90 | Aux loss: 84.83
24-04-01 19:50:42.755 - INFO: Train epoch 336: [83200/94637 (88%)] Step: [1992641] | Lr: 0.000100 | Loss: 1.2683 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 85.72
24-04-01 19:51:10.821 - INFO: Train epoch 336: [84800/94637 (90%)] Step: [1992741] | Lr: 0.000100 | Loss: 2.0364 | MSE loss: 0.0004 | Bpp loss: 1.31 | Aux loss: 82.10
24-04-01 19:51:39.764 - INFO: Train epoch 336: [86400/94637 (91%)] Step: [1992841] | Lr: 0.000100 | Loss: 1.1671 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 86.08
24-04-01 19:52:07.894 - INFO: Train epoch 336: [88000/94637 (93%)] Step: [1992941] | Lr: 0.000100 | Loss: 1.4700 | MSE loss: 0.0005 | Bpp loss: 0.64 | Aux loss: 84.35
24-04-01 19:52:36.002 - INFO: Train epoch 336: [89600/94637 (95%)] Step: [1993041] | Lr: 0.000100 | Loss: 1.5291 | MSE loss: 0.0004 | Bpp loss: 0.86 | Aux loss: 77.66
24-04-01 19:53:05.000 - INFO: Train epoch 336: [91200/94637 (96%)] Step: [1993141] | Lr: 0.000100 | Loss: 1.0284 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 81.38
24-04-01 19:53:33.464 - INFO: Train epoch 336: [92800/94637 (98%)] Step: [1993241] | Lr: 0.000100 | Loss: 1.0359 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 82.61
24-04-01 19:54:02.003 - INFO: Train epoch 336: [94400/94637 (100%)] Step: [1993341] | Lr: 0.000100 | Loss: 1.4200 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 80.55
24-04-01 19:54:17.559 - INFO: Learning rate: 0.0001
24-04-01 19:54:18.343 - INFO: Train epoch 337: [    0/94637 (0%)] Step: [1993356] | Lr: 0.000100 | Loss: 1.3166 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 82.06
24-04-01 19:54:46.765 - INFO: Train epoch 337: [ 1600/94637 (2%)] Step: [1993456] | Lr: 0.000100 | Loss: 0.9695 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 83.16
24-04-01 19:55:15.611 - INFO: Train epoch 337: [ 3200/94637 (3%)] Step: [1993556] | Lr: 0.000100 | Loss: 1.1200 | MSE loss: 0.0003 | Bpp loss: 0.69 | Aux loss: 81.05
24-04-01 19:55:44.174 - INFO: Train epoch 337: [ 4800/94637 (5%)] Step: [1993656] | Lr: 0.000100 | Loss: 1.3291 | MSE loss: 0.0003 | Bpp loss: 0.84 | Aux loss: 78.45
24-04-01 19:56:12.971 - INFO: Train epoch 337: [ 6400/94637 (7%)] Step: [1993756] | Lr: 0.000100 | Loss: 1.9589 | MSE loss: 0.0005 | Bpp loss: 1.17 | Aux loss: 81.63
24-04-01 19:56:41.662 - INFO: Train epoch 337: [ 8000/94637 (8%)] Step: [1993856] | Lr: 0.000100 | Loss: 1.1519 | MSE loss: 0.0003 | Bpp loss: 0.65 | Aux loss: 75.23
24-04-01 19:57:10.413 - INFO: Train epoch 337: [ 9600/94637 (10%)] Step: [1993956] | Lr: 0.000100 | Loss: 1.1754 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 84.20
24-04-01 19:57:38.752 - INFO: Train epoch 337: [11200/94637 (12%)] Step: [1994056] | Lr: 0.000100 | Loss: 2.3030 | MSE loss: 0.0007 | Bpp loss: 1.22 | Aux loss: 77.27
24-04-01 19:58:07.245 - INFO: Train epoch 337: [12800/94637 (14%)] Step: [1994156] | Lr: 0.000100 | Loss: 1.2851 | MSE loss: 0.0003 | Bpp loss: 0.77 | Aux loss: 80.09
24-04-01 19:58:35.527 - INFO: Train epoch 337: [14400/94637 (15%)] Step: [1994256] | Lr: 0.000100 | Loss: 0.8384 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 81.28
24-04-01 19:59:04.544 - INFO: Train epoch 337: [16000/94637 (17%)] Step: [1994356] | Lr: 0.000100 | Loss: 1.0753 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 80.84
24-04-01 19:59:32.950 - INFO: Train epoch 337: [17600/94637 (19%)] Step: [1994456] | Lr: 0.000100 | Loss: 1.5489 | MSE loss: 0.0004 | Bpp loss: 0.88 | Aux loss: 79.45
24-04-01 20:00:01.027 - INFO: Train epoch 337: [19200/94637 (20%)] Step: [1994556] | Lr: 0.000100 | Loss: 0.7089 | MSE loss: 0.0001 | Bpp loss: 0.47 | Aux loss: 80.29
24-04-01 20:00:29.252 - INFO: Train epoch 337: [20800/94637 (22%)] Step: [1994656] | Lr: 0.000100 | Loss: 1.1126 | MSE loss: 0.0002 | Bpp loss: 0.71 | Aux loss: 84.06
24-04-01 20:00:57.551 - INFO: Train epoch 337: [22400/94637 (24%)] Step: [1994756] | Lr: 0.000100 | Loss: 2.0453 | MSE loss: 0.0006 | Bpp loss: 1.13 | Aux loss: 85.81
24-04-01 20:01:26.864 - INFO: Train epoch 337: [24000/94637 (25%)] Step: [1994856] | Lr: 0.000100 | Loss: 1.7976 | MSE loss: 0.0004 | Bpp loss: 1.08 | Aux loss: 79.78
24-04-01 20:01:56.055 - INFO: Train epoch 337: [25600/94637 (27%)] Step: [1994956] | Lr: 0.000100 | Loss: 0.9530 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 78.23
24-04-01 20:02:28.099 - INFO: Train epoch 337: [27200/94637 (29%)] Step: [1995056] | Lr: 0.000100 | Loss: 1.3323 | MSE loss: 0.0003 | Bpp loss: 0.81 | Aux loss: 82.48
24-04-01 20:02:57.551 - INFO: Train epoch 337: [28800/94637 (30%)] Step: [1995156] | Lr: 0.000100 | Loss: 1.7733 | MSE loss: 0.0004 | Bpp loss: 1.07 | Aux loss: 80.01
24-04-01 20:03:26.868 - INFO: Train epoch 337: [30400/94637 (32%)] Step: [1995256] | Lr: 0.000100 | Loss: 1.7537 | MSE loss: 0.0004 | Bpp loss: 1.05 | Aux loss: 83.89
24-04-01 20:03:56.285 - INFO: Train epoch 337: [32000/94637 (34%)] Step: [1995356] | Lr: 0.000100 | Loss: 0.9502 | MSE loss: 0.0002 | Bpp loss: 0.61 | Aux loss: 81.04
24-04-01 20:04:25.372 - INFO: Train epoch 337: [33600/94637 (36%)] Step: [1995456] | Lr: 0.000100 | Loss: 2.1462 | MSE loss: 0.0006 | Bpp loss: 1.20 | Aux loss: 74.60
24-04-01 20:04:54.314 - INFO: Train epoch 337: [35200/94637 (37%)] Step: [1995556] | Lr: 0.000100 | Loss: 0.9550 | MSE loss: 0.0002 | Bpp loss: 0.56 | Aux loss: 77.61
24-04-01 20:05:22.577 - INFO: Train epoch 337: [36800/94637 (39%)] Step: [1995656] | Lr: 0.000100 | Loss: 1.4392 | MSE loss: 0.0003 | Bpp loss: 0.93 | Aux loss: 84.62
24-04-01 20:05:50.929 - INFO: Train epoch 337: [38400/94637 (41%)] Step: [1995756] | Lr: 0.000100 | Loss: 1.8752 | MSE loss: 0.0005 | Bpp loss: 1.06 | Aux loss: 80.36
24-04-01 20:06:19.334 - INFO: Train epoch 337: [40000/94637 (42%)] Step: [1995856] | Lr: 0.000100 | Loss: 0.6596 | MSE loss: 0.0002 | Bpp loss: 0.40 | Aux loss: 77.45
24-04-01 20:06:48.281 - INFO: Train epoch 337: [41600/94637 (44%)] Step: [1995956] | Lr: 0.000100 | Loss: 0.8110 | MSE loss: 0.0002 | Bpp loss: 0.51 | Aux loss: 83.16
24-04-01 20:07:16.593 - INFO: Train epoch 337: [43200/94637 (46%)] Step: [1996056] | Lr: 0.000100 | Loss: 1.5562 | MSE loss: 0.0004 | Bpp loss: 0.99 | Aux loss: 80.94
24-04-01 20:07:45.567 - INFO: Train epoch 337: [44800/94637 (47%)] Step: [1996156] | Lr: 0.000100 | Loss: 1.5219 | MSE loss: 0.0003 | Bpp loss: 1.00 | Aux loss: 88.22
24-04-01 20:08:13.869 - INFO: Train epoch 337: [46400/94637 (49%)] Step: [1996256] | Lr: 0.000100 | Loss: 1.4563 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 83.90
24-04-01 20:08:42.005 - INFO: Train epoch 337: [48000/94637 (51%)] Step: [1996356] | Lr: 0.000100 | Loss: 0.8489 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 81.63
24-04-01 20:09:10.410 - INFO: Train epoch 337: [49600/94637 (52%)] Step: [1996456] | Lr: 0.000100 | Loss: 1.6519 | MSE loss: 0.0004 | Bpp loss: 0.94 | Aux loss: 79.28
24-04-01 20:09:39.249 - INFO: Train epoch 337: [51200/94637 (54%)] Step: [1996556] | Lr: 0.000100 | Loss: 1.1374 | MSE loss: 0.0003 | Bpp loss: 0.73 | Aux loss: 78.82
24-04-01 20:10:07.297 - INFO: Train epoch 337: [52800/94637 (56%)] Step: [1996656] | Lr: 0.000100 | Loss: 1.1489 | MSE loss: 0.0003 | Bpp loss: 0.70 | Aux loss: 80.16
24-04-01 20:10:35.791 - INFO: Train epoch 337: [54400/94637 (57%)] Step: [1996756] | Lr: 0.000100 | Loss: 0.7374 | MSE loss: 0.0001 | Bpp loss: 0.51 | Aux loss: 82.95
24-04-01 20:11:04.059 - INFO: Train epoch 337: [56000/94637 (59%)] Step: [1996856] | Lr: 0.000100 | Loss: 1.1775 | MSE loss: 0.0003 | Bpp loss: 0.75 | Aux loss: 84.70
24-04-01 20:11:32.820 - INFO: Train epoch 337: [57600/94637 (61%)] Step: [1996956] | Lr: 0.000100 | Loss: 1.4557 | MSE loss: 0.0003 | Bpp loss: 0.90 | Aux loss: 85.11
24-04-01 20:12:01.070 - INFO: Train epoch 337: [59200/94637 (63%)] Step: [1997056] | Lr: 0.000100 | Loss: 1.5384 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 76.97
24-04-01 20:12:29.298 - INFO: Train epoch 337: [60800/94637 (64%)] Step: [1997156] | Lr: 0.000100 | Loss: 0.8356 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 84.34
24-04-01 20:12:57.565 - INFO: Train epoch 337: [62400/94637 (66%)] Step: [1997256] | Lr: 0.000100 | Loss: 1.7595 | MSE loss: 0.0004 | Bpp loss: 1.06 | Aux loss: 83.64
24-04-01 20:13:25.746 - INFO: Train epoch 337: [64000/94637 (68%)] Step: [1997356] | Lr: 0.000100 | Loss: 0.7243 | MSE loss: 0.0002 | Bpp loss: 0.42 | Aux loss: 81.70
24-04-01 20:13:53.716 - INFO: Train epoch 337: [65600/94637 (69%)] Step: [1997456] | Lr: 0.000100 | Loss: 1.8296 | MSE loss: 0.0004 | Bpp loss: 1.15 | Aux loss: 76.76
24-04-01 20:14:23.967 - INFO: Train epoch 337: [67200/94637 (71%)] Step: [1997556] | Lr: 0.000100 | Loss: 1.0396 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 82.57
24-04-01 20:14:52.891 - INFO: Train epoch 337: [68800/94637 (73%)] Step: [1997656] | Lr: 0.000100 | Loss: 1.0996 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 84.16
24-04-01 20:15:20.959 - INFO: Train epoch 337: [70400/94637 (74%)] Step: [1997756] | Lr: 0.000100 | Loss: 0.6960 | MSE loss: 0.0002 | Bpp loss: 0.43 | Aux loss: 83.76
24-04-01 20:15:49.610 - INFO: Train epoch 337: [72000/94637 (76%)] Step: [1997856] | Lr: 0.000100 | Loss: 2.1975 | MSE loss: 0.0007 | Bpp loss: 1.12 | Aux loss: 81.74
24-04-01 20:16:18.428 - INFO: Train epoch 337: [73600/94637 (78%)] Step: [1997956] | Lr: 0.000100 | Loss: 0.8357 | MSE loss: 0.0002 | Bpp loss: 0.53 | Aux loss: 82.46
24-04-01 20:16:47.365 - INFO: Train epoch 337: [75200/94637 (79%)] Step: [1998056] | Lr: 0.000100 | Loss: 1.2128 | MSE loss: 0.0003 | Bpp loss: 0.74 | Aux loss: 78.63
24-04-01 20:17:16.185 - INFO: Train epoch 337: [76800/94637 (81%)] Step: [1998156] | Lr: 0.000100 | Loss: 0.9307 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 72.77
24-04-01 20:17:45.459 - INFO: Train epoch 337: [78400/94637 (83%)] Step: [1998256] | Lr: 0.000100 | Loss: 0.8169 | MSE loss: 0.0002 | Bpp loss: 0.54 | Aux loss: 81.36
24-04-01 20:18:14.427 - INFO: Train epoch 337: [80000/94637 (85%)] Step: [1998356] | Lr: 0.000100 | Loss: 1.3199 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 84.09
24-04-01 20:18:43.222 - INFO: Train epoch 337: [81600/94637 (86%)] Step: [1998456] | Lr: 0.000100 | Loss: 1.2993 | MSE loss: 0.0003 | Bpp loss: 0.83 | Aux loss: 76.66
24-04-01 20:19:11.826 - INFO: Train epoch 337: [83200/94637 (88%)] Step: [1998556] | Lr: 0.000100 | Loss: 1.7387 | MSE loss: 0.0004 | Bpp loss: 1.05 | Aux loss: 76.83
24-04-01 20:19:40.078 - INFO: Train epoch 337: [84800/94637 (90%)] Step: [1998656] | Lr: 0.000100 | Loss: 1.0731 | MSE loss: 0.0003 | Bpp loss: 0.66 | Aux loss: 85.04
24-04-01 20:20:08.355 - INFO: Train epoch 337: [86400/94637 (91%)] Step: [1998756] | Lr: 0.000100 | Loss: 0.9648 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 86.85
24-04-01 20:20:36.808 - INFO: Train epoch 337: [88000/94637 (93%)] Step: [1998856] | Lr: 0.000100 | Loss: 1.0206 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 73.87
24-04-01 20:21:05.238 - INFO: Train epoch 337: [89600/94637 (95%)] Step: [1998956] | Lr: 0.000100 | Loss: 1.3384 | MSE loss: 0.0003 | Bpp loss: 0.79 | Aux loss: 75.83
24-04-01 20:21:33.810 - INFO: Train epoch 337: [91200/94637 (96%)] Step: [1999056] | Lr: 0.000100 | Loss: 1.6407 | MSE loss: 0.0004 | Bpp loss: 1.00 | Aux loss: 76.67
24-04-01 20:22:02.423 - INFO: Train epoch 337: [92800/94637 (98%)] Step: [1999156] | Lr: 0.000100 | Loss: 1.0117 | MSE loss: 0.0002 | Bpp loss: 0.62 | Aux loss: 78.87
24-04-01 20:22:31.178 - INFO: Train epoch 337: [94400/94637 (100%)] Step: [1999256] | Lr: 0.000100 | Loss: 1.0827 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 70.01
24-04-01 20:22:51.937 - INFO: Learning rate: 0.0001
24-04-01 20:22:52.679 - INFO: Train epoch 338: [    0/94637 (0%)] Step: [1999271] | Lr: 0.000100 | Loss: 1.7454 | MSE loss: 0.0004 | Bpp loss: 1.09 | Aux loss: 73.02
24-04-01 20:23:21.496 - INFO: Train epoch 338: [ 1600/94637 (2%)] Step: [1999371] | Lr: 0.000100 | Loss: 1.5999 | MSE loss: 0.0004 | Bpp loss: 0.96 | Aux loss: 70.63
24-04-01 20:23:49.832 - INFO: Train epoch 338: [ 3200/94637 (3%)] Step: [1999471] | Lr: 0.000100 | Loss: 2.0572 | MSE loss: 0.0005 | Bpp loss: 1.22 | Aux loss: 81.71
24-04-01 20:24:18.870 - INFO: Train epoch 338: [ 4800/94637 (5%)] Step: [1999571] | Lr: 0.000100 | Loss: 0.6066 | MSE loss: 0.0001 | Bpp loss: 0.40 | Aux loss: 78.83
24-04-01 20:24:47.145 - INFO: Train epoch 338: [ 6400/94637 (7%)] Step: [1999671] | Lr: 0.000100 | Loss: 1.3519 | MSE loss: 0.0003 | Bpp loss: 0.87 | Aux loss: 75.63
24-04-01 20:25:15.546 - INFO: Train epoch 338: [ 8000/94637 (8%)] Step: [1999771] | Lr: 0.000100 | Loss: 0.9812 | MSE loss: 0.0002 | Bpp loss: 0.60 | Aux loss: 69.72
24-04-01 20:25:43.937 - INFO: Train epoch 338: [ 9600/94637 (10%)] Step: [1999871] | Lr: 0.000100 | Loss: 1.1457 | MSE loss: 0.0003 | Bpp loss: 0.71 | Aux loss: 76.60
24-04-01 20:26:12.516 - INFO: Train epoch 338: [11200/94637 (12%)] Step: [1999971] | Lr: 0.000100 | Loss: 1.0382 | MSE loss: 0.0002 | Bpp loss: 0.65 | Aux loss: 78.42
24-04-01 20:26:43.073 - INFO: Train epoch 338: [12800/94637 (14%)] Step: [2000071] | Lr: 0.000100 | Loss: 1.2529 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 73.39
24-04-01 20:27:11.296 - INFO: Train epoch 338: [14400/94637 (15%)] Step: [2000171] | Lr: 0.000100 | Loss: 1.0678 | MSE loss: 0.0002 | Bpp loss: 0.68 | Aux loss: 78.06
24-04-01 20:27:39.571 - INFO: Train epoch 338: [16000/94637 (17%)] Step: [2000271] | Lr: 0.000100 | Loss: 0.8275 | MSE loss: 0.0002 | Bpp loss: 0.55 | Aux loss: 69.74
24-04-01 20:28:07.613 - INFO: Train epoch 338: [17600/94637 (19%)] Step: [2000371] | Lr: 0.000100 | Loss: 1.8571 | MSE loss: 0.0004 | Bpp loss: 1.14 | Aux loss: 76.10
24-04-01 20:28:36.040 - INFO: Train epoch 338: [19200/94637 (20%)] Step: [2000471] | Lr: 0.000100 | Loss: 1.3434 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 69.74
24-04-01 20:29:04.260 - INFO: Train epoch 338: [20800/94637 (22%)] Step: [2000571] | Lr: 0.000100 | Loss: 1.4435 | MSE loss: 0.0004 | Bpp loss: 0.85 | Aux loss: 78.58
24-04-01 20:29:32.282 - INFO: Train epoch 338: [22400/94637 (24%)] Step: [2000671] | Lr: 0.000100 | Loss: 1.2246 | MSE loss: 0.0003 | Bpp loss: 0.78 | Aux loss: 76.60
24-04-01 20:30:01.302 - INFO: Train epoch 338: [24000/94637 (25%)] Step: [2000771] | Lr: 0.000100 | Loss: 1.3527 | MSE loss: 0.0004 | Bpp loss: 0.77 | Aux loss: 76.62
24-04-01 20:30:29.378 - INFO: Train epoch 338: [25600/94637 (27%)] Step: [2000871] | Lr: 0.000100 | Loss: 1.0059 | MSE loss: 0.0002 | Bpp loss: 0.66 | Aux loss: 74.56
24-04-01 20:30:57.369 - INFO: Train epoch 338: [27200/94637 (29%)] Step: [2000971] | Lr: 0.000100 | Loss: 1.3010 | MSE loss: 0.0003 | Bpp loss: 0.82 | Aux loss: 74.27
24-04-01 20:31:25.832 - INFO: Train epoch 338: [28800/94637 (30%)] Step: [2001071] | Lr: 0.000100 | Loss: 1.1477 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 74.50
24-04-01 20:31:53.964 - INFO: Train epoch 338: [30400/94637 (32%)] Step: [2001171] | Lr: 0.000100 | Loss: 0.9021 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 80.04
24-04-01 20:32:22.317 - INFO: Train epoch 338: [32000/94637 (34%)] Step: [2001271] | Lr: 0.000100 | Loss: 1.9494 | MSE loss: 0.0006 | Bpp loss: 1.04 | Aux loss: 74.42
24-04-01 20:32:50.852 - INFO: Train epoch 338: [33600/94637 (36%)] Step: [2001371] | Lr: 0.000100 | Loss: 1.0619 | MSE loss: 0.0002 | Bpp loss: 0.70 | Aux loss: 75.00
24-04-01 20:33:19.523 - INFO: Train epoch 338: [35200/94637 (37%)] Step: [2001471] | Lr: 0.000100 | Loss: 1.1291 | MSE loss: 0.0003 | Bpp loss: 0.68 | Aux loss: 71.22
24-04-01 20:33:48.198 - INFO: Train epoch 338: [36800/94637 (39%)] Step: [2001571] | Lr: 0.000100 | Loss: 0.8855 | MSE loss: 0.0002 | Bpp loss: 0.58 | Aux loss: 72.60
24-04-01 20:34:16.577 - INFO: Train epoch 338: [38400/94637 (41%)] Step: [2001671] | Lr: 0.000100 | Loss: 1.1432 | MSE loss: 0.0002 | Bpp loss: 0.74 | Aux loss: 81.26
24-04-01 20:34:45.322 - INFO: Train epoch 338: [40000/94637 (42%)] Step: [2001771] | Lr: 0.000100 | Loss: 1.5791 | MSE loss: 0.0004 | Bpp loss: 0.92 | Aux loss: 73.00
24-04-01 20:35:13.775 - INFO: Train epoch 338: [41600/94637 (44%)] Step: [2001871] | Lr: 0.000100 | Loss: 1.4235 | MSE loss: 0.0004 | Bpp loss: 0.81 | Aux loss: 74.28
24-04-01 20:35:42.373 - INFO: Train epoch 338: [43200/94637 (46%)] Step: [2001971] | Lr: 0.000100 | Loss: 0.9387 | MSE loss: 0.0002 | Bpp loss: 0.59 | Aux loss: 72.95
24-04-01 20:36:10.834 - INFO: Train epoch 338: [44800/94637 (47%)] Step: [2002071] | Lr: 0.000100 | Loss: 1.0579 | MSE loss: 0.0003 | Bpp loss: 0.64 | Aux loss: 75.00
24-04-01 20:36:39.006 - INFO: Train epoch 338: [46400/94637 (49%)] Step: [2002171] | Lr: 0.000100 | Loss: 1.6099 | MSE loss: 0.0004 | Bpp loss: 0.98 | Aux loss: 78.89
24-04-01 20:37:07.359 - INFO: Train epoch 338: [48000/94637 (51%)] Step: [2002271] | Lr: 0.000100 | Loss: 1.4154 | MSE loss: 0.0003 | Bpp loss: 0.85 | Aux loss: 75.28
24-04-01 20:37:36.322 - INFO: Train epoch 338: [49600/94637 (52%)] Step: [2002371] | Lr: 0.000100 | Loss: 1.5202 | MSE loss: 0.0003 | Bpp loss: 0.95 | Aux loss: 82.16
24-04-01 20:38:04.699 - INFO: Train epoch 338: [51200/94637 (54%)] Step: [2002471] | Lr: 0.000100 | Loss: 1.6639 | MSE loss: 0.0004 | Bpp loss: 1.01 | Aux loss: 77.66
